==========================================
SLURM_JOB_ID = 22837494
SLURM_JOB_NODELIST = a01-20
TMPDIR = /tmp/SLURM_22837494
==========================================
/var/spool/slurm/d/job22837494/slurm_script: line 16: conda: command not found
/var/spool/slurm/d/job22837494/slurm_script: line 17: deactivate: command not found
  0%|          | 0/625 [00:00<?, ?it/s]  0%|          | 1/625 [00:01<12:07,  1.17s/it]  1%|          | 4/625 [00:01<02:41,  3.86it/s]  1%|          | 7/625 [00:01<01:27,  7.05it/s]  2%|▏         | 10/625 [00:01<00:58, 10.51it/s]  2%|▏         | 13/625 [00:01<00:43, 13.92it/s]  3%|▎         | 16/625 [00:01<00:35, 17.09it/s]  3%|▎         | 19/625 [00:01<00:30, 19.83it/s]  4%|▎         | 22/625 [00:01<00:27, 22.13it/s]  4%|▍         | 25/625 [00:02<00:25, 23.97it/s]  4%|▍         | 28/625 [00:02<00:23, 25.39it/s]  5%|▍         | 31/625 [00:02<00:22, 26.45it/s]  5%|▌         | 34/625 [00:02<00:21, 27.22it/s]  6%|▌         | 37/625 [00:02<00:21, 27.78it/s]  6%|▋         | 40/625 [00:02<00:20, 28.19it/s]  7%|▋         | 43/625 [00:02<00:20, 28.50it/s]  7%|▋         | 46/625 [00:02<00:20, 28.72it/s]  8%|▊         | 49/625 [00:02<00:19, 28.87it/s]  8%|▊         | 52/625 [00:02<00:19, 28.98it/s]  9%|▉         | 55/625 [00:03<00:19, 29.04it/s]  9%|▉         | 58/625 [00:03<00:19, 29.09it/s] 10%|▉         | 61/625 [00:03<00:19, 29.13it/s] 10%|█         | 64/625 [00:03<00:19, 29.15it/s] 11%|█         | 67/625 [00:03<00:19, 29.15it/s] 11%|█         | 70/625 [00:03<00:19, 29.17it/s] 12%|█▏        | 73/625 [00:03<00:18, 29.19it/s] 12%|█▏        | 76/625 [00:03<00:18, 29.18it/s] 13%|█▎        | 79/625 [00:03<00:18, 29.18it/s] 13%|█▎        | 82/625 [00:03<00:18, 29.15it/s] 14%|█▎        | 85/625 [00:04<00:18, 29.17it/s] 14%|█▍        | 88/625 [00:04<00:18, 29.18it/s] 15%|█▍        | 91/625 [00:04<00:18, 29.19it/s] 15%|█▌        | 94/625 [00:04<00:18, 29.21it/s] 16%|█▌        | 97/625 [00:04<00:18, 29.21it/s] 16%|█▌        | 100/625 [00:04<00:17, 29.21it/s] 16%|█▋        | 103/625 [00:04<00:17, 29.20it/s] 17%|█▋        | 106/625 [00:04<00:17, 29.19it/s] 17%|█▋        | 109/625 [00:04<00:17, 29.18it/s] 18%|█▊        | 112/625 [00:05<00:17, 29.16it/s] 18%|█▊        | 115/625 [00:05<00:17, 29.18it/s] 19%|█▉        | 118/625 [00:05<00:17, 29.19it/s] 19%|█▉        | 121/625 [00:05<00:17, 29.16it/s] 20%|█▉        | 124/625 [00:05<00:17, 29.17it/s] 20%|██        | 127/625 [00:05<00:17, 29.11it/s] 21%|██        | 130/625 [00:05<00:17, 29.10it/s] 21%|██▏       | 133/625 [00:05<00:16, 29.14it/s] 22%|██▏       | 136/625 [00:05<00:16, 29.16it/s] 22%|██▏       | 139/625 [00:05<00:16, 29.19it/s] 23%|██▎       | 142/625 [00:06<00:16, 29.19it/s] 23%|██▎       | 145/625 [00:06<00:16, 29.18it/s] 24%|██▎       | 148/625 [00:06<00:16, 29.19it/s] 24%|██▍       | 151/625 [00:06<00:16, 29.24it/s] 25%|██▍       | 154/625 [00:06<00:16, 29.29it/s] 25%|██▌       | 157/625 [00:06<00:15, 29.29it/s] 26%|██▌       | 160/625 [00:06<00:15, 29.30it/s] 26%|██▌       | 163/625 [00:06<00:15, 29.32it/s] 27%|██▋       | 166/625 [00:06<00:15, 29.36it/s] 27%|██▋       | 169/625 [00:06<00:15, 29.41it/s] 28%|██▊       | 172/625 [00:07<00:15, 29.41it/s] 28%|██▊       | 175/625 [00:07<00:15, 29.40it/s] 28%|██▊       | 178/625 [00:07<00:15, 29.40it/s] 29%|██▉       | 181/625 [00:07<00:15, 29.40it/s] 29%|██▉       | 184/625 [00:07<00:15, 29.34it/s] 30%|██▉       | 187/625 [00:07<00:14, 29.33it/s] 30%|███       | 190/625 [00:07<00:14, 29.38it/s] 31%|███       | 193/625 [00:07<00:14, 29.36it/s] 31%|███▏      | 196/625 [00:07<00:14, 29.38it/s] 32%|███▏      | 199/625 [00:07<00:14, 29.38it/s] 32%|███▏      | 202/625 [00:08<00:14, 29.36it/s] 33%|███▎      | 205/625 [00:08<00:14, 29.36it/s] 33%|███▎      | 208/625 [00:08<00:14, 29.39it/s] 34%|███▍      | 211/625 [00:08<00:14, 29.42it/s] 34%|███▍      | 214/625 [00:08<00:13, 29.37it/s] 35%|███▍      | 217/625 [00:08<00:13, 29.36it/s] 35%|███▌      | 220/625 [00:08<00:13, 29.34it/s] 36%|███▌      | 223/625 [00:08<00:13, 29.33it/s] 36%|███▌      | 226/625 [00:08<00:13, 29.37it/s] 37%|███▋      | 229/625 [00:09<00:13, 29.41it/s] 37%|███▋      | 232/625 [00:09<00:13, 29.42it/s] 38%|███▊      | 235/625 [00:09<00:13, 29.43it/s] 38%|███▊      | 238/625 [00:09<00:13, 29.39it/s] 39%|███▊      | 241/625 [00:09<00:13, 29.40it/s] 39%|███▉      | 244/625 [00:09<00:12, 29.35it/s] 40%|███▉      | 247/625 [00:09<00:12, 29.35it/s] 40%|████      | 250/625 [00:09<00:12, 29.26it/s] 40%|████      | 253/625 [00:09<00:12, 29.32it/s] 41%|████      | 256/625 [00:09<00:12, 29.30it/s] 41%|████▏     | 259/625 [00:10<00:12, 29.33it/s] 42%|████▏     | 262/625 [00:10<00:12, 29.38it/s] 42%|████▏     | 265/625 [00:10<00:12, 29.42it/s] 43%|████▎     | 268/625 [00:10<00:12, 29.43it/s] 43%|████▎     | 271/625 [00:10<00:12, 29.43it/s] 44%|████▍     | 274/625 [00:10<00:11, 29.40it/s] 44%|████▍     | 277/625 [00:10<00:11, 29.35it/s] 45%|████▍     | 280/625 [00:10<00:11, 29.37it/s] 45%|████▌     | 283/625 [00:10<00:11, 29.33it/s] 46%|████▌     | 286/625 [00:10<00:11, 29.33it/s] 46%|████▌     | 289/625 [00:11<00:11, 29.35it/s] 47%|████▋     | 292/625 [00:11<00:11, 29.37it/s] 47%|████▋     | 295/625 [00:11<00:11, 29.39it/s] 48%|████▊     | 298/625 [00:11<00:11, 29.37it/s] 48%|████▊     | 301/625 [00:11<00:11, 29.36it/s] 49%|████▊     | 304/625 [00:11<00:10, 29.34it/s] 49%|████▉     | 307/625 [00:11<00:10, 29.38it/s] 50%|████▉     | 310/625 [00:11<00:10, 29.33it/s] 50%|█████     | 313/625 [00:11<00:10, 29.25it/s] 51%|█████     | 316/625 [00:11<00:10, 29.31it/s] 51%|█████     | 319/625 [00:12<00:10, 29.33it/s] 52%|█████▏    | 322/625 [00:12<00:10, 29.39it/s] 52%|█████▏    | 325/625 [00:12<00:10, 29.40it/s] 52%|█████▏    | 328/625 [00:12<00:10, 29.38it/s] 53%|█████▎    | 331/625 [00:12<00:10, 29.35it/s] 53%|█████▎    | 334/625 [00:12<00:09, 29.37it/s] 54%|█████▍    | 337/625 [00:12<00:09, 29.40it/s] 54%|█████▍    | 340/625 [00:12<00:09, 29.33it/s] 55%|█████▍    | 343/625 [00:12<00:09, 29.33it/s] 55%|█████▌    | 346/625 [00:13<00:09, 29.29it/s] 56%|█████▌    | 349/625 [00:13<00:09, 29.34it/s] 56%|█████▋    | 352/625 [00:13<00:09, 29.37it/s] 57%|█████▋    | 355/625 [00:13<00:09, 29.33it/s] 57%|█████▋    | 358/625 [00:13<00:09, 29.13it/s] 58%|█████▊    | 361/625 [00:13<00:09, 29.21it/s] 58%|█████▊    | 364/625 [00:13<00:08, 29.27it/s] 59%|█████▊    | 367/625 [00:13<00:08, 29.31it/s] 59%|█████▉    | 370/625 [00:13<00:08, 29.32it/s] 60%|█████▉    | 373/625 [00:13<00:08, 29.32it/s] 60%|██████    | 376/625 [00:14<00:08, 29.30it/s] 61%|██████    | 379/625 [00:14<00:08, 29.32it/s] 61%|██████    | 382/625 [00:14<00:08, 29.32it/s] 62%|██████▏   | 385/625 [00:14<00:08, 29.32it/s] 62%|██████▏   | 388/625 [00:14<00:08, 29.28it/s] 63%|██████▎   | 391/625 [00:14<00:07, 29.30it/s] 63%|██████▎   | 394/625 [00:14<00:07, 29.34it/s] 64%|██████▎   | 397/625 [00:14<00:07, 29.33it/s] 64%|██████▍   | 400/625 [00:14<00:07, 29.33it/s] 64%|██████▍   | 403/625 [00:14<00:07, 29.33it/s] 65%|██████▍   | 406/625 [00:15<00:07, 29.31it/s] 65%|██████▌   | 409/625 [00:15<00:07, 29.28it/s] 66%|██████▌   | 412/625 [00:15<00:07, 29.31it/s] 66%|██████▋   | 415/625 [00:15<00:07, 29.31it/s] 67%|██████▋   | 418/625 [00:15<00:07, 29.30it/s] 67%|██████▋   | 421/625 [00:15<00:06, 29.31it/s] 68%|██████▊   | 424/625 [00:15<00:06, 29.31it/s] 68%|██████▊   | 427/625 [00:15<00:06, 29.32it/s] 69%|██████▉   | 430/625 [00:15<00:06, 29.32it/s] 69%|██████▉   | 433/625 [00:15<00:06, 29.28it/s] 70%|██████▉   | 436/625 [00:16<00:06, 29.29it/s] 70%|███████   | 439/625 [00:16<00:06, 29.30it/s] 71%|███████   | 442/625 [00:16<00:06, 29.30it/s] 71%|███████   | 445/625 [00:16<00:06, 29.33it/s] 72%|███████▏  | 448/625 [00:16<00:06, 29.26it/s] 72%|███████▏  | 451/625 [00:16<00:05, 29.24it/s] 73%|███████▎  | 454/625 [00:16<00:05, 29.28it/s] 73%|███████▎  | 457/625 [00:16<00:05, 29.29it/s] 74%|███████▎  | 460/625 [00:16<00:05, 29.33it/s] 74%|███████▍  | 463/625 [00:16<00:05, 29.34it/s] 75%|███████▍  | 466/625 [00:17<00:05, 29.33it/s] 75%|███████▌  | 469/625 [00:17<00:05, 29.33it/s] 76%|███████▌  | 472/625 [00:17<00:05, 29.33it/s] 76%|███████▌  | 475/625 [00:17<00:05, 29.32it/s] 76%|███████▋  | 478/625 [00:17<00:05, 29.33it/s] 77%|███████▋  | 481/625 [00:17<00:04, 29.29it/s] 77%|███████▋  | 484/625 [00:17<00:04, 29.27it/s] 78%|███████▊  | 487/625 [00:17<00:04, 29.26it/s] 78%|███████▊  | 490/625 [00:17<00:04, 29.27it/s] 79%|███████▉  | 493/625 [00:18<00:04, 29.34it/s] 79%|███████▉  | 496/625 [00:18<00:04, 29.29it/s] 80%|███████▉  | 499/625 [00:18<00:04, 29.28it/s] 80%|████████  | 502/625 [00:18<00:04, 29.26it/s] 81%|████████  | 505/625 [00:18<00:04, 29.29it/s] 81%|████████▏ | 508/625 [00:18<00:03, 29.27it/s] 82%|████████▏ | 511/625 [00:18<00:03, 29.29it/s] 82%|████████▏ | 514/625 [00:18<00:03, 29.29it/s] 83%|████████▎ | 517/625 [00:18<00:03, 29.27it/s] 83%|████████▎ | 520/625 [00:18<00:03, 29.30it/s] 84%|████████▎ | 523/625 [00:19<00:03, 29.25it/s] 84%|████████▍ | 526/625 [00:19<00:03, 29.27it/s] 85%|████████▍ | 529/625 [00:19<00:03, 29.29it/s] 85%|████████▌ | 532/625 [00:19<00:03, 29.30it/s] 86%|████████▌ | 535/625 [00:19<00:03, 29.29it/s] 86%|████████▌ | 538/625 [00:19<00:02, 29.27it/s] 87%|████████▋ | 541/625 [00:19<00:02, 29.34it/s] 87%|████████▋ | 544/625 [00:19<00:02, 29.33it/s] 88%|████████▊ | 547/625 [00:19<00:02, 29.27it/s] 88%|████████▊ | 550/625 [00:19<00:02, 29.26it/s] 88%|████████▊ | 553/625 [00:20<00:02, 29.28it/s] 89%|████████▉ | 556/625 [00:20<00:02, 29.26it/s] 89%|████████▉ | 559/625 [00:20<00:02, 29.22it/s] 90%|████████▉ | 562/625 [00:20<00:02, 29.25it/s] 90%|█████████ | 565/625 [00:20<00:02, 29.27it/s] 91%|█████████ | 568/625 [00:20<00:01, 29.28it/s] 91%|█████████▏| 571/625 [00:20<00:01, 29.30it/s] 92%|█████████▏| 574/625 [00:20<00:01, 29.31it/s] 92%|█████████▏| 577/625 [00:20<00:01, 29.29it/s] 93%|█████████▎| 580/625 [00:20<00:01, 29.27it/s] 93%|█████████▎| 583/625 [00:21<00:01, 29.26it/s] 94%|█████████▍| 586/625 [00:21<00:01, 29.24it/s] 94%|█████████▍| 589/625 [00:21<00:01, 29.23it/s] 95%|█████████▍| 592/625 [00:21<00:01, 29.25it/s] 95%|█████████▌| 595/625 [00:21<00:01, 29.28it/s] 96%|█████████▌| 598/625 [00:21<00:00, 29.30it/s] 96%|█████████▌| 601/625 [00:21<00:00, 29.32it/s] 97%|█████████▋| 604/625 [00:21<00:00, 29.31it/s] 97%|█████████▋| 607/625 [00:21<00:00, 29.28it/s] 98%|█████████▊| 610/625 [00:22<00:00, 29.29it/s] 98%|█████████▊| 613/625 [00:22<00:00, 29.26it/s] 99%|█████████▊| 616/625 [00:22<00:00, 29.28it/s] 99%|█████████▉| 619/625 [00:22<00:00, 29.29it/s]100%|█████████▉| 622/625 [00:22<00:00, 29.26it/s]100%|██████████| 625/625 [00:22<00:00, 29.24it/s]100%|██████████| 625/625 [00:22<00:00, 27.74it/s]
/home1/bansalsi/csci-467-project/csci467/lib/python3.9/site-packages/lime/explanation.py:168: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  fig = plt.figure()
Num samples 2500
Num samples 2500
Accuracy:  0.8584
Precision:  0.8536038252235371
Recall:  0.854340826732662
F1:  0.8533909329988222
Original label:  cs.PL
Predicted label:  8
Correct label:  2
Text:  [CLS] journal of latex class files, vol. 14, no. 8, august 2015 1 from deterministic to generative : multi - modal stochastic rnns for video captioning arxiv : 1708. 02478v2 [ ] 20 oct 2017 jingkuan song, yuyu guo, lianli gao, xuelong li, ieee fellow alan hanjalic, ieee fellow heng tao shen abstract — video captioning in essential is a complex natural process, which is affected by various uncertainties stemming from video content, subjective judgment, etc. in this paper we build on the recent progress in using encoder - decoder framework for video captioning and address what we find to be a critical deficiency of the existing methods, that most of the decoders propagate deterministic hidden states. such complex uncertainty cannot be modeled efficiently by the deterministic models. in this paper, we propose a generative approach, referred to as multi - modal stochastic rnns networks ( ms - rnn ), which models the uncertainty observed in the data using latent stochastic variables. therefore, ms - rnn can improve the performance of video captioning, and generate multiple sentences to describe a video considering different random factors. specifically, a multimodal lstm ( m - lstm ) is first proposed to interact with both visual and textual features to capture a high - level representation. then, a backward stochastic lstm ( s - lstm ) is proposed to support uncertainty propagation by introducing latent variables. experimental results on the challenging datasets msvd and msr - vtt show that our proposed ms - rnn approach outperforms the state - of - the - art video captioning benchmarks. index terms — video captioning, rnn, uncertainty. i. i ntroduction with the explosive growth of online videos over the past decade, video captioning has become a hot research topic. in a nutshell, video captioning is the problem of translating a video into meaningful textual sentences describing its visual content. as such, solving this problem has the potential to help various applications, from video indexing and search to human - robot interaction. building on the pioneering work of kojima et al. [ 1 ], a series of studies have been conducted to come up with a first generation of video captioning systems [ 2 ], [ 3 ], [ 4 ]. [SEP]
Text from DS:  JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

1

From Deterministic to Generative: Multi-Modal
Stochastic RNNs for Video Captioning

arXiv:1708.02478v2 [] 20 Oct 2017

Jingkuan Song, Yuyu Guo, Lianli Gao, Xuelong Li, IEEE Fellow Alan Hanjalic, IEEE Fellow Heng Tao Shen

Abstract—Video captioning in essential is a complex natural
process, which is affected by various uncertainties stemming
from video content, subjective judgment, etc. In this paper we
build on the recent progress in using encoder-decoder framework
for video captioning and address what we find to be a critical
deficiency of the existing methods, that most of the decoders
propagate deterministic hidden states. Such complex uncertainty
cannot be modeled efficiently by the deterministic models. In
this paper, we propose a generative approach, referred to as
multi-modal stochastic RNNs networks (MS-RNN), which models
the uncertainty observed in the data using latent stochastic
variables. Therefore, MS-RNN can im
Original label:  cs.CE
Predicted label:  0
Correct label:  5
Text:  [CLS] differential equation axiomatization the impressive power of differential ghosts arxiv : 1802. 01226v1 [ cs. lo ] 5 feb 2018 andre platzer yong kiam tan ∗ abstract we prove the completeness of an axiomatization for differential equation invariants. first, we show that the differential equation axioms in differential dynamic logic are complete for all algebraic invariants. our proof exploits differential ghosts, which introduce additional variables that can be chosen to evolve freely along new differential equations. cleverly chosen differential ghosts are the proof - theoretical counterpart of dark matter. they create new hypothetical state, whose relationship to the original state variables satisfies invariants that did not exist before. the reflection of these new invariants in the original system enables its analysis. we then show that extending the axiomatization with existence and uniqueness axioms makes it complete for all local progress properties, and further extension with a real induction axiom makes it complete for all real arithmetic invariants. this yields a parsimonious axiomatization, which serves as the logical foundation for reasoning about invariants of differential equations. moreover, our approach is purely axiomatic, and so the axiomatization is suitable for sound implementation in foundational theorem provers. keywords : differential equation axiomatization, differential dynamic logic, differential ghosts 1 introduction classically, differential equations are studied by analyzing their solutions. this is at odds with the fact that solutions are often much more complicated than the differential equations themselves. the stark difference between the simple local description as differential equations and the complex global behavior exhibited by solutions is fundamental to the descriptive power of differential equations. poincare ’ s qualitative study of differential equations crucially exploits this difference by deducing properties of solutions directly from the differential equations. this paper completes an important step in this enterprise by identifying the logical foundations for proving invariance properties of polynomial differential equations. we exploit the differential equation axioms of differential dynamic logic ( dl ) [ 13, 15 ]. dl is a logic for deductive verification of hybrid systems that are modelled by hybrid programs combining discrete computation ( e. g., assignments, tests and loops ), and continuous dynamics specified ∗ computer science department, carnegie mellon university, pittsburgh, usa { aplatzer | yongkiat } @ cs. cmu. edu a. platzer and y. k. tan differential equation axiomatization using systems of ordinary differential equations ( odes ). by the continuous relative complete [SEP]
Text from DS:  Differential Equation Axiomatization
The Impressive Power of Differential Ghosts

arXiv:1802.01226v1 [cs.LO] 5 Feb 2018

André Platzer

Yong Kiam Tan ∗

Abstract
We prove the completeness of an axiomatization for differential equation invariants. First,
we show that the differential equation axioms in differential dynamic logic are complete for
all algebraic invariants. Our proof exploits differential ghosts, which introduce additional variables that can be chosen to evolve freely along new differential equations. Cleverly chosen
differential ghosts are the proof-theoretical counterpart of dark matter. They create new hypothetical state, whose relationship to the original state variables satisfies invariants that did not
exist before. The reflection of these new invariants in the original system enables its analysis.
We then show that extending the axiomatization with existence and uniqueness axioms
makes it complete for all local progress properties, and further extension with a real
Original label:  cs.CV
Predicted label:  6
Correct label:  2
Text:  [CLS] 1 on the capacity of face representation arxiv : 1709. 10433v2 [ ] 15 feb 2018 sixue gong, student member, ieee, vishnu naresh boddeti, member, ieee and anil k. jain, life fellow, ieee abstract — face recognition is a widely used technology with numerous large - scale applications, such as surveillance, social media and law enforcement. there has been tremendous progress in face recognition accuracy over the past few decades, much of which can be attributed to deep learning based approaches during the last five years. indeed, automated face recognition systems are now believed to surpass human performance in some scenarios. despite this progress, a crucial question still remains unanswered : given a face representation, how many identities can it resolve? in other words, what is the capacity of the face representation? a scientific basis for estimating the capacity of a given face representation will not only benefit the evaluation and comparison of different face representation methods, but will also establish an upper bound on the scalability of an automatic face recognition system. we cast the face capacity estimation problem under the information theoretic framework of capacity of a gaussian noise channel. by explicitly accounting for two sources of representational noise : epistemic ( model ) uncertainty and aleatoric ( data ) variability, our approach is able to estimate the capacity of any given face representation. to demonstrate the efficacy of our approach, we estimate the capacity of a 128 - dimensional deep neural network based face representation, facenet [ 1 ], and that of the classical eigenfaces [ 2 ] representation of the same dimensionality. our numerical experiments on unconstrained faces indicate that, ( a ) our capacity estimation model yields a capacity upper bound of 5. 8×108 for facenet and 1×100 for eigenface representation at a false acceptance rate ( far ) of 1 %, ( b ) the capacity of the face representation reduces drastically as you lower the desired far ( for facenet representation ; the capacity at far of 0. 1 % and 0. 001 % is 2. 4×106 and 7. 0×102, respectively ), and ( c ) the empirical performance of the facenet representation is significantly below the theoretical limit. index terms — face recognition, face representation, channel capacity, gaussian noise channel, bayesian inference f 1 i ntroduction face recognition has witnessed rapid progress and wide applicability in a variety of practical applications : social media, surveillance systems and law enforcement to [SEP]
Text from DS:  1

On the Capacity of Face Representation

arXiv:1709.10433v2 [] 15 Feb 2018

Sixue Gong, Student Member, IEEE, Vishnu Naresh Boddeti, Member, IEEE
and Anil K. Jain, Life Fellow, IEEE
Abstract—Face recognition is a widely used technology with numerous large-scale applications, such as surveillance, social media
and law enforcement. There has been tremendous progress in face recognition accuracy over the past few decades, much of which
can be attributed to deep learning based approaches during the last five years. Indeed, automated face recognition systems are now
believed to surpass human performance in some scenarios. Despite this progress, a crucial question still remains unanswered: given a
face representation, how many identities can it resolve? In other words, what is the capacity of the face representation? A scientific
basis for estimating the capacity of a given face representation will not only benefit the evaluation and comparison of different face
representation methods, but
Original label:  cs.PL
Predicted label:  6
Correct label:  2
Text:  [CLS] ultra - dense networks : a new look at the proportional fair scheduler ming ding ‡, david lopez perez †, amir h. jafari∗, guoqiang [UNK] ‡, zihuai lin ¶ ‡ data61, [UNK] school of computing and communication, university of technology sydney, australia ∗ dept. of electronic & electrical engineering, university of sheffield, uk ¶ the arxiv : 1708. 07961v2 [ cs. ni ] 26 sep 2017 australia, † nokia bell labs, ireland university of sydney, australia abstract — in this paper, we theoretically study the proportional fair ( pf ) scheduler in the context of ultra - dense networks ( udns ). analytical results are obtained for the coverage probability and the area spectral efficiency ( ase ) performance of dense small cell networks ( scns ) with the pf scheduler employed at base stations ( bss ). the key point of our analysis is that the typical user is no longer a random user as assumed in most studies in the literature. instead, a user with the maximum pf metric is chosen by its serving bs as the typical user. by comparing the previous results of the round - robin ( rr ) scheduler with our new results of the pf scheduler, we quantify the loss of the multiuser diversity of the pf scheduler with the network densification, which casts a new look at the role of the pf scheduler in udns. our conclusion is that the rr scheduler should be used in udns to simplify the radio resource management ( rrm ) 1. i. i ntroduction network densification is envisioned to be the key solution to meet users ’ traffic demands in the 5th - generation ( 5g ) networks [ 1 ]. indeed, the orthogonal deployment2 of dense small cell networks ( scns ) within the existing macrocell networks [ 2 ] has been the workhorse for capacity enhancement in the 4th - generation ( 4g ), developed by the 3rd generation partnership project ( 3gpp ), and this approach to capacity enhancement will continue in 5g with the adoption of ultradense networks ( udns ) [ 1, 3 ]. in this paper, we focus on the analysis of such orthogonal deployment of udns. despite of its benefits, the scn densification also opens up new research questions. in particular, scheduling has been conceived as an effective technique used at base stations ( bss ) to efficiently use the available spectrum and improve the [SEP]
Text from DS:  Ultra-Dense Networks: A New Look at
the Proportional Fair Scheduler
Ming Ding‡ , David López Pérez† , Amir H. Jafari∗ , Guoqiang Mao∦‡ , Zihuai Lin¶
‡ Data61,
∦ School

of Computing and Communication, University of Technology Sydney, Australia

∗ Dept.

of Electronic & Electrical Engineering, University of Sheffield, UK
¶ The

arXiv:1708.07961v2 [cs.NI] 26 Sep 2017

Australia, † Nokia Bell Labs, Ireland

University of Sydney, Australia

Abstract—In this paper, we theoretically study the proportional
fair (PF) scheduler in the context of ultra-dense networks (UDNs).
Analytical results are obtained for the coverage probability and
the area spectral efficiency (ASE) performance of dense small
cell networks (SCNs) with the PF scheduler employed at base
stations (BSs). The key point of our analysis is that the typical
user is no longer a random user as assumed in most studies in
the literature. Instead, a user with the maximum PF metric is
chosen by its serving BS as the typical user. By 
Original label:  cs.IT
Predicted label:  10
Correct label:  8
Text:  [CLS] approximating weighted duo - preservation in comparative genomics∗ arxiv : 1708. 09325v1 [ ] 30 aug 2017 saeed mehrabi school of computer science carleton university, ottawa, canada mehrabi235 @ gmail. com abstract motivated by comparative genomics, chen et al. [ 9 ] introduced the maximum duo - preservation string mapping ( mdsm ) problem in which we are given two strings s1 and s2 from the same alphabet and the goal is to find a mapping π between them so as to maximize the number of duos preserved. a duo is any two consecutive characters in a string and it is preserved in the mapping if its two consecutive characters in s1 are mapped to same two consecutive characters in s2. the mdsm problem is known to be np - hard and there are approximation algorithms for this problem [ 3, 5, 13 ], but all of them consider only the “ unweighted ” version of the problem in the sense that a duo from s1 is preserved by mapping to any same duo in s2 regardless of their positions in the respective strings. however, it is well - desired in comparative genomics to find mappings that consider preserving duos that are “ closer ” to each other under some distance measure [ 19 ]. in this paper, we introduce a generalized version of the problem, called the maximum - weight duo - preservation string mapping ( mwdsm ) problem that captures both duos - preservation and duos - distance measures in the sense that mapping a duo from s1 to each preserved duo in s2 has a weight, indicating the “ closeness ” of the two duos. the objective of the mwdsm problem is to find a mapping so as to maximize the total weight of preserved duos. in this paper, we give a polynomial - time 6 - approximation algorithm for this problem. 1 introduction strings comparison is one of the central problems in the field of stringology with many applications such as in data compression and bioinformatics. one of the most common goals of strings comparison is to measure the similarity between them, and one of the many ways in doing so is to compute the edit distance between them. the edit distance between two strings is defined as the minimum number of edit operations to transform one string into the other. in biology, during the process of dna sequencing for instance, computing the edit distance between the dna molecules of different species can provide insight about the level of “ synteny ” between them ; here, each edit operation is [SEP]
Text from DS:  Approximating Weighted Duo-Preservation in Comparative
Genomics∗

arXiv:1708.09325v1 [] 30 Aug 2017

Saeed Mehrabi
School of Computer Science
Carleton University, Ottawa, Canada
mehrabi235@gmail.com

Abstract
Motivated by comparative genomics, Chen et al. [9] introduced the Maximum Duo-preservation
String Mapping (MDSM) problem in which we are given two strings s1 and s2 from the same alphabet and the goal is to find a mapping π between them so as to maximize the number of
duos preserved. A duo is any two consecutive characters in a string and it is preserved in the
mapping if its two consecutive characters in s1 are mapped to same two consecutive characters
in s2 . The MDSM problem is known to be NP-hard and there are approximation algorithms for
this problem [3, 5, 13], but all of them consider only the “unweighted” version of the problem
in the sense that a duo from s1 is preserved by mapping to any same duo in s2 regardless of
their positions in the respective strings. However, it 
Original label:  cs.IT
Predicted label:  5
Correct label:  3
Text:  [CLS] arxiv : 1511. 02486v1 [ ] 8 nov 2015 hardness and approximation for network flow interdiction stephen r. chestnut∗ rico zenklusen † november 10, 2015 abstract in the network flow interdiction problem an adversary attacks a network in order to minimize the maximum s - t - flow. very little is known about the approximatibility of this problem despite decades of interest in it. we present the first approximation hardness, showing that network flow interdiction and several of its variants cannot be much easier to approximate than densest k - subgraph. in particular, any no ( 1 ) - approximation algorithm for network flow interdiction would imply an no ( 1 ) - approximation algorithm for densest k - subgraph. we complement this hardness results with the first approximation algorithm for network flow interdiction, which has approximation ratio 2 ( n − 1 ). we also show that network flow interdiction is essentially the same as the budgeted minimum s - t - cut problem, and transferring our results gives the first approximation hardness and algorithm for that problem, as well. keywords : network flow interdiction, approximation algorithms, hardness of approximation, budgeted optimization 1 introduction we are given an undirected graph g = ( v, e ) with edge capacities u ( e ) ≥ 0, for all e ∈ e, and distinct vertices s, t ∈ v. an adversary removes edges from the graph with the goal of reducing the maximum s - t - flow. it costs the adversary c ( e ) to remove edge e and he has a total budget b for removing edges. the network flow interdiction ( nfi ) problem is to determine the optimal strategy for the adversary. more precisely, given g, s, t, u, c, and b, p the goal is to find a set of edges r ⊆ e such that c ( r ) : = e∈r c ( e ) ≤ b and the maximum s - t - flow in ( v, e \ r ) is minimized. network flow interdiction has a long history in combinatorial optimization beginning with the famous max - flow / min - cut theorem of ford and fulkerson. a declassified rand report from 1955 [ 13 ] regarding interdiction of the soviet rail network in eastern europe is cited by ford and fulkerson as motivation for the minimum s - t - cut problem [ 22 ]. if there is an s - t - cut with cost at most b [SEP]
Text from DS:  arXiv:1511.02486v1 [] 8 Nov 2015

Hardness and Approximation for Network Flow
Interdiction
Stephen R. Chestnut∗

Rico Zenklusen†

November 10, 2015

Abstract
In the Network Flow Interdiction problem an adversary attacks a network in order
to minimize the maximum s-t-flow. Very little is known about the approximatibility of
this problem despite decades of interest in it. We present the first approximation hardness, showing that Network Flow Interdiction and several of its variants cannot be much
easier to approximate than Densest k-Subgraph. In particular, any no(1) -approximation
algorithm for Network Flow Interdiction would imply an no(1) -approximation algorithm
for Densest k-Subgraph. We complement this hardness results with the first approximation algorithm for Network Flow Interdiction, which has approximation ratio 2(n − 1).
We also show that Network Flow Interdiction is essentially the same as the Budgeted
Minimum s-t-Cut problem, and transferring our results gives the first app
Original label:  cs.DS
Predicted label:  2
Correct label:  6
Text:  [CLS] international journal of data mining & knowledge management process ( ijdkp ) vol. 5, no. 1, january 2015 diagnosis of diabetes using classification mining techniques aiswarya iyer, s. jeyalatha and ronak sumbaly department of computer science, bits pilani dubai, united arab emirates abstract diabetes has affected over 246 million people worldwide with a majority of them being women. according to the who report, by 2025 this number is expected to rise to over 380 million. the disease has been named the fifth deadliest disease in the united states with no imminent cure in sight. with the rise of information technology and its continued advent into the medical and healthcare sector, the cases of diabetes as well as their symptoms are well documented. this paper aims at finding solutions to diagnose the disease by analyzing the patterns found in the data through classification analysis by employing decision tree and naive bayes algorithms. the research hopes to propose a quicker and more efficient technique of diagnosing the disease, leading to timely treatment of the patients. keywords classification, data mining, decision tree, diabetes and naive bayes. 1. introduction effects of diabetes have been reported to have a more fatal and worsening impact on women than on men because of their lower survival rate and poorer quality of life. who reports state that almost one – third of the women who suffer from diabetes have no knowledge about it. the effect of diabetes is unique in case of mothers because the disease is transmitted to their unborn children. strokes, miscarriages, blindness, kidney failure and amputations are just some of the complications that arise from this disease. for the purposes of this paper, the analyses of diabetes cases have been restricted to pregnant women. generally a person is considered to be suffering from diabetes, when blood sugar levels are above normal ( 4. 4 to 6. 1 mmol / l ) [ 1 ]. pancreas present in the human body produces insulin, a hormone that is responsible to help glucose reach each cell of the body. a diabetic patient essentially has low production of insulin or their body is not able to use the insulin well. there are three main types of diabetes, viz. type 1, type 2 and gestational [ 2 ]. type 1 – the disease manifest as an autoimmune disease occurring at a very young age of below 20 years. in this type of diabetes, the pancreatic cells that produce insulin have been destroyed. type 2 - diabetes is in the state when the various organs [SEP]
Text from DS:  International Journal of Data Mining & Knowledge Management Process (IJDKP) Vol.5, No.1, January 2015

DIAGNOSIS OF DIABETES USING
CLASSIFICATION MINING TECHNIQUES
Aiswarya Iyer, S. Jeyalatha and Ronak Sumbaly
Department of Computer Science, BITS Pilani Dubai, United Arab Emirates

ABSTRACT
Diabetes has affected over 246 million people worldwide with a majority of them being women. According
to the WHO report, by 2025 this number is expected to rise to over 380 million. The disease has been
named the fifth deadliest disease in the United States with no imminent cure in sight. With the rise of
information technology and its continued advent into the medical and healthcare sector, the cases of
diabetes as well as their symptoms are well documented. This paper aims at finding solutions to diagnose
the disease by analyzing the patterns found in the data through classification analysis by employing
Decision Tree and Naïve Bayes algorithms. The research hopes to propose a quicker and more ef
Original label:  cs.CE
Predicted label:  1
Correct label:  9
Text:  [CLS] bulletin of the polish academy of sciences technical sciences vol. 58, no. 1, 2010 1 extending scientific computing system with structural quantum programming capabilities piotr gawron jerzy klamka jarosław adam miszczak ryszard winiarczyk the institute of theoretical and applied informatics of the polish academy of sciences bałtycka 5, 44 - 100 gliwice, poland arxiv : 1006. 1549v1 [ ] 8 jun 2010 november 12, 2009 abstract — we present a basic high - level structures used for developing quantum programming languages. the presented structures are commonly used in many existing quantum programming languages and we use quantum pseudo - code based on qcl quantum programming language to describe them. we also present the implementation of introduced structures in gnu octave language for scientific computing. procedures used in the implementation are available as a package quantum - octave, providing a library of functions, which facilitates the simulation of quantum computing. this package allows also to incorporate highlevel programming concepts into the simulation in gnu octave and matlab. as such it connects features unique for high - level quantum programming languages, with the full palette of efficient computational routines commonly available in modern scientific computing systems. to present the major features of the described package we provide the implementation of selected quantum algorithms. we also show how quantum errors can be taken into account during the simulation of quantum algorithms using quantum - octave package. this is possible thanks to the ability to operate on density matrices. index terms — quantum information, quantum programming, models of quantum computation i. i ntroduction quantum information theory aims to harness the quantum nature of information carriers in order to develop more efficient algorithms and more secure communication protocols [ 1 ], [ 2 ], [ 3 ], [ 4 ]. unfortunately, counterintuitive laws of quantum mechanics make the development of new quantum information processing procedures highly non - trivial task. this can be seen as one of the reasons why only few truly quantum algorithms were proposed [ 5 ], [ 6 ]. the laws of quantum mechanics are in many cases very different from those we know from the classical world. that is why one needs to seek for the novel methods for describing information processing which involves quantum elements. to this day several formal e - mail address : gawron @ iitis. pl ( corresponding author ) models were proposed for the description of quantum computation process [ 7 ], [ 8 ], [ 9 ], [ 10 ], [ 11 ], [ 12 ]. the most popular of them [SEP]
Text from DS:  BULLETIN OF THE POLISH ACADEMY OF SCIENCES

TECHNICAL SCIENCES

VOL. 58, NO. 1, 2010

1

Extending scientific computing system with
structural quantum programming capabilities
Piotr Gawron

Jerzy Klamka

Jarosław Adam Miszczak

Ryszard Winiarczyk

The Institute of Theoretical and Applied Informatics
of the Polish Academy of Sciences
Bałtycka 5, 44-100 Gliwice, Poland

arXiv:1006.1549v1 [] 8 Jun 2010

November 12, 2009

Abstract—We present a basic high-level structures
used for developing quantum programming languages.
The presented structures are commonly used in many
existing quantum programming languages and we use
quantum pseudo-code based on QCL quantum programming language to describe them.
We also present the implementation of introduced
structures in GNU Octave language for scientific computing. Procedures used in the implementation are available
as a package quantum-octave, providing a library of
functions, which facilitates the simulation of quantum
computing. This package all
Original label:  cs.PL
Predicted label:  8
Correct label:  6
Text:  [CLS] 1 parity - check polar coding for 5g and beyond arxiv : 1801. 03616v1 [ ] 11 jan 2018 huazi zhang, rong li, jian wang, shengchen dai, gongzheng zhang, ying chen, hejia luo, jun wang huawei technologies co. ltd. email : { zhanghuazi, rongone. li, justin. wangjun } @ huawei. com abstract — in this paper, we propose a comprehensive polar coding solution that integrates reliability calculation, rate matching and parity - check coding. judging a channel coding design from the industry ’ s viewpoint, there are two primary concerns : ( i ) low - complexity implementation in applicationspecific integrated circuit ( asic ), and ( ii ) superior & stable performance under a wide range of code lengths and rates. the former provides cost - & power - efficiency which are vital to any commercial system ; the latter ensures flexible and robust services. our design respects both criteria. it demonstrates better performance than existing schemes in literature, but requires only a fraction of implementation cost. with easilyreproducible code construction for arbitrary code rates and lengths, we are able to report “ 1 - bit ” fine - granularity simulation results for thousands of cases. the released results can serve as a baseline for future optimization of polar codes. 1 index terms — 5g, polar codes, construction, parity - check. i. i ntroduction a. background and related works answering the question of “ what will 5g be? ” [ 1 ], the result is clear at least for channel coding. for the enhanced mobile broadband ( embb ) service category in 5g, ldpc codes and polar codes [ 2 ], [ 3 ] have been adopted for data channel and control channel, respectively. with state - ofthe - art code construction techniques [ 4 ], [ 5 ] and list decoding algorithm [ 6 ], polar codes demonstrate competitive performance under short information block length ( k < 1000 ), whereas the block error rate ( bler ) gain over ldpc and turbo codes is up to 1db. such advantages make polar codes the most suitable candidate for the control channel, where the payload size is relatively small. polar code construction refers to determining the sets of information / frozen bits given certain information block length k and code length n. according to [ 2 ], [ 3 ], the most reliable synthesized sub - channels should be selected as information set to obtain the best performance under [SEP]
Text from DS:  1

Parity-Check Polar Coding for 5G and Beyond

arXiv:1801.03616v1 [] 11 Jan 2018

Huazi Zhang, Rong Li, Jian Wang, Shengchen Dai, Gongzheng Zhang, Ying Chen, Hejia Luo, Jun Wang
Huawei Technologies Co. Ltd.
Email: {zhanghuazi,rongone.li,justin.wangjun}@huawei.com

Abstract—In this paper, we propose a comprehensive Polar coding solution that integrates reliability calculation, rate
matching and parity-check coding. Judging a channel coding
design from the industry’s viewpoint, there are two primary
concerns: (i) low-complexity implementation in applicationspecific integrated circuit (ASIC), and (ii) superior & stable
performance under a wide range of code lengths and rates.
The former provides cost- & power-efficiency which are vital to
any commercial system; the latter ensures flexible and robust
services. Our design respects both criteria. It demonstrates
better performance than existing schemes in literature, but
requires only a fraction of implementation cost. With easilyreproducib
Original label:  math.AC
Predicted label:  1
Correct label:  9
Text:  [CLS] positive characteristic algebraic geometry arxiv : 1412. 2203v2 [ math. ag ] 23 jan 2017 zsolt patakfalvi, karl schwede, and kevin tucker contents 1. introduction 2. frobenius splittings 3. trace of frobenius and global sections 3. 1. examples and computations of s 0 4. f - singularities versus singularities of the mmp 4. 1. questions 5. global applications 5. 1. semi - positivity of pushforwards 5. 2. miscellaneous exercises 5. 3. problems 6. seshadri constants, f - pure centers and test ideals 6. 1. seshadri constants 6. 2. f - pure centers 6. 3. test ideals 6. 4. jumping numbers 6. 5. test ideals of non - q - gorenstein rings 7. numerical invariants 8. more on test ideals and f - singularities in families 8. 1. bertini theorems for test ideals 8. 2. test ideals by finite covers and alterations 8. 3. other types of singularities and deformation thereof 8. 4. bertini theorems for f - rational and f - injective singularities references 1 2 6 9 10 17 19 19 23 25 27 27 28 30 31 31 32 33 33 35 36 37 37 1. introduction the goal of these notes is to give a geometric introduction to recent methods utilizing the frobenius morphism ( see [ st12a ] for more algebraic aspects ) in higher dimensional algebraic geometry. these methods have been used extensively to move arguments from characteristic zero to positive characteristic. the main obstacle in doing so is usually some theorems of either analytic or p - adic origin that are known not to hold in positive characteristic : e. g., kodaira - vanishing the current version of these notes were written for the the boot camp for the 2015 algebraic geometry summer research institute, which was supported by nsf dms # 1500652. the first version of these notes arose from a “ positive characteristic algebraic geometry workshop ” held at the university of illinois at chicago in march 2014, supported by nsf rtg grant # 1246844 and uic.. the second author was partially supported by nsf frg grant dms # 1265261 / 1501115, nsf career grant dms # 1252860 / 1501102 and a sloan fellowship. the third author was partially supported by nsf grant d [SEP]
Text from DS:  POSITIVE CHARACTERISTIC ALGEBRAIC GEOMETRY

arXiv:1412.2203v2 [math.AG] 23 Jan 2017

ZSOLT PATAKFALVI, KARL SCHWEDE, AND KEVIN TUCKER

Contents
1. Introduction
2. Frobenius Splittings
3. Trace of Frobenius and Global Sections
3.1. Examples and computations of S 0
4. F -singularities versus Singularities of the MMP
4.1. Questions
5. Global Applications
5.1. Semi-positivity of pushforwards
5.2. Miscellaneous exercises
5.3. Problems
6. Seshadri constants, F -pure centers and test ideals
6.1. Seshadri constants
6.2. F -pure centers
6.3. Test ideals
6.4. Jumping numbers
6.5. Test ideals of non-Q-Gorenstein rings
7. Numerical Invariants
8. More on test ideals and F -Singularities in Families
8.1. Bertini theorems for test ideals
8.2. Test ideals by finite covers and alterations
8.3. Other types of singularities and deformation thereof
8.4. Bertini theorems for F -rational and F -injective singularities
References

1
2
6
9
10
17
19
19
23
25
27
27
28
30
31
31
32
33
33
35
36
37
37

1. Introduct
Original label:  math.ST
Predicted label:  9
Correct label:  1
Text:  [CLS] arxiv : 1209. 0703v3 [ ] 4 may 2016 bernoulli 22 ( 3 ), 2016, 1808 – 1838 doi : 10. 3150 / 15 - bej712 markov chain monte carlo confidence intervals yves f. atchade 1 university of michigan, 1085 south university, ann arbor, 48109, mi, united states. e - mail : yvesa @ umich. edu for a reversible and ergodic markov chain { xn, n ≥ 0 } with invariant distribution π, we show that a valid confidence interval for π ( h ) can be constructed whenever the asymptotic variance σp2 ( h ) is finite and positive. we do not impose any additional condition on the convergence rate of the markov chain. the confidence interval is derived using the so - called fixed - b lag - window estimator of σp2 ( h ). we also derive a result that suggests that the proposed confidence interval procedure converges faster than classical confidence interval procedures based on the gaussian distribution and standard central limit theorems for markov chains. keywords : berry – esseen bounds ; confidence interval ; lag - window estimators ; martingale approximation ; mcmc ; reversible markov chains 1. introduction confidence intervals play an important role in monte carlo simulation ( robert and casella [ 26 ], asmussen and glynn [ 1 ] ). in markov chain monte carlo ( mcmc ), the existing literature requires the markov chain to be geometrically ergodic for the validity of confidence interval procedures ( jones et al. [ 15 ], flegal and jones [ 8 ], atchade [ 3 ] ). the main objective of this work is to simplify some of these assumptions. we show that for a reversible ergodic markov chain, a valid confidence interval can be constructed whenever the asymptotic variance itself is finite. no additional convergence rate assumption on the markov chain is required. let { xn, n ≥ 0 } be a reversible stationary markov chain with invariant distribution π. for h ∈ l2 ( π ), the asymptotic variance of h is denoted σp2 ( h ) ( see ( 2 ) below for the definition ). a remarkable result by c. kipnis and s. r. varadhan ( kipnis and varadhan pn 1 √ [ 19 ] [SEP]
Text from DS:  arXiv:1209.0703v3 [] 4 May 2016

Bernoulli 22(3), 2016, 1808–1838
DOI: 10.3150/15-BEJ712

Markov Chain Monte Carlo
confidence intervals
YVES F. ATCHADÉ
1

University of Michigan, 1085 South University, Ann Arbor, 48109, MI, United States.
E-mail: yvesa@umich.edu

For a reversible and ergodic Markov chain {Xn , n ≥ 0} with invariant distribution π, we show
that a valid confidence interval for π(h) can be constructed whenever the asymptotic variance
σP2 (h) is finite and positive. We do not impose any additional condition on the convergence rate
of the Markov chain. The confidence interval is derived using the so-called fixed-b lag-window
estimator of σP2 (h). We also derive a result that suggests that the proposed confidence interval
procedure converges faster than classical confidence interval procedures based on the Gaussian
distribution and standard central limit theorems for Markov chains.
Keywords: Berry–Esseen bounds; confidence interval; lag-window estimators; martingale
approxi
Original label:  math.ST
Predicted label:  6
Correct label:  5
Text:  [CLS] monotonicity and robustness in wiener disorder detection erik ekstrom∗ juozas vaicenavicius † arxiv : 1710. 10821v1 [ ] 30 oct 2017 abstract we study the problem of detecting a drift change of a brownian motion under various extensions of the classical case. specifically, we consider the case of a random post - change drift and examine monotonicity properties of the solution with respect to different model parameters. moreover, robustness properties – effects of misspecification of the underlying model – are explored. 1 introduction in the classical version of the quickest disorder detection ( qdd ) problem [ 9 ], one observes a one - dimensional process y which satisfies yt = b ( t − θ ) + + σwt, where b and σ are non - zero constants, w is a standard brownian motion and the disorder time θ is an exponentially distributed random variable ( with intensity λ > 0 ) such that w and θ are independent. the associated bayes ’ risk ( expected cost ) corresponding to a stopping rule τ is defined as p ( θ > τ ) + ce [ ( τ − θ ) + ], ( 1. 1 ) where c > 0 is the cost of one unit of detection delay. it is well - known ( see [ 10, chapter 4 ] ) that to minimise the bayes risk one should stop the first time the conditional probability process πt : = p ( θ ≤ t | fty ) reaches a certain level a. moreover, the level a is characterized as the unique solution of a transcendental equation. in many situations, however, it is natural not to know the exact value of the disorder magnitude b, but merely its distribution. this is the case for example when a specific machine is monitored continuously, and the machine can break down in several possible ways. to study such a situation, we allow for the new drift to be a random variable b with distribution µ such that b is independent of the other sources of randomness. in this setting we study monotonicity properties of the qdd problem, i. e. whether the ∗ department of mathematics, uppsala university, box 480, 751 06 uppsala, sweden ( ekstrom @ math. uu. se ). † department of information technology, uppsala university, box 337, 751 05 uppsala, sweden ( juozas. vaicenavicius @ it. uu. se ). 1 ( minimal ) expected cost is monotone with respect to [SEP]
Text from DS:  Monotonicity and robustness in Wiener disorder detection
Erik Ekström∗

Juozas Vaicenavicius

†

arXiv:1710.10821v1 [] 30 Oct 2017

Abstract
We study the problem of detecting a drift change of a Brownian motion under
various extensions of the classical case. Specifically, we consider the case of a random
post-change drift and examine monotonicity properties of the solution with respect
to different model parameters. Moreover, robustness properties – effects of misspecification of the underlying model – are explored.

1

Introduction

In the classical version of the quickest disorder detection (QDD) problem [9], one observes
a one-dimensional process Y which satisfies
Yt = b(t − Θ)+ + σWt ,
where b and σ are non-zero constants, W is a standard Brownian motion and the disorder
time Θ is an exponentially distributed random variable (with intensity λ > 0) such that
W and Θ are independent. The associated Bayes’ risk (expected cost) corresponding to
a stopping rule τ is defined as
P(Θ > τ 
Original label:  cs.IT
Predicted label:  8
Correct label:  2
Text:  [CLS] adaptive boolean monotonicity testing in total influence time arxiv : 1801. 02816v1 [ ] 9 jan 2018 deeparnab chakrabarty dartmouth college deeparnab @ dartmouth. edu c. seshadhri university of california, santa cruz sesh @ ucsc. edu abstract the problem of testing monotonicity of a boolean function f : { 0, 1 } n → { 0, 1 } has received much attention recently. denoting the proximity parameter by ε, the best tester is the e √n / ε2 ) tester of khot - minzer - safra ( focs 2015 ). let i ( f ) denote the total non - adaptive o ( influence of f. we give an adaptive tester whose running time is i ( f ) poly ( ε−1 log n ). 1 introduction consider the boolean hypercube { 0, 1 } n, endowed with the coordinate - wise partial order denoted by [UNK]. a function f : { 0, 1 } n → { 0, 1 } is monotone if [UNK] [UNK] y, f ( x ) ≤ f ( y ). let d ( f, g ), the distance between two functions f, g, be | { x : f ( x ) 6 = g ( x ) } | / 2n. the distance to monotonicity, εf, is the minimum distance of f to a monotone g. the problem of monotonicity testing is as follows. given query access to f and a proximity parameter ε > 0, design a ( randomized ) procedure that accepts if f is monotone ( εf = 0 ), and rejects if f is ε - far from monotone ( εf > ε ). both the above guarantees hold with probability at least 2 / 3. such a procedure is called a monotonicity tester. a tester is non - adaptive if the queries made are independent of the values of f, and adaptive otherwise. a tester is one - sided if it accepts monotone functions with probability 1, and two - sided otherwise. the problem of monotonicity testing over the hypercube has been the subject of much study [ ras99, ggl + 00, dgl + 99, cs14, cst14, cdst15, kms15, bb16, cwx17 ]. the first result was the o ( n / ε ) tester by goldreich et al [SEP]
Text from DS:  Adaptive Boolean Monotonicity Testing in Total Influence Time

arXiv:1801.02816v1 [] 9 Jan 2018

Deeparnab Chakrabarty
Dartmouth College
deeparnab@dartmouth.edu

C. Seshadhri
University of California, Santa Cruz
sesh@ucsc.edu

Abstract
The problem of testing monotonicity of a Boolean function f : {0, 1}n → {0, 1} has received much attention
recently. Denoting the proximity parameter by ε, the best tester is the
e √n/ε2 ) tester of Khot-Minzer-Safra (FOCS 2015). Let I(f ) denote the total
non-adaptive O(
influence of f . We give an adaptive tester whose running time is I(f )poly(ε−1 log n).

1

Introduction

Consider the boolean hypercube {0, 1}n , endowed with the coordinate-wise partial order denoted
by ≺. A function f : {0, 1}n → {0, 1} is monotone if ∀x ≺ y, f (x) ≤ f (y). Let d(f, g), the distance
between two functions f, g, be |{x : f (x) 6= g(x)}|/2n . The distance to monotonicity, εf , is the
minimum distance of f to a monotone g. The problem of monotonicity testing is as follow
Original label:  cs.AI
Predicted label:  3
Correct label:  5
Text:  [CLS] arxiv : 1709. 02618v4 [ ] 18 sep 2017 the shape of a benedictine monastery : the saintgall ontology ( extended version ) claudia cantale, a domenico cantone, b manuela lupica rinato, c marianna nicolosi - asmundo, b and daniele francesco santamaria b a dept. of humanities, university of catania, italy b dept. of mathematics and computer science, university of catania, italy c officine culturali, catania, italy abstract. we present an owl 2 ontology representing the saint gall plan, one of the most ancient documents arrived intact to us, which describes the ideal model of a benedictine monastic complex that inspired the design of many european monasteries. keywords. ontology, owl 2, digital humanities, benedictine monasteries. 1. introduction monasteries are conceived by the benedictine monastic order, founded by saint benedict of nursia, during the last period of the western roman empire. the monastic shape aims preserving the european christianity inside small self - sustaining communities where to lead a life of mystic and religious contemplation and introspection. 1 the main principle is to protect and shield christian religion and tradition from barbarian invasions. monasteries differ from convents primarily because of their purpose. monasteries are inhabited by monks belonging to some monastic order such as the benedictine one, having an ascetic and solitary lifestyle. convents, originated later with the mendicant orders, such as the franciscan one, are more dependent by the outside world. the two religious constructions arise in different historical periods carrying out different functions inside the religious community. starting from the vii century, western europe is characterized by a capillary network of monasteries. their shape in occident remained largely unchanged in its characteristics during the whole middle age and in all christian countries. monasteries are often also abbeys that are spaces where the nullius diocesis is effective. such norm, in the canon law, represents the independence of a church and of the 1 « monasticism has its root in the interpretation of the christian faith developed in the theology of the vi century firstly in orient. analogously to theology and architecture, it is subjected to a deep transformation in occident. [... ] the benedictine order remains for a long time the principal one. hundreds of convents and monasteries are spread across the christian europe and represent cells of christian tradition and faith, of science, and of culture » [ 10 ]. figure 1. the plan of saint gall. related [SEP]
Text from DS:  arXiv:1709.02618v4 [] 18 Sep 2017

The Shape of a Benedictine Monastery:
The SaintGall Ontology
(Extended Version)
Claudia Cantale, a Domenico Cantone, b Manuela Lupica Rinato, c
Marianna Nicolosi-Asmundo, b and Daniele Francesco Santamaria b
a Dept. of Humanities, University of Catania, Italy
b Dept. of Mathematics and Computer Science, University of Catania, Italy
c Officine Culturali, Catania, Italy
Abstract. We present an OWL 2 ontology representing the Saint Gall plan, one of
the most ancient documents arrived intact to us, which describes the ideal model of
a Benedictine monastic complex that inspired the design of many European monasteries.
Keywords. Ontology, OWL 2, Digital Humanities, Benedictine Monasteries.

1. Introduction
Monasteries are conceived by the Benedictine monastic order, founded by Saint Benedict
of Nursia, during the last period of the Western Roman Empire. The monastic shape aims
preserving the European Christianity inside small self-sustaining communities whe
Original label:  math.AC
Predicted label:  6
Correct label:  2
Text:  [CLS] estimation under group actions : recovering orbits from invariants arxiv : 1712. 10163v1 [ ] 29 dec 2017 afonso s. bandeira∗1, 2, ben blum - smith † 1, amelia perry ‡ 3, jonathan weed § 3, and alexander s. wein ¶ k3 1 department of mathematics, courant institute of mathematical sciences, new york university, new york ny, usa 2 center for data science, new york university, new york ny, usa 3 department of mathematics, massachusetts institute of technology, cambridge ma, usa january 1, 2018 abstract motivated by geometric problems in signal processing, computer vision, and structural biology, we study a class of orbit recovery problems where we observe noisy copies of an unknown signal, each acted upon by a random element of some group ( such as z / p or so ( 3 ) ). the goal is to recover the orbit of the signal under the group action. this generalizes problems of interest such as multi - reference alignment ( mra ) and the reconstruction problem in cryo - electron microscopy ( cryo - em ). we obtain matching lower and upper bounds on the sample complexity of these problems in high generality, showing that the statistical difficulty is intricately determined by the invariant theory of the underlying symmetry group. in particular, we determine that for cryo - em with noise variance σ 2 and uniform viewing directions, the number of samples required scales as σ 6. we match this bound with a novel algorithm for ab initio reconstruction in cryo - em, based on invariant features of degree at most 3. we further discuss how to recover multiple molecular structures from heterogeneous cryo - em samples. 1 introduction many computational problems throughout the sciences exhibit rich symmetry and geometry, especially in fields such as signal and image processing, computer vision, and microscopy. this is exemplified in cryoelectron microscopy ( cryo - em ) [ adlm84, ss11, nog16 ], an imaging technique in structural biology that was recently awarded the 2017 nobel prize in chemistry. this technique seeks to estimate the structure of a large biological molecule, such as a protein, from many noisy tomographic projections ( 2 - dimensional images ) of the molecule from random unknown directions in 3 - dimensional space. in cryo - em, our signal of interest is the density θ of the molecule, considered as an element of the vector space of functions on r3. we have access to observations of the following form : our microscopy sample contains many [SEP]
Text from DS:  Estimation under group actions: recovering orbits from invariants

arXiv:1712.10163v1 [] 29 Dec 2017

Afonso S. Bandeira∗1,2 , Ben Blum-Smith†1 , Amelia Perry‡3 , Jonathan Weed§3 , and
Alexander S. Wein¶k3
1

Department of Mathematics, Courant Institute of Mathematical Sciences, New York
University, New York NY, USA
2
Center for Data Science, New York University, New York NY, USA
3
Department of Mathematics, Massachusetts Institute of Technology, Cambridge MA, USA
January 1, 2018

Abstract
Motivated by geometric problems in signal processing, computer vision, and structural biology, we
study a class of orbit recovery problems where we observe noisy copies of an unknown signal, each acted
upon by a random element of some group (such as Z/p or SO(3)). The goal is to recover the orbit of the
signal under the group action. This generalizes problems of interest such as multi-reference alignment
(MRA) and the reconstruction problem in cryo-electron microscopy (cryo-EM). We obtain matching
lo
Original label:  cs.CE
Predicted label:  6
Correct label:  2
Text:  [CLS] automated debugging in java using ocl and jdi * david j. murray lehigh university bethlehem, pa 18015 dama @ lehigh. edu dale e. parson bell labs, lucent technologies allentown, pa 18013 dparson @ lucent. com abstract correctness constraints provide a foundation for automated debugging within object - oriented systems. this paper discusses a new approach to incorporating correctness constraints into java development environments. our approach uses the object constraint language ( “ ocl ” ) as a specification language and the java debug interface ( “ jdi ” ) as a verification api. ocl provides a standard language for expressing object - oriented constraints that can integrate with unified modeling language ( “ uml ” ) software models. jdi provides a standard java api capable of supporting type - safe and side effect free runtime constraint evaluation. the resulting correctness constraint mechanism : ( 1 ) entails no programming language modifications ; ( 2 ) requires neither access nor changes to existing source code ; and ( 3 ) works with standard off - the - shelf java virtual machines ( “ vms ” ). a prototype correctness constraint auditor is presented to demonstrate the utility of this mechanism for purposes of automated debugging. 1 introduction this work arises out of the rteem project at lucent technologies. rteem is a research project relating to the development of a next generation successor to the luxworks family of software tools for embedded system architectures [ 1, 2 ]. within the context of rteem, correctness constraints — in the form of axiomatic assertions — serve two distinct purposes : ( 1 ) they provide a means for specifying and validating the semantics of rteem project components ; and ( 2 ) they address the need for high level language debugging facilities for embedded system architectures. the use of axiomatic assertions to specify the semantics of programming language constructs is hardly a new idea. pioneering work by hoare, among others, demonstrated the utility of axiomatic specification for purposes of reasoning about program correctness [ 3, 4 ]. ultimately, meyer ’ s less formal design by contract methodology paved the way for widespread use of axiomatic assertions in object - oriented systems. as embodied in eiffel, such assertions can be used not only for purposes of specification, but also for purposes of runtime validation [ 5, 6, 7 ]. the design by contract methodology employs three different types of assertions to express correctness constraints for object - oriented programs [SEP]
Text from DS:  AUTOMATED DEBUGGING IN JAVA
USING OCL AND JDI *
David J. Murray
Lehigh University
Bethlehem, PA 18015
dama@lehigh.edu

Dale E. Parson
Bell Labs, Lucent Technologies
Allentown, PA 18013
dparson@lucent.com

Abstract
Correctness constraints provide a foundation for automated debugging within object-oriented
systems. This paper discusses a new approach to incorporating correctness constraints into Java
development environments. Our approach uses the Object Constraint Language (“OCL”) as a
specification language and the Java Debug Interface (“JDI”) as a verification API. OCL provides a
standard language for expressing object-oriented constraints that can integrate with Unified
Modeling Language (“UML”) software models. JDI provides a standard Java API capable of
supporting type-safe and side effect free runtime constraint evaluation. The resulting correctness
constraint mechanism: (1) entails no programming language modifications; (2) requires neither
access nor changes to existing source c
Original label:  math.AC
Predicted label:  1
Correct label:  2
Text:  [CLS] arxiv : 1611. 08881v1 [ ] 27 nov 2016 codualizing modules mohammad rahmani and abdoljavad taherizadeh abstract. let ( r, m ) be a noetherian local ring. in this paper, we introduce a dual notion for dualizing modules, namely codualizing modules. we study the basic properties of codualizing modules and use them to establish an equivalence between the category of noetherian modules of finite projective dimension and the category of artinian modules of finite projective dimension. next, we give some applications of codualizing modules. finally, we present a mixed identity involving quasidualizing module that characterize the codualizing module. as an application, we obtain a necessary and sufficient condition for r to be gorenstein. 1. introduction throughout this paper, ( r, m, k ) is a commutative noetherian local ring with non - zero identity. a finitely generated r - module c is semidualizing if the natural homothety map r −→ hom r ( c, c ) is an isomorphism and ext ir ( c, c ) = 0 for all i > 0. semidualizing modules have been studied by foxby [ 6 ], vasconcelos [ 23 ] and golod [ 8 ]. a semidualizing r - module c is called dualizing if id r ( c ) < ∞. recently, b. kubik [ 12 ], introduced the dual notion of semidualizing modules, namely quasidualizing modules. an artinian r - module b −→ hom r ( t, t ) is an isomorphism t is quasidualizing if the natural homothety map r and ext ir ( t, t ) = 0 for all i > 0. we denote the class of semidualizing and quasidualizing r - modules by s0 ( r ) and q0 ( r ), respectively. in [ 12, theorem 3. 1 ], kubik showed that if r is complete, then the matlis duality functor, that is hom r ( −, e ( k ) ), provides an inverse bijection between s0 ( r ) and q0 ( r ). in theorem 3. 1, we replace e ( k ) with a suitable quasidualizing r - module. more precisely, we prove the following : theorem 1. let c be a [SEP]
Text from DS:  arXiv:1611.08881v1 [] 27 Nov 2016

CODUALIZING MODULES
MOHAMMAD RAHMANI AND ABDOLJAVAD TAHERIZADEH

Abstract. Let (R, m) be a Noetherian local ring. In this paper, we introduce a dual
notion for dualizing modules, namely codualizing modules. We study the basic properties
of codualizing modules and use them to establish an equivalence between the category of
noetherian modules of finite projective dimension and the category of artinian modules
of finite projective dimension. Next, we give some applications of codualizing modules.
Finally, we present a mixed identity involving quasidualizing module that characterize
the codualizing module. As an application, we obtain a necessary and sufficient condition
for R to be Gorenstein.

1. introduction
Throughout this paper, (R, m, k) is a commutative Noetherian local ring with non-zero
identity. A finitely generated R-module C is semidualizing if the natural homothety map
R −→ Hom R (C, C) is an isomorphism and Ext iR (C, C) = 0 for all i > 0. 
Original label:  cs.CV
Predicted label:  6
Correct label:  2
Text:  [CLS] learning to reason : end - to - end module networks for visual question answering ronghang hu1 jacob andreas1 marcus rohrbach1, 2 trevor darrell1 kate saenko3 1 2 3 university of california, berkeley facebook ai research boston university arxiv : 1704. 05526v3 [ ] 11 sep 2017 { ronghang, jda, trevor, rohrbach } @ eecs. berkeley. edu, saenko @ bu. edu abstract natural language questions are inherently compositional, and many are most easily answered by reasoning about their decomposition into modular sub - problems. for example, to answer “ is there an equal number of balls and boxes? ” we can look for balls, look for boxes, count them, and compare the results. the recently proposed neural module network ( nmn ) architecture [ 3, 2 ] implements this approach to question answering by parsing questions into linguistic substructures and assembling question - specific deep networks from smaller modules that each solve one subtask. however, existing nmn implementations rely on brittle off - the - shelf parsers, and are restricted to the module configurations proposed by these parsers rather than learning them from data. in this paper, we propose end - to - end module networks ( n2nmns ), which learn to reason by directly predicting instance - specific network layouts without the aid of a parser. our model learns to generate network structures ( by imitating expert demonstrations ) while simultaneously learning network parameters ( using the downstream task loss ). experimental results on the new clevr dataset targeted at compositional question answering show that n2nmns achieve an error reduction of nearly 50 % relative to state - of - theart attentional approaches, while discovering interpretable network architectures specialized for each question. 1. introduction visual question answering ( vqa ) requires joint comprehension of images and text. this comprehension often depends on compositional reasoning, for example locating multiple objects in a scene and inspecting their properties or comparing them to one another ( figure 1 ). while conventional deep networks have shown promising vqa performance [ 9 ], there is limited evidence that they are capable of explicit compositional reasoning [ 15 ]. much of the success of state - of - the - art approaches to vqa instead comes from their ability to discover statistical biases in the data distribu - there is a shiny object that is right of the gray metallic cylinder ; does it have the same size as the large [SEP]
Text from DS:  Learning to Reason: End-to-End Module Networks
for Visual Question Answering
Ronghang Hu1 Jacob Andreas1 Marcus Rohrbach1,2 Trevor Darrell1 Kate Saenko3
1
2
3
University of California, Berkeley
Facebook AI Research
Boston University

arXiv:1704.05526v3 [] 11 Sep 2017

{ronghang,jda,trevor,rohrbach}@eecs.berkeley.edu, saenko@bu.edu

Abstract
Natural language questions are inherently compositional,
and many are most easily answered by reasoning about their
decomposition into modular sub-problems. For example, to
answer “is there an equal number of balls and boxes?” we
can look for balls, look for boxes, count them, and compare the results. The recently proposed Neural Module Network (NMN) architecture [3, 2] implements this approach to
question answering by parsing questions into linguistic substructures and assembling question-specific deep networks
from smaller modules that each solve one subtask. However,
existing NMN implementations rely on brittle off-the-shelf
parsers, and are rest
Original label:  cs.IT
Predicted label:  7
Correct label:  8
Text:  [CLS] a heuristic algorithm for the bin packing problem with conflicts on interval graphs arxiv : 1707. 00496v2 [ math. co ] 14 sep 2017 tiziano bacci ∗ sara nicoloso † september 15, 2017 abstract in this paper we deal with the bin packing problem with conflicts on interval graphs : given an interval graph, a nonnegative integer weight for each vertex, and a nonnegative integer b, find a partition of the vertex set of the graph into k subsets such that the sum of the weights of the vertices assigned to same subset is less than or equal to b, two vertices connected by an edge do not belong to the same subset, and k is minimum. we design a heuristic algorithm, and propose a new random interval graph generator which builds interval conflict graphs with desired edge density. we test the algorithm on a huge test bed, and compare the results with existing algorithms. keywords : bin packing with conflicts, interval graphs, threshold graphs, random interval graph generator. ∗ universita di roma tor vergata, dipartimento di ingegneria informatica e civile, via del politecnico 1, 00133 roma, italia, bacci. tiziano @ gmail. com † iasi - cnr, via dei taurini 19, 00185 roma, italia, sara. nicoloso @ iasi. cnr. it 1 1 introduction in this paper we deal with the bin packing problem with conflicts ( bp p c ) on interval graphs. bp p c, first introduced in a scheduling context ( jansen and oehring ( 1997 ) ), is defined as follows. given a graph g = ( v, e ), a nonnegative integer weight wi for each vertex i ∈ v, and a nonnegative integer b, find a partition of v into k subsets v1,..., vk, such that the sum of the weights of the vertices assigned to a same subset is less than or equal to b, two vertices connected by an edge do not belong to the same subset, and k is minimum. such minimum value of k will be denoted kbp p c. the graph g = ( v, e ) is called conflict graph and two vertices connected by an edge are said to be in conflict. bp p c is the union of two well known combinatorial optimization problems, the bin packing problem ( bp ) and the vertex coloring problem ( v c ), [SEP]
Text from DS:  A heuristic algorithm for the
Bin Packing Problem with Conflicts
on Interval Graphs
arXiv:1707.00496v2 [math.CO] 14 Sep 2017

Tiziano Bacci

∗

Sara Nicoloso†

September 15, 2017

Abstract
In this paper we deal with the Bin Packing Problem with Conflicts on interval
graphs: given an interval graph, a nonnegative integer weight for each vertex, and a
nonnegative integer B, find a partition of the vertex set of the graph into k subsets
such that the sum of the weights of the vertices assigned to same subset is less
than or equal to B, two vertices connected by an edge do not belong to the same
subset, and k is minimum. We design a heuristic algorithm, and propose a new
random interval graph generator which builds interval conflict graphs with desired
edge density. We test the algorithm on a huge test bed, and compare the results
with existing algorithms.

Keywords: Bin Packing with Conflicts, Interval Graphs, Threshold Graphs, Random
Interval Graph Generator.

∗

Università di Roma Tor 
Original label:  cs.DS
Predicted label:  5
Correct label:  6
Text:  [CLS] investigating mathematical models of immuno - interactions with early - stage cancer under an agent - based modelling perspective grazziela p figueredo * 1, peer - olaf siebers1 and uwe aickelin1'intelligent modelling and analysis research group, school of computer science, the university of nottingham, ng8 1bb, uk email : grazziela p figueredo * - grazziela. figueredo @ nottingham. ac. uk ; peer - olaf siebers - pos @ cs. nott. ac. uk ; uwe aickelin - uxa @ cs. nott. ac. uk ; * corresponding author abstract many advances in research regarding immuno - interactions with cancer were developed with the help of ordinary differential equation ( ode ) models. these models, however, are not effectively capable of representing problems involving individual localisation, memory and emerging properties, which are common characteristics of cells and molecules of the immune system. agent - based modelling and simulation is an alternative paradigm to ode models that overcomes these limitations. in this paper we investigate the potential contribution of agentbased modelling and simulation when compared to ode modelling and simulation. we seek answers to the following questions : is it possible to obtain an equivalent agent - based model from the ode formulation? do the outcomes differ? are there any benefits of using one method compared to the other? to answer these questions, we have considered three case studies using established mathematical models of immune interactions with earlystage cancer. these case studies were re - conceptualised under an agent - based perspective and the simulation results were then compared with those from the ode models. our results show that it is possible to obtain equivalent agent - based models ( i. e. implementing the same mechanisms ) ; the simulation output of both types of models however might differ depending on the attributes of the system to be modelled. in some cases, additional insight from using agent - based modelling was obtained. overall, we can confirm that agent - based modelling is a useful addition to the tool set of immunologists, as it has extra features that allow for simulations with characteristics that are closer to the biological phenomena. 1 introduction advances in cancer immunology have been facilitated by the joint work of immunologists and mathematicians [ 1 – 3 ]. some of the knowledge regarding interactions between the immune system and tumours is a result of using mathematical models. most existing mathematical models in cancer immunology are based on sets of ordinary differential equations ( odes ) [ 2 ]. [SEP]
Text from DS:  Investigating Mathematical Models of Immuno-Interactions
with Early-Stage Cancer under an Agent-Based Modelling
Perspective
Grazziela P Figueredo*1 , Peer-Olaf Siebers1 and Uwe Aickelin1

'Intelligent Modelling and Analysis Research Group, School of Computer Science, The University of Nottingham, NG8 1BB, UK

Email: Grazziela P Figueredo*- grazziela.figueredo@nottingham.ac.uk; Peer-Olaf Siebers - pos@cs.nott.ac.uk; Uwe Aickelin
- uxa@cs.nott.ac.uk;

*

Corresponding author

Abstract
Many advances in research regarding immuno-interactions with cancer were developed with the help of
ordinary differential equation (ODE) models. These models, however, are not effectively capable of representing
problems involving individual localisation, memory and emerging properties, which are common characteristics of
cells and molecules of the immune system. Agent-based modelling and simulation is an alternative paradigm to
ODE models that overcomes these limitations. In this paper we investigate the p
Original label:  cs.NE
Predicted label:  6
Correct label:  2
Text:  [CLS] geometry and expressive power of conditional restricted boltzmann machines guido montufar1, nihat ay1, 2, 3, and keyan ghazi - zahedi1 1 arxiv : 1402. 3346v3 [ ] 12 mar 2015 2 max planck institute for mathematics in the sciences, inselstraße 22, 04103 leipzig, germany department of mathematics and computer science, leipzig university, pf 10 09 20, 04009 leipzig, germany 3 santa fe institute, 1399 hyde park road, santa fe, nm 87501, usa abstract conditional restricted boltzmann machines are undirected stochastic neural networks with a layer of input and output units connected bipartitely to a layer of hidden units. these networks define models of conditional probability distributions on the states of the output units given the states of the input units, parametrized by interaction weights and biases. we address the representational power of these models, proving results their ability to represent conditional markov random fields and conditional distributions with restricted supports, the minimal size of universal approximators, the maximal model approximation errors, and on the dimension of the set of representable conditional distributions. we contribute new tools for investigating conditional probability models, which allow us to improve the results that can be derived from existing work on restricted boltzmann machine probability models. keywords : conditional restricted boltzmann machine, universal approximation, kullback - leibler approximation error, expected dimension 1 introduction restricted boltzmann machines ( rbms ) ( smolensky 1986 ; freund and haussler 1994 ) are generative probability models defined by undirected stochastic networks with bipartite interactions between visible and hidden units. these models are well - known in machine learning applications, where they are used to infer distributed representations of data and to train the layers of deep neural networks ( hinton et al. 2006 ; bengio 2009 ). the restricted connectivity of these networks allows to train them efficiently on the basis of cheap inference and finite gibbs sampling ( hinton 2002 ; 2012 ), even when they are defined with many units and parameters. an rbm defines gibbs - boltzmann probability distributions over the observable states of the network, depending on the interaction weights and biases. an introduction is offered by fischer and igel ( 2012 ). the expressive power of these probability models has attracted much attention and has been studied in numerous papers, treating, in particular, their universal approximation properties ( younes 1996 [SEP]
Text from DS:  Geometry and Expressive Power of
Conditional Restricted Boltzmann Machines
Guido Montúfar1 , Nihat Ay1,2,3 , and Keyan Ghazi-Zahedi1
1

arXiv:1402.3346v3 [] 12 Mar 2015

2

Max Planck Institute for Mathematics in the Sciences, Inselstraße 22, 04103 Leipzig, Germany
Department of Mathematics and Computer Science, Leipzig University, PF 10 09 20, 04009 Leipzig,
Germany
3
Santa Fe Institute, 1399 Hyde Park Road, Santa Fe, NM 87501, USA

Abstract
Conditional restricted Boltzmann machines are undirected stochastic neural networks with a layer
of input and output units connected bipartitely to a layer of hidden units. These networks define
models of conditional probability distributions on the states of the output units given the states of the
input units, parametrized by interaction weights and biases. We address the representational power
of these models, proving results their ability to represent conditional Markov random fields and
conditional distributions with restricted supports, the
Original label:  cs.AI
Predicted label:  8
Correct label:  7
Text:  [CLS] an adaptive prefix - assignment technique for symmetry reduction arxiv : 1706. 08325v1 [ cs. lo ] 26 jun 2017 tommi junttila, matti karppa, petteri kaski, and jukka kohonen abstract. this paper presents a technique for symmetry reduction that adaptively assigns a prefix of variables in a system of constraints so that the generated prefix - assignments are pairwise nonisomorphic under the action of the symmetry group of the system. the technique is based on mckay ’ s canonical extension framework [ j. algorithms 26 ( 1998 ), no. 2, 306 – 324 ]. among key features of the technique are ( i ) adaptability — the prefix sequence can be user - prescribed and truncated for compatibility with the group of symmetries ; ( ii ) parallelisability — prefix - assignments can be processed in parallel independently of each other ; ( iii ) versatility — the method is applicable whenever the group of symmetries can be concisely represented as the automorphism group of a vertex - colored graph ; and ( iv ) implementability — the method can be implemented relying on a canonical labeling map for vertex - colored graphs as the only nontrivial subroutine. to demonstrate the tentative practical applicability of our technique we have prepared a preliminary implementation and report on a limited set of experiments that demonstrate ability to reduce symmetry on hard instances. 1. introduction 1. 1. symmetry reduction. systems of constraints often have substantial symmetry. for example, consider the following system of boolean clauses : ( 1 ) ( x1 ∨ x2 ) ∧ ( x1 ∨ x3 ∨ x5 ) ∧ ( x2 ∨ x4 ∨ x6 ). the associative and commutative symmetries of disjunction and conjunction induce symmetries between the variables of ( 1 ), a fact that can be captured by stating that the group γ generated by the two permutations ( x1 x2 ) ( x3 x4 ) ( x5 x6 ) and ( x4 x6 ) consists of all permutations of the variables that map ( 1 ) to itself. that is, γ is the automorphism group of the system ( 1 ), cf. sect. 2. known symmetry in a constraint system is a great asset from the perspective of solving the system, in particular since symmetry enables one to disregard partial solutions that are isomorphic to each other under the action of γ on the space of partial solutions. techniques [SEP]
Text from DS:  AN ADAPTIVE PREFIX-ASSIGNMENT TECHNIQUE
FOR SYMMETRY REDUCTION

arXiv:1706.08325v1 [cs.LO] 26 Jun 2017

TOMMI JUNTTILA, MATTI KARPPA, PETTERI KASKI, AND JUKKA KOHONEN

Abstract. This paper presents a technique for symmetry reduction that
adaptively assigns a prefix of variables in a system of constraints so that the
generated prefix-assignments are pairwise nonisomorphic under the action of
the symmetry group of the system. The technique is based on McKay’s canonical extension framework [J. Algorithms 26 (1998), no. 2, 306–324]. Among
key features of the technique are (i) adaptability—the prefix sequence can be
user-prescribed and truncated for compatibility with the group of symmetries;
(ii) parallelisability—prefix-assignments can be processed in parallel independently of each other; (iii) versatility—the method is applicable whenever the
group of symmetries can be concisely represented as the automorphism group
of a vertex-colored graph; and (iv) implementability—the method can be i
Original label:  cs.PL
Predicted label:  10
Correct label:  8
Text:  [CLS] arxiv : 1703. 09204v2 [ math. nt ] 1 jan 2018 on period polynomials of degree 2m and weight distributions of certain irreducible cyclic codes ioulia n. baoulina abstract. we explicitly determine the values of reduced cyclotomic periods of order 2m, m ≥ 4, for finite fields of characteristic p ≡ 3 or 5 ( mod 8 ). these evaluations are applied to obtain explicit factorizations of the corresponding reduced period polynomials. as another application, the weight distributions of certain irreducible cyclic codes are described. keywords : cyclotomic period ; f - nomial gaussian period ; period polynomial ; reduced period polynomial ; factorization ; irreducible cyclic code ; weight distribution. mathematics subject classification 2010 : 11l05, 11t22, 11t24, 94b15 1. introduction let fq be a finite field of characteristic p with q = ps elements, f∗q = fq \ { 0 }, and let γ be a fixed generator of the cyclic group f∗q. by tr : fq → fp we denote the 2 s−1 trace mapping, that is, tr ( x ) = x + xp + xp + · · · + xp for x ∈ fq. let e and f be positive integers such that q = ef + 1. denote by h the subgroup of e - th powers in f∗q. for any positive integer n, write ζn = exp ( 2πi / n ). the cyclotomic ( or f - nomial gaussian ) periods of order e for fq with respect to γ are defined by ηj = x ζptr ( x ) x∈γ j h = f −1 x ζptr ( γ eh + j ), j = 0, 1,..., e − 1. h = 0 the reduced cyclotomic ( or reduced f - nomial gaussian ) periods of order e for fq with respect to γ are defined by x j e ζptr ( γ x ) = 1 + eηj, j = 0, 1,..., e − 1. ηj∗ = x∈fq the period polynomial of degree e for fq is the polynomial e−1 y pe ( x ) = ( x − ηj ), j = 0 and the reduced period polynomial of degree e for fq is pe∗ ( x ) e−1 y [SEP]
Text from DS:  arXiv:1703.09204v2 [math.NT] 1 Jan 2018

ON PERIOD POLYNOMIALS OF DEGREE 2m AND WEIGHT
DISTRIBUTIONS OF CERTAIN IRREDUCIBLE CYCLIC CODES
IOULIA N. BAOULINA

Abstract. We explicitly determine the values of reduced cyclotomic periods of
order 2m , m ≥ 4, for finite fields of characteristic p ≡ 3 or 5 (mod 8). These evaluations are applied to obtain explicit factorizations of the corresponding reduced
period polynomials. As another application, the weight distributions of certain
irreducible cyclic codes are described.

Keywords: Cyclotomic period; f -nomial Gaussian period; period polynomial; reduced period polynomial; factorization; irreducible cyclic code; weight distribution.
Mathematics Subject Classification 2010: 11L05, 11T22, 11T24, 94B15
1. Introduction
Let Fq be a finite field of characteristic p with q = ps elements, F∗q = Fq \ {0}, and
let γ be a fixed generator of the cyclic group F∗q . By Tr : Fq → Fp we denote the
2
s−1
trace mapping, that is, Tr(x) = x + xp + xp + · · · + 
Original label:  math.GR
Predicted label:  8
Correct label:  1
Text:  [CLS] arxiv : 1605. 01849v3 [ ] 29 mar 2017 classification of p - groups by their schur multiplier sumana hatui abstract. let g be a non - abelian p - group of order pn and m ( g ) be its 1 schur multiplier. it is well known result by green that | m ( g ) | ≤ p 2 n ( n−1 ). 1 p 2 n ( n−1 ) −t ( g ) so | m ( g ) | = for some t ( g ) ≥ 0. the groups has already been classified for t ( g ) ≤ 5 by several authors. for t ( g ) = 6 the classification has been done in [ 12 ]. in this paper we classify p - groups g for t ( g ) = 6 in different method. 1. introduction the schur multiplier m ( g ) of a group g was introduced by schur [ 1 ] in 1904 on the study of projective representation of groups. 1 for p - groups g of order pn, green [ 3 ] gave an upper bound p 2 n ( n−1 ) for order of 1 the schur multiplier m ( g ). so we have | m ( g ) | = p 2 n ( n−1 ) −t ( g ), for some t ( g ) ≥ 0. now the question comes in our mind that whether it is possible to classify the structure of all p - groups g by the order of the schur multiplier m ( g ), i. e., when t ( g ) is known. several authors have already answered this question. they classified the groups of order pn for t ( g ) ≤ 5 in [ 4, 5, 6, 8, 9 ]. the structure of p - groups with t ( g ) = 6 has been determined in [ 12 ]. in the present paper, we classify the structure 1 of all non - abelian finite p - groups when t ( g ) = 6, i. e. | m ( g ) | = p 2 n ( n−1 ) −6. our method is quite different to that of [ 12 ]. we have stated some structural results of group g with the assumtion t ( g ) = 6. by esp ( p3 ) and esp2 ( p3 ) we denote extra - special p - groups of order p3 having exponent p and p2 respectively. by esp ( p5 [SEP]
Text from DS:  arXiv:1605.01849v3 [] 29 Mar 2017

CLASSIFICATION OF p-GROUPS BY THEIR SCHUR
MULTIPLIER
SUMANA HATUI
Abstract. Let G be a non-abelian p-group of order pn and M (G) be its
1

Schur multiplier. It is well known result by Green that |M (G)| ≤ p 2 n(n−1) .
1
p 2 n(n−1)−t(G)

So |M (G)| =
for some t(G) ≥ 0. The groups has already been
classified for t(G) ≤ 5 by several authors. For t(G) = 6 the classification has
been done in [12]. In this paper we classify p-groups G for t(G) = 6 in different
method.

1. Introduction
The Schur multiplier M (G) of a group G was introduced by Schur [1] in 1904 on
the study of projective representation of groups.
1

For p-groups G of order pn , Green [3] gave an upper bound p 2 n(n−1) for order of
1
the Schur Multiplier M (G). So we have |M (G)| = p 2 n(n−1)−t(G) , for some t(G) ≥ 0.
Now the question comes in our mind that whether it is possible to classify the
structure of all p-groups G by the order of the Schur multiplier M (G), i.e., when
t(G) is known. S
Original label:  math.AC
Predicted label:  5
Correct label:  6
Text:  [CLS] arxiv : 1310. 0414v1 [ math. sg ] 1 oct 2013 an impossibility theorem for linear symplectic circle quotients hans - christian herbig and christopher seaton abstract. we prove that when d > 2, a d - dimensional symplectic quotient 1 at the zero level of a unitary circle representation v such that v s = { 0 } cannot be z - graded regularly symplectomorphic to the quotient of a unitary representations of a finite group. contents 1. introduction acknowledgements 2. background 2. 1. z - graded regular symplectomorphisms 2. 2. results on symplectic circle quotients 3. restriction of regular symplectomorphisms 4. reduction to the case n = 3 5. the case n = 3 5. 1. the hilbert series of m0 5. 2. the hilbert series of c2 / γ 5. 3. elimination of each γ < u2 references 1 3 3 4 6 8 12 15 15 18 19 24 1. introduction let g → u ( v ) be a unitary representation of a compact lie group g on a finite dimensional hermitian vector space ( v, h, i ). by convention, the hermitian scalar product h, i is assumed to be complex antilinear in the first argument. for the infinitesimal action d / dt exp ( −tξ ). v | t = 0 of an element ξ of the lie algebra g of g on an element v ∈ v we write ξ. v. the moment map of the representation is the regular map √ −1 ∗ hv, ξ. vi, j : v → g, v 7→ jξ ( v ) : = ( j ( v ), ξ ) : = 2 2010 mathematics subject classification. primary 53d20, 13a50 ; secondary 57s17. key words and phrases. symplectic reduction, unitary circle representations. the research was supported by the centre for the quantum geometry of moduli spaces, which is funded by the danish national research foundation. in addition, hch was supported by the austrian ministry of science and research bmwf ( start - prize y377 ) and by the grant ga cr p201 / 12 / g028. cs was supported by a rhodes college faculty development grant as well as the e. c. ellett professorship in mathematics. 1 2 hans - christian herbig and christopher seaton where ( j ( v ), [SEP]
Text from DS:  arXiv:1310.0414v1 [math.SG] 1 Oct 2013

AN IMPOSSIBILITY THEOREM FOR LINEAR SYMPLECTIC
CIRCLE QUOTIENTS
HANS-CHRISTIAN HERBIG AND CHRISTOPHER SEATON
Abstract. We prove that when d > 2, a d-dimensional symplectic quotient
1
at the zero level of a unitary circle representation V such that V S = {0}
cannot be Z-graded regularly symplectomorphic to the quotient of a unitary
representations of a finite group.

Contents
1. Introduction
Acknowledgements
2. Background
2.1. Z-graded regular symplectomorphisms
2.2. Results on symplectic circle quotients
3. Restriction of regular symplectomorphisms
4. Reduction to the case n = 3
5. The case n = 3
5.1. The Hilbert series of M0
5.2. The Hilbert series of C2 /Γ
5.3. Elimination of each Γ < U2
References

1
3
3
4
6
8
12
15
15
18
19
24

1. Introduction
Let G → U(V ) be a unitary representation of a compact Lie group G on a finite
dimensional Hermitian vector space (V, h , i). By convention, the Hermitian scalar
product h , i is assumed to be complex a
Original label:  cs.PL
Predicted label:  1
Correct label:  9
Text:  [CLS] digital domain power division multiplexed dual polarization coherent optical ofdm transmission qiong wu1, zhenhua feng1, ming tang1 *, xiang li2, ming luo2, huibin zhou1, songnian fu1, and deming liu1 1 wuhan national lab for optoelectronics ( wnlo ) & national engineering laboratory for next generation internet access system, school of optical and electronic information, huazhong university of science and technology, wuhan, 430074, china 2 state key laboratory of optical communication technologies and networks, wuhan research institute of post and telecommunication, wuhan 430074, hubei, china * tangming @ mail. hust. edu. cn abstract capacity is the eternal pursuit for communication systems due to the overwhelming demand of bandwidth hungry applications. as the backbone infrastructure of modern communication networks, the optical fiber transmission system undergoes a significant capacity growth over decades by exploiting available physical dimensions ( time, frequency, quadrature, polarization and space ) of the optical carrier for multiplexing. for each dimension, stringent orthogonality must be guaranteed for perfect separation of independent multiplexed signals. to catch up with the ever - increasing capacity requirement, it is therefore interesting and important to develop new multiplexing methodologies relaxing the orthogonal constraint thus achieving better spectral efficiency and more flexibility of frequency reuse. inspired by the idea of non - orthogonal multiple access ( noma ) scheme, here we propose a digital domain power division multiplexed ( pdm ) transmission technology which is fully compatible with current dual polarization ( dp ) coherent optical communication system. the coherent optical orthogonal frequency division multiplexing ( co - ofdm ) modulation has been employed owing to its great superiority on high spectral efficiency, flexible coding, ease of channel estimation and robustness against fiber dispersion. and a pdm - dp - co - ofdm has been theoretically and experimentally demonstrated with 100gb / s wavelength division multiplexing ( wdm ) transmission over 1440km standard single mode fibers ( ssmfs ). two baseband quadrature phase shift keying ( qpsk ) ofdm signals are overlaid together with different power levels. after iq modulation, polarization multiplexing and long distance fiber transmission, the pdm - dp - co - ofdm signal has been successfully recovered in the typical polarization diversity coherent receiver by successive interference cancellation ( sic ) algorithm. non - orthogonal overlaid signals different in power double the system spectral efficiency and [SEP]
Text from DS:  Digital Domain Power Division Multiplexed Dual
Polarization Coherent Optical OFDM Transmission
Qiong Wu1, Zhenhua Feng1, Ming Tang1*, Xiang Li2, Ming Luo2, Huibin Zhou1, Songnian
Fu1, and Deming Liu1
1

Wuhan National Lab for Optoelectronics (WNLO) & National Engineering Laboratory for Next Generation
Internet Access System, School of Optical and Electronic Information, Huazhong University of Science and
Technology, Wuhan, 430074, China
2
State Key Laboratory of Optical Communication Technologies and Networks, Wuhan Research Institute of Post
and Telecommunication, Wuhan 430074, Hubei, China
* tangming@mail.hust.edu.cn

ABSTRACT
Capacity is the eternal pursuit for communication systems due to the overwhelming demand of bandwidth
hungry applications. As the backbone infrastructure of modern communication networks, the optical fiber
transmission system undergoes a significant capacity growth over decades by exploiting available physical
dimensions (time, frequency, quadrature, polarizati
Original label:  math.ST
Predicted label:  9
Correct label:  8
Text:  [CLS] the shape of data and probability measures diego h. dıaz martıneza, facundo memolib, washington mioa arxiv : 1509. 04632v2 [ stat. ml ] 28 feb 2017 a department of mathematics, florida state university, tallahassee, fl 32306 - 4510 usa b department of mathematics, ohio state university, columbus, oh 43210 - 1174 usa abstract we introduce the notion of multiscale covariance tensor fields ( ctf ) associated with euclidean random variables as a gateway to the shape of their distributions. multiscale ctfs quantify variation of the data about every point in the data landscape at all spatial scales, unlike the usual covariance tensor that only quantifies global variation about the mean. empirical forms of localized covariance previously have been used in data analysis and visualization, for example, in local principal component analysis, but we develop a framework for the systematic treatment of theoretical questions and mathematical analysis of computational models. we prove strong stability theorems with respect to the wasserstein distance between probability measures, obtain consistency results for estimators, as well as bounds on the rate of convergence of empirical ctfs. these results show that ctfs are robust to sampling, noise and outliers. we provide numerous illustrations of how ctfs let us extract shape from data and also apply ctfs to manifold clustering, the problem of categorizing data points according to their noisy membership in a collection of possibly intersecting smooth submanifolds of euclidean space. we prove that the proposed manifold clustering method is stable and carry out several experiments to illustrate the method. keywords : shape of data, multiscale data analysis, covariance fields, frechet functions, manifold clustering 1. introduction probing, analyzing and visualizing the shape of complex data are challenges that are magnified by the intricate dependence of their structural properties, as basic as dimensionality, on location and scale ( cf. [ 1 ] ). as such, resolving and integrating the geometry and topology of data across scales are 1 problems of foremost importance. in this paper, we develop the notion of multiscale covariance tensor fields ( ctf ) associated with euclidean random variables and show that many properties of the shape of their distributions become accessible through ctfs, which provide stable representations that can be estimated reliably from data. for a random vector y ∈ rd, scale dependence is controlled by a kernel function k ( x, y [SEP]
Text from DS:  The Shape of Data and Probability Measures
Diego H. Dı́az Martı́neza , Facundo Mémolib , Washington Mioa

arXiv:1509.04632v2 [stat.ML] 28 Feb 2017

a

Department of Mathematics, Florida State University, Tallahassee, FL 32306-4510 USA
b
Department of Mathematics, Ohio State University, Columbus, OH 43210-1174 USA

Abstract
We introduce the notion of multiscale covariance tensor fields (CTF) associated with Euclidean random variables as a gateway to the shape of their
distributions. Multiscale CTFs quantify variation of the data about every
point in the data landscape at all spatial scales, unlike the usual covariance tensor that only quantifies global variation about the mean. Empirical
forms of localized covariance previously have been used in data analysis and
visualization, for example, in local principal component analysis, but we develop a framework for the systematic treatment of theoretical questions and
mathematical analysis of computational models. We prove strong stability
t
Original label:  cs.AI
Predicted label:  3
Correct label:  1
Text:  [CLS] measuring catastrophic forgetting in neural networks ronald kemker, marc mcclure, angelina abitino, tyler hayes, christopher kanan chester f. carlson center for imaging science rochester institute of technology 54 lomb memorial drive rochester ny 14623 abstract deep neural networks are used in many state - of - the - art systems for machine perception. once a network is trained to do a specific task, e. g., bird classification, it cannot easily be trained to do new tasks, e. g., incrementally learning to recognize additional bird species or learning an entirely different task such as flower recognition. when new tasks are added, typical deep neural networks are prone to catastrophically forgetting previous tasks. networks that are capable of assimilating new information incrementally, much like how humans form new memories over time, will be more efficient than retraining the model from scratch each time a new task needs to be learned. there have been multiple attempts to develop schemes that mitigate catastrophic forgetting, but these methods have not been directly compared, the tests used to evaluate them vary considerably, and these methods have only been evaluated on small - scale problems ( e. g., mnist ). in this paper, we introduce new metrics and benchmarks for directly comparing five different mechanisms designed to mitigate catastrophic forgetting in neural networks : regularization, ensembling, rehearsal, dual - memory, and sparse - coding. our experiments on real - world images and sounds show that the mechanism ( s ) that are critical for optimal performance vary based on the incremental training paradigm and type of data being used, but they all demonstrate that the catastrophic forgetting problem has yet to be solved. introduction while the basic architecture and training algorithms behind deep neural networks ( dnns ) are over 30 years old, interest in them has never been greater in both industry and the artificial intelligence research community. owing to far larger datasets, increases in computational power, and innovations in activation functions, dnns have achieved near - human or super - human abilities on a number of problems, including image classification ( he et al. 2016 ), speech - to - text ( khilari and bhope 2015 ), and face identification ( schroff, kalenichenko, and philbin 2015 ). these algorithms power most of the recent advances in semantic segmentation ( long, shelhamer, and darrell 2015 ), visual question answering ( kafle and kanan 2017 ), and reinforcement learning ( mnih et al. [SEP]
Text from DS:  Measuring Catastrophic Forgetting in Neural Networks
Ronald Kemker, Marc McClure, Angelina Abitino, Tyler Hayes, Christopher Kanan
Chester F. Carlson Center for Imaging Science
Rochester Institute of Technology
54 Lomb Memorial Drive
Rochester NY 14623

Abstract
Deep neural networks are used in many state-of-the-art systems for machine perception. Once a network is trained to
do a specific task, e.g., bird classification, it cannot easily be
trained to do new tasks, e.g., incrementally learning to recognize additional bird species or learning an entirely different
task such as flower recognition. When new tasks are added,
typical deep neural networks are prone to catastrophically forgetting previous tasks. Networks that are capable of assimilating new information incrementally, much like how humans
form new memories over time, will be more efficient than retraining the model from scratch each time a new task needs
to be learned. There have been multiple attempts to develop
schemes that
Original label:  cs.PL
Predicted label:  8
Correct label:  5
Text:  [CLS] uav - enabled wireless power transfer : trajectory design and energy region characterization jie xu1, yong zeng2, and rui zhang2 of information engineering, guangdong university of technology 2 department of electrical and computer engineering, national university of singapore e - mail : jiexu @ gdut. edu. cn, { elezeng, elezhang } @ nus. edu. sg arxiv : 1706. 07010v1 [ ] 21 jun 2017 1 school abstract — this paper studies a new unmanned aerial vehicle ( uav ) - enabled wireless power transfer ( wpt ) system, where a uav - mounted energy transmitter ( et ) broadcasts wireless energy to charge distributed energy receivers ( ers ) on the ground. in particular, we consider a basic two - user scenario, and investigate how the uav can optimally exploit its mobility to maximize the amount of energy transferred to the two ers during a given charging period. we characterize the achievable energy region of the two ers, by optimizing the uav ’ s trajectory subject to a maximum speed constraint. we show that when the distance between the two ers is smaller than a certain threshold, the boundary of the energy region is achieved when the uav hovers above a fixed location between them for all time ; while when their distance is larger than the threshold, to achieve the boundary of the energy region, the uav in general needs to hover and fly between two different locations above the line connecting them. numerical results show that the optimized uav trajectory can significantly improve the wpt efficiency and fairness of the two ers, especially when the uav ’ s maximum speed is large and / or the charging duration is long. index terms — wireless power transfer, unmanned aerial vehicle ( uav ), energy region, trajectory design. i. i ntroduction radio frequency ( rf ) transmission enabled wireless power transfer ( wpt ) has been regarded as a promising technique to provide perpetual and cost - effective energy supplies to lowpower wireless networks ( see, e. g., [ 1 ], [ 2 ] and the references therein ). in conventional wpt systems, dedicated energy transmitters ( ets ) are usually deployed at fixed locations to charge distributed energy receivers ( ers ) such as low - power sensors and internet - of - things ( iot ) devices, etc. however, due to the severe propagation loss of rf signals over distance, the performance of practical wpt [SEP]
Text from DS:  UAV-Enabled Wireless Power Transfer: Trajectory
Design and Energy Region Characterization
Jie Xu1 , Yong Zeng2, and Rui Zhang2
of Information Engineering, Guangdong University of Technology
2 Department of Electrical and Computer Engineering, National University of Singapore
E-mail: jiexu@gdut.edu.cn, {elezeng, elezhang}@nus.edu.sg

arXiv:1706.07010v1 [] 21 Jun 2017

1 School

Abstract—This paper studies a new unmanned aerial vehicle
(UAV)-enabled wireless power transfer (WPT) system, where a
UAV-mounted energy transmitter (ET) broadcasts wireless energy
to charge distributed energy receivers (ERs) on the ground. In
particular, we consider a basic two-user scenario, and investigate
how the UAV can optimally exploit its mobility to maximize the
amount of energy transferred to the two ERs during a given
charging period. We characterize the achievable energy region
of the two ERs, by optimizing the UAV’s trajectory subject to
a maximum speed constraint. We show that when the distance
betw
Original label:  math.GR
Predicted label:  10
Correct label:  8
Text:  [CLS] arxiv : 1703. 01282v1 [ ] 3 mar 2017 invariant random subgroups of semidirect products ian biringer∗, lewis bowen † and omer tamuz ‡ march 6, 2017 abstract we study invariant random subgroups ( irss ) of semidirect products g = a [UNK] γ. in particular, we characterize all irss of parabolic subgroups of sld ( r ), and show that all ergodic irss of rd [UNK] sld ( r ) are either of the form rd [UNK] k for some irs of sld ( r ), or are induced from irss of λ [UNK] sl ( λ ), where λ < rd is a lattice. contents 1 introduction 1. 1 irss of special affine groups........................... 1. 2 irss of parabolic subgroups of sld ( r )..................... 1. 3 plan of the paper................................. 1 2 3 5 2 irss in general semidirect 2. 1 the cocycle sh..... 2. 2 group actions preserving 2. 3 transverse irss..... 5 5 6 7 products............................. finite measures................................................. 3 irss of parabolic subgroups 9 4 irss of special affine groups 12 1 introduction let g be a locally compact, second countable group and let subg be the space of closed subgroups of g, considered with the chabauty topology [ 9 ]. ∗ boston college. supported in part by nsf grant dms - 1611851 and career award dms - 1654114. university of texas at austin. supported in part by nsf grant dms - 0968762, nsf career award dms - 0954606 and bsf [SEP]
Text from DS:  arXiv:1703.01282v1 [] 3 Mar 2017

Invariant random subgroups of semidirect products
Ian Biringer∗, Lewis Bowen†and Omer Tamuz‡
March 6, 2017

Abstract
We study invariant random subgroups (IRSs) of semidirect products G = A ⋊ Γ. In
particular, we characterize all IRSs of parabolic subgroups of SLd (R), and show that
all ergodic IRSs of Rd ⋊ SLd (R) are either of the form Rd ⋊ K for some IRS of SLd (R),
or are induced from IRSs of Λ ⋊ SL(Λ), where Λ < Rd is a lattice.

Contents
1 Introduction
1.1 IRSs of special affine groups . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.2 IRSs of parabolic subgroups of SLd (R) . . . . . . . . . . . . . . . . . . . . .
1.3 Plan of the paper . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1
2
3
5

2 IRSs in general semidirect
2.1 The cocycle SH . . . . .
2.2 Group actions preserving
2.3 Transverse IRSs . . . . .

5
5
6
7

products
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
finite measures . . . . . . . . . . . .
Original label:  cs.SY
Predicted label:  7
Correct label:  8
Text:  [CLS] 1 decentralized and distributed temperature control via hvac systems in energy efficient buildings arxiv : 1702. 03308v1 [ ] 10 feb 2017 xuan zhang, wenbo shi, bin yan, ali malkawi and na li abstract — in this paper, we design real - time decentralized and distributed control schemes for heating ventilation and air conditioning ( hvac ) systems in energy efficient buildings. the control schemes balance user comfort and energy saving, and are implemented without measuring or predicting exogenous disturbances. firstly, we introduce a thermal dynamic model of building systems and formulate a steady - state resource allocation problem, which aims to minimize the aggregate deviation between zone temperatures and their set points, as well as the building energy consumption, subject to practical operating constraints, by adjusting zone flow rates. because this problem is nonconvex, we propose two methods to ( approximately ) solve it and to design the real - time control. in the first method, we present a convex relaxation approach to solve an approximate version of the steady - state optimization problem, where the heat transfer between neighboring zones is ignored. we prove the tightness of the relaxation and develop a real - time decentralized algorithm to regulate the zone flow rate. in the second method, we introduce a mild assumption under which the original optimization problem becomes convex, and then a real - time distributed algorithm is developed to regulate the zone flow rate. in both cases, the thermal dynamics can be driven to equilibria which are optimal solutions to those associated steady - state optimization problems. finally, numerical examples are provided to illustrate the effectiveness of the designed control schemes. index terms — temperature control, hvac systems, convex relaxation, distributed / decentralized control, gradient algorithms. i. i ntroduction it is reported that buildings are responsible for 40 % of energy consumption, 70 % of electricity consumption, and result in 30 % of greenhouse gas emission [ 1 ]. roughly speaking, heating ventilation and air conditioning ( hvac ) systems in buildings account for 40 % of the energy use [ 2 ]. therefore, making hvac systems more energy efficient is urgent for improving environmental sustainability. to date, various control techniques have been developed for hvac systems, including gain scheduling, optimal control, robust control, nonlinear adaptive control, model predictive control ( mpc ), intelligent control based on artificial neural network, fuzzy logic, and genetic algorithm, and so forth [ 3 ] – [ 7 ]. compared with the conventional on / off plus proportionalsome of [SEP]
Text from DS:  1

Decentralized and Distributed Temperature Control
via HVAC Systems in Energy Efficient Buildings

arXiv:1702.03308v1 [] 10 Feb 2017

Xuan Zhang, Wenbo Shi, Bin Yan, Ali Malkawi and Na Li

Abstract—In this paper, we design real-time decentralized and
distributed control schemes for Heating Ventilation and Air
Conditioning (HVAC) systems in energy efficient buildings. The
control schemes balance user comfort and energy saving, and
are implemented without measuring or predicting exogenous
disturbances. Firstly, we introduce a thermal dynamic model of
building systems and formulate a steady-state resource allocation
problem, which aims to minimize the aggregate deviation between
zone temperatures and their set points, as well as the building
energy consumption, subject to practical operating constraints,
by adjusting zone flow rates. Because this problem is nonconvex,
we propose two methods to (approximately) solve it and to
design the real-time control. In the first method, we present 
Original label:  cs.PL
Predicted label:  2
Correct label:  10
Text:  [CLS] 1 on the achievable spectral efficiency of spatial modulation aided downlink non - orthogonal multiple access arxiv : 1705. 06466v1 [ ] 18 may 2017 xuesi wang, student member, ieee, jintao wang, senior member, ieee, longzhuang he, student member, ieee, zihan tang, student member, ieee, and jian song, fellow, ieee abstract — in this paper, a novel spatial modulation aided nonorthogonal multiple access ( sm - noma ) system is proposed. we use mutual information ( mi ) to characterize the achievable spectral efficiency ( se ) of the proposed sm - noma system. due to the finite - alphabet space - domain inputs employed by sm, the expression of the corresponding mi lacks a closed - form formulation. hence, a lower bound is proposed to quantify the mi of the sm - noma system. furthermore, its asymptotic property is also theoretically investigated in both low and high signal - tonoise ratio ( snr ) regions. the se performance and its analysis of our proposed sm - noma system are confirmed by simulation results. index terms — non - orthogonal multiple access ( noma ) ; spatial modulation ( sm ) ; spectral efficiency ( se ) ; mutual information ( mi ) ; lower bound. i. i ntroduction non - orthogonal multiple access ( noma ) constitutes a promising technique in the fifth - generation ( 5g ) mobile networks [ 1 ]. different from the traditional orthogonal multiple access ( oma ), different users are designed to access the same time, frequency and code domain resources, but different power levels in noma. compared to oma, noma is more flexible and is capable of offering a higher sum rate and lower outage probability [ 1 ] [ 2 ]. moreover, the combination of noma and multiple - input multiple - output ( mimo ) has recently attracted substantial research interest [ 3 ]. however, in conventional mimo systems, the simultaneous use of multiple transmit antennas ( tas ) requires a large amount of radio frequency ( rf ) chains, which significantly increases the corresponding power dissipation and the implementation complexity. to circumvent this problem, spatial modulation ( sm ) technique has recently been applied to mimo systems [ 4 ] - [ 7 ]. in conventional sm, only one ta is activated for each symbol ’ s transmission, hence, only one single rf chain is needed. since the active antenna is uniform - randomly selected from [SEP]
Text from DS:  1

On the Achievable Spectral Efficiency of Spatial
Modulation Aided Downlink Non-Orthogonal
Multiple Access
arXiv:1705.06466v1 [] 18 May 2017

Xuesi Wang, Student Member, IEEE, Jintao Wang, Senior Member, IEEE,
Longzhuang He, Student Member, IEEE, Zihan Tang, Student Member, IEEE, and Jian Song, Fellow, IEEE

Abstract—In this paper, a novel spatial modulation aided nonorthogonal multiple access (SM-NOMA) system is proposed.
We use mutual information (MI) to characterize the achievable
spectral efficiency (SE) of the proposed SM-NOMA system. Due
to the finite-alphabet space-domain inputs employed by SM,
the expression of the corresponding MI lacks a closed-form
formulation. Hence, a lower bound is proposed to quantify the MI
of the SM-NOMA system. Furthermore, its asymptotic property
is also theoretically investigated in both low and high signal-tonoise ratio (SNR) regions. The SE performance and its analysis
of our proposed SM-NOMA system are confirmed by simulation
results.
Index Ter
Original label:  cs.PL
Predicted label:  10
Correct label:  7
Text:  [CLS] 1 exponent function for one helper source coding problem at rates outside the rate region arxiv : 1504. 05891v5 [ ] 12 jan 2018 yasutada oohama abstract — we consider the one helper source coding problem posed and investigated by ahlswede, korner and wyner. two correlated sources are separately encoded and are sent to a destination where the decoder wishes to decode one of the two sources with an arbitrary small error probability of decoding. in this system, the error probability of decoding goes to one as the source block length n goes to infinity. this implies that we have a strong converse theorem for the one helper source coding problem. in this paper we provide the much stronger version of this strong converse theorem for the one helper source coding problem. we prove that the error probability of decoding tends to one exponentially and derive an explicit lower bound of this exponent function. index terms — one helper source coding problem, strong converse theorem, exponent of correct probability of decoding i. i ntroduction we consider the one helper source coding problem posed and investigated by ahlswede, korner and wyner. two correlated sources are separately encoded and are sent to a destination where the decoder wishes to decode one of the two sources with an arbitrary small error probability of decoding. in this system, the error probability of decoding goes to one as the source block length n goes to infinity. this implies that we have a strong converse theorem for the one helper source coding problem. in this paper we provide the much stronger version of this strong converse theorem for the one helper source coding problem. we prove that the error probability of decoding tends to one exponentially and derive an explicit lower bound of this exponent function. ii. p roblem f ormulation ∞ { ( xt, yt ) } t = 1 let x and y be finite sets and be a stationary discrete memoryless source. for each t = 1, 2, · · ·, the random pair ( xt, yt ) takes values in x × y, and has a probability distribution pxy = { pxy ( x, y ) } ( x, y ) ∈x ×y ∞ we write n independent copies of { xt } ∞ t = 1 and { yt } t = 1, respectively as x n = x1, x2, · · ·, xn and y n = y [SEP]
Text from DS:  1

Exponent Function for One Helper Source Coding
Problem at Rates outside the Rate Region

arXiv:1504.05891v5 [] 12 Jan 2018

Yasutada Oohama

Abstract—We consider the one helper source coding problem
posed and investigated by Ahlswede, Körner and Wyner. Two
correlated sources are separately encoded and are sent to a
destination where the decoder wishes to decode one of the two
sources with an arbitrary small error probability of decoding.
In this system, the error probability of decoding goes to one as
the source block length n goes to infinity. This implies that we
have a strong converse theorem for the one helper source coding
problem. In this paper we provide the much stronger version of
this strong converse theorem for the one helper source coding
problem. We prove that the error probability of decoding tends
to one exponentially and derive an explicit lower bound of this
exponent function.
Index Terms—One helper source coding problem, strong converse theorem, exponent of correc
Original label:  math.AC
Predicted label:  7
Correct label:  3
Text:  [CLS] on bezout inequalities for non - homogeneous polynomial ideals∗ amir hashemi ( a ), joos heintz ( b ), luis miguel pardo ( c ), pablo solerno ( d ) arxiv : 1701. 04341v1 [ cs. sc ] 16 jan 2017 ( a ) department of mathematical sciences, isfahan university of technology, isfahan, 84156 - 83111, iran school of mathematics, institute for research in fundamental sciences ( ipm ), tehran, 19395 - 5746, iran ( b ) departamento de computacion and icc, uba - conicet, facultad de ciencias exactas y naturales, universidad de buenos aires, ciudad universitaria, 1428, buenos aires, argentina ( c ) depto. de matematicas, estadıstica y computacion facultad de ciencias, universidad de cantabria, avda. los castros s / n e - 39071 santander, spain ( d ) departamento de matematica and imas, uba - conicet, facultad de ciencias exactas y naturales, universidad de buenos aires, ciudad universitaria, 1428, buenos aires, argentina e - mail addresses : amir. hashemi @ cc. iut. ac. ir, joos @ dc. uba. ar, luis. pardo @ unican. es, psolerno @ dm. uba. ar january 17, 2017 abstract we introduce a “ workable ” notion of degree for non - homogeneous polynomial ideals and formulate and prove ideal theoretic bezout inequalities for the sum of two ideals in terms of this notion of degree and the degree of generators. we compute probabilistically the degree of an equidimensional ideal. keywords. non - homogeneous polynomial ideal, ideal degree, idealistic bezout inequality. msc 13f20, 14a10, 13p10 introduction motivated by the aim to formulate and prove an idealistic version of bezout ’ s theorem ( see [ 18 ] ) and by applications to transcendence theory ( see [ 15, 4 ] ), the notion of degree of ∗ partially supported by the following iranian, argentinean and spanish grants : ipm no. 95550420 ( a. h ), ubacyt 2002 [SEP]
Text from DS:  On Bézout Inequalities for non-homogeneous Polynomial
Ideals∗
Amir Hashemi(a) , Joos Heintz(b) , Luis Miguel Pardo(c) , Pablo Solernó(d)

arXiv:1701.04341v1 [cs.SC] 16 Jan 2017

(a) Department of Mathematical Sciences, Isfahan University of Technology,
Isfahan, 84156-83111, Iran
School of Mathematics, Institute for Research in Fundamental Sciences (IPM),
Tehran, 19395-5746, Iran
(b) Departamento de Computación and ICC, UBA-CONICET,
Facultad de Ciencias Exactas y Naturales, Universidad de Buenos Aires,
Ciudad Universitaria, 1428, Buenos Aires, Argentina
(c) Depto. de Matemáticas, Estadı́stica y Computación Facultad de Ciencias,
Universidad de Cantabria, Avda. Los Castros s/n E-39071 Santander, Spain
(d) Departamento de Matemática and IMAS, UBA-CONICET,
Facultad de Ciencias Exactas y Naturales, Universidad de Buenos Aires,
Ciudad Universitaria, 1428, Buenos Aires, Argentina
E-mail addresses:
Amir.Hashemi@cc.iut.ac.ir, joos@dc.uba.ar, luis.pardo@unican.es, psolerno@dm.uba.ar

Januar
Original label:  math.ST
Predicted label:  4
Correct label:  8
Text:  [CLS] note on information bias and efficiency of composite likelihood arxiv : 1612. 06967v1 [ ] 21 dec 2016 ximing xu, nancy reid and libai xu abstract does the asymptotic variance of the maximum composite likelihood estimator of a parameter of interest always decrease when the nuisance parameters are known? will a composite likelihood necessarily become more efficient by incorporating additional independent component likelihoods, or by using component likelihoods with higher dimension? in this note we show through illustrative examples that the answer to both questions is no, and indeed the opposite direction might be observed. the role of information bias is highlighted to understand the occurrence of these paradoxical phenomenon. key words : pairwise likelihood ; estimating function ; bartlett ’ s second identity ; godambe information matrix ; nuisance parameter. 1 introduction the likelihood function for a complex multivariate model may not be available or very difficult to evaluate, and a composite likelihood function constructed from low - dimensional marginal or conditional distributions has become a popular alternative ( varin, 2008 ; varin, reid & firth, 2011 ). suppose y is a p - dimensional random vector with prob1 ability density function f ( y ; θ ), with a q - dimensional parameter vector θ ∈ θ. given a set of likelihood functions lk ( θ ; y ), k = 1,..., k, defined by the joint or conditional densities of some sub - vectors of y, the composite likelihood function ( lindsay, 1988 ) is defined as cl ( θ ; y ) = k y lk ( θ ; y ) wk, k = 1 where the wk ’ s are nonnegative weights and the component likelihood lk ( θ ; y ) might depend only on a sub - vector of θ. the choice of lk ( θ ; y ) and the weights { wk } is critical for improving the efficiency of the resulting statistical inference ( lindsay, 1988 ; joe & lee, 2009 ; lindsay, yi & sun, 2011 ). in this paper we focus on the two most commonly used composite likelihood functions in literature, independence likelihood and pairwise likelihood, which are defined as clind ( θ ; y ) = qp−1 qp r = 1 s = r + 1 qp r = 1 f ( yr ; θ ) and clpair ( θ ; y ) = f ( yr, ys ; θ ), respectively. given a random sample { y ( 1 ),..., y [SEP]
Text from DS:  Note on information bias and efficiency of composite
likelihood

arXiv:1612.06967v1 [] 21 Dec 2016

Ximing Xu, Nancy Reid and Libai Xu

Abstract
Does the asymptotic variance of the maximum composite likelihood estimator of
a parameter of interest always decrease when the nuisance parameters are known?
Will a composite likelihood necessarily become more efficient by incorporating additional independent component likelihoods, or by using component likelihoods with
higher dimension? In this note we show through illustrative examples that the answer to both questions is no, and indeed the opposite direction might be observed.
The role of information bias is highlighted to understand the occurrence of these
paradoxical phenomenon.
Key words: Pairwise likelihood; estimating function; Bartlett’s second identity;
Godambe information matrix; nuisance parameter.

1

Introduction

The likelihood function for a complex multivariate model may not be available or very difficult to evaluate, and a co
Original label:  math.AC
Predicted label:  9
Correct label:  5
Text:  [CLS] arxiv : 1210. 1284v1 [ ] 4 oct 2012 factorization from a poset - theoretic view i ∗ † zike deng abstract : we introduce b - ideals and based on them establish several necessary and sufficient conditions for an element of a monoid to be decomposed into a least common multiple of infinite or a finite number of powers of prime factors. besides, we introduce a sort of galois connection relating them to divisorial ideals. 1 introduction the objective of this treatise, which consists of two parts, is to investigate factorization in a monoid by means of the relation of divisibility mainly, while the multiplication plays a secondary roll. or rather, what relates to factorization is something essentially posettheoretic, which through connection of order with operation transforms into an algebraic result. we are partly inspired in ideas by [ 1, 5 ] and in techniques by [ 2, 6 ] so as to do this. we introduce b - ideals, which connect decomposition with complete distributivity [ 3 ], as the tool and establish a sort of galois connection relating them to divisorial integral ideals [ 1 ]. as early as in the thirties of last century it was recognized that factorization in itself referred to multiplication and dispensed with addition, however, factorization in a monoid is a problem which has not yet been solved up to now because no ideal is available. here there is divisibility only that remains. based on it we reduce the original problem to the posettheoretic one and solve it. then we transform the results back into the algebraic ones. in contrast, we view an ideal as an element of a monoid and so its decomposition also becomes factorization. b - ideal, in case of a domain, relates to a divisorial integral ideal through a galois connection and hence it is in a sense a generalization of the latter to a monoid. b - ideal also relates to the dual of a filtre in topology. jb is the analogue of the dual of open neighborhood base, of the kernel of a valuation restricted to its ring in the poset - theoretic setting respectively. b - ideals can avoid the same set of factors determining different ideals and different sets of factors determining the same divisorial ideal. that is why they work in factorization. we study arbitrary decomposition, i. e., a least common multiple of infinite or a finite number of powers [SEP]
Text from DS:  arXiv:1210.1284v1 [] 4 Oct 2012

Factorization from a poset-theoretic view I

∗†

Zike Deng

Abstract: We introduce B-ideals and based on them establish several necessary and sufficient conditions for an element of a monoid to be decomposed into a least common multiple
of infinite or a finite number of powers of prime factors. Besides, we introduce a sort of
Galois connection relating them to divisorial ideals.

1

Introduction

The objective of this treatise, which consists of two parts, is to investigate factorization
in a monoid by means of the relation of divisibility mainly, while the multiplication plays
a secondary roll. Or rather, what relates to factorization is something essentially posettheoretic, which through connection of order with operation transforms into an algebraic
result. We are partly inspired in ideas by [1,5] and in techniques by [2,6] so as to do this.
We introduce B-ideals, which connect decomposition with complete distributivity [3], as the
tool and establish
Original label:  cs.AI
Predicted label:  5
Correct label:  9
Text:  [CLS] under review as a conference paper at iclr 2018 h ierarchical and i nterpretable s kill acqui sition in m ulti - task r einforcement l earning tianmin shu∗ university of california, los angeles tianmin. shu @ ucla. edu caiming xiong † & richard socher salesforce research { cxiong, rsocher } @ salesforce. com arxiv : 1712. 07294v1 [ ] 20 dec 2017 a bstract learning policies for complex tasks that require multiple different skills is a major challenge in reinforcement learning ( rl ). it is also a requirement for its deployment in real - world scenarios. this paper proposes a novel framework for efficient multi - task reinforcement learning. our framework trains agents to employ hierarchical policies that decide when to use a previously learned policy and when to learn a new skill. this enables agents to continually acquire new skills during different stages of training. each learned task corresponds to a human language description. because agents can only access previously learned skills through these descriptions, the agent can always provide a human - interpretable description of its choices. in order to help the agent learn the complex temporal dependencies necessary for the hierarchical policy, we provide it with a stochastic temporal grammar that modulates when to rely on previously learned skills and when to execute new skills. we validate our approach on minecraft games designed to explicitly test the ability to reuse previously learned skills while simultaneously learning new skills. 1 i ntroduction deep reinforcement learning has demonstrated success in policy search for tasks in domains like game playing ( mnih et al., 2015 ; silver et al., 2016 ; 2017 ; kempka et al., 2016 ; mirowski et al., 2017 ) and robotic control ( levine et al., 2016a ; b ; pinto & gupta, 2016 ). however, it is very difficult to accumulate multiple skills using just one policy network teh et al. ( 2017 ). knowledge transfer techniques like distillation ( bengio, 2012 ; rusu et al., 2016 ; parisotto et al., 2016 ; teh et al., 2017 ) have been applied to train a policy network both to learn new skills while preserving previously learned skill as well as to combine single - task policies into a multi - task policy. existing approaches usually treat all tasks independently. this often prevents full exploration of the underlying relations between different tasks. they also typically assume that all policies share the same state space and action space [SEP]
Text from DS:  Under review as a conference paper at ICLR 2018

H IERARCHICAL AND I NTERPRETABLE S KILL ACQUI SITION IN M ULTI - TASK R EINFORCEMENT L EARNING
Tianmin Shu∗
University of California, Los Angeles
tianmin.shu@ucla.edu

Caiming Xiong†& Richard Socher
Salesforce Research
{cxiong, rsocher}@salesforce.com

arXiv:1712.07294v1 [] 20 Dec 2017

A BSTRACT
Learning policies for complex tasks that require multiple different skills is a major
challenge in reinforcement learning (RL). It is also a requirement for its deployment in real-world scenarios. This paper proposes a novel framework for efficient
multi-task reinforcement learning. Our framework trains agents to employ hierarchical policies that decide when to use a previously learned policy and when to
learn a new skill. This enables agents to continually acquire new skills during different stages of training. Each learned task corresponds to a human language description. Because agents can only access previously learned skills through these
d
Original label:  cs.CV
Predicted label:  5
Correct label:  3
Text:  [CLS] an evolutionary computing enriched rs attack resilient medical image steganography model for telemedicine applications romany f. mansour elsaid md. abdelrahim department of mathematics faculty of science, new valley, assiut university assiut, egypt romanyf @ aun. edu. eg department of mathematics computer science division, faculty of science, tanta university, tanta, egypt elsaid _ abdelrahim @ yahoo. com abstract — the recent advancement in computing technologies and resulting vision based applications have gives rise to a novel practice called telemedicine that requires patient diagnosis images or allied information to recommend or even perform diagnosis practices being located remotely. however, to ensure accurate and optimal telemedicine there is the requirement of seamless or flawless biomedical information about patient. on the contrary, medical data transmitted over insecure channel often remains prone to get manipulated or corrupted by attackers. the existing cryptosystems alone are not sufficient to deal with these issues and hence in this paper a highly robust reversible image steganography model has been developed for secret information hiding. unlike traditional wavelet transform techniques, we incorporated discrete ripplet transformation ( drt ) technique for message embedding in the medical cover images. in addition, to assure seamless communication over insecure channel, a dual cryptosystem model containing proposed steganography scheme and rsa cryptosystem has been developed. one of the key novelties of the proposed research work is the use of adaptive genetic algorithm ( aga ) for optimal pixel adjustment process ( opap ) that enriches data hiding capacity as well as imperceptibility features. the performance assessment reveals that the proposed steganography model outperforms other wavelet transformation based approaches in terms of high psnr, embedding capacity, imperceptibility etc. keywords — medical image steganography ; ripplet transform ; adaptive genetic algorithm ; opap ; telemedicine. i. introduction the high pace emergence in technologies and associated computing approaches have given rise to a broad horizon serving an array of applications among which medical image communication is one of the dominating one. in present day health care system, biomedical image transmission has become one of the inevitable needs to ensure efficient seamless and secure data transmission over uncertain channels. presently, the telemedicine field has gained impressive momentum, which has enabled efficient and timely diagnosis remotely. however, the probable adversaries caused due to ( image ) information deviation could [SEP]
Text from DS:  An Evolutionary Computing Enriched RS Attack
Resilient Medical Image Steganography Model for
Telemedicine Applications
Romany F. Mansour

Elsaid MD. Abdelrahim

Department of Mathematics
Faculty of Science, New Valley, Assiut University
Assiut, Egypt
romanyf@aun.edu.eg

Department of Mathematics
Computer Science Division, Faculty of Science,
Tanta University, Tanta, Egypt
elsaid_abdelrahim@yahoo.com

Abstract—The recent advancement in computing technologies
and resulting vision based applications have gives rise to a novel
practice called telemedicine that requires patient diagnosis images
or allied information to recommend or even perform diagnosis
practices being located remotely. However, to ensure accurate and
optimal telemedicine there is the requirement of seamless or
flawless biomedical information about patient. On the contrary,
medical data transmitted over insecure channel often remains
prone to get manipulated or corrupted by attackers. The existing
cryptosystems alone are n
Original label:  cs.NE
Predicted label:  7
Correct label:  10
Text:  [CLS] hello edge : keyword spotting on microcontrollers yundong zhang1, 2, naveen suda1, liangzhen lai1 and vikas chandra1 arxiv : 1711. 07128v3 [ cs. sd ] 14 feb 2018 2 1 arm, san jose, ca stanford university, stanford, ca abstract keyword spotting ( kws ) is a critical component for enabling speech based user interactions on smart devices. it requires real - time response and high accuracy for good user experience. recently, neural networks have become an attractive choice for kws architecture because of their superior accuracy compared to traditional speech processing algorithms. due to its always - on nature, kws application has highly constrained power budget and typically runs on tiny microcontrollers with limited memory and compute capability. the design of neural network architecture for kws must consider these constraints. in this work, we perform neural network architecture evaluation and exploration for running kws on resource - constrained microcontrollers. we train various neural network architectures for keyword spotting published in literature to compare their accuracy and memory / compute requirements. we show that it is possible to optimize these neural network architectures to fit within the memory and compute constraints of microcontrollers without sacrificing accuracy. we further explore the depthwise separable convolutional neural network ( ds - cnn ) and compare it against other neural network architectures. ds - cnn achieves an accuracy of 95. 4 %, which is ~ 10 % higher than the dnn model with similar number of parameters. 1 introduction deep learning algorithms have evolved to a stage where they have surpassed human accuracies in a variety of cognitive tasks including image classification [ 1 ] and conversational speech recognition [ 2 ]. motivated by the recent breakthroughs in deep learning based speech recognition technologies, speech is increasingly becoming a more natural way to interact with consumer electronic devices, for example, amazon echo, google home and smart phones. however, always - on speech recognition is not energy - efficient and may also cause network congestion to transmit continuous audio stream from billions of these devices to the cloud. furthermore, such a cloud based solution adds latency to the application, which hurts user experience. there are also privacy concerns when audio is continuously transmitted to the cloud. to mitigate these concerns, the devices first detect predefined keyword ( s ) such as " alexa ", " ok google ", " hey siri ", etc., which is commonly known as [SEP]
Text from DS:  Hello Edge: Keyword Spotting on Microcontrollers
Yundong Zhang1,2 , Naveen Suda1 , Liangzhen Lai1 and Vikas Chandra1

arXiv:1711.07128v3 [cs.SD] 14 Feb 2018

2

1
Arm, San Jose, CA
Stanford University, Stanford, CA

Abstract
Keyword spotting (KWS) is a critical component for enabling speech based user
interactions on smart devices. It requires real-time response and high accuracy for
good user experience. Recently, neural networks have become an attractive choice
for KWS architecture because of their superior accuracy compared to traditional
speech processing algorithms. Due to its always-on nature, KWS application has
highly constrained power budget and typically runs on tiny microcontrollers with
limited memory and compute capability. The design of neural network architecture
for KWS must consider these constraints. In this work, we perform neural network
architecture evaluation and exploration for running KWS on resource-constrained
microcontrollers. We train various neural network 
Original label:  cs.NE
Predicted label:  9
Correct label:  8
Text:  [CLS] pasmoqap : a parallel asynchronous memetic algorithm for solving the multi - objective quadratic assignment problem claudio sanhueza∗, francia jimenez∗, regina berretta∗ and pablo moscato∗ ∗ school arxiv : 1706. 08700v1 [ ] 27 jun 2017 of electrical engineering and computing, the university of newcastle, callaghan, nsw, australia. emails : { claudio. sanhuezalobos, francia. jimenezfuentes } @ uon. edu. au, { regina. berretta, pablo. moscato } @ newcastle. edu. au abstract — multi - objective optimization problems ( mops ) have attracted growing attention during the last decades. multiobjective evolutionary algorithms ( moeas ) have been extensively used to address mops because are able to approximate a set of non - dominated high - quality solutions. the multi - objective quadratic assignment problem ( mqap ) is a mop. the mqap is a generalization of the classical qap which has been extensively studied, and used in several real - life applications. the mqap is defined as having as input several flows between the facilities which generate multiple cost functions that must be optimized simultaneously. in this study, we propose pas m o qap, a parallel asynchronous memetic algorithm to solve the multi - objective quadratic assignment problem. pas m o qap is based on an island model that structures the population by creating subpopulations. the memetic algorithm on each island individually evolve a reduced population of solutions, and they asynchronously cooperate by sending selected solutions to the neighboring islands. the experimental results show that our approach significatively outperforms all the island - based variants of the multi - objective evolutionary algorithm nsga - ii. we show that pas m o qap is a suitable alternative to solve the multi - objective quadratic assignment problem. keywords — multi - objective optimization ; parallel island model ; memetic algorithms. i. i ntroduction mathematical models based on multi - objective optimization problems ( mops ) have been extensively used to address real - world applications [ 3 ], [ 17 ]. in mops, the task we face is to simultaneously satisfy multiple and possibly conflicting objectives. multi - objective evolutionary algorithms ( moeas ) have received especial attention because they are well - suited to tackle a wide variety of mops [ 28 ], [SEP]
Text from DS:  PasMoQAP: A Parallel Asynchronous Memetic
Algorithm for solving the Multi-Objective Quadratic
Assignment Problem
Claudio Sanhueza∗ , Francia Jiménez∗ , Regina Berretta∗ and Pablo Moscato∗
∗ School

arXiv:1706.08700v1 [] 27 Jun 2017

of Electrical Engineering and Computing, The University of Newcastle, Callaghan, NSW, Australia.
Emails: {claudio.sanhuezalobos, francia.jimenezfuentes}@uon.edu.au, {regina.berretta, pablo.moscato}@newcastle.edu.au
Abstract—Multi-Objective Optimization Problems (MOPs)
have attracted growing attention during the last decades. MultiObjective Evolutionary Algorithms (MOEAs) have been extensively used to address MOPs because are able to approximate a
set of non-dominated high-quality solutions. The Multi-Objective
Quadratic Assignment Problem (mQAP) is a MOP. The mQAP is
a generalization of the classical QAP which has been extensively
studied, and used in several real-life applications. The mQAP is
defined as having as input several flows between the facilitie
Original label:  cs.PL
Predicted label:  1
Correct label:  9
Text:  [CLS] 1 ultra - reliable short - packet communications : half - duplex or full - duplex relaying? arxiv : 1711. 08199v1 [ ] 22 nov 2017 yifan gu, he chen, yonghui li and branka vucetic abstract — this letter analyzes and compares the performance of full - duplex relaying ( fdr ) and half - duplex relaying ( hdr ) for ultra - reliable short - packet communications. specifically, we derive both approximate and asymptotic closed - form expressions of the block error rate ( bler ) for fdr and hdr using short packets with finite blocklength codes. we define and attain a closed - form expression of a critical bler, which can be used to efficiently determine the optimal duplex mode for ultra - reliable low latency communication scenarios. our results unveil that fdr is more appealing to the system with relatively lower transmit power constraint, less stringent bler requirement and stronger loop interference suppression. index terms — ultra - reliable, low latency, short - packet communication, finite blocklength, full - duplex relay. i. i ntroduction in conventional wireless systems, extremely long packet has been used in coding and transmission. however, to support ultra - reliable low latency communications ( urllc ) as a new service type of 5g cellular systems [ 1 ], short - packet transmissions are essential. in this case, errors cannot be reduced to arbitrarily low for a given coding rate due to the limited packet size. motivated by this, [ 2 ] developed a new fundamental framework for short - packet communications and derived an error probability bound for a given blocklength and coding rate. it was shown that the block error rate ( bler ) increases as the blocklength of the system decreases. this new theoretical framework opens a new research direction for the revisit of conventional communication networks, which were mainly designed based on the shannon formula and thus cannot be directly applied to short - packet communications. references [ 3 ], [ 4 ] investigated a classical three node cooperative network under finite blocklenth regime with static and quasi - static channel conditions. it was shown that there exists a performance tradeoff between cooperative and noncooperative communications : on the one hand, a relay can boost the power gains of both hops and thus improve the system performance ; on the other hand, it can degrade the system performance by halving the blocklength of [SEP]
Text from DS:  1

Ultra-Reliable Short-Packet Communications:
Half-Duplex or Full-Duplex Relaying?

arXiv:1711.08199v1 [] 22 Nov 2017

Yifan Gu, He Chen, Yonghui Li and Branka Vucetic

Abstract—This letter analyzes and compares the performance
of full-duplex relaying (FDR) and half-duplex relaying (HDR)
for ultra-reliable short-packet communications. Specifically, we
derive both approximate and asymptotic closed-form expressions
of the block error rate (BLER) for FDR and HDR using short
packets with finite blocklength codes. We define and attain a
closed-form expression of a critical BLER, which can be used to
efficiently determine the optimal duplex mode for ultra-reliable
low latency communication scenarios. Our results unveil that
FDR is more appealing to the system with relatively lower
transmit power constraint, less stringent BLER requirement and
stronger loop interference suppression.
Index Terms—Ultra-reliable, low latency, short-packet communication, finite blocklength, full-duplex relay.

I
Original label:  cs.SY
Predicted label:  8
Correct label:  5
Text:  [CLS] control of nonlinear switched systems based on validated simulation arxiv : 1611. 06692v1 [ ] 21 nov 2016 adrien le coent? a, julien alexandre dit sandretto b, alexandre chapoutot b, laurent fribourg c a b cmla, ens cachan, cnrs, universite paris - saclay, 61 av. du president wilson, 94235 cachan cedex, france u2is, ensta paristech, universite paris - saclay, 828, boulevard des marechaux, 91762 palaiseau cedex, france c lsv, ens cachan, cnrs, universite paris - saclay, 61 av. du president wilson, 94235 cachan cedex, france abstract we present an algorithm of control synthesis for nonlinear switched systems, based on an existing procedure of state - space bisection and made available for nonlinear systems with the help of validated simulation. the use of validated simulation also permits to take bounded perturbations and varying parameters into account. it is particularly interesting for safety critical applications, such as in aeronautical, military or medical fields. the whole approach is entirely guaranteed and the induced controllers are correct - by - design. key words : nonlinear control systems, reachability, formal methods, numerical simulation, control system synthesis 1 introduction we focus here on switched control systems, a class of hybrid systems recently used with success in various domains such as automotive industry and power electronics. these systems are merely described by piecewise dynamics, periodically sampled with a given period. at each period, the system is in one and only one mode, decided by a control rule [ 14, 23 ]. moreover, the considered systems can switch between any two modes instantaneously. this simplification can be easily by - passed by the addition of intermediate facticious modes. in this paper, we consider that these modes are represented by nonlinear odes. in order to compute the control of a switched system, we do need the solution of differential equations. in the general case, differential equations can not be integrated formally, and a numerical in? this paper was not presented at any ifac meeting. a short version of this paper appeared in snr ’ 16 [ 9 ]. corresponding author a. le coent tel. + 33147407429. email addresses : adrien. le - coent @ ens - cachan. fr ( adrien le coent? ), alexandre [SEP]
Text from DS:  Control of Nonlinear Switched Systems Based on Validated
Simulation

arXiv:1611.06692v1 [] 21 Nov 2016

Adrien Le Coënt? a , Julien Alexandre dit Sandretto b , Alexandre Chapoutot b ,
Laurent Fribourg c
a
b

CMLA, ENS Cachan, CNRS, Université Paris-Saclay, 61 av. du Président Wilson, 94235 Cachan Cedex, France

U2IS, ENSTA ParisTech, Université Paris-Saclay, 828, Boulevard des Maréchaux, 91762 Palaiseau Cedex, France
c

LSV, ENS Cachan, CNRS, Université Paris-Saclay, 61 av. du Président Wilson, 94235 Cachan Cedex, France

Abstract
We present an algorithm of control synthesis for nonlinear switched systems, based on an existing procedure of state-space
bisection and made available for nonlinear systems with the help of validated simulation. The use of validated simulation also
permits to take bounded perturbations and varying parameters into account. It is particularly interesting for safety critical
applications, such as in aeronautical, military or medical fields. The whole app
Original label:  math.GR
Predicted label:  2
Correct label:  9
Text:  [CLS] arxiv : 1711. 01881v3 [ math. lo ] 25 feb 2018 finite rank and pseudofinite groups daniel palacin abstract. it is proven that an inﬁnite ﬁnitely generated group cannot be elementarily equivalent to an ultraproduct of ﬁnite groups of a given prufer rank. furthermore, it is shown that an inﬁnite ﬁnitely generated group of ﬁnite prufer rank is not pseudoﬁnite. 1. introduction a pseudofinite group is an infinite model of the first - order theory of finite groups, or equivalently, an infinite group is pseudofinite if it is elementary equivalent to an ultraproduct of finite groups. in a similar way, one can define pseudofinite fields, which were first considered by ax [ 1 ]. these two notions are closely related as exhibited by wilson in [ 17 ], who showed that a simple pseudofinite group is elementarily equivalent to a chevalley group over a pseudofinite field. furthermore, it was later observed by ryten [ 13 ] that it is even isomorphic to such a group, see [ 3, proposition 2. 14 ( i ) ] for a more detailed argument. in a pseudofinite group any definable map is injective if and only if it is surjective. hence, it can be easily noticed, by considering the definable map x 7→ n · x for a suitable positive integer n, that an infinite finitely generated abelian group is not pseudofinite. consequently, since centralizers of nonidentity elements in free groups are infinite cyclic groups, free groups, and in particular finitely generated ones, are not pseudofinite. in fact, sabbagh raised the following question, which so far remains open : question. are there infinite finitely generated groups which are pseudofinite? one can of course reformulate this question and ask which families of finite groups admit an ultraproduct elementarily equivalent to an infinite finitely generated group. using deep results from finite group theory, ould houcine and point [ 11 ] have made substantial progress in this direction and towards the understanding of the structure of a possible example. they showed date : february 27, 2018. 2010 mathematics subject classification. 20a05, 03c60. key words and phrases. pseudoﬁnite group, finite generation, prufer rank. research partially [SEP]
Text from DS:  arXiv:1711.01881v3 [math.LO] 25 Feb 2018

FINITE RANK AND PSEUDOFINITE GROUPS
DANIEL PALACÍN

Abstract. It is proven that an inﬁnite ﬁnitely generated group cannot
be elementarily equivalent to an ultraproduct of ﬁnite groups of a given
Prüfer rank. Furthermore, it is shown that an inﬁnite ﬁnitely generated
group of ﬁnite Prüfer rank is not pseudoﬁnite.

1. Introduction
A pseudofinite group is an infinite model of the first-order theory of finite
groups, or equivalently, an infinite group is pseudofinite if it is elementary
equivalent to an ultraproduct of finite groups. In a similar way, one can
define pseudofinite fields, which were first considered by Ax [1]. These two
notions are closely related as exhibited by Wilson in [17], who showed that
a simple pseudofinite group is elementarily equivalent to a Chevalley group
over a pseudofinite field. Furthermore, it was later observed by Ryten [13]
that it is even isomorphic to such a group, see [3, Proposition 2.14(i)] for a
more detaile
Original label:  cs.DS
Predicted label:  4
Correct label:  0
Text:  [CLS] compact representation of photosynthesis dynamics by rule - based models ( full version ) l. brim, j. niznan, d. safranek ∗ arxiv : 1410. 3632v1 [ q - bio. mn ] 14 oct 2014 faculty of informatics, masaryk university brno, czech republic safranek @ fi. muni. cz traditional mathematical models of photosynthesis are based on mass action kinetics of light reactions. this approach requires the modeller to enumerate all the possible state combinations of the modelled chemical species. this leads to combinatorial explosion in the number of reactions although the structure of the model could be expressed more compactly. we explore the use of rule - based modelling, in particular, a simplified variant of kappa, to compactly capture and automatically reduce existing mathematical models of photosynthesis. finally, the reduction procedure is implemented in bionetgen language and demonstrated on several ode models of photosynthesis processes. this is an extended version of the paper published in proceedings of 5th international workshop on static analysis and systems biology ( sasb ) 2014. 1 introduction photosynthesis is one of the most important biophysical processes driving life on earth. most life forms, including humans, depend on photosynthesis that transforms energy of solar radiation into energy - rich organic matter, releases oxygen that we breathe, and removes excess carbon dioxide from the atmosphere that would threaten the earth ’ s energy balance. adding to the relevance of photosynthesis, significant expectations emerged lately in connection with potential human interventions in the global carbon cycle – among the considered alternatives are the higher generation biofuels [ 1 ] or biomineralization by pointsource carbon capture [ 10 ]. current coarse - grained mathematical models of photosynthesis [ 12 ] cover the known parts of the entire process. they build up the light reactions dynamics from simplified interactions on and inbetween complicated protein complexes involved in the transfer of the energy from light into the cell. many different local modifications at these protein structures are traversed after reception of the photon. to capture the process mechanistically, many elementary chemical reactions connect together to form the model. each effective structure combination has to be enumerated in order to assign the appropriate kinetic laws. this inevitable expansion then leads to combinatorial explosion in the number of possible complexes. in [ 21 ] we have developed an online repository for mathematical models of photosynthesis. that effort has opened many questions regarding the differing levels of available models and [SEP]
Text from DS:  Compact Representation of Photosynthesis Dynamics by
Rule-based Models (Full Version)
L. Brim, J. Nižnan, D. Šafránek ∗

arXiv:1410.3632v1 [q-bio.MN] 14 Oct 2014

Faculty of Informatics, Masaryk University
Brno, Czech Republic
safranek@fi.muni.cz

Traditional mathematical models of photosynthesis are based on mass action kinetics of light reactions. This approach requires the modeller to enumerate all the possible state combinations of
the modelled chemical species. This leads to combinatorial explosion in the number of reactions
although the structure of the model could be expressed more compactly. We explore the use of
rule-based modelling, in particular, a simplified variant of Kappa, to compactly capture and automatically reduce existing mathematical models of photosynthesis. Finally, the reduction procedure
is implemented in BioNetGen language and demonstrated on several ODE models of photosynthesis
processes. This is an extended version of the paper published in proceedings of
Original label:  math.ST
Predicted label:  3
Correct label:  10
Text:  [CLS] nonparametric shape - restricted regression arxiv : 1709. 05707v1 [ ] 17 sep 2017 adityanand guntuboyina∗ and bodhisattva sen † department of statistics university of california at berkeley 423 evans hall berkeley, ca 94720 e - mail : aditya @ stat. berkeley. edu department of statistics columbia university 1255 amsterdam avenue new york, ny 10027 e - mail : bodhi @ stat. columbia. edu abstract : we consider the problem of nonparametric regression under shape constraints. the main examples include isotonic regression ( with respect to any partial order ), unimodal / convex regression, additive shape - restricted regression, and constrained single index model. we review some of the theoretical properties of the least squares estimator ( lse ) in these problems, emphasizing on the adaptive nature of the lse. in particular, we study the risk behavior of the lse, and its pointwise limiting distribution theory, with special emphasis to isotonic regression. we survey various methods for constructing pointwise confidence intervals around these shape - restricted functions. we also briefly discuss the computation of the lse and indicate some open research problems and future directions. keywords and phrases : adaptive risk bounds, bootstrap, chernoff ’ s distribution, convex regression, isotonic regression, likelihood ratio test, monotone function, order preserving function estimation, projection on a closed convex set, tangent cone. 1. introduction in nonparametric shape - restricted regression the observations { ( xi, yi ) : i = 1,..., n } satisfy yi = f ( xi ) + εi, for i = 1,..., n, ( 1 ) where x1,..., xn are design points in some space ( e. g., rd, d ≥ 1 ), ε1,..., εn are unobserved mean - zero errors, and the real - valued regression function f is unknown but obeys certain known qualitative restrictions like monotonicity, convexity, etc. let f denote the class of all such regression functions. letting θ∗ : = ( f ( x1 ),..., f ( xn ) ), y : = ( y1,..., yn ) and ε : = ( ε1,..., εn ), model ( 1 ) may be rewritten as y = θ∗ + ε, ( 2 [SEP]
Text from DS:  Nonparametric Shape-restricted Regression

arXiv:1709.05707v1 [] 17 Sep 2017

Adityanand Guntuboyina∗ and Bodhisattva Sen†
Department of Statistics
University of California at Berkeley
423 Evans Hall
Berkeley, CA 94720
e-mail: aditya@stat.berkeley.edu
Department of Statistics
Columbia University
1255 Amsterdam Avenue
New York, NY 10027
e-mail: bodhi@stat.columbia.edu
Abstract: We consider the problem of nonparametric regression under shape constraints. The main examples include isotonic regression (with respect to any partial order), unimodal/convex regression, additive shape-restricted regression, and constrained
single index model. We review some of the theoretical properties of the least squares
estimator (LSE) in these problems, emphasizing on the adaptive nature of the LSE. In
particular, we study the risk behavior of the LSE, and its pointwise limiting distribution theory, with special emphasis to isotonic regression. We survey various methods
for constructing pointwise confidenc
Original label:  cs.SY
Predicted label:  6
Correct label:  5
Text:  [CLS] arxiv : 1711. 03026v1 [ ] 8 nov 2017 intelligent fault analysis in electrical power grids biswarup bhattacharya abhishek sinha department of computer science university of southern california los angeles, ca 90089. usa. email : bbhattac @ usc. edu adobe systems incorporated noida, up 201301. india. email : abhishek. sinha94 @ gmail. com abstract — power grids are one of the most important components of infrastructure in today ’ s world. every nation is dependent on the security and stability of its own power grid to provide electricity to the households and industries. a malfunction of even a small part of a power grid can cause loss of productivity, revenue and in some cases even life. thus, it is imperative to design a system which can detect the health of the power grid and take protective measures accordingly even before a serious anomaly takes place. to achieve this objective, we have set out to create an artificially intelligent system which can analyze the grid information at any given time and determine the health of the grid through the usage of sophisticated formal models and novel machine learning techniques like recurrent neural networks. our system simulates grid conditions including stimuli like faults, generator output fluctuations, load fluctuations using siemens pss / e software and this data is trained using various classifiers like svm, lstm and subsequently tested. the results are excellent with our methods giving very high accuracy for the data. this model can easily be scaled to handle larger and more complex grid architectures. i. i ntroduction power grids are now been considered to be one of the important components of infrastructure on which the modern society depends. the primary objective of power system operation is to supply uninterrupted power to the customers. but small and large scale faults and disturbances in the grid often cause power outages and thereby affect the system reliability and customer satisfaction. electrical power grids are huge systems, especially at the national level. the “ synchrophasors project ” in india [ 1 ] has been deployed with the help of which system operators are now able to monitor the magnitude and angle of each phase of the three phase voltage and current, frequency, rate of change of frequency and angular separation at every few millisecond intervals ( 40 milliseconds ) at a load dispatch centre ( ldc ). thus the transient or dynamic behavior of the power system can be observed in near real - time at [SEP]
Text from DS:  arXiv:1711.03026v1 [] 8 Nov 2017

Intelligent Fault Analysis in Electrical Power Grids
Biswarup Bhattacharya

Abhishek Sinha

Department of Computer Science
University of Southern California
Los Angeles, CA 90089. USA.
Email: bbhattac@usc.edu

Adobe Systems Incorporated
Noida, UP 201301. India.
Email: abhishek.sinha94@gmail.com

Abstract—Power grids are one of the most important components of infrastructure in today’s world. Every nation is dependent on the security and stability of its own power grid to provide
electricity to the households and industries. A malfunction of
even a small part of a power grid can cause loss of productivity,
revenue and in some cases even life. Thus, it is imperative to
design a system which can detect the health of the power grid
and take protective measures accordingly even before a serious
anomaly takes place. To achieve this objective, we have set out
to create an artificially intelligent system which can analyze the
grid information at any given time
Original label:  cs.CV
Predicted label:  7
Correct label:  8
Text:  [CLS] iet research journals multi - view pose estimation with mixtures - of - parts and adaptive viewpoint selection issn 1751 - 8644 doi : 0000000000 www. ietdl. org emre dogan1, 2, 3∗ gonen eren3 christian wolf1, 2 eric lombardi1 atilla baskurt1, 2 1 universite de lyon, cnrs insa - lyon, liris, umr cnrs 5205, f - 69621, france 3 galatasaray university, dept. of comp. eng., 36 ciragan cd, istanbul 34349, turkey * e - mail : edogan @ gsu. edu. tr arxiv : 1709. 08527v1 [ ] 25 sep 2017 2 abstract : we propose a new method for human pose estimation which leverages information from multiple views to impose a strong prior on articulated pose. the novelty of the method concerns the types of coherence modelled. consistency is maximised over the different views through different terms modelling classical geometric information ( coherence of the resulting poses ) as well as appearance information which is modelled as latent variables in the global energy function. moreover, adequacy of each view is assessed and their contributions are adjusted accordingly. experiments on the humaneva and umpm datasets show that the proposed method significantly decreases the estimation error compared to single - view results. this paper is a preprint of a paper submitted to iet computer vision. if accepted, the copy of record will be available at the iet digital library. 1 introduction human pose estimation is a building block in many industrial applications such as human - computer interaction, motion capture systems, etc. whereas the problem has been almost solved for easy instances, such as cooperative settings in close distance and depth data without occlusions, other realistic configurations still present a significant challenge. in particular, pose estimation from rgb input in non - cooperative settings remains a difficult problem. methods range from unstructured and purely discriminative approaches in simple tasks on depth data, which allow real - time performance on low - cost hardware, up to complex methods imposing strong priors on pose. the latter are dominant on the more difficult rgb data but also increasingly popular on depth. these priors are often modelled as kinematic trees ( as in the proposed method ) or, using inverse rendering as geometric parametric models ( see section 2 for related works ). in this paper, we leverage the information from multiple [SEP]
Text from DS:  IET Research Journals

Multi-view pose estimation with
mixtures-of-parts and adaptive viewpoint
selection

ISSN 1751-8644
doi: 0000000000
www.ietdl.org

Emre Dogan1,2,3∗ Gonen Eren3 Christian Wolf1,2 Eric Lombardi1 Atilla Baskurt1,2
1

Université de Lyon, CNRS
INSA-Lyon, LIRIS, UMR CNRS 5205, F-69621, France
3
Galatasaray University, Dept. of Comp. Eng., 36 Ciragan Cd, Istanbul 34349, Turkey
* E-mail: edogan@gsu.edu.tr

arXiv:1709.08527v1 [] 25 Sep 2017

2

Abstract: We propose a new method for human pose estimation which leverages information from multiple views to impose a
strong prior on articulated pose. The novelty of the method concerns the types of coherence modelled. Consistency is maximised
over the different views through different terms modelling classical geometric information (coherence of the resulting poses) as
well as appearance information which is modelled as latent variables in the global energy function. Moreover, adequacy of each
view is assessed and their contribu
Original label:  cs.IT
Predicted label:  0
Correct label:  4
Text:  [CLS] arxiv : 1609. 03993v1 [ ] 13 sep 2016 a generic bet - and - run strategy for speeding up traveling salesperson and minimum vertex cover∗ tobias friedrich1, timo kotzing1, markus wagner2 1 hasso plattner institute, potsdam, germany 2 optimisation and logistics, the university of adelaide, adelaide, australia note : this article is currently under review. september 14, 2016 abstract a common strategy for improving optimization algorithms is to restart the algorithm when it is believed to be trapped in an inferior part of the search space. however, while specific restart strategies have been developed for specific problems ( and specific algorithms ), restarts are typically not regarded as a general tool to speed up an optimization algorithm. in fact, many optimization algorithms do not employ restarts at all. recently, bet - and - run was introduced in the context of mixed - integer programming, where first a number of short runs with randomized initial conditions is made, and then the most promising run of these is continued. in this article, we consider two classical np - complete combinatorial optimization problems, traveling salesperson and minimum vertex cover, and study the effectiveness of different bet - and - run strategies. in particular, our restart strategies do not take any problem knowledge into account, nor are tailored to the optimization algorithm. therefore, they can be used off - the - shelf. we observe that state - of - the - art solvers for these problems can benefit significantly from restarts on standard benchmark instances. 1 introduction when a desktop pc is not working properly, the default answer of an experienced system administrator is restarting it. the same holds for stochastic algorithms and randomized search heuristics : if we are not satisfied with the result, we might just try restarting the algorithm again and again. while thish is well - known [ 16, 18 ], very few algorithms directly incorporate such restart strategies. we assume that this is due to the ∗ this work has been supported by the arc discovery early career researcher award de160100850. 1 added complexity of designing an appropriate restart strategy that is advantageous for the considered algorithm. hence, it would be beneficial to have a generic framework for restart strategies which is not overly dependent on the exact algorithm used or the problem under consideration. in this paper we want to show that there are restart strategies which are of benefit in a variety of settings. there are some theories on how to choose optimal restart strategies, independently of the setting. [SEP]
Text from DS:  arXiv:1609.03993v1 [] 13 Sep 2016

A Generic Bet-and-run Strategy for Speeding Up
Traveling Salesperson and Minimum Vertex
Cover∗
Tobias Friedrich1 , Timo Kötzing1 , Markus Wagner2
1
Hasso Plattner Institute, Potsdam, Germany
2
Optimisation and Logistics, The University of Adelaide, Adelaide, Australia
Note: this article is currently under review.
September 14, 2016

Abstract
A common strategy for improving optimization algorithms is to restart the algorithm when it is believed to be trapped in an inferior part of the search space.
However, while specific restart strategies have been developed for specific problems (and specific algorithms), restarts are typically not regarded as a general tool
to speed up an optimization algorithm. In fact, many optimization algorithms do
not employ restarts at all.
Recently, bet-and-run was introduced in the context of mixed-integer programming, where first a number of short runs with randomized initial conditions is
made, and then the most promisin
Original label:  cs.AI
Predicted label:  2
Correct label:  9
Text:  [CLS] arxiv : 1803. 05027v1 [ ] 11 feb 2018 solving the course - timetabling problem of cairo university using max - sat mohamed el halaby march 15, 2018 abstract due to the good performance of current sat ( satisfiability ) and maxsat ( maximum satisfiability ) solvers, many real - life optimization problems such as scheduling can be solved by encoding them into max - sat. in this paper we tackle the course timetabling problem of the department of mathematics, cairo university by encoding it into max - sat. generating timetables for the department by hand has proven to be cumbersome and the generated timetable almost always contains conflicts. we show how the constraints can be modelled as a max - sat instance. 1 introduction the satisfiability problem ( sat ), which is the problem of deciding if there exists a truth assignment that satisfies a boolean formula in conjunctive normal form ( cnf ), is a core problem in theoretical computer science because of its central position in complexity theory. given a boolean formula, sat asks if there is an assignment to the variables of the formula such that it is satisfied ( evaluates to true ). sat was the first problem proven to be n p - complete by cook [ 4 ]. each instance of an n p - complete problem can be translated into an instance of sat in polynomial time. this makes it very important to develop fast and efficient sat solvers. an important optimization of sat is max - sat which asks for a truth assignment that satisfies the maximum number of clauses of a given cnf formula. many theoretical and practical problems can be encoded into sat and maxsat such as debugging [ 13 ], circuits design and scheduling of how an observation satellite captures photos of earth [ 15 ], course timetabling [ 2, 10, 9, 7 ], software package upgrades [ 6 ], routing [ 16, 11 ], reasoning [ 14 ] and protein structure alignment in bioinformatics [ 12 ]. this paper addresses the course timetabling problem of the department of mathematics, faculty of science, cairo university. generating a timetable is done every semester and with the growing number of students and the limited number of teaching staff, this is becoming a difficult task. an important aspect of this problem is that students of the department take different courses belonging to 1 different curricula at the same time. this fact complicates the problem because the number of students taking an arbitrary set of courses is small [SEP]
Text from DS:  arXiv:1803.05027v1 [] 11 Feb 2018

Solving the Course-timetabling Problem of Cairo
University Using Max-SAT
Mohamed El Halaby
March 15, 2018
Abstract
Due to the good performance of current SAT (satisfiability) and MaxSAT (maximum satisfiability) solvers, many real-life optimization problems such as scheduling can be solved by encoding them into Max-SAT. In
this paper we tackle the course timetabling problem of the department of
mathematics, Cairo University by encoding it into Max-SAT. Generating
timetables for the department by hand has proven to be cumbersome and
the generated timetable almost always contains conflicts. We show how
the constraints can be modelled as a Max-SAT instance.

1

Introduction

The satisfiability problem (SAT), which is the problem of deciding if there exists
a truth assignment that satisfies a Boolean formula in conjunctive normal form
(CNF), is a core problem in theoretical computer science because of its central
position in complexity theory. Given a Bool
Original label:  cs.AI
Predicted label:  9
Correct label:  3
Text:  [CLS] hierarchical expertise - level modeling for user specific robot - behavior explanations arxiv : 1802. 06895v1 [ ] 19 feb 2018 sarath sreedharan and siddharth srivastava and subbarao kambhampati school of computing, informatics, and decision systems engineering arizona state university, tempe, az 85281 usa { ssreedh3, siddharths, rao } @ asu. edu abstract there is a growing interest within the ai research community to develop autonomous systems capable of explaining their behavior to users. one aspect of the explanation generation problem that has yet to receive much attention is the task of explaining plans to users whose level of expertise differ from that of the explainer. we propose an approach for addressing this problem by representing the user ’ s model as an abstraction of the domain model that the planner uses. we present algorithms for generating minimal explanations in cases where this abstract human model is not known. we reduce the problem of generating explanation to a search over the space of abstract models and investigate possible greedy approximations for minimal explanations. we also empirically show that our approach can efficiently compute explanations for a variety of problems. 1 introduction ai systems have the potential to transform society by assisting humans in diverse situations ranging from extraplanetary exploration to assisted living. in order to achieve this potential, however, humans working with such systems need to be able to understand them just as they would understand human team members. this presents a number of challenges because most humans do not understand ai algorithms and their behavior at the same intuitive level that they understand other humans. recently, there have been attempts to bridge this gap by developing systems capable of explaining its behavior. most recently [ chakraborti et al., 2017 ] formulated the problem of generating explanations for plans as that of model reconciliation. their approach relied on identifying ways of bringing the human model ( i. e the explainee model ) closer to the robot model so that the plan in question appears optimal in the new model. their work looked at scenarios in which the human used a model of the domain that was at the same level of fidelity as the one used by the agent to generate the plan. this approach, unfortunately, did not capture scenarios where the human possessed a lower level of expertise and thus used a more “ abstract ” or coarser representation of the model as compared to the ai agent. in this paper, we propose a new approach to this problem where the agent explains its ongoing or planned behavior to humans with arbitrary levels of expertise. [SEP]
Text from DS:  Hierarchical Expertise-Level Modeling for User Specific Robot-Behavior
Explanations

arXiv:1802.06895v1 [] 19 Feb 2018

Sarath Sreedharan and Siddharth Srivastava and Subbarao Kambhampati
School of Computing, Informatics, and Decision Systems Engineering
Arizona State University, Tempe, AZ 85281 USA
{ ssreedh3, siddharths, rao } @ asu.edu
Abstract
There is a growing interest within the AI research
community to develop autonomous systems capable of explaining their behavior to users. One aspect
of the explanation generation problem that has yet
to receive much attention is the task of explaining
plans to users whose level of expertise differ from
that of the explainer. We propose an approach for
addressing this problem by representing the user’s
model as an abstraction of the domain model that
the planner uses. We present algorithms for generating minimal explanations in cases where this abstract human model is not known. We reduce the
problem of generating explanation to a search over

Original label:  cs.CV
Predicted label:  7
Correct label:  4
Text:  [CLS] arxiv : 1711. 08760v1 [ ] 23 nov 2017 boosted cascaded convnets for multilabel classification of thoracic diseases in chest radiographs pulkit kumar * paralleldots, inc. monika grewal∗ paralleldots, inc. muktabh mayank srivastava paralleldots, inc. pulkit @ paralleldots. com monika @ paralleldots. com muktabh @ paralleldots. com abstract deep learning methods have been rigorously applied for disease classification and image segmentation tasks. the gradual rise of interest in deep learning based diagnostic solutions can be attributed to their tremendous potential in modelling complex relationships between input and output variables and faster inference. training highly accurate deep learning systems in any domain requires a large annotated dataset. we only had relatively smaller datasets available for chest x - ray diagnosis until recently. a significant step in this direction is the work by wang et. al. [ 9 ], who developed a large dataset of chest x - ray images along with annotations for chest diseases through natural language processing ( nlp ). the dataset is the largest open dataset for chest x - ray images, and therefore paves a path for development of better algorithms for automated diagnosis of chest diseases. chest x - ray 14 dataset provides labels for 14 lung related diseases for 112, 120 radiograph images of 1024 by 1024 resolution with above 90 % label accuracy. most of the radiographs are labelled with more than one disease making it a typical multi - label classification problem. apart from the inherent challenges posed by multi - label classification, the dataset has heavy imbalance in number of instances of individual classes. moreover, the co - occurrence instances of each class with every other class are very high. for instance, the disease cardiomegaly co - occurs with disease effusion in 1060 images, whereas the total images of the diseases are 2772 and 13307, respectively. these challenges make the multi label classification task quite difficult and necessitate the incorporation of label dependencies along with employing robust learning approaches. the standard approach to multi - label classification is binary relevance ( br ), wherein the problem of multilabel classification for n classes is transformed into n binary classification problems [ 5 ]. however, br approach does not account for the interdependence of different class labels. the prevalent approaches to account for label dependencies include chain classification [ 1 ], label power [SEP]
Text from DS:  arXiv:1711.08760v1 [] 23 Nov 2017

Boosted Cascaded Convnets for Multilabel Classification of Thoracic Diseases in
Chest Radiographs
Pulkit Kumar*
Paralleldots, Inc.

Monika Grewal∗
Paralleldots, Inc.

Muktabh Mayank Srivastava
Paralleldots, Inc.

pulkit@paralleldots.com

monika@paralleldots.com

muktabh@paralleldots.com

Abstract

Deep learning methods have been rigorously applied for
disease classification and image segmentation tasks. The
gradual rise of interest in deep learning based diagnostic
solutions can be attributed to their tremendous potential in
modelling complex relationships between input and output variables and faster inference. Training highly accurate
deep learning systems in any domain requires a large annotated dataset. We only had relatively smaller datasets available for chest X-ray diagnosis until recently. A significant
step in this direction is the work by Wang et. al.[9], who developed a large dataset of chest X-ray images along with annotations for chest di
Original label:  cs.CE
Predicted label:  1
Correct label:  9
Text:  [CLS] proc. of the 6th eur. conf. on python in science ( euroscipy 2013 ) 59 jyni – using native cpython - extensions in jython stefan richthofer∗ † f arxiv : 1404. 6390v2 [ ] 29 apr 2014 cpython jyni fig. 1 : extensions fig. 2 : jyni abstract — jython is a java based python implementation and the most seamless way to integrate python and java. however, it does not support native extensions written for cpython like numpy or scipy. since most scientific python code fundamentally depends on exactly such native extensions directly or indirectly, it usually cannot be run with jython. jyni ( jython native interface ) aims to close this gap. it is a layer that enables jython users to load native cpython extensions and access them from jython the same way as they would do in cpython. in order to leverage the jyni functionality, you just have to put it on the java classpath when jython is launched. it neither requires you to recompile the extension code, nor to build a customized jython fork. that means, it is binary compatible with existing extension builds. at the time of writing, jyni does not fully implement the python c - api and it is only capable of loading simple examples that only involve most basic builtin types. the concept is rather complete though and our goal is to provide the c - api needed to load numpy as soon as possible. after that we will focus on scipy and others. we expect that our work will also enable java developers to use cpython extensions like numpy in their java code. the frequent occurrence of preprocessor macros in the public c - api allows for no naive approaches like directly delegating every c - api call to jython. it turned out, that most built - in types need individual fixes, considerations and adjustments to allow seamless integration with jython. there have been similar approaches for other python implementations, namely [ ironclad ] for ironpython and [ cpyext ] for pypy. as far as we know, these suffer from equal difficulties as jyni and also did not yet reach a satisfying compatibility level for current python versions. another interesting work is numpy4j [ np4j ], which provides java interfaces for nu [SEP]
Text from DS:  PROC. OF THE 6th EUR. CONF. ON PYTHON IN SCIENCE (EUROSCIPY 2013)

59

JyNI – Using native CPython-Extensions in Jython
Stefan Richthofer∗†

F

arXiv:1404.6390v2 [] 29 Apr 2014

CPython
JyNI

Fig. 1: Extensions

Fig. 2: JyNI

Abstract—Jython is a Java based Python implementation and the most seamless way to integrate Python and Java. However, it does not support native
extensions written for CPython like NumPy or SciPy. Since most scientific
Python code fundamentally depends on exactly such native extensions directly
or indirectly, it usually cannot be run with Jython. JyNI (Jython Native Interface)
aims to close this gap. It is a layer that enables Jython users to load native
CPython extensions and access them from Jython the same way as they would
do in CPython. In order to leverage the JyNI functionality, you just have to
put it on the Java classpath when Jython is launched. It neither requires you
to recompile the extension code, nor to build a customized Jython fork. That
means, i
Original label:  math.ST
Predicted label:  9
Correct label:  2
Text:  [CLS] arxiv : 1608. 02990v3 [ ] 31 jan 2017 bayesian mendelian randomization carlo berzuini1, hui guo1, stephen burgess2, luisa bernardinelli3 centre for biostatistics, the university of manchester, manchester, uk∗ 2 department of public health and primary care, university of cambridge, cambridge, united kingdom 3 department of brain and behavioural sciences, university of pavia, italy 1 keywords : pleiotropy ; horseshoe prior ; shrinkage estimators ; egger regression ; median estimator ; causal inference ; instrumental variable analysis ; invalid instruments ; instrument - exposure interaction ; metabolomics abstract our bayesian approach to mendelian randomization uses multiple instruments to assess the putative causal effect of an exposure on an outcome. the approach is robust to violations of the ( untestable ) exclusion restriction condition, and hence it does not require instruments to be independent of the outcome conditional on the exposure and on the confounders of the exposure - outcome relationship. the bayesian approach offers a rigorous handling of the uncertainty ( e. g. about the estimated instrument - exposure associations ), freedom from asymptotic approximations of the null distribution and the possibility to elaborate the model in any direction of scientific relevance. we illustrate the last feature with the aid of a study of the metabolic mediators of the disease - inducing effects of obesity, where we elaborate the model to investigate whether the causal effect of interest interacts with a covariate. the proposed model contains a vector of unidentifiable parameters, β, whose jth element represents the pleiotropic ( i. e., ∗ carlo. berzuini @ manchester. ac. uk 1 not mediated by the exposure ) component of the association of instrument j with the outcome. we deal with the incomplete identifiability by assuming that the pleiotropic effect of some instruments is null, or nearly so, formally by imposing on β carvalho ’ s horseshoe shrinkage prior, in such a way that different components of β are subjected to different degrees of shrinking, adaptively and in accord with the compatibility of each individual instrument with the hypothesis of no pleiotropy. this prior requires a minimal input from the user. we present the results of a simulation study into the performance of the proposed method under different types of pleiotropy and sample sizes. comparisons with the performance of the weighted median estimator are [SEP]
Text from DS:  arXiv:1608.02990v3 [] 31 Jan 2017

Bayesian Mendelian Randomization
Carlo Berzuini1 , Hui Guo1 , Stephen Burgess2 , Luisa Bernardinelli3
Centre for Biostatistics, The University of Manchester, Manchester, UK∗
2
Department of Public Health and Primary Care, University of Cambridge,
Cambridge, United Kingdom
3
Department of Brain and Behavioural Sciences, University of Pavia, Italy
1

Keywords: Pleiotropy; Horseshoe Prior; Shrinkage Estimators; Egger Regression; Median Estimator; Causal Inference; Instrumental Variable Analysis; Invalid
Instruments; Instrument-Exposure Interaction; Metabolomics
Abstract
Our Bayesian approach to Mendelian Randomization uses multiple instruments to assess the putative causal effect of an exposure on an outcome.
The approach is robust to violations of the (untestable) Exclusion Restriction condition, and hence it does not require instruments to be independent
of the outcome conditional on the exposure and on the confounders of the
exposure-outcome relations
Original label:  cs.CE
Predicted label:  10
Correct label:  8
Text:  [CLS] n - version obfuscation : impeding software tampering replication with program diversity hui xu∗ †, yangfan zhou † ‡, michael r. lyu∗ ∗ arxiv : 1506. 03032v1 [ cs. cr ] 8 jun 2015 † department of computer science, the chinese university of hong kong moe key laboratory of high confidence software technologies ( cuhk sub - lab ) ‡ department of computer science, fudan university according to a recent survey [ 16 ], existing software diversification approaches generally consider functionally equivalent programs, which can be effective against several kinds of attacks such as return oriented programming. however, such approaches with the functionally equivalence constraint cannot meet our need to disable the replication of tampered software. as a first attempt, we propose to deliver same featured, but functionally nonequivalent software copies to different machines. a major challenge towards this goal is which part of a program can have such functionally nonequivalent diversities. we formally define the problem as n - version obfuscation, and provide a viable solution for the software of client - server architecture, i. e., by integrating a message authentication code ( mac ) mechanism with functionally nonequivalent sha1 algorithms [ 1 ] to the original software, it can be resistant to tampering replication. we further show that many software integrity protection problems can be reduced to our solution model. it is worth noting that nversion obfuscation can be applied seamlessly to other existing tampering - resistant approaches, and hence equipping them with the replication - resistant property. our analysis result shows that the tampering complexity incurred by n - version obfuscation increases almost linearly with the number of functionally nonequivalent software versions. abstract — tamper - resistance is a fundamental software security research area. many approaches have been proposed to thwart specific procedures of tampering, e. g., obfuscation and self - checksumming. however, to our best knowledge, none of them can achieve theoretically tamper - resistance. our idea is to impede the replication of tampering via program diversification, and thus increasing the complexity to break the whole software system. to this end, we propose to deliver same featured, but functionally nonequivalent software copies to different machines. we formally define the problem as n - version obfuscation, and provide a viable means to solve the problem. our evaluation result shows that the time required for breaking a software system is linear [SEP]
Text from DS:  N-Version Obfuscation: Impeding Software
Tampering Replication with Program Diversity
Hui Xu∗† , Yangfan Zhou†‡ , Michael R. Lyu∗
∗

arXiv:1506.03032v1 [cs.CR] 8 Jun 2015

†

Department of Computer Science, The Chinese University of Hong Kong
MoE Key Laboratory of High Confidence Software Technologies (CUHK Sub-Lab)
‡ Department of Computer Science, Fudan University
According to a recent survey [16], existing software diversification approaches generally consider functionally equivalent programs, which can be effective against several kinds of
attacks such as return oriented programming. However, such
approaches with the functionally equivalence constraint cannot
meet our need to disable the replication of tampered software.
As a first attempt, we propose to deliver same featured,
but functionally nonequivalent software copies to different
machines. A major challenge towards this goal is which
part of a program can have such functionally nonequivalent
diversities. We formally define th
Original label:  cs.IT
Predicted label:  1
Correct label:  9
Text:  [CLS] 1 strategic bidding for producers in nodal electricity markets : a convex relaxation approach arxiv : 1606. 05979v1 [ math. oc ] 20 jun 2016 mahdi ghamkhari, student member, ieee, ashkan sadeghi - mobarakeh, student member, ieee and hamed mohsenian - rad, senior member, ieee abstract — strategic bidding problems in electricity markets are widely studied in power systems, often by formulating complex bi - level optimization problems that are hard to solve. the state - of - the - art approach to solve such problems is to reformulate them as mixed - integer linear programs ( milps ). however, the computational time of such milp reformulations grows dramatically, once the network size increases, scheduling horizon increases, or randomness is taken into consideration. in this paper, we take a fundamentally different approach and propose effective and customized convex programming tools to solve the strategic bidding problem for producers in nodal electricity markets. our approach is inspired by the schmudgen ’ s positivstellensatz theorem in semi - algebraic geometry ; but then we go through several steps based upon both convex optimization and mixed - integer programming that results in obtaining close to optimal bidding solutions, as evidenced by several numerical case studies, besides having a huge advantage on reducing computation time. while the computation time of the state - ofthe - art milp approach grows exponentially when we increase the scheduling horizon or the number of random scenarios, the computation time of our approach increases rather linearly. keywords : nodal electricity market, strategic bidding, equilibrium constraints, convex optimization, computation time. r, r + s n d g s l k [ t ] t k pg pd θ λ σ, δ, ζ, ξ, φ, ψ a bg bd bs v n omenclature set of real and non - negative real numbers set of symmetric matrices set of nodes in power grid in arbitrary order set of demand nodes in ascending order set of generation nodes in ascending order subset of strategic generation nodes in set g set of transmission lines, in arbitrary order index for random scenarios hourly time slots number of hourly time slots number of random scenarios vector of power generations vector of demands vector of phase angels of power grid vector of locational marginal prices vectors of dual variables corresponding to inequalities in economic dispatch problem bus - line incidence matrix generator - bus incidence matrix demand - bus incidence matrix strategic generators to generators incidence matrix diagonal matrix of transmission lines react [SEP]
Text from DS:  1

Strategic Bidding for Producers in Nodal Electricity
Markets: A Convex Relaxation Approach

arXiv:1606.05979v1 [math.OC] 20 Jun 2016

Mahdi Ghamkhari, Student Member, IEEE, Ashkan Sadeghi-Mobarakeh, Student Member, IEEE
and Hamed Mohsenian-Rad, Senior Member, IEEE

Abstract—Strategic bidding problems in electricity markets
are widely studied in power systems, often by formulating
complex bi-level optimization problems that are hard to solve.
The state-of-the-art approach to solve such problems is to
reformulate them as mixed-integer linear programs (MILPs).
However, the computational time of such MILP reformulations
grows dramatically, once the network size increases, scheduling
horizon increases, or randomness is taken into consideration.
In this paper, we take a fundamentally different approach and
propose effective and customized convex programming tools
to solve the strategic bidding problem for producers in nodal
electricity markets. Our approach is inspired by the Schmudgen’s

Original label:  cs.NE
Predicted label:  9
Correct label:  2
Text:  [CLS] international journal on computational sciences & applications ( ijcsa ) vol. 3, no. 4, august 2013 evaluation the efficiency of artificial bee colony and the firefly algorithm in solving the continuous optimization problem seyyed reza khaze1, isa maleki2, sohrab hojjatkhah3 and ali bagherinia4 1 department of computer engineering, dehdasht branch, islamic azad university, iran, 2 department of computer engineering, dehdasht branch, islamic azad university, iran, 3 department of computer engineering, dehdasht branch, islamic azad university, iran, 4 department of computer engineering, dehdasht branch, islamic azad university, iran, khaze @ iaudehdasht. ac. ir, khaze. reza @ gmail. com maleki @ iaudehdasht. ac. ir, maleki. misa @ gmail. com hojjatkhah @ gmail. com ali. bagherinia @ gmail. com abstract now the meta - heuristic algorithms have been used vastly in solving the problem of continuous optimization. in this paper the artificial bee colony ( abc ) algorithm and the firefly algorithm ( fa ) are valuated. and for presenting the efficiency of the algorithms and also for more analysis of them, the continuous optimization problems which are of the type of the problems of vast limit of answer and the close optimized points are tested. so, in this paper the efficiency of the abc algorithm and fa are presented for solving the continuous optimization problems and also the said algorithms are studied from the accuracy in reaching the optimized solution and the resulting time and the reliability of the optimized answer points of view. keywords meta - heuristic algorithm, artificial bee colony ( abc ), firefly algorithm ( fa ), continuous optimization 1. introduction now the use of the meta - heuristic algorithms in accessing the optimized solution in the continuous optimization problems has progressed a lot. according to the increase of the complexity of the continuous optimization problems and the inability of the mathematical methods for the optimized solution, the meta heuristic algorithms are the suitable solution for the continuous optimization problems. the mathematical methods are used in many scientific and engineering problems and cover a vast area of the different problems but despite the accurate efficiency, the mathematical methods still face many problems solving the optimization problems. the late researches and the struggles of the researchers have led to innovation of the algorithms [SEP]
Text from DS:  International Journal on Computational Sciences & Applications (IJCSA) Vol.3, No.4, August 2013

EVALUATION THE EFFICIENCY OF ARTIFICIAL BEE
COLONY AND THE FIREFLY ALGORITHM IN SOLVING
THE CONTINUOUS OPTIMIZATION PROBLEM
Seyyed Reza Khaze1, Isa maleki2, Sohrab Hojjatkhah3 and Ali Bagherinia4
1

Department of Computer Engineering, Dehdasht Branch, Islamic Azad University, Iran,

2

Department of Computer Engineering, Dehdasht Branch, Islamic Azad University, Iran,

3

Department of Computer Engineering, Dehdasht Branch, Islamic Azad University, Iran,

4

Department of Computer Engineering, Dehdasht Branch, Islamic Azad University, Iran,

khaze@iaudehdasht.ac.ir, khaze.reza@gmail.com
maleki@iaudehdasht.ac.ir, maleki.misa@gmail.com
hojjatkhah@gmail.com
ali.bagherinia@gmail.com

ABSTRACT
Now the Meta-Heuristic algorithms have been used vastly in solving the problem of continuous
optimization. In this paper the Artificial Bee Colony (ABC) algorithm and the Firefly Algorithm (FA) are
valuate
Original label:  cs.IT
Predicted label:  3
Correct label:  1
Text:  [CLS] knowledge and information systems manuscript no. ( will be inserted by the editor ) parallel construction of wavelet trees on multicore architectures arxiv : 1610. 05994v1 [ ] 19 oct 2016 jose fuentes - sepulveda · erick elejalde · leo ferres · diego seco abstract the wavelet tree has become a very useful data structure to efficiently represent and query large volumes of data in many different domains, from bioinformatics to geographic information systems. one problem with wavelet trees is their construction time. in this paper, we introduce two algorithms that reduce the time complexity of a wavelet tree ’ s construction by taking advantage of nowadays ubiquitous multicore machines. our first algorithm constructs all the levels of the wavelet in parallel in o ( n ) time and o ( n lg σ + σ lg n ) bits of working space, where n is the size of the input sequence and σ is the size of the alphabet. our second algorithm constructs the wavelet tree in a domain - decomposition fashion, using our first algorithm in each segment, reaching o ( lg n ) time and o ( n lg σ + pσ lg n / lg σ ) bits of extra space, where p is the number of available cores. both algorithms are practical and report good speedup for large real datasets. keywords succinct data structure · wavelet tree construction · multicore · parallel algorithm a previous version of this paper appeared in the 13th international symposium on experimental algorithms ( sea 2014 ) [ 15 ]. this work was supported in part by the european union ’ s horizon 2020 research and innovation programme under the marie sklodowska - curie grant agreement no 690941 and the doctoral scholarships of conicyt no 21120974 and 63130228 ( ﬁrst and second authors, respectively ). we also would like to thank roberto asın for making his multicore computers, mastropiero and gunther frager, available to us. this is an author ’ s original manuscript of an article whose ﬁnal and deﬁnitive form, the version of record, has been published in knowledge and information systems [ copyright springer ], available online at : http : / / dx. doi. org / 10. 1007 / s10115 - 016 - 1000 - 6. jose fuentes - sepulveda · erick elejalde · diego seco department of computer science [SEP]
Text from DS:  Knowledge and Information Systems manuscript No.
(will be inserted by the editor)

Parallel Construction of Wavelet Trees on Multicore
Architectures

arXiv:1610.05994v1 [] 19 Oct 2016

José Fuentes-Sepúlveda · Erick Elejalde ·
Leo Ferres · Diego Seco

Abstract The wavelet tree has become a very useful data structure to efficiently
represent and query large volumes of data in many different domains, from bioinformatics to geographic information systems. One problem with wavelet trees is
their construction time. In this paper, we introduce two algorithms that reduce the
time complexity of a wavelet tree’s construction by taking advantage of nowadays
ubiquitous multicore machines.
Our first algorithm constructs all the levels of the wavelet in parallel in O(n)
time and O(n lg σ + σ lg n) bits of working space, where n is the size of the input
sequence and σ is the size of the alphabet. Our second algorithm constructs the
wavelet tree in a domain-decomposition fashion, using our first al
Original label:  math.AC
Predicted label:  0
Correct label:  4
Text:  [CLS] arxiv : 1611. 06082v1 [ ] 18 nov 2016 on the convexity of numerical range over certain fields e. ballico abstract. let l be a degree 2 galois extension of the field k and m an n×n matrix with coefficients in l. let h, i : ln × ln −→ l be the sesquilinear form associated to the involution σ : l −→ l fixing k. this sesquilinear form defines the numerical range num ( m ) of any n × n matrix over l. in this paper we study the convexity of num ( m ) ( under certain assumptions on k and / or m ). many of the results are for ordered fields. 1. introduction for any field f let mn, n ( f ) denote the set of all n × n matrices with coefficients in f. fix fields k ⊂ l such that l is a degree 2 galois extension of k and call σ the generator of the galois group of the extension k ⊂ l. for any u = pn ( u1,..., un ), v = ( v1,..., vn ) ∈ ln set hu, vi : = i = 1 σ ( ui ) vi. the map h, i : ln × ln −→ l is sesquilinear ( linear in the second variable and σ - linear in the first one ) and hu, vi = σ ( hv, ui ) for all u, v ∈ ln. for any m ∈ mn, n ( l ) and u ∈ l set νm ( u ) : = hu, m ui. we obtain a map νm : ln −→ l, call the numerical map of m. when k = r and l = c ( and so σ is the complex conjugation and h, i is the usual hermitian product ) the image of the restriction of νm to cn ( 1 ) : = { z ∈ ln | hz, zi = 1 } is called the numerical range of m ( [ 5 ], [ 9 ] ) ; it is always a convex subset of c ( [ 5 ], [ 9 ] ) and the main aim of this paper is to explore the convexity for other ( l, k, σ ), sometimes with strong restrictions on the matrix m. under mild assumptions on l and k we have m = m † if and only if num [SEP]
Text from DS:  arXiv:1611.06082v1 [] 18 Nov 2016

ON THE CONVEXITY OF NUMERICAL RANGE OVER
CERTAIN FIELDS
E. BALLICO
Abstract. Let L be a degree 2 Galois extension of the field K and M an n×n
matrix with coefficients in L. Let h , i : Ln × Ln −→ L be the sesquilinear
form associated to the involution σ : L −→ L fixing K. This sesquilinear form
defines the numerical range Num(M ) of any n × n matrix over L. In this paper
we study the convexity of Num(M ) (under certain assumptions on K and/or
M ). Many of the results are for ordered fields.

1. Introduction
For any field F let Mn,n (F ) denote the set of all n × n matrices with coefficients
in F . Fix fields K ⊂ L such that L is a degree 2 Galois extension of K and
call σ the generator of the Galois group of the extension
K ⊂ L. For any u =
Pn
(u1 , . . . , un ), v = (v1 , . . . , vn ) ∈ Ln set hu, vi :=
i=1 σ(ui )vi . The map h , i :
Ln × Ln −→ L is sesquilinear (linear in the second variable and σ-linear in the
first one) and hu, vi = σ(hv, ui) for 
Original label:  cs.CV
Predicted label:  1
Correct label:  5
Text:  [CLS] on lyapunov exponents and adversarial perturbations ∗ vinay uday prabhu unifyid inc san francisco, 94107 arxiv : 1802. 06927v1 [ ] 20 feb 2018 vinay @ unify. id nishant desai john whaley unifyid inc san francisco, 94107 unifyid inc san francisco, 94107 nishant @ unify. id abstract in this paper, we would like to disseminate a serendipitous discovery involving lyapunov exponents of a 1 - d time series and their use in serving as a filtering defense tool against a specific kind of deep adversarial perturbation. to this end, we use the state - of - the - art cleverhans library to generate adversarial perturbations against a standard convolutional neural network ( cnn ) architecture trained on the mnist as well as the fashion - mnist datasets. we empirically demonstrate how the lyapunov exponents computed on the flattened 1 - d vector representations of the images served as highly discriminative features that could be to pre - classify images as adversarial or legitimate before feeding the image into the cnn for classification. we also explore the issue of possible false - alarms when the input images are noisy in a non - adversarial sense. keywords deep learning, adversarial attacks, transfer learning 1. background on defenses against adversarial attacks in the recent past, a plethora of defenses against adversarial attacks have been proposed. these include safetynet [ 13 ], adversarial training [ 21 ], label smoothing [ 22 ], defensive distillation [ 19 ] and feature - squeezing [ 24, 25 ] to name a few. there is also an ongoing kaggle contest [ 2 ] underway for exploring novel defenses against adversarial attacks. as evinced by the recent spurt in the papers written on this topic, most defenses proposed are quelled by a novel attack that exploits some weakness in the defense. in [ 10 ], the authors queried if one could concoct a strong defense by combining multiple defenses and showed that an ensemble of weak defenses was not sufficient in providing strong defense against adversarial examples that they were able to craft. ∗primary author john @ unify. id in the accompanying blog1 associated with [SEP]
Text from DS:  On Lyapunov exponents and adversarial perturbations
∗

Vinay Uday Prabhu

UnifyID Inc
San Francisco, 94107

arXiv:1802.06927v1 [] 20 Feb 2018

vinay@unify.id

Nishant Desai

John Whaley

UnifyID Inc
San Francisco, 94107

UnifyID Inc
San Francisco, 94107

nishant@unify.id

ABSTRACT
In this paper, we would like to disseminate a serendipitous
discovery involving Lyapunov exponents of a 1-D time series
and their use in serving as a filtering defense tool against a
specific kind of deep adversarial perturbation. To this end,
we use the state-of-the-art CleverHans library to generate
adversarial perturbations against a standard Convolutional
Neural Network (CNN) architecture trained on the MNIST
as well as the Fashion-MNIST datasets. We empirically
demonstrate how the Lyapunov exponents computed on the
flattened 1-D vector representations of the images served as
highly discriminative features that could be to pre-classify
images as adversarial or legitimate before feeding the image
into the 
Original label:  cs.IT
Predicted label:  5
Correct label:  8
Text:  [CLS] better process mapping and sparse quadratic assignment∗ christian schulz1 and jesper larsson traff2 1 karlsruhe institute of technology, karlsruhe, germany, and university of vienna, vienna, austria christian. schulz @ { kit. edu, univie. ac. at } tu wien, vienna, austria traff @ par. tuwien. ac. at 2 arxiv : 1702. 04164v1 [ cs. dc ] 14 feb 2017 abstract communication and topology aware process mapping is a powerful approach to reduce communication time in parallel applications with known communication patterns on large, distributed memory systems. we address the problem as a quadratic assignment problem ( qap ), and present algorithms to construct initial mappings of processes to processors as well as fast local search algorithms to further improve the mappings. by exploiting assumptions that typically hold for applications and modern supercomputer systems such as sparse communication patterns and hierarchically organized communication systems, we arrive at significantly more powerful algorithms for these special qaps. our multilevel construction algorithms employ recently developed, perfectly balanced graph partitioning techniques and excessively exploit the given communication system hierarchy. we present improvements to a local search algorithm of brandfass et al., and decrease the running time by reducing the time needed to perform swaps in the assignment as well as by carefully constraining local search neighborhoods. experiments indicate that our algorithms not only dramatically speed up local search, but due to the multilevel approach also find much better solutions in practice. 1 introduction communication performance between processes in high - performance systems depends on many factors. for example, communication is typically faster if communicating processes are located on the same processor node compared to the cases where processes reside on different nodes. this becomes even more pronounced for large supercomputer systems where processors are hierarchically organized into, e. g., islands, racks, nodes, processors, cores with corresponding communication links of similar quality. given the communication pattern between processes and a hardware topology description that reflects the quality of the communication links, one hence seeks to find a good mapping of processes onto processors such that pairs of processes exchanging large amounts of information are located closely. such a mapping can be computed by solving a corresponding quadratic assignment problem ( qap ) which is a hard optimization problem. sahni and gonzalez [ 21 ] have shown qap to be strongly np - hard and, unless p = np, admitting no constant factor approximation algorithm. in addition, there are no algorithms that can [SEP]
Text from DS:  Better Process Mapping and Sparse Quadratic
Assignment∗
Christian Schulz1 and Jesper Larsson Träff2
1

Karlsruhe Institute of Technology, Karlsruhe, Germany, and
University of Vienna, Vienna, Austria
christian.schulz@{kit.edu, univie.ac.at}
TU Wien, Vienna, Austria
traff@par.tuwien.ac.at

2

arXiv:1702.04164v1 [cs.DC] 14 Feb 2017

Abstract
Communication and topology aware process mapping is a powerful approach to reduce communication time in parallel applications with known communication patterns on large, distributed
memory systems. We address the problem as a quadratic assignment problem (QAP), and present
algorithms to construct initial mappings of processes to processors as well as fast local search
algorithms to further improve the mappings. By exploiting assumptions that typically hold for
applications and modern supercomputer systems such as sparse communication patterns and hierarchically organized communication systems, we arrive at significantly more powerful algorithms
for t
Original label:  cs.NE
Predicted label:  2
Correct label:  9
Text:  [CLS] unsure when to stop? ask your semantic neighbors ivo goncalves sara silva nova ims, universidade nova de lisboa 1070 - 312 lisbon, portugal igoncalves @ novaims. unl. pt bioisi - biosystems & integrative sciences institute, faculty of sciences, university of lisbon 1749 - 016 lisbon, portugal sara @ fc. ul. pt arxiv : 1706. 06195v1 [ ] 19 jun 2017 carlos m. fonseca mauro castelli cisuc, department of informatics engineering, university of coimbra 3030 - 290 coimbra, portugal cmfonsec @ dei. uc. pt nova ims, universidade nova de lisboa 1070 - 312 lisbon, portugal mcastelli @ novaims. unl. pt abstract 1 in iterative supervised learning algorithms it is common to reach a point in the search where no further induction seems to be possible with the available data. if the search is continued beyond this point, the risk of overfitting increases significantly. following the recent developments in inductive semantic stochastic methods, this paper studies the feasibility of using information gathered from the semantic neighborhood to decide when to stop the search. two semantic stopping criteria are proposed and experimentally assessed in geometric semantic genetic programming ( gsgp ) and in the semantic learning machine ( slm ) algorithm ( the equivalent algorithm for neural networks ). the experiments are performed on real - world high - dimensional regression datasets. the results show that the proposed semantic stopping criteria are able to detect stopping points that result in a competitive generalization for both gsgp and slm. this approach also yields computationally efficient algorithms as it allows the evolution of neural networks in less than 3 seconds on average, and of gp trees in at most 10 seconds. the usage of the proposed semantic stopping criteria in conjunction with the computation of optimal mutation / learning steps also results in small trees and neural networks. supervised learning refers to the task of inducing a general pattern from a provided set of examples. a common issue in supervised learning is the possibility that the resulting models could be simply learning the provided set of examples, instead of learning the underlying pattern. a model that is incurring in such a behavior is commonly said to be overfitting. genetic programming ( gp ) [ 10 ] has been extensively applied in supervised learning tasks. despite this, it was uncommon in the early years of gp to find approaches aimed at improving the generalization of the resulting models [SEP]
Text from DS:  Unsure When to Stop? Ask Your Semantic Neighbors
Ivo Gonçalves

Sara Silva

NOVA IMS, Universidade Nova de Lisboa
1070-312 Lisbon, Portugal
igoncalves@novaims.unl.pt

BioISI - BioSystems & Integrative Sciences Institute,
Faculty of Sciences, University of Lisbon
1749-016 Lisbon, Portugal
sara@fc.ul.pt

arXiv:1706.06195v1 [] 19 Jun 2017

Carlos M. Fonseca

Mauro Castelli

CISUC, Department of Informatics Engineering,
University of Coimbra
3030-290 Coimbra, Portugal
cmfonsec@dei.uc.pt

NOVA IMS, Universidade Nova de Lisboa
1070-312 Lisbon, Portugal
mcastelli@novaims.unl.pt

ABSTRACT

1

In iterative supervised learning algorithms it is common to reach
a point in the search where no further induction seems to be possible with the available data. If the search is continued beyond
this point, the risk of overfitting increases significantly. Following
the recent developments in inductive semantic stochastic methods, this paper studies the feasibility of using information gathered
from the s
Original label:  cs.CE
Predicted label:  2
Correct label:  7
Text:  [CLS] international journal of parallel programming manuscript no. ( will be inserted by the editor ) automatic parallelization : executing sequential programs on a task - based parallel runtime alcides fonseca · bruno cabral · joao rafael · ivo correia arxiv : 1604. 03211v1 [ ] 11 apr 2016 received : date / accepted : date abstract there are billions of lines of sequential code inside nowadays ’ software which do not benefit from the parallelism available in modern multicore architectures. automatically parallelizing sequential code, to promote an efficient use of the available parallelism, has been a research goal for some time now. this work proposes a new approach for achieving such goal. we created a new parallelizing compiler that analyses the read and write instructions, and control - flow modifications in programs to identify a set of dependencies between the instructions in the program. afterwards, the compiler, based on the generated dependencies graph, rewrites and organizes the program in a taskoriented structure. parallel tasks are composed by instructions that cannot be executed in parallel. a work - stealing - based parallel runtime is responsible for scheduling and managing the granularity of the generated tasks. furthermore, a compile - time granularity control mechanism also avoids creating unnecessary data - structures. this work focuses on the java language, but the techniques are general enough to be applied to other programming languages. we have evaluated our approach on 8 benchmark programs against ooojava, achieving higher speedups. in some cases, values were close to those of this work was partially supported by the portuguese research agency fct, through cisuc ( r & d unit 326 / 97 ) and the cmu | portugal program ( r & d project æminium cmu - pt / se / 0038 / 2008 ). supported by the portuguese national foundation for science and technology ( fct ) through a doctoral grant ( sfrh / bd / 84448 / 2012 ). alcides fonseca, bruno cabral, joao rafael, ivo correia department of informatics engineering universidade de coimbra tel : + 351 239 790 000 fax : + 351 239 701 266 e - mail : { amaf, bcabral } @ dei. uc. pt, e - mail : { jprafael, icorreia } @ student. dei. uc. pt 2 alcides fonseca et al. a manual parallelization. the resulting parallel code also has the advantage of being read [SEP]
Text from DS:  International Journal of Parallel Programming manuscript No.
(will be inserted by the editor)

Automatic Parallelization: Executing Sequential
Programs on a Task-Based Parallel Runtime
Alcides Fonseca · Bruno Cabral · João
Rafael · Ivo Correia

arXiv:1604.03211v1 [] 11 Apr 2016

Received: date / Accepted: date

Abstract There are billions of lines of sequential code inside nowadays’ software which do not benefit from the parallelism available in modern multicore
architectures. Automatically parallelizing sequential code, to promote an efficient use of the available parallelism, has been a research goal for some time
now.
This work proposes a new approach for achieving such goal. We created a
new parallelizing compiler that analyses the read and write instructions, and
control-flow modifications in programs to identify a set of dependencies between the instructions in the program. Afterwards, the compiler, based on the
generated dependencies graph, rewrites and organizes the program in
Original label:  cs.NE
Predicted label:  8
Correct label:  10
Text:  [CLS] a new distributed evolutionary computation technique for multi - objective optimization md. asadul islam1, g. m. mashrur - e - elahi2, m. m. a. hashem3 department of computer science and engineering khulna university of engineering & technology ( kuet ) khulna 9203, bangladesh asad _ kuet @ yahoo. com1, ranju2k4cse _ kuet @ yahoo. com2, mma _ hashem @ hotmail. com3 abstract — now - a - days, it is important to find out solutions of multi - objective optimization problems ( mops ). evolutionary strategy helps to solve such real world problems efficiently and quickly. but sequential evolutionary algorithms ( eas ) require an enormous computation power to solve such problems and it takes much time to solve large problems. to enhance the performance for solving this type of problems, this paper presents a new distributed novel evolutionary strategy algorithm ( dnesa ) for multi - objective optimization. the proposed dnesa applies the divide - and - conquer approach to decompose population into smaller sub - population and involves multiple solutions in the form of cooperative sub - populations. in dnesa, the server distributes the total computation load to all associate clients and simulation results show that the time for solving large problems is much less than sequential eas. also dnesa shows better performance in convergence test when compared with other three well - known eas. keywords - novel evolutionary algorithm ; time variant mutation ; subpopulation ; mops ; distributed computing ; i. introduction multi - objective optimization optimize a set of conflicting objectives simultaneously. mop is a very important research topic, not only for the multi - objective nature of most realworld decision problems, but also there are still many open questions in this area. traditionally, there are several methods available in the operational research ( or ) literature for solving mops as mathematical programming models [ 1 ]. none of the or methods treats all the objectives simultaneously which is a basic requirement in most mops. in addition, these methods handle mops with a set of impractical assumptions such as linearity and convexity. in mops, there is no single optimal solution, but contains a set of alternative solutions. these solutions are optimal in the wider sense since there is no other solutions in the search space that is superior to them when all objectives are simultaneously considered. they are known as pareto - optimal solutions or non - dominated solutions [ 2 ] [ 3 [SEP]
Text from DS:  A New Distributed Evolutionary Computation
Technique for Multi-Objective Optimization
Md. Asadul Islam1, G.M. Mashrur-E-Elahi2, M.M.A. Hashem3
Department of Computer Science and Engineering
Khulna University of Engineering & Technology (KUET)
Khulna 9203, Bangladesh
asad_kuet@yahoo.com1, ranju2k4cse_kuet@yahoo.com2, mma_hashem@hotmail.com3

Abstract— Now-a-days, it is important to find out solutions of
Multi-Objective Optimization Problems (MOPs). Evolutionary
Strategy helps to solve such real world problems efficiently and
quickly. But sequential Evolutionary Algorithms (EAs) require
an enormous computation power to solve such problems and it
takes much time to solve large problems. To enhance the
performance for solving this type of problems, this paper
presents a new Distributed Novel Evolutionary Strategy
Algorithm (DNESA) for Multi-Objective Optimization. The
proposed DNESA applies the divide-and-conquer approach to
decompose population into smaller sub-population and involves
mul
Original label:  math.GR
Predicted label:  10
Correct label:  8
Text:  [CLS] bogomolov multipliers for some p - groups of nilpotency class 2 arxiv : 1307. 0738v3 [ ] 18 jul 2016 ivo m. michailov abstract. the bogomolov multiplier b0 ( g ) of a finite group g is defined as the subgroup of the schur multiplier consisting of the cohomology classes vanishing after restriction to all abelian subgroups of g. the triviality of the bogomolov multiplier is an obstruction to noether ’ s problem. we show that if g is a central product of g1 and g2, regarding ki ≤ z ( gi ), i = 1, 2, and θ : g1 → g2 is a group homomorphism such that its restriction θ | k1 : k1 → k2 is an isomorphism, then the triviality of b0 ( g1 / k1 ), b0 ( g1 ) and b0 ( g2 ) implies the triviality of b0 ( g ). we give a positive answer to noether ’ s problem for all 2 - generator p - groups of nilpotency class 2, and for one series of 4 - generator p - groups of nilpotency class 2 ( with the usual requirement for the roots of unity ). 1. introduction let k be a field, g a finite group and v a faithful representation of g over k. then there is a natural action of g upon the field of rational functions k ( v ). the rationality problem ( also known as noether ’ s problem when g acts on v by permutations ) then asks whether the field of g - invariant functions k ( v ) g is rational ( i. e., purely transcendental ) over k. a question related to the above mentioned is whether k ( v ) g is stably rational, that is, whether there exist independent variables x1,..., xr such that k ( v ) g ( x1,..., xr ) becomes a purely transcendental extension of k. this problem has close connection with luroth ’ s problem [ 24 ] and the inverse galois problem [ 23, 25 ]. saltman [ 23 ] found examples of groups g of order p9 such that c ( v ) g is not stably rational over c. his main method was application of the unramified cohomology group 2 2 hnr ( c ( v [SEP]
Text from DS:  BOGOMOLOV MULTIPLIERS FOR SOME p-GROUPS OF
NILPOTENCY CLASS 2

arXiv:1307.0738v3 [] 18 Jul 2016

IVO M. MICHAILOV
Abstract. The Bogomolov multiplier B0 (G) of a finite group G is defined as the
subgroup of the Schur multiplier consisting of the cohomology classes vanishing after
restriction to all abelian subgroups of G. The triviality of the Bogomolov multiplier
is an obstruction to Noether’s problem. We show that if G is a central product of G1
and G2 , regarding Ki ≤ Z(Gi ), i = 1, 2, and θ : G1 → G2 is a group homomorphism
such that its restriction θ|K1 : K1 → K2 is an isomorphism, then the triviality of
B0 (G1 /K1 ), B0 (G1 ) and B0 (G2 ) implies the triviality of B0 (G). We give a positive
answer to Noether’s problem for all 2-generator p-groups of nilpotency class 2, and for
one series of 4-generator p-groups of nilpotency class 2 (with the usual requirement
for the roots of unity).

1. Introduction
Let K be a field, G a finite group and V a faithful representation of G over K. 
Original label:  cs.IT
Predicted label:  3
Correct label:  7
Text:  [CLS] connected vertex cover for ( sp1 + p5 ) - free [UNK] matthew johnson, giacomo paesani, and daniel paulusma arxiv : 1712. 08362v2 [ ] 28 feb 2018 department of computer science, durham university, uk { matthew. johnson2, giacomo. paesani, daniel. paulusma } @ durham. ac. uk abstract. the connected vertex cover problem is to decide if a graph g has a vertex cover of size at most k that induces a connected subgraph of g. this is a well - studied problem, known to be np - complete for restricted graph classes, and, in particular, for h - free graphs if h is not a linear forest ( a graph is h - free if it does not contain h as an induced subgraph ). it is easy to see that connected vertex cover is polynomial - time solvable for p4 - free graphs. we continue the search for tractable graph classes : we prove that it is also polynomial - time solvable for ( sp1 + p5 ) - free graphs for every integer s ≥ 0. 1 introduction a set s of vertices in a graph g form a vertex cover of g if every edge of g is incident with a vertex of s. the set s is an an independent set if no two vertices in s are adjacent. these definitions lead to two classical graph problems, which are both npcomplete : the vertex cover problem is to decide if a given graph g has a vertex cover of size at most k for a given integer k ; the independent set problem is to decide if a given graph g has an independent set of size at least ℓ for a given integer ℓ. a set s of at least k vertices of a graph g on n vertices is a vertex cover if and only if vg \ s is an independent set ( of size at most n − k ). hence vertex cover and independent set are polynomially equivalent. a vertex cover of a graph g is connected if it induces a connected subgraph of g. in our paper, we focus on the corresponding decision problem. connected vertex cover instance : a graph g and an integer k. question : does g have a connected vertex cover s with | s | ≤ k? in 1977, garey and johnson [ 10 ] proved that connected vertex cover is npcomplete for planar graphs of maximum degree 4. more recently, priyadarsini and hemalatha [ 22 ] and fernau and manlove [ 9 [SEP]
Text from DS:  Connected Vertex Cover
for (sP1 + P5 )-Free Graphs⋆
Matthew Johnson, Giacomo Paesani, and Daniël Paulusma

arXiv:1712.08362v2 [] 28 Feb 2018

Department of Computer Science, Durham University, UK
{matthew.johnson2,giacomo.paesani,daniel.paulusma}@durham.ac.uk

Abstract. The Connected Vertex Cover problem is to decide if a graph
G has a vertex cover of size at most k that induces a connected subgraph
of G. This is a well-studied problem, known to be NP-complete for restricted
graph classes, and, in particular, for H-free graphs if H is not a linear forest (a
graph is H-free if it does not contain H as an induced subgraph). It is easy to
see that Connected Vertex Cover is polynomial-time solvable for P4 -free
graphs. We continue the search for tractable graph classes: we prove that it is
also polynomial-time solvable for (sP1 +P5 )-free graphs for every integer s ≥ 0.

1

Introduction

A set S of vertices in a graph G form a vertex cover of G if every edge of G is incident
with a vertex
Original label:  cs.NE
Predicted label:  10
Correct label:  3
Text:  [CLS] 2017 ieee congress on evolutionary computation ( cec ) preprint ; the camera ready version will be published in ieee proceedings arxiv : 1704. 01859v1 [ ] 6 apr 2017 tackling dynamic vehicle routing problem with time windows by means of ant colony system raluca necula mihaela breaban madalina raschip faculty of computer science alexandru ioan cuza university iasi, romania email : raluca. necula @ info. uaic. ro faculty of computer science alexandru ioan cuza university iasi, romania email : pmihaela @ info. uaic. ro faculty of computer science alexandru ioan cuza university iasi, romania email : mionita @ info. uaic. ro abstract — the dynamic vehicle routing problem with time windows ( dvrptw ) is an extension of the well - known vehicle routing problem ( vrp ), which takes into account the dynamic nature of the problem. this aspect requires the vehicle routes to be updated in an ongoing manner as new customer requests arrive in the system and must be incorporated into an evolving schedule during the working day. besides the vehicle capacity constraint involved in the classical vrp, dvrptw considers in addition time windows, which are able to better capture realworld situations. despite this, so far, few studies have focused on tackling this problem of greater practical importance. to this end, this study devises for the resolution of dvrptw, an ant colony optimization based algorithm, which resorts to a joint solution construction mechanism, able to construct in parallel the vehicle routes. this method is coupled with a local search procedure, aimed to further improve the solutions built by ants, and with an insertion heuristics, which tries to reduce the number of vehicles used to service the available customers. the experiments indicate that the proposed algorithm is competitive and effective, and on dvrptw instances with a higher dynamicity level, it is able to yield better results compared to existing ant - based approaches. i. i ntroduction the vehicle routing problem plays a central part in capturing logistics and distribution operations, with an impact in the economy, more prominent as the need for transportation is increasingly growing. thus, this class of problems has a practical importance and has attracted a lot of research interest over the years. recently, the technological advancements made possible the use of mobile devices to enable the direct communication between the clients and the drivers, such that a driver could dynamically [SEP]
Text from DS:  2017 IEEE Congress on Evolutionary Computation (CEC) PREPRINT; the camera ready version will be published in IEEE proceedings

arXiv:1704.01859v1 [] 6 Apr 2017

Tackling Dynamic Vehicle Routing Problem with
Time Windows by means of Ant Colony System
Raluca Necula

Mihaela Breaban

Madalina Raschip

Faculty of Computer Science
Alexandru Ioan Cuza University
Iasi, Romania
Email: raluca.necula@info.uaic.ro

Faculty of Computer Science
Alexandru Ioan Cuza University
Iasi, Romania
Email: pmihaela@info.uaic.ro

Faculty of Computer Science
Alexandru Ioan Cuza University
Iasi, Romania
Email: mionita@info.uaic.ro

Abstract—The Dynamic Vehicle Routing Problem with Time
Windows (DVRPTW) is an extension of the well-known Vehicle
Routing Problem (VRP), which takes into account the dynamic
nature of the problem. This aspect requires the vehicle routes
to be updated in an ongoing manner as new customer requests
arrive in the system and must be incorporated into an evolving
schedule during the working
Original label:  cs.CE
Predicted label:  3
Correct label:  7
Text:  [CLS] an introduction to quantum programming in quipper alexander s. green1 †, peter lefanu lumsdaine2 † ‡, neil j. ross1 † ‡, peter selinger1 † ‡, and benoıt valiron3 † arxiv : 1304. 5485v1 [ ] 19 apr 2013 1 dalhousie university, halifax, ns, canada agreen @ mathstat. dal. ca, neil. jr. ross @ dal. ca, selinger @ mathstat. dal. ca 2 institute of advanced studies, princeton, nj, u. s. a. p. l. lumsdaine @ gmail. com 3 university of pennsylvania, philadelphia, pa, u. s. a. benoit. valiron @ monoidal. net abstract. quipper is a recently developed programming language for expressing quantum computations. this paper gives a brief tutorial introduction to the language, through a demonstration of how to make use of some of its key features. we illustrate many of quipper ’ s language features by developing a few well known examples of quantum computation, including quantum teleportation, the quantum fourier transform, and a quantum circuit for addition. keywords : quantum computation, programming languages, quipper 1 introduction 1. 1 overview quipper [ 10 ] is an embedded functional programming language for quantum computation. it has been developed as part of iarpa ’ s qcs project [ 13 ]. the stated goal of the qcs project is to “ accurately estimate and reduce the computational resources required to implement quantum algorithms on a realistic quantum computer ”, with an emphasis on using techniques that have been developed in the realms of computer science. in this paper, we will look at how quipper can be used to implement existing quantum algorithms, through a close look at some of the language features that have been added specifically for this task. quipper ’ s development was guided by the goal of implementing seven non - trivial quantum algorithms from the literature [ 3, 5, 11, 12, 14, 17, 18 ]. these algorithms were chosen by the qcs project, and provided to us in modified form. they cover a broad spectrum of techniques ‡ this research was supported by nserc. † this research was supported by the intelligence advanced research projects activity ( iarpa ) via department of interior national business center contract number d12pc00527. the u. s. government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright [SEP]
Text from DS:  An Introduction to
Quantum Programming in Quipper
Alexander S. Green1† , Peter LeFanu Lumsdaine2†‡ , Neil J. Ross1†‡ ,
Peter Selinger1†‡ , and Benoı̂t Valiron3†

arXiv:1304.5485v1 [] 19 Apr 2013

1

Dalhousie University, Halifax, NS, Canada
agreen@mathstat.dal.ca, Neil.JR.Ross@Dal.Ca, selinger@mathstat.dal.ca
2
Institute of Advanced Studies, Princeton, NJ, U.S.A.
p.l.lumsdaine@gmail.com
3
University of Pennsylvania, Philadelphia, PA, U.S.A.
benoit.valiron@monoidal.net

Abstract. Quipper is a recently developed programming language for
expressing quantum computations. This paper gives a brief tutorial introduction to the language, through a demonstration of how to make
use of some of its key features. We illustrate many of Quipper’s language
features by developing a few well known examples of Quantum computation, including quantum teleportation, the quantum Fourier transform,
and a quantum circuit for addition.
Keywords: Quantum Computation, Programming Languages, Quipper

1

Introducti
Original label:  math.AC
Predicted label:  8
Correct label:  5
Text:  [CLS] arxiv : 1511. 06327v1 [ math - ph ] 19 nov 2015 isotypical components of rational functions vincent knibbeler, sara lombardo and jan a. sanders abstract a finite group of mobius transformations acts on the field of rational functions, which in turn decomposes into isotypical components. in spite of the modest group sizes, it is a substantial computational problem to obtain an explicit description of these components by straightforward methods such as averaging. in this paper we find various properties of the isotypical components of rational functions without the need for computations. in particular, we find that each summand is freely generated as a module over the automorphic functions, and the number of generators is the square of the dimension of the associated irreducible representation. the determinant of these generators is expressed in the classical ( kleinian ) ground forms. 1. introduction invariant vectors are considered in many branches of mathematics. they form a natural object of study in representation theory and invariant theory, and they received particular attention in the theory of dynamical systems, where ‘ equivariant vector ’ is the usual terminology ( e. g. equivariant bifurcations, cf. [ gss88, gs02, gs85, dr09, adm08 ] ), as well as in mathematical physics, where rational maps can be used to understand the structure of solutions of the skyrme model [ hms98 ], known as skyrmions ( e. g. [ ms04 ] and references therein ). recently, the theory of automorphic lie algebras [ lm05, lom04 ], related to integrable systems, has been a motivator to study invariant vectors over rational functions in depth. in this paper we consider a finite group g < aut ( p1 ) of mobius transformations ( hence g is isomorphic either to a cyclic group z / n, a dihedral group dn, the tetrahedral group t, the octahedral group o or the icosahedral group y ) and an orbit γ ⊂ p1 of g and study the isotypical components m ( p1 ) χγ, χ ∈ irr ( g ) of the space of meromorphic ( i. e. rational ) functions m ( p1 ) whose poles are contained in γ. here we write irr ( g ) for the set of irreducible characters of g. there is [SEP]
Text from DS:  arXiv:1511.06327v1 [math-ph] 19 Nov 2015

Isotypical Components of Rational Functions
Vincent Knibbeler, Sara Lombardo and Jan A. Sanders
Abstract
A finite group of Möbius transformations acts on the field of rational functions, which
in turn decomposes into isotypical components. In spite of the modest group sizes,
it is a substantial computational problem to obtain an explicit description of these
components by straightforward methods such as averaging. In this paper we find various properties of the isotypical components of rational functions without the need
for computations. In particular, we find that each summand is freely generated as a
module over the automorphic functions, and the number of generators is the square of
the dimension of the associated irreducible representation. The determinant of these
generators is expressed in the classical (Kleinian) ground forms.
1. Introduction
Invariant vectors are considered in many branches of mathematics. They form a natural object o
Original label:  math.GR
Predicted label:  4
Correct label:  7
Text:  [CLS] projectors separating spectra for l2 on pseudounitary groups u ( p, q ) arxiv : 1703. 08814v1 [ math. rt ] 26 mar 2017 yury a. neretin1 the spectrum of l2 on a pseudo - unitary group u ( p, q ) ( we assume p > q ) naturally splits into q + 1 types. we write explicitly orthogonal projectors in l2 to subspaces with uniform spectra ( this is an old question formulated by gelfand and gindikin ). we also write two finer separations of l2. in the first case pieces are enumerated by r = 0, 1,..., q and representations of discrete series of u ( p − r, q − r ), where r = 0,..., q. in the second case pieces are enumerated by all discrete parameters of the tempered spectrum of u ( p, q ). 1 formulas for the projectors 1. 1. problem of separation of spectra. recall a problem formulated in the paper [ 8 ] by i. m. gelfand and s. g. gindikin in 1977. consider a real semisimple lie group g, the left - right action of g × g on g and the corresponding regular representation in l2 ( g ) ( the group is equipped with the haar measure ). the spectrum of the regular representation splits in a natural way into several pieces ( according the number of non - conjugate cartan subgroups ). therefore there is a natural decomposition of l2 ( g ) into a direct sum of subrepresentations with uniform spectra, l2 ( g ) = l1 ⊕ · · · ⊕ lm. respectively, we have a natural decomposition of the identity operator e = π1 + · · · + πm, where πj are orthogonal projectors to the subspaces lj. there arises a question about explicit descriptions of such decompositions. in [ 8 ] there was considered the case g = sl ( 2, r ). the space l2 sl ( 2, r ) is a sum of highest weight representations, a sum of lowest weight representations, and a direct integral over the continuous series. it appears that the summands corresponding to highest weight and lowest weight representations can be regarded as certain hardy spaces h 2. the same question about separation of spectra arises for l2 on semi - simple pseudo - riemannian symmetric spaces and for some other problems [SEP]
Text from DS:  Projectors separating spectra
for L2 on pseudounitary groups U(p, q)

arXiv:1703.08814v1 [math.RT] 26 Mar 2017

Yury A. Neretin1
The spectrum of L2 on a pseudo-unitary group U(p, q) (we assume p > q) naturally
splits into q + 1 types. We write explicitly orthogonal projectors in L2 to subspaces
with uniform spectra (this is an old question formulated by Gelfand and Gindikin).
We also write two finer separations of L2 . In the first case pieces are enumerated by
r = 0, 1, . . . , q and representations of discrete series of U(p − r, q − r), where r = 0,
. . . , q. In the second case pieces are enumerated by all discrete parameters of the
tempered spectrum of U(p, q).

1

Formulas for the projectors

1.1. Problem of separation of spectra. Recall a problem formulated in the
paper [8] by I. M. Gelfand and S. G. Gindikin in 1977. Consider a real semisimple
Lie group G, the left-right action of G × G on G and the corresponding regular
representation in L2 (G) (the group is equipped with the H
Original label:  cs.AI
Predicted label:  10
Correct label:  3
Text:  [CLS] published as a conference paper at iclr 2018 g raph attention n etworks guillem cucurull∗ centre de visio per computador, uab gcucurull @ gmail. com petar velickovic∗ department of computer science and technology university of cambridge petar. velickovic @ cst. cam. ac. uk arxiv : 1710. 10903v3 [ stat. ml ] 4 feb 2018 arantxa casanova∗ centre de visio per computador, uab ar. casanova. 8 @ gmail. com adriana romero montreal institute for learning algorithms adriana. romero. soriano @ umontreal. ca pietro lio department of computer science and technology university of cambridge pietro. lio @ cst. cam. ac. uk yoshua bengio montreal institute for learning algorithms yoshua. umontreal @ gmail. com a bstract we present graph attention networks ( gats ), novel neural network architectures that operate on graph - structured data, leveraging masked self - attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. by stacking layers in which nodes are able to attend over their neighborhoods ’ features, we enable ( implicitly ) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation ( such as inversion ) or depending on knowing the graph structure upfront. in this way, we address several key challenges of spectral - based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. our gat models have achieved or matched state - of - theart results across four established transductive and inductive graph benchmarks : the cora, citeseer and pubmed citation network datasets, as well as a proteinprotein interaction dataset ( wherein test graphs remain unseen during training ). 1 i ntroduction convolutional neural networks ( cnns ) have been successfully applied to tackle problems such as image classification ( he et al., 2016 ), semantic segmentation ( jegou et al., 2017 ) or machine translation ( gehring et al., 2016 ), where the underlying data representation has a grid - like structure. these architectures efficiently reuse their local filters, with learnable parameters, by applying them to all the input positions. however, many interesting tasks involve data that can [SEP]
Text from DS:  Published as a conference paper at ICLR 2018

G RAPH ATTENTION N ETWORKS
Guillem Cucurull∗
Centre de Visió per Computador, UAB
gcucurull@gmail.com

Petar Veličković∗
Department of Computer Science and Technology
University of Cambridge
petar.velickovic@cst.cam.ac.uk

arXiv:1710.10903v3 [stat.ML] 4 Feb 2018

Arantxa Casanova∗
Centre de Visió per Computador, UAB
ar.casanova.8@gmail.com

Adriana Romero
Montréal Institute for Learning Algorithms
adriana.romero.soriano@umontreal.ca

Pietro Liò
Department of Computer Science and Technology
University of Cambridge
pietro.lio@cst.cam.ac.uk

Yoshua Bengio
Montréal Institute for Learning Algorithms
yoshua.umontreal@gmail.com

A BSTRACT
We present graph attention networks (GATs), novel neural network architectures
that operate on graph-structured data, leveraging masked self-attentional layers to
address the shortcomings of prior methods based on graph convolutions or their
approximations. By stacking layers in which nodes are able to atte
Original label:  math.AC
Predicted label:  10
Correct label:  3
Text:  [CLS] on f - and h - vectors of relative simplicial complexes arxiv : 1711. 02729v1 [ math. co ] 7 nov 2017 giulia codenotti, lukas katthan, and raman sanyal abstract. a relative simplicial complex is a collection of sets of the form ∆ \ γ, where γ ⊂ ∆ are simplicial complexes. relative complexes played key roles in recent advances in algebraic, geometric, and topological combinatorics but, in contrast to simplicial complexes, little is known about their general combinatorial structure. in this paper, we address a basic question in this direction and give a characterization of f - vectors of relative ( multi ) complexes on a ground set of fixed size. on the algebraic side, this yields a characterization of hilbert functions of quotients of homogeneous ideals over polynomial rings with a fixed number of indeterminates. moreover, we characterize h - vectors of fully cohen – macaulay relative complexes as well as hvectors of cohen – macaulay relative complexes with minimal faces of given dimensions. the latter resolves a question of bjorner. 1. introduction a simplicial complex ∆ is a collection of subsets of a finite ground set, say [ n ] : = { 1,..., n }, such that σ ∈ ∆ and τ ⊆ σ implies τ ∈ ∆. simplicial complexes are fundamental objects in algebraic, geometric, and topological combinatorics ; see, for example, [ sta96, bs, bjo95 ]. a basic combinatorial statistic of ∆ is the face vector ( or f - vector ) f ( ∆ ) = ( f−1, f0,..., fd−1 ), where fk = fk ( ∆ ) records the number of faces σ ∈ ∆ of dimension k, where dim σ : = | σ | − 1 and d − 1 = dim ∆ : = max { dim σ : σ ∈ ∆ }. notice that we allow ∆ = ∅, the void complex, which is the only complex with fk ( ∆ ) = 0 for all k ≥ −1. a relative simplicial complex ψ on the ground set [ n ] is the collection of sets ∆ \ γ = { τ ∈ ∆ : τ 6∈ γ }, where γ ⊂ ∆ ⊆ 2 [ n ] are simplicial complexes. in general, the pair of simplicial complexes ( ∆, γ ) is not [SEP]
Text from DS:  ON f - AND h-VECTORS OF RELATIVE SIMPLICIAL COMPLEXES

arXiv:1711.02729v1 [math.CO] 7 Nov 2017

GIULIA CODENOTTI, LUKAS KATTHÄN, AND RAMAN SANYAL

Abstract. A relative simplicial complex is a collection of sets of the form ∆ \ Γ, where Γ ⊂ ∆ are
simplicial complexes. Relative complexes played key roles in recent advances in algebraic, geometric,
and topological combinatorics but, in contrast to simplicial complexes, little is known about their
general combinatorial structure. In this paper, we address a basic question in this direction and give
a characterization of f -vectors of relative (multi)complexes on a ground set of fixed size. On the
algebraic side, this yields a characterization of Hilbert functions of quotients of homogeneous ideals
over polynomial rings with a fixed number of indeterminates.
Moreover, we characterize h-vectors of fully Cohen–Macaulay relative complexes as well as hvectors of Cohen–Macaulay relative complexes with minimal faces of given dimensions. The latt
Original label:  cs.NE
Predicted label:  9
Correct label:  3
Text:  [CLS] a hybrid aco algorithm for the next release problem he jiang jingyuan zhang jifeng xuan school of software dalian university of technology dalian 116621, china jianghe @ dlut. edu. cn school of software dalian university of technology dalian 116621, china zhangjy019 @ hotmail. com school of mathematical sciences dalian university of technology dalian 116024, china xuan @ mail. dlut. edu. cn zhilei ren yan hu school of mathematical sciences dalian university of technology dalian 116024, china ren @ mail. dlut. edu. cn school of software dalian university of technology dalian 116621, china huyan @ dlut. edu. cn abstract — in this paper, we propose a hybrid ant colony optimization algorithm ( haco ) for next release problem ( nrp ). nrp, a np - hard problem in requirement engineering, is to balance customer requests, resource constraints, and requirement dependencies by requirement selection. inspired by the successes of ant colony optimization algorithms ( aco ) for solving np - hard problems, we design our haco to approximately solve nrp. similar to traditional aco algorithms, multiple artificial ants are employed to construct new solutions. during the solution construction phase, both pheromone trails and neighborhood information will be taken to determine the choices of every ant. in addition, a local search ( first found hill climbing ) is incorporated into haco to improve the solution quality. extensively wide experiments on typical nrp test instances show that haco outperforms the existing algorithms ( grasp and simulated annealing ) in terms of both solution quality and running time. reasonable time, including greedy algorithms, hill climbing, simulated annealing ( sa ) [ 2, 6 ], and genetic algorithms [ 3, 8 ]. among these algorithms, lmsa ( a simulated annealing algorithm by lundy and mees ) can work efficiently on some problem instances [ 2 ]. ant colony optimization ( aco ) is one of the new technologies in approximately solving np - hard problems since 1991 [ 11 ]. with a colony of artificial ants, aco can achieve good solutions for numerous hard discrete optimization problems. to improve the performance of aco, some hybrid aco algorithms ( i. e. aco with local search ) have also been proposed for solving classical optimization problems, including traveling salesman problem ( tsp ) [ 11 ], quadratic assignment problem ( qap ) [ 12 ], [SEP]
Text from DS:  A Hybrid ACO Algorithm for the Next Release
Problem
He Jiang

Jingyuan Zhang

Jifeng Xuan

School of Software
Dalian University of Technology
Dalian 116621, China
jianghe@dlut.edu.cn

School of Software
Dalian University of Technology
Dalian 116621, China
zhangjy019@hotmail.com

School of Mathematical Sciences
Dalian University of Technology
Dalian 116024, China
xuan@mail.dlut.edu.cn

Zhilei Ren

Yan Hu

School of Mathematical Sciences
Dalian University of Technology
Dalian 116024, China
ren@mail.dlut.edu.cn

School of Software
Dalian University of Technology
Dalian 116621, China
huyan@dlut.edu.cn

Abstract—In this paper, we propose a Hybrid Ant Colony
Optimization algorithm (HACO) for Next Release Problem
(NRP). NRP, a NP-hard problem in requirement engineering, is
to balance customer requests, resource constraints, and
requirement dependencies by requirement selection. Inspired by
the successes of Ant Colony Optimization algorithms (ACO) for
solving NP-hard problems, we design our HA
Original label:  cs.IT
Predicted label:  1
Correct label:  2
Text:  [CLS] identification of repeats in dna sequences using doc - start nucleotide distribution uniformity vol. 00 no. 00 2016 pages 1 – 7 changchuan yin ∗ arxiv : 1608. 00567v1 [ q - bio. gn ] 31 jul 2016 department of mathematics, statistics and computer science the university of illinois at chicago, chicago, il 60607 - 7045, usa abstract motivation : repetitive elements are important in genomic structures, functions and regulations, yet effective methods in precisely identifying repetitive elements in dna sequences are not fully accessible, and the relationship between repetitive elements and periodicities of genomes is not clearly understood. results : we present an ab initio method to quantitatively detect repetitive elements and infer the consensus repeat pattern in repetitive elements. the method uses the measure of the distribution uniformity of nucleotides at periodic positions in dna sequences or genomes. it can identify periodicities, consensus repeat patterns, copy numbers and perfect levels of repetitive elements. the results of using the method on different dna sequences and genomes demonstrate efficacy and accuracy in identifying repeat patterns and periodicities. the complexity of the method is linear with respect to the lengths of the analyzed sequences. availability : the python programs in this study are freely available to the public upon request or at https : / / github. com / cyinbox contact : cyin1 @ uic. edu 1 introduction repetitive elements in dna sequences consist two or more copies of approximate patterns of nucleotides and are abundant in both prokaryotic and eukaryotic genomes. over two - thirds of the human genome and 5 - 10 % bacterial genomes are repetitive regions ( de koning et al., 2011 ). repetitive elements play important roles in genome structure and functions such as nucleoprotein complex formation, chromosome structure, and gene expression. various diseases including cancer and neurodegentive disease can also arise from changes of repetitive elements. the distribution of repetitive dna sequences can be used as fingerprints of bacterial genomes ( versalovic et al., 1991 ) and human individuals. repetitive elements are complex structures. they may exist as imperfect tandem repeats, insertion and deletions in repeats, interspersed repeats, and palindromic sequences, etc. these partial and hidden repeat signals in dna sequences are difficult to analyze through straightforward observation and sequence comparison. currently, repetitive elements and hidden periodicities of dna and protein sequences are primarily detected by digital signal processing and statistical approaches ( treangen and sal [SEP]
Text from DS:  Identification
of repeats in DNA sequences using
Doc-Start
nucleotide distribution uniformity

Vol. 00 no. 00 2016
Pages 1–7

Changchuan Yin ∗

arXiv:1608.00567v1 [q-bio.GN] 31 Jul 2016

Department of Mathematics, Statistics and Computer Science
The University of Illinois at Chicago, Chicago, IL 60607-7045, USA

ABSTRACT
Motivation: Repetitive elements are important in genomic structures,
functions and regulations, yet effective methods in precisely
identifying repetitive elements in DNA sequences are not fully
accessible, and the relationship between repetitive elements and
periodicities of genomes is not clearly understood.
Results: We present an ab initio method to quantitatively detect
repetitive elements and infer the consensus repeat pattern in
repetitive elements. The method uses the measure of the distribution
uniformity of nucleotides at periodic positions in DNA sequences or
genomes. It can identify periodicities, consensus repeat patterns,
copy numbers and perfect levels of 
Original label:  cs.DS
Predicted label:  9
Correct label:  2
Text:  [CLS] astromlskit : a new statistical machine learning toolkit : a platform for data analytics in astronomy 1 2 3 4 5 6 snehanshu saha, surbhi agrawal, manikandan. r, kakoli bora, swati routh, anand narasimhamurthy 1, 2, 3, 6 department of computer science & engineering, pesit south campus, bangalore department of information science & engineering, pesit south campus, bangalore 5 department of physics, center for postgraduate studies, jain university, bangalore 1 2 3 4 snehanshusaha @ pes. edu, surbhiagrawal @ pes. edu, vishnumani. 2009 @ gmail. com, k _ bora @ pes. edu, 5 6 swati. routh @ jainuniversity. ac. in, anandmn @ pes. edu 4 abstract astroinformatics is a new impact area in the world of astronomy, occasionally called the final frontier, where several astrophysicists, statisticians and computer scientists work together to tackle various data intensive astronomical problems. exponential growth in the data volume and increased complexity of the data augments difficult questions to the existing challenges. classical problems in astronomy are compounded by accumulation of astronomical volume of complex data, rendering the task of classification and interpretation incredibly laborious. the presence of noise in the data makes analysis and interpretation even more arduous. machine learning algorithms and data analytic techniques provide the right platform for the challenges posed by these problems. a diverse range of open problem like star - galaxy separation, detection and classification of exoplanets, classification of supernovae is discussed. the focus of the paper is the applicability and efficacy of various machine learning algorithms like k nearest neighbor ( knn ), random forest ( rf ), decision tree ( dt ), support vector machine ( svm ), naive bayes and linear discriminant analysis ( lda ) in analysis and inference of the decision theoretic problems in astronomy. the machine learning algorithms, integrated into astromlskit, a toolkit developed in the course of the work, have been used to analyze habcat data and supernovae data. accuracy has been found to be appreciably good. keywords : habitability catalog ( habcat ), supernova classification, data analysis, astroinformatics, machine learning, astromls toolkit, naive bayes, svd, pc [SEP]
Text from DS:  ASTROMLSKIT: A New Statistical Machine Learning Toolkit: A
Platform for Data Analytics in Astronomy
1

2

3

4

5

6

Snehanshu Saha , Surbhi Agrawal , Manikandan. R , Kakoli Bora , Swati Routh , Anand Narasimhamurthy
1,2,3,6

Department of Computer Science & Engineering, PESIT South Campus, Bangalore
Department of Information Science & Engineering, PESIT South Campus, Bangalore
5
Department of Physics, Center for Postgraduate Studies, Jain University, Bangalore
1
2
3
4
snehanshusaha@pes.edu, surbhiagrawal@pes.edu, vishnumani.2009@gmail.com, k_bora@pes.edu,
5
6
swati.routh@jainuniversity.ac.in, anandmn@pes.edu
4

ABSTRACT
Astroinformatics is a new impact area in the world of astronomy, occasionally called the final frontier,
where several astrophysicists, statisticians and computer scientists work together to tackle various data
intensive astronomical problems. Exponential growth in the data volume and increased complexity of
the data augments difficult questions to the existing challe
Original label:  math.AC
Predicted label:  8
Correct label:  1
Text:  [CLS] neural ideals and stimulus space visualization arxiv : 1607. 00697v1 [ q - bio. nc ] 3 jul 2016 elizabeth gross, nida kazi obatake, and nora youngs abstract. a neural code c is a collection of binary vectors of a given length n that record the co - firing patterns of a set of neurons. our focus is on neural codes arising from place cells, neurons that respond to geographic stimulus. in this setting, the stimulus space can be visualized as subset of r2 covered by a collection u of convex sets such that the arrangement u forms an euler diagram for c. there are some methods to determine whether such a convex realization u exists ; however, these methods do not describe how to draw a realization. in this work, we look at the problem of algorithmically drawing euler diagrams for neural codes using two polynomial ideals : the neural ideal, a pseudomonomial ideal ; and the neural toric ideal, a binomial ideal. in particular, we study how these objects are related to the theory of piercings in information visualization, and we show how minimal generating sets of the ideals reveal whether or not a code is 0, 1, or 2 - inductively pierced. 1. introduction in 2014, the nobel prize in medicine or physiology was awarded to john o ’ keefe and his team for their 1971 discovery of place cells [ 22 ]. a place cell is a neuron that codes a distinct region in an animal ’ s environment called a place field. that is, if the animal is in a place field, the associated place cell fires ; otherwise it is silent. such neurons are believed to be an essential part of the navigation system and spatial memory. the firing activity of a population of neurons over time results in a set of co - firing patterns, which can be stored using binary vectors, or codewords. each codeword indicates the set of neurons that were firing together during some time window. a set c ⊂ { 0, 1 } n of codewords on n neurons is called a combinatorial neural code ; the descriptor “ combinatorial ” is commonly used since the precise details of neural spiking and timing are discarded, leaving only discrete co - firing patterns. for a description of how neuronal firing data may be discretized, see [ 6 ]. each codeword in a combinatorial neural code c is associated with the set of neurons it represents ; that is, given c ∈ c [SEP]
Text from DS:  NEURAL IDEALS AND STIMULUS SPACE VISUALIZATION

arXiv:1607.00697v1 [q-bio.NC] 3 Jul 2016

ELIZABETH GROSS, NIDA KAZI OBATAKE, AND NORA YOUNGS

Abstract. A neural code C is a collection of binary vectors of a given length n that
record the co-firing patterns of a set of neurons. Our focus is on neural codes arising from
place cells, neurons that respond to geographic stimulus. In this setting, the stimulus
space can be visualized as subset of R2 covered by a collection U of convex sets such that
the arrangement U forms an Euler diagram for C. There are some methods to determine
whether such a convex realization U exists; however, these methods do not describe how
to draw a realization. In this work, we look at the problem of algorithmically drawing
Euler diagrams for neural codes using two polynomial ideals: the neural ideal, a pseudomonomial ideal; and the neural toric ideal, a binomial ideal. In particular, we study how
these objects are related to the theory of piercings in informati
Original label:  cs.IT
Predicted label:  10
Correct label:  8
Text:  [CLS] i i “ main ” — 2017 / 4 / 19 — 0 : 38 — page 1 — # 1 i i xxxxxx / xxxxxx / xxxxxx advance access publication date : day month year manuscript category subject section fmtree : a fast locating algorithm of fm - indexes for genomic data haoyu cheng 1, 2, 3, ming wu 1, 2, 3 and yun xu 1, 2, 3, ∗ 1 school of computer science, university of science and technology of china, heifei, anhui, 230027, china key laboratory on high performance computing, anhui province 2 collaborative innovation center of high performance computing, national university of defense technology, changsha, 410073, china 2 ∗ to whom correspondence should be addressed. associate editor : xxxxxxx arxiv : 1704. 04615v2 [ ] 18 apr 2017 received on xxxxx ; revised on xxxxx ; accepted on xxxxx abstract motivation : as a fundamental task in bioinformatics, searching for massive short patterns over a long text has been accelerated by various compressed full - text indexes. these indexes are able to provide similar searching functionalities to classical indexes, e. g., suffix trees and suffix arrays, while requiring less space. for genomic data, a well - known family of compressed full - text index, called fm - indexes, presents unmatched performance in practice. one major drawback of fm - indexes is that their locating operations, which report all occurrence positions of patterns in a given text, are particularly slow, especially for the patterns with many occurrences. results : in this paper, we introduce a novel locating algorithm, fmtree, to fast retrieve all occurrence positions of any pattern via fm - indexes. when searching for a pattern over a given text, fmtree organizes the search space of the locating operation into a conceptual quadtree. as a result, multiple occurrence positions of this pattern can be retrieved simultaneously by traversing the quadtree. compared with the existing locating algorithms, our tree - based algorithm reduces large numbers of redundant operations and presents better data locality. experimental results show that fmtree is one order of magnitude faster than the state - of - the - art algorithms, and still memory - efficient. availability : fmtree is freely available at https : / / github. com / chhylp123 / fmtree. contact : xuyun @ ustc. edu. cn supplementary information : supplementary data [SEP]
Text from DS:  i

i
“main” — 2017/4/19 — 0:38 — page 1 — #1

i

i

xxxxxx/xxxxxx/xxxxxx
Advance Access Publication Date: Day Month Year
Manuscript Category

Subject Section

FMtree: A fast locating algorithm of FM-indexes for
genomic data
Haoyu Cheng 1,2,3 , Ming Wu 1,2,3 and Yun Xu 1,2,3,∗
1

School of Computer Science, University of Science and Technology of China, Heifei, Anhui, 230027, China
Key Laboratory on High Performance Computing, Anhui Province
2
Collaborative Innovation Center of High Performance Computing, National University of Defense Technology, Changsha, 410073,
China
2

∗ To

whom correspondence should be addressed.

Associate Editor: XXXXXXX

arXiv:1704.04615v2 [] 18 Apr 2017

Received on XXXXX; revised on XXXXX; accepted on XXXXX

Abstract
Motivation: As a fundamental task in bioinformatics, searching for massive short patterns over a long
text has been accelerated by various compressed full-text indexes. These indexes are able to provide
similar searching functionalities to class
Original label:  math.AC
Predicted label:  6
Correct label:  0
Text:  [CLS] planar, outerplanar and ring graph arxiv : 1712. 06993v1 [ ] 17 dec 2017 of the intersection graph ∗ s. khojasteh department of mathematics, lahijan branch, islamic azad university, lahijan, iran s khojasteh @ liau. ac. ir abstract let m, n > 1 be two integers, and zn be a zm - module. let i ( zm ) ∗ be the set of all non - zero proper ideals of zm. the zn - intersection graph of zm, denoted by gn ( zm ) is a graph with the vertex set i ( zm ) ∗, and two distinct vertices i and j are adjacent if and only if izn ∩ jzn 6 = 0. in this paper, we determine the values of m and n for which gn ( zm ) is planar, outerplanar or ring graph. 1 introduction let r be a commutative ring, and i ( r ) ∗ be the set of all non - zero proper ideals of r. there are many papers on assigning a graph to a ring r, for instance see [ 1 ], [ 2 ], [ 5 ], [ 6 ] and [ 13 ]. also the intersection graphs of some algebraic structures such as groups, rings and modules have been studied by several authors, see [ 3, 4, 8, 9 ]. in [ 8 ], the intersection graph of ideals of r, denoted by g ( r ), was introduced as the graph with vertices i ( r ) ∗ and for distinct i, j ∈ i ( r ) ∗, the vertices i and j are adjacent if and only if i ∩ j 6 = 0. also in [ 4 ], the intersection graph of submodules of an r - module m, denoted by g ( m ), is defined to be the graph whose vertices are the non - zero proper submodules of m and two distinct vertices are adjacent if and only if they have non - zero intersection. in [ 11 ], the m intersection graph of ideals of r denoted by gm ( r ), is defined to be the graph with the vertex set i ( r ) ∗, and two distinct vertices i and j are adjacent if and only ∗ key words : intersection graph, ring graph, planarity, outerplanarity. 2010 mathematics subject classification : 05c10, 05c25, 13 [SEP]
Text from DS:  Planar, outerplanar and ring graph

arXiv:1712.06993v1 [] 17 Dec 2017

of the intersection graph

∗

S. Khojasteh

Department of Mathematics, Lahijan Branch, Islamic Azad University, Lahijan, Iran
s khojasteh@liau.ac.ir

Abstract
Let m, n > 1 be two integers, and Zn be a Zm -module. Let I(Zm )∗ be the set of all
non- zero proper ideals of Zm . The Zn -intersection graph of Zm , denoted by Gn (Zm )
is a graph with the vertex set I(Zm )∗ , and two distinct vertices I and J are adjacent
if and only if IZn ∩ JZn 6= 0. In this paper, we determine the values of m and n for
which Gn (Zm ) is planar, outerplanar or ring graph.

1

Introduction

Let R be a commutative ring, and I(R)∗ be the set of all non-zero proper ideals of R.
There are many papers on assigning a graph to a ring R, for instance see [1], [2], [5], [6]
and [13]. Also the intersection graphs of some algebraic structures such as groups, rings
and modules have been studied by several authors, see [3, 4, 8, 9]. In [8], the interse
Original label:  math.GR
Predicted label:  9
Correct label:  2
Text:  [CLS] arxiv : 1607. 02079v1 [ ] 7 jul 2016 normal subgroups of limit groups of prime index jhoel s. gutierrez and thomas s. weigel abstract. motivated by their study of pro - p limit groups, d. h. kochloukova and p. a. zalesskii formulated in [ 14, remark after thm. 3. 3 ] a question concerning the minimum number of generators d ( n ) of a normal subgroup n of index p in a non - abelian limit group g ( cf. question * ). it is shown that the analogous question for the rational rank has an affirmative answer ( cf. thm. a ). from this result one may conclude that the original question of d. h. kochloukova and p. a. zalesskii has an affirmative answer if the abelianization gab of g is torsion free and d ( g ) = d ( gab ) ( cf. cor. b ), or if g has the if - property ( cf. thm c ). 1. introduction in recent years limit groups ( or ω - residually free groups ) have received much attention ( cf. [ 1 ], [ 3 ], [ 5 ], [ 8 ], [ 15 ] ) primarily due to the groundbreaking work of z. sela ( cf. [ 16 ], [ 17 ] and the references therein ). this class of groups was first introduced by b. baumslag in [ 2 ] under the more traditional name of fully residually free groups, and subsequently studied intensively by many authors ( cf. [ 6 ], [ 9 ], [ 10 ], [ 11 ], [ 12 ] ). indeed, this notion reflects the fact that for any limit group g and any finite subset t of g there exists a homomorphism from g to a free group f that is injective on t. examples of limit groups include all finitely generated free groups, all finitely generated free abelian groups, and all the fundamental groups of closed oriented surfaces. moreover, the class of limit groups is closed with respect to finitely generated subgroups and free products. this fact can be used to construct many examples. more sophisticated examples can be found in some of the articles cited above. the purpose of this note is to investigate the following question which was raised by d. h. kochloukova and p. a. zalesskii in [ 14 ], where they answered [SEP]
Text from DS:  arXiv:1607.02079v1 [] 7 Jul 2016

NORMAL SUBGROUPS OF LIMIT GROUPS OF PRIME INDEX
JHOEL S. GUTIERREZ AND THOMAS S. WEIGEL
Abstract. Motivated by their study of pro-p limit groups, D.H. Kochloukova
and P.A. Zalesskii formulated in [14, Remark after Thm. 3.3] a question concerning the minimum number of generators d(N ) of a normal subgroup N of
index p in a non-abelian limit group G (cf. Question*). It is shown that
the analogous question for the rational rank has an affirmative answer (cf.
Thm. A). From this result one may conclude that the original question of
D.H. Kochloukova and P.A. Zalesskii has an affirmative answer if the abelianization Gab of G is torsion free and d(G) = d(Gab ) (cf. Cor. B), or if G has
the IF-property (cf. Thm C).

1. Introduction
In recent years limit groups (or ω-residually free groups) have received much
attention (cf. [1], [3], [5], [8], [15]) primarily due to the groundbreaking work
of Z. Sela (cf. [16], [17] and the references therein). This class of gro
Original label:  cs.AI
Predicted label:  2
Correct label:  3
Text:  [CLS] 1 “ in folly ripe. in reason rotten ” 1 putting machine theology to rest mihai nadin, institute for research in anticipatory systems, university of texas at dallas, richardson tx usa abstract : computation has changed the world more than any previous expressions of knowledge. in its particular algorithmic embodiment, it offers a perspective, within which the digital computer ( one of many possible ) exercises a role reminiscent of theology. since it is closed to meaning, algorithmic digital computation can at most mimic the creative aspects of life. ai, in the perspective of time, proved to be less an acronym for artificial intelligence and more of automating tasks associated with intelligence. the entire development led to the hypostatized role of the machine : outputting nothing else but reality, including that of the humanity that made the machine happen. the convergence machine called deep learning is only the latest form through which the deterministic theology of the machine claims more than what extremely effective data processing actually is. a new understanding of complexity, as well as the need to distinguish between the reactive nature of the artificial and the anticipatory nature of the living are suggested as practical responses to the challenges posed by machine theology. keywords : hypostatize, convergence, anticipatory, information, meaning, deep learning, gcomplexity, 1 raleigh, walter ( 1596 ) 2 “ … it ’ s just a block of wood! i burned half of it for heat and used it to bake my bread and roast my meat. how can the rest of it be a god? should i bow down to worship a piece of wood? ” ” 2 1 introduction / preliminaries a distinguished colleague ( holding an endowed chair at an ivy league university ), known for his work in computational molecular biology, rushed a kind note to me : “ your anticipatory research theme is now a thematic focus in iarpa program : anticipatory intelligence. the world is catching up with you. ” on the iarpa website i read : “ anticipatory intelligence focuses on characterizing and reducing uncertainty by providing decision makers with timely and accurate forecasts of significant global events. ” as well - intended as the congratulation was, it brought up many instances of no less well - intended but deceiving use of the word “ anticipation. ” “ have you anticipated this? ” would be the well - meant comical remark that gives away the fact that the person asking had no idea what anticipation is [SEP]
Text from DS:  1
“In folly ripe. In reason rotten”1 Putting machine theology to rest

Mihai Nadin, Institute for Research in Anticipatory Systems, University of Texas at Dallas,
Richardson TX USA

Abstract: Computation has changed the world more than any previous expressions of knowledge.
In its particular algorithmic embodiment, it offers a perspective, within which the digital
computer (one of many possible) exercises a role reminiscent of theology. Since it is closed to
meaning, algorithmic digital computation can at most mimic the creative aspects of life. AI, in the
perspective of time, proved to be less an acronym for artificial intelligence and more of
automating tasks associated with intelligence. The entire development led to the hypostatized role
of the machine: outputting nothing else but reality, including that of the humanity that made the
machine happen. The convergence machine called deep learning is only the latest form through
which the deterministic theology of the machine claims mo
Original label:  cs.CV
Predicted label:  3
Correct label:  8
Text:  [CLS] this paper is submitted for peer - review. interpretation of mammogram and chest radiograph reports using deep neural networks arxiv : 1708. 09254v3 [ ] 12 sep 2017 hojjat salehinejad, shahrokh valaee, senior member, ieee, aren mnatzakanian, tim dowdell, joseph barfett, and errol colak abstract — radiology reports are an important means of communication between radiologists and other physicians. these reports express a radiologist ’ s interpretation of a medical imaging examination and are critical in establishing a diagnosis and formulating a treatment plan. in this paper, we propose a bidirectional convolutional neural network ( bi - cnn ) model for the interpretation and classification of mammograms based on breast density and chest radiographic radiology reports based on the basis of chest pathology. the proposed approach is a part of an auditing system that evaluates radiology reports to decrease incorrect diagnoses. our study revealed that the proposed bicnn outperforms convolutional neural network, random forest and support vector machine methods. index terms — breast density, chest radiograph, convolutional neural networks, mammography, radiology reports classification. i. i ntroduction radiology reports are an important means of communication between radiologists and other physicians [ 1 ]. these reports express a radiologist ’ s interpretation of a medical imaging examination and are critical in establishing a diagnosis and formulating a treatment plan. radiology is among the medical specialties with the highest rate of malpractice claims [ 2 ]. these claims can arise from a failure to communicate important findings, a failure of perception, lack of knowledge, and misjudgment. a failure to detect an abnormality on a medical imaging examination can lead to significant medical consequences for patients such as a delayed diagnosis. with a delayed or incorrect diagnosis, patients can present later with worsened symptoms and more advanced disease that may require more aggressive treatment or may be untreatable. in this paper, we propose an auditing system for radiologists that has two main components : a natural language processing ( nlp ) model to process and interpret a radiology report and a machine vision model that interprets the medical imaging examination. this auditing system reviews the radiologist ’ s report and compares it with the interpretation of a machine vision model. the proposed system would notify the radiologist if there is a discrepancy between [SEP]
Text from DS:  This paper is submitted for peer-review.

Interpretation of Mammogram and Chest
Radiograph Reports Using Deep Neural Networks

arXiv:1708.09254v3 [] 12 Sep 2017

Hojjat Salehinejad, Shahrokh Valaee, Senior Member, IEEE, Aren Mnatzakanian, Tim Dowdell,
Joseph Barfett, and Errol Colak
Abstract—Radiology reports are an important means of communication between radiologists and other physicians. These
reports express a radiologist’s interpretation of a medical imaging
examination and are critical in establishing a diagnosis and
formulating a treatment plan. In this paper, we propose a Bidirectional convolutional neural network (Bi-CNN) model for the
interpretation and classification of mammograms based on breast
density and chest radiographic radiology reports based on the
basis of chest pathology. The proposed approach is a part of
an auditing system that evaluates radiology reports to decrease
incorrect diagnoses. Our study revealed that the proposed BiCNN outperforms convolutional neural
Original label:  cs.PL
Predicted label:  5
Correct label:  1
Text:  [CLS] 1 fast discrete linear canonical transform based on cm - cc - cm decomposition and fft arxiv : 1709. 06222v1 [ ] 19 sep 2017 soo - chang pei, life fellow, ieee, and shih - gu huang abstract — in this paper, a discrete lct ( dlct ) irrelevant to the sampling periods and without oversampling operation is developed. this dlct is based on the well - known cm - cccm decomposition, that is, implemented by two discrete chirp multiplications ( cms ) and one discrete chirp convolution ( cc ). this decomposition doesn ’ t use any scaling operation which will change the sampling period or cause the interpolation error. compared with previous works, dlct calculated by direct summation and dlct based on center discrete dilated hermite functions ( cddhfs ), the proposed method implemented by ffts has much lower computational complexity. the relation between the proposed dlct and the continuous lct is also derived to approximate the samples of the continuous lct. simulation results show that the proposed method somewhat outperforms the cddhfs - based method in the approximation accuracy. besides, the proposed method has approximate additivity property with error as small as the cddhfs - based method. most importantly, the proposed method has perfect reversibility, which doesn ’ t hold in many existing dlcts. with this property, it is unnecessary to develop the inverse dlct additionally because it can be replaced by the forward dlct. index terms — abcd transform, affine fourier transform, fractional fourier transform, linear canonical transform, quadratic - phase integrals. i. i ntroduction the linear canonical transform ( lct ), first introduced in [ 1 ], [ 2 ], is a parameterized general linear integral transform with three degrees of freedom. the lct unifies a variety of transforms from the well - known fourier transform ( ft ), fractional fourier transform ( frft ) and fresnel transform ( also known as chirp convolution ( cc ) ) to simple operations such as scaling and chirp multiplication ( cm ) [ 3 ] – [ 5 ]. the lct is an important tool in optics because the paraxial light propagation through a first - order optical system can be modeled by the lct [ 3 ], [ 6 ], [ 7 ]. besides, as a generalization of the transforms mentioned above, the lct could be more useful and attractive in many signal [SEP]
Text from DS:  1

Fast Discrete Linear Canonical Transform Based on
CM-CC-CM Decomposition and FFT

arXiv:1709.06222v1 [] 19 Sep 2017

Soo-Chang Pei, Life Fellow, IEEE, and Shih-Gu Huang

Abstract—In this paper, a discrete LCT (DLCT) irrelevant
to the sampling periods and without oversampling operation
is developed. This DLCT is based on the well-known CM-CCCM decomposition, that is, implemented by two discrete chirp
multiplications (CMs) and one discrete chirp convolution (CC).
This decomposition doesn’t use any scaling operation which will
change the sampling period or cause the interpolation error.
Compared with previous works, DLCT calculated by direct
summation and DLCT based on center discrete dilated Hermite
functions (CDDHFs), the proposed method implemented by FFTs
has much lower computational complexity. The relation between
the proposed DLCT and the continuous LCT is also derived
to approximate the samples of the continuous LCT. Simulation
results show that the proposed method somewhat out
Original label:  cs.IT
Predicted label:  6
Correct label:  2
Text:  [CLS] a distributed method for optimal capacity reservation nicholas moehle∗ xinyue shen † zhi - quan luo ‡ stephen boyd § arxiv : 1705. 00677v1 [ cs. dc ] 1 may 2017 may 3, 2017 abstract we consider the problem of reserving link capacity in a network in such a way that any of a given set of flow scenarios can be supported. in the optimal capacity reservation problem, we choose the reserved link capacities to minimize the reservation cost. this problem reduces to a large linear program, with the number of variables and constraints on the order of the number of links times the number of scenarios. small and medium size problems are within the capabilities of generic linear program solvers. we develop a more scalable, distributed algorithm for the problem that alternates between solving ( in parallel ) one flow problem per scenario, and coordination steps, which connect the individual flows and the reservation capacities. 1 introduction we address the capacity reservation problem, the problem of reserving link capacity in a network in order to support multiple possible flow patterns. we are given a description of the network, and a collection of traffic demand scenarios, which specify the amount of flow to be routed from some sources to some sinks. we must reserve enough link capacity so that for any of these scenarios, there exist flows that route the traffic demand while using no more than the reserved capacity on each link. subject to this requirement, we seek to minimize a linear reservation cost. this problem is also referred to as the network design problem. the capacity reservation problem can be expressed as a linear program ( lp ), a fact first recognized by gomory and hu in 1962 [ gh62 ]. for moderate problem sizes it can be solved using generic lp solvers. however, problems with a large number of scenarios ( and especially those that do not fit in a single computer ’ s memory ) are beyond the reach of such solvers. we present an iterative method for solving the capacity reservation problem based on the alternating direction method of multipliers ( admm ). each iteration of the algorithm involves solving, in parallel, a single minimum - cost flow problem for each scenario. this means that ∗ mechanical engineering department, stanford university. moehle @ stanford. edu electronic engineering department, tsinghua university. ‡ electrical and computer engineering, university of minnesota. § electrical engineering department, stanford university. † 1 our method can easily exploit parallel computing architectures, and can scale to enormous problem instances that do not fit in the [SEP]
Text from DS:  A Distributed Method for Optimal Capacity Reservation
Nicholas Moehle∗

Xinyue Shen†

Zhi-Quan Luo‡

Stephen Boyd§

arXiv:1705.00677v1 [cs.DC] 1 May 2017

May 3, 2017

Abstract
We consider the problem of reserving link capacity in a network in such a way
that any of a given set of flow scenarios can be supported. In the optimal capacity
reservation problem, we choose the reserved link capacities to minimize the reservation
cost. This problem reduces to a large linear program, with the number of variables and
constraints on the order of the number of links times the number of scenarios. Small
and medium size problems are within the capabilities of generic linear program solvers.
We develop a more scalable, distributed algorithm for the problem that alternates
between solving (in parallel) one flow problem per scenario, and coordination steps,
which connect the individual flows and the reservation capacities.

1

Introduction

We address the capacity reservation problem, the problem of r
Original label:  cs.SY
Predicted label:  2
Correct label:  8
Text:  [CLS] 1 arxiv : 1604. 00217v2 [ ] 4 apr 2018 moving horizon estimation for discrete - time linear systems with binary sensors : algorithms and stability results g. battistellia, l. chiscia, s. gherardinia, b a universita di firenze, dipartimento di ingegneria dell ’ informazione ( dinfo ), via di santa marta 3, 50139 firenze, italy. b csdc, universita di firenze, infn, and lens, via g. sansone 1, i - 50019 sesto fiorentino, italy, and qstar, largo e. fermi 2, i - 50125 firenze, italy. { giorgio. battistelli, luigi. chisci, stefano. gherardini } @ unifi. it abstract the paper addresses state estimation for linear discrete - time systems with binary ( threshold ) measurements. a moving horizon estimation ( mhe ) approach is followed and different estimators, characterized by two different choices of the cost function to be minimized and / or by the possible inclusion of constraints, are proposed. specifically, the cost function is either quadratic, when only the information pertaining to the threshold - crossing instants is exploited, or piece - wise quadratic, when all the available binary measurements are taken into account. stability results are provided for the proposed mhe algorithms in the presence of unknown but bounded disturbances and measurement noise. performance of the proposed techniques is also assessed by means of simulation examples. keywords : state estimation ; moving - horizon estimation ; binary measurements ; stability analysis. i. i ntroduction binary ( threshold ) sensors whose output can take two possible values according to whether the sensed variable exceed or not a given threshold, are nowadays commonly exploited for monitoring / control aims in a wide range of application domains. a non - exhaustive list of existing binary sensors includes : industrial sensors for brushless dc motors, liquid levels, pressure switches ; chemical process sensors for vacuum, pressure, gas concentration and power levels ; switching sensors for exhaust gas oxygen ( ego or lambda sensors ), abs, shift - by - wire in automotive applications ; gas content sensors ( co, co2, h2, etc. ) for gas & oil industry ; traffic condition indicators for asynchronous transmission mode ( atm ) networks ; medical sensors / analyses with dichotomous outcomes. in some applications, binary sensors represent [SEP]
Text from DS:  1

arXiv:1604.00217v2 [] 4 Apr 2018

Moving horizon estimation for discrete-time linear
systems with binary sensors: algorithms and
stability results
G. Battistellia , L. Chiscia , S. Gherardinia,b
a Università di Firenze, Dipartimento di Ingegneria dell’Informazione (DINFO), Via di Santa Marta 3,
50139 Firenze, Italy.
b CSDC, Università di Firenze, INFN, and LENS, Via G. Sansone 1, I-50019 Sesto Fiorentino, Italy,
and QSTAR, Largo E. Fermi 2, I-50125 Firenze, Italy.
{giorgio.battistelli, luigi.chisci, stefano.gherardini}@unifi.it

Abstract
The paper addresses state estimation for linear discrete-time systems with binary (threshold) measurements. A
Moving Horizon Estimation (MHE) approach is followed and different estimators, characterized by two different
choices of the cost function to be minimized and/or by the possible inclusion of constraints, are proposed. Specifically,
the cost function is either quadratic, when only the information pertaining to the threshold-crossing instant
Original label:  cs.NE
Predicted label:  8
Correct label:  6
Text:  [CLS] a theoretical basis for efficient computations with noisy spiking neurons zeno jonke †, stefan habenschuss †, wolfgang maass∗ arxiv : 1412. 5862v1 [ ] 18 dec 2014 institute for theoretical computer science, graz university of technology, austria december 19, 2014 abstract. network of neurons in the brain apply – unlike processors in our current generation of computer hardware – an event - based processing strategy, where short pulses ( spikes ) are emitted sparsely by neurons to signal the occurrence of an event at a particular point in time. such spike - based computations promise to be substantially more power - efficient than traditional clocked processing schemes. however it turned out to be surprisingly difficult to design networks of spiking neurons that are able to carry out demanding computations. we present here a new theoretical framework for organizing computations of networks of spiking neurons. in particular, we show that a suitable design enables them to solve hard constraint satisfaction problems from the domains of planning / optimization and verification / logical inference. the underlying design principles employ noise as a computational resource. nevertheless the timing of spikes ( rather than just spike rates ) plays an essential role in the resulting computations. furthermore, one can demonstrate for the traveling salesman problem a surprising computational advantage of networks of spiking neurons compared with traditional artificial neural networks and gibbs sampling. the identification of such advantage has been a well - known open problem. the number of neurons in the brain lies in the same range as the number of transistor in a supercomputer. but whereas the brain consumes less then 30 watt, a supercomputer consumes as much energy as a major part of a city. the power consumption has not only become a bottleneck for supercomputers, but for many applications and improvements of computing hardware, including the design of intelligent mobile devices. but how can one capture the drastically different style of computations by networks of neurons in the brain, and apply similar energy - efficient methods for the organization of computation in novel computing hardware? in particular, how can one carry out complex computations in massively parallel systems without a clock, that synchronizes the contributions of individual processors? when the membrane potential of a biological neuron crosses a threshold, the neuron emits a spike, i. e. a sudden voltage increase that lasts for 1 - 2 ms. spikes occur asynchronously in continuous time and are communicated to numerous other neurons via synaptic connections with different strengths ( “ [SEP]
Text from DS:  A theoretical basis for efficient computations
with noisy spiking neurons
Zeno Jonke† , Stefan Habenschuss† , Wolfgang Maass∗

arXiv:1412.5862v1 [] 18 Dec 2014

Institute for Theoretical Computer Science, Graz University of Technology, Austria

December 19, 2014
Abstract. Network of neurons in the brain apply – unlike processors in our current generation of computer
hardware – an event-based processing strategy, where short pulses (spikes) are emitted sparsely by neurons to
signal the occurrence of an event at a particular point in time. Such spike-based computations promise to be
substantially more power-efficient than traditional clocked processing schemes. However it turned out to be
surprisingly difficult to design networks of spiking neurons that are able to carry out demanding computations.
We present here a new theoretical framework for organizing computations of networks of spiking neurons. In
particular, we show that a suitable design enables them to solve hard constraint sati
Original label:  cs.CV
Predicted label:  3
Correct label:  2
Text:  [CLS] a deep unsupervised learning approach toward mtbi identification using diffusion mri arxiv : 1802. 02925v1 [ ] 8 feb 2018 shervin minaee1, yao wang1, anna choromanska1, sohae chung2, xiuyuan wang2, els fieremans2, steven flanagan3, joseph rath3, yvonne w. lui2, 1 electrical and computer engineering department, new york university 2 department of radiology, new york university 3 department of rehabilitation medicine, new york university abstract — mild traumatic brain injury ( mtbi ) is a growing public health problem with an estimated incidence of one million people annually in us. neurocognitive tests have been used to both assess the patient condition and to monitor the patient progress. this work aims to directly use diffusion mr images taken shortly after injury to detect whether a patient suffers from mtbi, by incorporating deep learning techniques. to overcome the challenge due to limited training data, we describe each brain region using the bag of word representation, which specifies the distribution of representative patch patterns. we apply a convolutional auto - encoder to learn the patch - level features, from overlapping image patches extracted from the mr images. to learn features from diffusion mr images of brain using an unsupervised approach. our experimental results show that the bag of word representation using patch level features learnt by the auto encoder provides similar performance as that using the raw patch patterns, both significantly outperform earlier work relying on the mean values of mr metrics in selected brain regions. the raw mri volume data as the input. we have proposed a new approach for feature extraction from mr images, where we first learn the feature representation of patches using a deep unsupervised learning approach [ 8 ], and then aggregate the features from different patches through a bag of word representation, and use them along with demographic and neuro - cognitive test features as the overall feature vector. we then use feature selection followed by a classification algorithm to identify mtbi patients. the block diagram of the overall algorithm is shown in fig. 1. through experimental study, we show that by learning patch level deep features and aggregating them through a bag of word representation for each brain region, we get much higher accuracy compared to using mean values of the various mr metrics in each region. i. i ntroduction mild traumatic brain injury ( mtbi ) is a growing public health problem, which can cause loss of consciousness [SEP]
Text from DS:  A Deep Unsupervised Learning Approach Toward
MTBI Identification Using Diffusion MRI

arXiv:1802.02925v1 [] 8 Feb 2018

Shervin Minaee1 , Yao Wang1 , Anna Choromanska1 , Sohae Chung2 , Xiuyuan Wang2 , Els Fieremans2 ,
Steven Flanagan3 , Joseph Rath3 , Yvonne W. Lui2 ,
1 Electrical and Computer Engineering Department, New York University
2 Department of Radiology, New York University
3 Department of Rehabilitation Medicine, New York University

Abstract—Mild traumatic brain injury (mTBI) is a growing
public health problem with an estimated incidence of one million
people annually in US. Neurocognitive tests have been used to
both assess the patient condition and to monitor the patient
progress. This work aims to directly use diffusion MR images
taken shortly after injury to detect whether a patient suffers from
mTBI, by incorporating deep learning techniques. To overcome
the challenge due to limited training data, we describe each brain
region using the bag of word representation, which
Original label:  cs.IT
Predicted label:  2
Correct label:  9
Text:  [CLS] constant query time ( 1 + o ) - approximate distance oracle for planar graphs1. qian - ping gu and gengchun xu arxiv : 1706. 03108v1 [ ] 9 jun 2017 school of computing science, simon fraser university burnaby bc canada v5a1s6 qgu @ cs. sfu. ca, gxa2 @ sfu. ca abstract : we give a ( 1 + o ) - approximate distance oracle with o ( 1 ) query time for an undirected planar graph g with n vertices and non - negative edge lengths. for o > 0 and any two vertices u [UNK] v ) with stretch ( 1 + o ) in o ( 1 ) time. the oracle has size and v in g, our oracle gives a distance d ( u, o ( n log n ( ( log n ) / o + f ( o ) ) ) and pre - processing time o ( n log n ( ( log3 n ) / o2 + f ( o ) ) ), where f ( o ) = 2o ( 1 / o ). this is the first ( 1 + o ) - approximate distance oracle with o ( 1 ) query time independent of o and the size and pre - processing time nearly linear in n, and improves the query time o ( 1 / o ) of previous ( 1 + o ) - approximate distance oracle with size nearly linear in n. key words : distance oracle, planar graphs, approximate algorithms, graph decomposition 1 introduction finding a distance between two vertices in a graph is a fundamental computational problem and has a wide range of applications. for this problem, there is a rich literature of algorithms. this problem can be solved by a single source shortest path algorithm such as the dijkstra and bellmanford algorithms. in many applications, it is required to compute the shortest path distance in an extreme short time. one approach to meet such a requirement is to use distance oracles. a distance oracle is a data structure which keeps the pre - computed distance information and provides a distance between any given pair of vertices very efficiently. there are two phases in the distance oracle approach. the first phase is to compute the data structure for a given graph g and the second is to provide an answer for a query on the distance between a pair of vertices in g. the efficiency of distance oracles is mainly measured by the time to answer a query ( query time ), the memory space required for the data structure ( oracle size ) and the time to create the [SEP]
Text from DS:  Constant Query Time (1 + ǫ)-Approximate Distance Oracle for Planar
Graphs1.
Qian-Ping Gu and Gengchun Xu

arXiv:1706.03108v1 [] 9 Jun 2017

School of Computing Science, Simon Fraser University
Burnaby BC Canada V5A1S6
qgu@cs.sfu.ca,gxa2@sfu.ca
Abstract: We give a (1 + ǫ)-approximate distance oracle with O(1) query time for an undirected
planar graph G with n vertices and non-negative edge lengths. For ǫ > 0 and any two vertices u
˜ v) with stretch (1 + ǫ) in O(1) time. The oracle has size
and v in G, our oracle gives a distance d(u,
O(n log n((log n)/ǫ + f (ǫ))) and pre-processing time O(n log n((log3 n)/ǫ2 + f (ǫ))), where f (ǫ) =
2O(1/ǫ) . This is the first (1 + ǫ)-approximate distance oracle with O(1) query time independent of
ǫ and the size and pre-processing time nearly linear in n, and improves the query time O(1/ǫ) of
previous (1 + ǫ)-approximate distance oracle with size nearly linear in n.
key words: Distance oracle, planar graphs, approximate algorithms, graph decomposition


Original label:  math.GR
Predicted label:  9
Correct label:  2
Text:  [CLS] traces on reduced group c * - algebras arxiv : 1706. 05903v1 [ math. oa ] 19 jun 2017 by matthew kennedy and sven raum abstract. in this short note we prove that the reduced group c * - algebra of a locally compact group admits a non - zero trace if and only if the amenable radical of the group is open. this completely answers a question raised by forrest, spronk and wiersma. introduction an important fact about the reduced c * - algebra of a discrete group is that it admits at least one non - zero trace. more generally, the reduced c * - algebra of a locally compact group may admit no non - zero traces at all. this is one reason why discrete groups are generally considered to be more tractable in the theory of group c * - algebras. in a recent preprint, forrest, spronk and wiersma [ fsw17, question 1. 1 ] ask for a characterization of the locally compact groups with reduced c * - algebras that admit a non - zero trace. they provide a partial answer to this question by proving that a compactly generated locally compact group g has this property if and only if its amenable radical rad ( g ) is open. in this note, we completely settle this question by proving that the result of forrest - spronkwiersma holds without the assumption that the group is compactly generated. further, we prove that any trace on the reduced c * - algebra concentrates on the amenable radical. theorem 1. let g be a locally compact group. the reduced c * - algebra c∗red ( g ) admits a non - zero trace if and only if the amenable radical rad ( g ) of g is open. further, every trace concentrates on rad ( g ), meaning that it factors through the canonical conditional expectation from c∗red ( g ) onto c∗red ( rad ( g ) ). we view theorem 1 as the natural generalization to locally compact groups of [ bre + 14, theorem 4. 1 ], which states that every trace on the reduced c * - algebra of a discrete group concentrates on the amenable radical. our approach to the proof is much different than the approach taken in [ fsw17 ]. we are motivated by the perspective introduced in [ kk14 ], which relates the structure of the reduced group c * - algebra of a discrete group to [SEP]
Text from DS:  Traces on reduced group C*-algebras

arXiv:1706.05903v1 [math.OA] 19 Jun 2017

by Matthew Kennedy and Sven Raum

Abstract. In this short note we prove that the reduced group C*-algebra of
a locally compact group admits a non-zero trace if and only if the amenable
radical of the group is open. This completely answers a question raised by
Forrest, Spronk and Wiersma.

Introduction
An important fact about the reduced C*-algebra of a discrete group is that it admits at least one
non-zero trace. More generally, the reduced C*-algebra of a locally compact group may admit no
non-zero traces at all. This is one reason why discrete groups are generally considered to be more
tractable in the theory of group C*-algebras.
In a recent preprint, Forrest, Spronk and Wiersma [FSW17, Question 1.1] ask for a characterization of the locally compact groups with reduced C*-algebras that admit a non-zero trace. They
provide a partial answer to this question by proving that a compactly generated locally comp
Original label:  cs.PL
Predicted label:  2
Correct label:  1
Text:  [CLS] fourier phase retrieval : uniqueness and algorithms arxiv : 1705. 09590v3 [ ] 6 nov 2017 tamir bendory∗1, robert beinert † 2 and yonina c. eldar ‡ 3 1 the program in applied and computational mathematics, princeton university, princeton, nj, usa 2 institute of mathematics and scientific computing, university of graz, heinrichstraße 36, 8010 graz, austria 3 the andrew and erna viterbi faculty of electrical engineering, technion - israel institute of technology, haifa, israel abstract the problem of recovering a signal from its phaseless fourier transform measurements, called fourier phase retrieval, arises in many applications in engineering and science. fourier phase retrieval poses fundamental theoretical and algorithmic challenges. in general, there is no unique mapping between a one - dimensional signal and its fourier magnitude and therefore the problem is ill - posed. additionally, while almost all multidimensional signals are uniquely mapped to their fourier magnitude, the performance of existing algorithms is generally not well - understood. in this chapter we survey methods to guarantee uniqueness in fourier phase retrieval. we then present different algorithmic approaches to retrieve the signal in practice. we conclude by outlining some of the main open questions in this field. ∗ tamir. bendory @ princeton. edu † robert. beinert @ uni - graz. at. the institute of mathematics and scientific computing is a member of nawi graz ( http : / / www. nawigraz. at ). the author is supported by the austrian science fund ( fwf ) within the project p 28858. ‡ yonina @ ee. technion. ac. il. the author is supported by the european unions horizon 2020 research and innovation program under grant agreement no. 646804 - erc - cog - bnyq, and from the israel science foundation under grant no. 335 / 14. 1 1 introduction the task of recovering a signal from its fourier transform magnitude, called fourier phase retrieval, arises in many areas in engineering and science. the problem has a rich history, tracing back to 1952 [ 110 ]. important examples for fourier phase retrieval naturally appear in many optical settings since optical sensors, such as a charge - coupled device ( ccd ) and the human eye, are insensitive to phase information of the light wave. a typical example is coherent diffraction imaging ( cdi ) which is used in a variety of imaging techniques [ 24, 33, 34, 92, 105, [SEP]
Text from DS:  Fourier Phase Retrieval:
Uniqueness and Algorithms
arXiv:1705.09590v3 [] 6 Nov 2017

Tamir Bendory∗1 , Robert Beinert†2 and Yonina C. Eldar‡3
1 The

Program in Applied and Computational Mathematics,
Princeton University, Princeton, NJ, USA
2 Institute of Mathematics and Scientific Computing, University of
Graz, Heinrichstraße 36, 8010 Graz, Austria
3 The Andrew and Erna Viterbi Faculty of Electrical Engineering,
Technion - Israel Institute of Technology, Haifa, Israel

Abstract
The problem of recovering a signal from its phaseless Fourier transform
measurements, called Fourier phase retrieval, arises in many applications in
engineering and science. Fourier phase retrieval poses fundamental theoretical and algorithmic challenges. In general, there is no unique mapping
between a one-dimensional signal and its Fourier magnitude and therefore
the problem is ill-posed. Additionally, while almost all multidimensional
signals are uniquely mapped to their Fourier magnitude, the performance
of 
Original label:  cs.AI
Predicted label:  6
Correct label:  4
Text:  [CLS] arxiv : 1711. 02810v1 [ cs. lg ] 8 nov 2017 deep fault analysis and subset selection in solar power grids biswarup bhattacharya university of southern california los angeles, ca 90089. usa. email : bbhattac @ usc. edu abhishek sinha adobe systems incorporated noida, up 201301. india. email : abhishek. sinha94 @ gmail. com abstract non - availability of reliable and sustainable electric power is a major problem in the developing world. renewable energy sources like solar are not very lucrative in the current stage due to various uncertainties like weather, storage, land use among others. there also exists various other issues like mis - commitment of power, absence of intelligent fault analysis, congestion, etc. in this paper, we propose a novel deep learning - based system for predicting faults and selecting power generators optimally so as to reduce costs and ensure higher reliability in solar power systems. the results are highly encouraging and they suggest that the approaches proposed in this paper have the potential to be applied successfully in the developing world. 1 introduction electric power grids are an essential component of modern society. a reliable power supply is conducive to development of infrastructure and improving people ’ s quality of life. the demand for power has increased to the point that resources need to be conserved carefully to generate power in optimal amounts so that no power is wasted and there is no shortage. with the help of technology like synchrophasors, the magnitude and angle of each phase of the three phase voltage and / or current, frequency, rate of change of frequency and angular separation at every few millisecond interval ( say 40 milliseconds ) can be monitored [ 8, 7 ]. this data can be leveraged to incorporate intelligence into the system to make better predictions and design better schemes for generation and fault analysis. in developing countries like india, renewable energy is often wasted due to mismanagement and due to irregularities in the generation process [ 5 ]. for example, in case of solar energy, storage of generated power becomes an issue and non - optimal choices lead to wastage of generated power. power outages are common in developing countries due to faults appearing in the system which could not be predicted earlier. often the load forecast does not match the actual scenario and that leads to problems like congestion and faults. in this paper, we have proposed a method to analyze faults using lstms which can analyze the [SEP]
Text from DS:  arXiv:1711.02810v1 [cs.LG] 8 Nov 2017

Deep Fault Analysis and Subset Selection in Solar
Power Grids
Biswarup Bhattacharya
University of Southern California
Los Angeles, CA 90089. USA.
Email: bbhattac@usc.edu

Abhishek Sinha
Adobe Systems Incorporated
Noida, UP 201301. India.
Email: abhishek.sinha94@gmail.com

Abstract
Non-availability of reliable and sustainable electric power is a major problem in
the developing world. Renewable energy sources like solar are not very lucrative
in the current stage due to various uncertainties like weather, storage, land use
among others. There also exists various other issues like mis-commitment of
power, absence of intelligent fault analysis, congestion, etc. In this paper, we
propose a novel deep learning-based system for predicting faults and selecting
power generators optimally so as to reduce costs and ensure higher reliability in
solar power systems. The results are highly encouraging and they suggest that the
approaches proposed in this paper 
Original label:  cs.DS
Predicted label:  4
Correct label:  7
Text:  [CLS] 1 numerical removal of water - vapor effects from thz - tds measurements arxiv : 0710. 3621v1 [ ] 19 oct 2007 withawat withayachumnankul, bernd m. fischer, samuel p. mickan, member, ieee, and derek abbott, fellow, ieee abstract — one source of disturbance in a pulsed t - ray signal is attributed to ambient water vapor. water molecules in the gas phase selectively absorb t - rays at discrete frequencies corresponding to their molecular rotational transitions. this results in prominent resonances spread over the t - ray spectrum, and in the time domain the t - ray signal is observed as fluctuations after the main pulse. these effects are generally undesired, since they may mask critical spectroscopic data. so, ambient water vapor is commonly removed from the t - ray path by using a closed chamber during the measurement. yet, in some applications a closed chamber is not applicable. this situation, therefore, motivates the need for another method to reduce these unwanted artifacts. this paper presents a study on a computational means to address the problem. initially, a complex frequency response of water vapor is modeled from a spectroscopic catalog. using a deconvolution technique, together with fine tuning of the strength of each resonance, parts of the water - vapor response are removed from a measured t - ray signal, with minimal signal distortion. index terms — t - rays, terahertz, thz - tds, water vapor, rotational transitions, removal i. i ntroduction terahertz time - domain spectroscopy ( thz - tds ) has received much attention from researchers due to its outstanding performance [ 1 ], [ 2 ]. with the assistance of ultrafast femtosecond laser technology, a t - ray system generates and detects a short pulse, and thus the corresponding frequency range spanning from a few hundred gigahertz to a few terahertz or more. this frequency range has a relatively high black - body radiation background, prohibiting a high - snr detection with a conventional detector. however, this problem is suppressed by adopting a coherent detection scheme, lifting the snr to as high as 60 db [ 3 ]. in the t - ray frequency region, many polar gases of general interest possess unique rotational transition energies, which give rise to spectral resonances [ 4 ]. because of these unique fingerprints, thz - tds proves useful for gas classification and recognition. however, this property [SEP]
Text from DS:  1

Numerical Removal of Water-Vapor Effects from
THz-TDS Measurements

arXiv:0710.3621v1 [] 19 Oct 2007

Withawat Withayachumnankul, Bernd M. Fischer, Samuel P. Mickan, Member, IEEE,
and Derek Abbott, Fellow, IEEE

Abstract— One source of disturbance in a pulsed T-ray signal
is attributed to ambient water vapor. Water molecules in the
gas phase selectively absorb T-rays at discrete frequencies corresponding to their molecular rotational transitions. This results
in prominent resonances spread over the T-ray spectrum, and in
the time domain the T-ray signal is observed as fluctuations after
the main pulse. These effects are generally undesired, since they
may mask critical spectroscopic data. So, ambient water vapor
is commonly removed from the T-ray path by using a closed
chamber during the measurement. Yet, in some applications
a closed chamber is not applicable. This situation, therefore,
motivates the need for another method to reduce these unwanted
artifacts. This paper presents a 
Original label:  cs.CE
Predicted label:  9
Correct label:  2
Text:  [CLS] arxiv : 1407. 6968v1 [ ] 23 jul 2014 hardware extensions to make lazy subscription safe ∗ dave dice timothy l. harris alex kogan oracle labs dave. dice @ oracle. com oracle labs timothy. l. harris @ oracle. com oracle labs alex. kogan @ oracle. com yossi lev mark moir oracle labs yossi. lev @ oracle. com oracle labs mark. moir @ oracle. com abstract because hardware transactions may fail due to conflicts or to limitations of the htm implementation, some critical sections must still be executed in the traditional manner ( i. e., not in a hardware transaction ) after acquiring the lock. to ensure that a critical section executed in a hardware transaction does not observe partial effects of a critical section executed by another thread that acquires the lock, the transaction “ subscribes ” to the lock, i. e., it reads the lock and confirms that it is available. similar techniques can be used to implement a transactional memory system in which all transactional data is protected by a single global lock ( sgl ), and transactions are executed either by acquiring the lock, or within a hardware transaction that subscribes to the lock. subscribing to the lock makes hardware transactions vulnerable to abort if another thread acquires the lock. typically, transactions subscribe to the lock at the beginning of the critical section and are thus vulnerable to such abort during the entire execution of the critical section. it is therefore tempting to use a lazy subscription optimization [ 7 ], which delays lock subscription, in order to reduce the duration of this vulnerability. calciu et al. [ 3 ] recently proposed to use this technique for sgl - based transactional systems. a simple ( but incorrect ) way to implement lazy subscription for tle is to delay subscription until immediately before committing the transaction. this way the implementation affects only library code and does not require analysis or modification of critical section code, retaining the key advantage of tle that makes it the most promising way to exploit htm in the near future. one might reason that this “ lazy subscription ” technique is safe for tle on the grounds that the hardware transaction ensures that all of the memory accesses performed by the critical section, together with the check that the lock is not held, are performed atomically, and therefore the effects of committing the transaction are identical from the perspective of other threads. unfortunately, as we show, there are subtle problems with this reasoning. in fact, tle with [SEP]
Text from DS:  arXiv:1407.6968v1 [] 23 Jul 2014

Hardware extensions to make lazy subscription safe ∗
Dave Dice

Timothy L. Harris

Alex Kogan

Oracle Labs
dave.dice@oracle.com

Oracle Labs
timothy.l.harris@oracle.com

Oracle Labs
alex.kogan@oracle.com

Yossi Lev

Mark Moir

Oracle Labs
yossi.lev@oracle.com

Oracle Labs
mark.moir@oracle.com

Abstract

Because hardware transactions may fail due to conflicts or to
limitations of the HTM implementation, some critical sections must
still be executed in the traditional manner (i.e., not in a hardware
transaction) after acquiring the lock. To ensure that a critical section
executed in a hardware transaction does not observe partial effects
of a critical section executed by another thread that acquires the
lock, the transaction “subscribes” to the lock, i.e., it reads the
lock and confirms that it is available. Similar techniques can be
used to implement a transactional memory system in which all
transactional data is protected by a single global lock (SGL)
Original label:  cs.PL
Predicted label:  8
Correct label:  10
Text:  [CLS] arxiv : 1802. 00872v1 [ ] 2 feb 2018 load - balanced fractional repetition codes alexandra porter shashwat silas mary wootters department of computer science stanford university stanford, ca amporter @ stanford. edu department of computer science stanford university stanford, ca silas @ stanford. edu departments of computer science and electrical engineering stanford university stanford, ca marykw @ stanford. edu abstract — we introduce load - balanced fractional repetition ( lbfr ) codes, which are a strengthening of fractional repetition ( fr ) codes. lbfr codes have the additional property that multiple node failures can be sequentially repaired by downloading no more than one block from any other node. this allows for better use of the network, and can additionally reduce the number of disk reads necessary to repair multiple nodes. we characterize lbfr codes in terms of their adjacency graphs, and use this characterization to present explicit constructions lbfr codes with storage capacity comparable existing fr codes. surprisingly, in some parameter regimes, our constructions of lbfr codes match the parameters of the best constructions of fr codes. index terms — fractional repetition codes ; distributed storage ; repair - by - transfer i. i ntroduction in distributed storage, we would like to store a file across n storage nodes, so that the system can be efficiently repaired from node failures without data loss. in this paper, we focus on two notions of “ efficient : ” network bandwidth and disk access. that is, when a node ( or a collection of nodes ) fails, we would like to minimize the amount of data that is read and sent by surviving nodes in order to repair the system. we would also like to maintain the mds property, which is that any k out of n nodes in the system are sufficient to recover the entire file. in this work, we present load - balanced fractional repetition ( lbfr ) codes, which are a strengthening of fractional repetition ( fr ) codes. fr codes are repetitionbased schemes which admit minimal bandwidth and disk access, and which have been well - studied since they were introduced in 2010 ; see [ 4 ], [ 9 ], [ 11 ] – [ 15 ]. lbfr codes have all of the same benefits of fr codes for a single repair — in particular, minimal bandwidth and disk access — but have additional benefits when multiple nodes fail. as the name implies, lbfr codes achieve better loadbalancing between helper nodes in the case of multiple failures. this makes better [SEP]
Text from DS:  arXiv:1802.00872v1 [] 2 Feb 2018

Load-Balanced Fractional Repetition Codes
Alexandra Porter

Shashwat Silas

Mary Wootters

Department of Computer Science
Stanford University
Stanford, CA
amporter@stanford.edu

Department of Computer Science
Stanford University
Stanford, CA
silas@stanford.edu

Departments of Computer Science
and Electrical Engineering
Stanford University
Stanford, CA
marykw@stanford.edu

Abstract—We introduce load-balanced fractional repetition
(LBFR) codes, which are a strengthening of fractional repetition
(FR) codes. LBFR codes have the additional property that multiple node failures can be sequentially repaired by downloading no
more than one block from any other node. This allows for better
use of the network, and can additionally reduce the number of
disk reads necessary to repair multiple nodes. We characterize
LBFR codes in terms of their adjacency graphs, and use this
characterization to present explicit constructions LBFR codes
with storage capacity comparab
Original label:  cs.AI
Predicted label:  1
Correct label:  2
Text:  [CLS] arxiv : 1706. 02929v1 [ ] 8 jun 2017 evidence against evidence theory (?! ) mieczyslaw a. klopotek and andrzej matuszewski institute of computer science, polish academy of sciences e - mail : klopotek @ ipipan. waw. pl abstract - streszczenie this paper is concerned with the apparent greatest weakness of the mathematical theory of evidence ( mte ) of shafer [ 27 ], which has been strongly criticized by wasserman [ 37 ] - the relationship to frequencies. weaknesses of various proposals of probabilistic interpretation of mte belief functions are demonstrated. a new frequency - based interpretation is presented overcoming various drawbacks of earlier interpretations. 1 introduction wasserman in [ 37 ] raised serious concerns against the mathematical theory of evidence ( mte ) developed by dempster and shafer since 1967 - hence also called dempster - shafertheory ( dst ) ( see [ 30 ] for a thorough review of this theory, for major formal deﬁnitions 2 mieczyslaw a. klopotek and andrzej matuszewski see appendix a ). one of arguments against mte is related to shafer ’ s attitude towards frequencies. shafer in [ 30 ] claims that probability theory developed over last years from the old - style frequencies towards modern subjective probability theory within the framework of bayesian theory. by analogy he claims that the very attempt to consider relation between mte and frequencies is old - fashioned and out of date and should be at least forbidden - for the sake of progress of humanity. wasserman opposes this view ( [ 37 ], p. 371 ) reminding ” major success story in bayesian theory ”, the exchangeability theory of de finetti [ 4 ]. it treats frequencies as special case of bayesian belief. ” the bayesian theory contains within it a deﬁnition of frequency probability and a description of the exact assumptions necessary to invoke that deﬁnition ” [ 37 ]. wasserman dismisses shafer ’ s suggestion that probability relies on analogy of frequency.. shafer, on the other hand, lets frequencies live a separate life. mte beliefs and frequencies are separated. but in this way we are left without a deﬁnition of frequentistic belief function [ 37 ]. this paper is devoted to discussion of drawbacks of various interpretations of mte. a way out is proposed [SEP]
Text from DS:  arXiv:1706.02929v1 [] 8 Jun 2017

Evidence Against Evidence Theory
(?!)
Mieczyslaw A. Klopotek and Andrzej Matuszewski
Institute of Computer Science, Polish Academy of Sciences
e-mail: klopotek@ipipan.waw.pl
ABSTRACT - STRESZCZENIE
This paper is concerned with the apparent greatest weakness of the Mathematical
Theory of Evidence (MTE) of Shafer [27], which has been strongly criticized by Wasserman [37] - the relationship to frequencies.
Weaknesses of various proposals of probabilistic interpretation of MTE belief functions
are demonstrated.
A new frequency-based interpretation is presented overcoming various drawbacks of earlier interpretations.

1

Introduction

Wasserman in [37] raised serious concerns against the Mathematical Theory of Evidence
(MTE) developed by Dempster and Shafer since 1967 - hence also called Dempster-ShaferTheory (DST) (see [30] for a thorough review of this theory, for major formal deﬁnitions

2

MIECZYSlAW A. KlOPOTEK AND ANDRZEJ MATUSZEWSKI

see Appendix A)
Original label:  cs.CV
Predicted label:  7
Correct label:  2
Text:  [CLS] arxiv : 1704. 03296v3 [ ] 10 jan 2018 interpretable explanations of black boxes by meaningful perturbation ruth c. fong university of oxford andrea vedaldi university of oxford ruthfong @ robots. ox. ac. uk vedaldi @ robots. ox. ac. uk flute : 0. 9973 abstract as machine learning algorithms are increasingly applied to high impact yet high risk tasks, such as medical diagnosis or autonomous driving, it is critical that researchers can explain how such algorithms arrived at their predictions. in recent years, a number of image saliency methods have been developed to summarize where highly complex neural networks “ look ” in an image for evidence for their predictions. however, these techniques are limited by their heuristic nature and architectural constraints. in this paper, we make two main contributions : first, we propose a general framework for learning different kinds of explanations for any black box algorithm. second, we specialise the framework to find the part of an image most responsible for a classifier decision. unlike previous works, our method is model - agnostic and testable because it is grounded in explicit and interpretable image perturbations. flute : 0. 0007 learned mask figure 1. an example of a mask learned ( right ) by blurring an image ( middle ) to suppress the softmax probability of its target class ( left : original image ; softmax scores above images ). be answered by providing interpretable rules that describe the input - output relationship captured by f. for example, one rule could be that f is rotation invariant, in the sense that “ f ( x ) = f ( x0 ) whenever images x and x0 are related by a rotation ”. in this paper, we make several contributions. first, we propose the general framework of explanations as metapredictors ( sec. 2 ), extending [ 18 ] ’ s work. second, we identify several pitfalls in designing automatic explanation systems. we show in particular that neural network artifacts are a major attractor for explanations. while artifacts are informative since they explain part of the network behavior, characterizing other properties of the network requires careful calibration of the generality and interpretability of explanations. third, we reinterpret network saliency in our framework. we show that this provides a natural generalization of the gradient - based saliency technique of [ 15 ] by integrating information over several rounds of backpropagation in order to learn an explanation. we [SEP]
Text from DS:  arXiv:1704.03296v3 [] 10 Jan 2018

Interpretable Explanations of Black Boxes by Meaningful Perturbation
Ruth C. Fong
University of Oxford

Andrea Vedaldi
University of Oxford

ruthfong@robots.ox.ac.uk

vedaldi@robots.ox.ac.uk

flute: 0.9973

Abstract
As machine learning algorithms are increasingly applied
to high impact yet high risk tasks, such as medical diagnosis or autonomous driving, it is critical that researchers
can explain how such algorithms arrived at their predictions. In recent years, a number of image saliency methods
have been developed to summarize where highly complex
neural networks “look” in an image for evidence for their
predictions. However, these techniques are limited by their
heuristic nature and architectural constraints.
In this paper, we make two main contributions: First, we
propose a general framework for learning different kinds
of explanations for any black box algorithm. Second, we
specialise the framework to find the part of an image most
responsible f
Original label:  cs.IT
Predicted label:  7
Correct label:  9
Text:  [CLS] arxiv : 1507. 00843v2 [ math. pr ] 27 sep 2016 optimal linear bernoulli factories for small mean problems∗ mark huber mhuber @ cmc. edu version : september 29, 2016 abstract suppose a coin with unknown probability p of heads can be flipped as often as desired. a bernoulli factory for a function f is an algorithm that uses flips of the coin together with auxiliary randomness to flip a single coin with probability f ( p ) of heads. applications include perfect sampling from the stationary distribution of certain regenerative processes. when f is analytic, the problem can be reduced to a bernoulli factory of the form f ( p ) = cp for constant c. presented here is a new algorithm that for small values of cp, requires roughly only c coin flips. from information theoretic considerations, this is also conjectured to be ( to first order ) the minimum number of flips needed by any such algorithm. for large values of cp, the new algorithm can also be used to build a new bernoulli factory that uses only 80 % of the expected coin flips of the older method. in addition, the new method also applies to the more general problem of a linear multivariate bernoulli factory, where there are k coins, the kth coin has unknown probability pk of heads, and the goal is to simulate a coin flip with probability c1 p1 + · · · + ck pk of heads. keywords : randomized algorithm, near perfect simulation, regenerative processes msc classes : 65c50, 68q17 the final publication is http : / / dx. doi. org / 10. 1007 / s11009 - 016 - 9518 - 3. ∗ 1 available at springer via 1 introduction the notion of a bernoulli factory was introduced in asmussen, glynn, and thorisson ( 1992 ) in the context of generating samples exactly from the stationary distribution of a regenerative markov process. a bernoulli factory works as follows. suppose we have the ability to draw independent identically distributed ( iid ) bernoulli random variables, each of which is 1 with probability p and 0 with probability 1 − p ( write x [UNK] bern ( p ). ) then given a function f, the goal is to use a random number of draws from x to build a new random variable which is also bernoulli, but with chance f ( p ) of being 1 [SEP]
Text from DS:  arXiv:1507.00843v2 [math.PR] 27 Sep 2016

Optimal linear Bernoulli factories for small
mean problems∗
Mark Huber
mhuber@cmc.edu
Version: September 29, 2016

Abstract
Suppose a coin with unknown probability p of heads can be flipped
as often as desired. A Bernoulli factory for a function f is an algorithm that uses flips of the coin together with auxiliary randomness to
flip a single coin with probability f (p) of heads. Applications include
perfect sampling from the stationary distribution of certain regenerative processes. When f is analytic, the problem can be reduced to
a Bernoulli factory of the form f (p) = Cp for constant C. Presented
here is a new algorithm that for small values of Cp, requires roughly
only C coin flips. From information theoretic considerations, this is
also conjectured to be (to first order) the minimum number of flips
needed by any such algorithm.
For large values of Cp, the new algorithm can also be used to build
a new Bernoulli factory that uses only 80% of
Original label:  cs.CE
Predicted label:  6
Correct label:  2
Text:  [CLS] logical methods in computer science vol. 10 ( 4 : 9 ) 2014, pp. 1 – 29 www. lmcs - online. org submitted published feb. 18, 2014 dec. 10, 2014 an effect system for algebraic effects and handlers ∗ andrej bauer and matija pretnar faculty of mathematics and physics, university of ljubljana, slovenia e - mail address : andrej. bauer @ andrej. com, matija. pretnar @ fmf. uni - lj. si abstract. we present an effect system for core eff, a simplified variant of eff, which is an ml - style programming language with first - class algebraic effects and handlers. we define an expressive effect system and prove safety of operational semantics with respect to it. then we give a domain - theoretic denotational semantics of core eff, using pitts ’ s theory of minimal invariant relations, and prove it adequate. we use this fact to develop tools for finding useful contextual equivalences, including an induction principle. to demonstrate their usefulness, we use these tools to derive the usual equations for mutable state, including a general commutativity law for computations using non - interfering references. we have formalized the effect system, the operational semantics, and the safety theorem in twelf. 1. introduction an effect system supplements a traditional type system for a programming language with information about which computational effects may, will, or will not happen when a piece of code is executed. a well designed and solidly implemented effect system helps programmers understand source code, find mistakes, as well as safely rearrange, optimize, and parallelize code [ 11, 8 ]. as many before us [ 11, 24, 25, 7 ] we take on the task of striking just the right balance between simplicity and expressiveness by devising an effect system for eff [ 2 ], an ml - style programming language with first - class algebraic effects [ 17, 15 ] and handlers [ 19 ]. our effect system is descriptive in the sense that it provides information about possible computational effects but it does not prescribe them. in contrast, haskell ’ s monads prescribe the possible effects by wrapping types into computational monads. in the implementation we envision effect inference which never fails, although in some cases it may be uninformative. of course, typing errors are still errors. an important feature of our effect system is non - monotonicity : it detects the [SEP]
Text from DS:  Logical Methods in Computer Science
Vol. 10(4:9)2014, pp. 1–29
www.lmcs-online.org

Submitted
Published

Feb. 18, 2014
Dec. 10, 2014

AN EFFECT SYSTEM FOR ALGEBRAIC EFFECTS AND HANDLERS ∗
ANDREJ BAUER AND MATIJA PRETNAR
Faculty of Mathematics and Physics, University of Ljubljana, Slovenia
e-mail address: Andrej.Bauer@andrej.com, matija.pretnar@fmf.uni-lj.si

Abstract. We present an effect system for core Eff, a simplified variant of Eff , which is
an ML-style programming language with first-class algebraic effects and handlers. We define an expressive effect system and prove safety of operational semantics with respect to it.
Then we give a domain-theoretic denotational semantics of core Eff , using Pitts’s theory
of minimal invariant relations, and prove it adequate. We use this fact to develop tools for
finding useful contextual equivalences, including an induction principle. To demonstrate
their usefulness, we use these tools to derive the usual equations for mutable state, includin
Original label:  cs.AI
Predicted label:  7
Correct label:  10
Text:  [CLS] learning - theoretic foundations of algorithm configuration for combinatorial partitioning problems∗ maria - florina balcan vaishnavh nagarajan ellen vitercik colin white arxiv : 1611. 04535v3 [ ] 17 may 2017 may 18, 2017 abstract max - cut, clustering, and many other partitioning problems that are of significant importance to machine learning and other scientific fields are np - hard, a reality that has motivated researchers to develop a wealth of approximation algorithms and heuristics. although the best algorithm to use typically depends on the specific application domain, a worst - case analysis is often used to compare algorithms. this may be misleading if worst - case instances occur infrequently, and thus there is a demand for optimization methods which return the algorithm configuration best suited for the given application ’ s typical inputs. we address this problem for clustering, max - cut, and other partitioning problems, such as integer quadratic programming, by designing computationally efficient and sample efficient learning algorithms which receive samples from an application - specific distribution over problem instances and learn a partitioning algorithm with high expected performance. our algorithms learn over common integer quadratic programming and clustering algorithm families : sdp rounding algorithms and agglomerative clustering algorithms with dynamic programming. for our sample complexity analysis, we provide tight bounds on the pseudodimension of these algorithm classes, and show that surprisingly, even for classes of algorithms parameterized by a single parameter, the pseudo - dimension is superconstant. in this way, our work both contributes to the foundations of algorithm configuration and pushes the boundaries of learning theory, since the algorithm classes we analyze consist of multi - stage optimization procedures and are significantly more complex than classes typically studied in learning theory. ∗ authors ’ addresses : { ninamf, vaishnavh, vitercik, crwhite } @ cs. cmu. edu. 1 introduction np - hard problems arise in a variety of diverse and oftentimes unrelated application domains. for example, clustering is a widely - studied np - hard problem in unsupervised machine learning, used to group protein sequences by function, organize documents in databases by subject, and choose the best locations for fire stations in a city. although the underlying objective is the same, a “ typical problem instance ” in one setting may be significantly different from that in another, causing approximation algorithms to have inconsistent performance across the different application domains. we study how to characterize [SEP]
Text from DS:  Learning-Theoretic Foundations of Algorithm Configuration for
Combinatorial Partitioning Problems∗
Maria-Florina Balcan

Vaishnavh Nagarajan

Ellen Vitercik

Colin White

arXiv:1611.04535v3 [] 17 May 2017

May 18, 2017

Abstract
Max-cut, clustering, and many other partitioning problems that are of significant importance to machine learning and other scientific fields are NP-hard, a reality that has motivated
researchers to develop a wealth of approximation algorithms and heuristics. Although the best
algorithm to use typically depends on the specific application domain, a worst-case analysis is
often used to compare algorithms. This may be misleading if worst-case instances occur infrequently, and thus there is a demand for optimization methods which return the algorithm
configuration best suited for the given application’s typical inputs. We address this problem
for clustering, max-cut, and other partitioning problems, such as integer quadratic programming, by designing computationall
Original label:  math.ST
Predicted label:  1
Correct label:  8
Text:  [CLS] the shark fin function – asymptotic behavior of the filtered derivative for point processes in case of change points arxiv : 1409. 1025v3 [ ] 17 may 2016 michael messer, gaby schneider institute of mathematics johann wolfgang goethe university robert - mayer - str. 10 60325 frankfurt ( main ), germany corresponding author : michael messer, messer @ math. uni - frankfurt. de abstract a multiple filter test ( mft ) for the analysis and detection of rate change points in point processes on the line has been proposed recently. the underlying statistical test investigates the null hypothesis of constant rate. for that purpose, multiple filtered derivative processes are observed simultaneously. under the null hypothesis, each process g asymptotically takes the form g [UNK] l, while l is a zero - mean gaussian process with unit variance. this result is used to derive a rejection threshold for statistical hypothesis testing. the purpose of this paper is to describe the behavior of g under the alternative hypothesis of rate changes and potential simultaneous variance changes. we derive the approximation g [UNK] ∆ · ( λ + l ), with deterministic functions ∆ and λ. the function λ accounts for the systematic deviation of g in the neighborhood of a change point. when only the rate changes, λ is hat shaped. when also the variance changes, λ takes the form of a shark ’ s fin. in addition, the parameter estimates required in practical application are not consistent in the neighborhood of a change point. therefore, we derive the factor ∆ termed here the distortion function. it accounts for the lack in consistency and describes the local parameter estimating process relative to the true scaling of the filtered derivative process. keywords : point processes ; renewal processes ; change point detection ; non - stationary rate ; alternative ; filtered derivative 1 introduction the statistical theory of change point detection aims at the detection of structural breaks ( so called change points ) in time series. for an overview of the topic see the textbooks of 1 brodsky and darkhovsky ( 1993 ) ; basseville and nikiforov ( 1993 ) ; csorgo and horvath ( 1997 ) or the review article of aue and horvath ( 2013 ). we focus here on renewal processes on the positive line ( e. g., gut and steinebach ( 2002, 2009 ) ; timmermann ( 2014 ) ). in applications such as neuronal spike trains, structural breaks can occur on different time scales. interesting multi scale methods have been proposed [SEP]
Text from DS:  The Shark Fin Function – Asymptotic Behavior of the Filtered
Derivative for Point Processes in Case of Change Points

arXiv:1409.1025v3 [] 17 May 2016

Michael Messer, Gaby Schneider
Institute of Mathematics
Johann Wolfgang Goethe University
Robert-Mayer-Str. 10
60325 Frankfurt (Main), Germany
corresponding author: Michael Messer, messer@math.uni-frankfurt.de
Abstract
A multiple filter test (MFT) for the analysis and detection of rate change points in
point processes on the line has been proposed recently. The underlying statistical test
investigates the null hypothesis of constant rate. For that purpose, multiple filtered
derivative processes are observed simultaneously. Under the null hypothesis, each process
G asymptotically takes the form
G ∼ L,
while L is a zero-mean Gaussian process with unit variance. This result is used to derive
a rejection threshold for statistical hypothesis testing.
The purpose of this paper is to describe the behavior of G under the alternative hypothesis

Original label:  cs.SY
Predicted label:  0
Correct label:  4
Text:  [CLS] arxiv : 1607. 07543v1 [ ] 26 jul 2016 task - space coordinated tracking of multiple heterogeneous manipulators via controller - estimator approaches ming - feng gea, zhi - hong guana, chao yanga, chao - yang chenb, ding - fu zhenga, ming chia a college of automation, huazhong university of science and technology, wuhan, 430074, china b school of information and electrical engineering, hunan university of sience and technology xiangtan, hunan, 411201, china abstract this paper studies the task - space coordinated tracking of a time - varying leader for multiple heterogeneous manipulators ( mhms ), containing redundant manipulators and nonredundant ones. different from the traditional coordinated control, distributed controller - estimator algorithms ( dcea ), which consist of local algorithms and networked algorithms, are developed for mhms with parametric uncertainties and input disturbances. by invoking differential inclusions, nonsmooth analysis, and input - to - state stability, some conditions ( including sufficient conditions, necessary and sufficient conditions ) on the asymptotic stability of the task - space tracking errors and the subtask errors are developed. simulation results are given to show the effectiveness of the presented dcea. keywords : task - space coordinated tracking, multiple heterogeneous manipulators ( mhms ), redundant manipulator, distributed controller - estimator algorithm ( dcea ). email addresses : fmgabc @ 163. com ( ming - feng gea ), zhguan @ mail. hust. edu. cn ( zhi - hong guana ) citation : journal of the franklin institute, 2016, doi : 10. 1016 / j. jfranklin. 2016. 06. 025 1. introduction coordinated control has been diffusely invoked in many practical applications of multiple manipulators, including coordination of bilateral humanswarm systems [ 1 ], single - master - multiple - slaves teleoperation [ 2 ], dual - user shared teleoperation [ 3 ] - [ 6 ], multi - robot teleoperation [ 7 ] - [ 10 ], multi - fingered grasping and manipulation [ 11, 12 ], due to their prominent superiority comparing with traditional centralized control, such as stronger stability, less energy consumption, greater operational efficiency [ 13 ] - [ 24 ]. existing works focused on [SEP]
Text from DS:  arXiv:1607.07543v1 [] 26 Jul 2016

Task-space coordinated tracking of multiple
heterogeneous manipulators via
controller-estimator approaches
Ming-Feng Gea , Zhi-Hong Guana , Chao Yanga , Chao-Yang Chenb , Ding-Fu
Zhenga , Ming Chia
a

College of Automation, Huazhong University of Science and Technology,
Wuhan, 430074, China
b
School of Information and Electrical Engineering, Hunan University of Sience and
Technology Xiangtan, Hunan, 411201, China

Abstract
This paper studies the task-space coordinated tracking of a time-varying
leader for multiple heterogeneous manipulators (MHMs), containing redundant manipulators and nonredundant ones. Different from the traditional coordinated control, distributed controller-estimator algorithms (DCEA), which
consist of local algorithms and networked algorithms, are developed for MHMs
with parametric uncertainties and input disturbances. By invoking differential inclusions, nonsmooth analysis, and input-to-state stability, some conditions (includin
Original label:  cs.IT
Predicted label:  10
Correct label:  5
Text:  [CLS] discrete preference games in heterogeneous social networks subverted majorities and the swing player arxiv : 1603. 02971v1 [ cs. gt ] 9 mar 2016 vincenzo auletta, ioannis caragiannis, diodato ferraioli, clemente galdi, and giuseppe persiano abstract we study discrete preference games in heterogeneous social networks. these games model the interplay between a player ’ s private belief and his / her publicly stated opinion ( which could be different from the player ’ s belief ) as a strategic game in which the players ’ strategies are the opinions and the cost of an opinion in a state is a convex combination through a parameter α ∈ [ 0, 1 ] of two factors : the disagreement between the player ’ s opinion and his / her internal belief and the number of neighbors whose opinions differ from the one of the player. the parameter α models how stubborn a player is : players with large α change their opinion only if many neighbors disagree with his / her belief. we consider social networks that are heterogeneous in the sense that the parameter α can vary from player to player. we ask whether decisions made by a social network are robust to internal pressure and investigate the phenomenon by which, because of local strategic decisions at the level of the players, the global majority can be subverted. more precisely, we ask if it is possible that the belief shared by the majority of the players does not coincide with the opinion that is publicly announced by the majority of the players in an equilibrium state. our main result is a characterization of the social networks that admit an initial belief assignment for which there exists a sequence of best response moves that reach an equilibrium in which the initial majority is subverted. our characterization is effective in the sense that can be tested efficiently and the initial belief assignment that can be subverted can be computed in time polynomial in the number of players. our result is actually stronger as we show that in each initial belief assignment that can be subverted, subversion is actually obtained in a very strong way : there exists one player, the swing player, that changes his / her opinion to improve his / her utility and, as a result of this best response move, every subsequent sequence of best response moves of the other players leads to an equilibrium in which majority is subverted. in other words, it only takes one move of the swing player to lead the social network to a point of no return in which any rational move from any player leads to a subverted [SEP]
Text from DS:  Discrete Preference Games in Heterogeneous Social
Networks
Subverted Majorities and the Swing Player

arXiv:1603.02971v1 [cs.GT] 9 Mar 2016

Vincenzo Auletta, Ioannis Caragiannis, Diodato Ferraioli,
Clemente Galdi, and Giuseppe Persiano
Abstract
We study discrete preference games in heterogeneous social networks. These games model the
interplay between a player’s private belief and his/her publicly stated opinion (which could be different
from the player’s belief) as a strategic game in which the players’ strategies are the opinions and
the cost of an opinion in a state is a convex combination through a parameter α ∈ [0, 1] of two
factors: the disagreement between the player’s opinion and his/her internal belief and the number of
neighbors whose opinions differ from the one of the player. The parameter α models how stubborn
a player is: players with large α change their opinion only if many neighbors disagree with his/her
belief. We consider social networks that are heterogeneous in th
Original label:  math.ST
Predicted label:  9
Correct label:  2
Text:  [CLS] arxiv : 1607. 07343v1 [ ] 25 jul 2016 gaussian processes and bayesian moment estimation∗ jean - pierre florens † anna simoni ‡ toulouse school of economics crest and ensae this version : july 2016 abstract given a set of estimating equations ( ee ) that characterize a parameter θ, we investigate a semiparametric bayesian approach for inference on θ that does not restrict the data distribution f apart from the ee. as main contribution, we construct a degenerate gaussian process prior that, conditionally on θ, restricts the f generated by this prior to satisfy the ee with probability one. our prior works even in the more involved case where the number of ee is larger than the dimension of θ. we show that this prior is computationally convenient. since the likelihood function is not specified by the model, we approximate it based on a linear functional transformation of f that has an asymptotically gaussian empirical counterpart. this likelihood is used to construct the posterior distribution. we provide a frequentist validation of our procedure by showing consistency and asymptotic normality of the posterior distribution of θ. key words : estimating equations, gaussian processes, overidentification, invariance, posterior consistency, functional equation. ∗ first version : february 2012. the authors especially thank yuichi kitamura for insightful discussions. the authors are grateful to seminars and conferences in : berlin, boston college, bristol, carlos iii, crest, northwestern, sbies 2015, iceee 2015, nasm 2012, toulouse. we thank financial support from anr - 13 - bsh1 - 0004 ( ipanema ). anna simoni gratefully acknowledges financial support from labex ecodec ( anr - 11 - labex - 0047 ), sfb - 884 and hospitality from the university of mannheim. † toulouse school of economics - 21, allee de brienne - 31000 toulouse ( france ). email : jeanpierre. florens @ tse - fr. eu ‡ crest, 15 boulevard gabriel peri, 92240 malakoff ( france ). email : simoni. anna @ gmail. com ( corresponding author ). 1 1 introduction statistical models are often formulated via estimating equations ( ee ) - or moment restrictions - of the form ef [ h ( θ, x ) ] = 0, where h ( θ, x ) is a vector - valued function of an obser [SEP]
Text from DS:  arXiv:1607.07343v1 [] 25 Jul 2016

Gaussian processes and Bayesian moment
estimation∗
Jean-Pierre Florens†

Anna Simoni‡

Toulouse School of Economics

CREST and Ensae

This version: July 2016
Abstract
Given a set of estimating equations (EE) that characterize a parameter θ,
we investigate a semiparametric Bayesian approach for inference on θ that does
not restrict the data distribution F apart from the EE. As main contribution,
we construct a degenerate Gaussian process prior that, conditionally on θ, restricts the F generated by this prior to satisfy the EE with probability one.
Our prior works even in the more involved case where the number of EE is
larger than the dimension of θ. We show that this prior is computationally
convenient. Since the likelihood function is not specified by the model, we
approximate it based on a linear functional transformation of F that has an
asymptotically Gaussian empirical counterpart. This likelihood is used to construct the posterior distribution. 
Original label:  cs.PL
Predicted label:  8
Correct label:  10
Text:  [CLS] how to obtain lattices from ( f, σ, δ ) - codes via a generalization of construction a arxiv : 1607. 03787v2 [ ] 30 sep 2017 s. pumplun abstract. we show how cyclic ( f, σ, δ ) - codes over finite rings canonically induce a z - lattice in rn by using certain quotients of orders in nonassociative division algebras defined using the skew polynomial f. this construction generalizes the one using certain σ - constacyclic codes by ducoat and oggier, which used quotients of orders in non - commutative associative division algebras defined by f, and can be viewed as a generalization of the classical construction a for lattices from linear codes. it has the potential to be applied to coset coding, in particular to wire - tap coding. previous results by ducoat and oggier are obtained as special cases. introduction in the classical construction a, a lattice is obtained by lifting a linear code over some finite ring [ 19 ]. this idea was recently generalized to the non - commutative setting by considering natural orders in cyclic algebras over number fields : by taking the quotient of the natural order by a suitable ideal, a ring is obtained which is isomorphic to the quotient of a twisted polynomial ring by some polynomial [ 21, 43 ]. this established a connection between twisted polynomials and certain σ - constacyclic codes. we generalize construction a using skew polynomial rings s [ t ; σ, δ ] and construct lattices by lifting cyclic ( f, σ, δ ) - codes, i. e. much more general linear codes than considered in [ 21, 43 ], to lattices in nonassociative algebras. the multiplicative structure of the algebra is not necessary to build a lattice, so we do not limit our considerations to associative algebras as has been done so far. as recently several classes of cyclic ( f, σ, δ ) - codes were constructed with a better minimal distance for certain lengths than previously known codes ( e. g., see [ 6 ], [ 7 ], [ 8 ], [ 9 ], [ 10 ], [ 12 ], [ 11 ] [ 16 ], [ 22 ], [ 29 ], [ 38 ], [ 62 ] ), ( f, σ, δ ) - codes become increasingly important. these codes employ [SEP]
Text from DS:  HOW TO OBTAIN LATTICES FROM (f, σ, δ)-CODES VIA A
GENERALIZATION OF CONSTRUCTION A

arXiv:1607.03787v2 [] 30 Sep 2017

S. PUMPLÜN
Abstract. We show how cyclic (f, σ, δ)-codes over finite rings canonically induce
a Z-lattice in RN by using certain quotients of orders in nonassociative division
algebras defined using the skew polynomial f . This construction generalizes the
one using certain σ-constacyclic codes by Ducoat and Oggier, which used quotients
of orders in non-commutative associative division algebras defined by f , and can
be viewed as a generalization of the classical Construction A for lattices from
linear codes. It has the potential to be applied to coset coding, in particular to
wire-tap coding. Previous results by Ducoat and Oggier are obtained as special
cases.

Introduction
In the classical Construction A, a lattice is obtained by lifting a linear code over
some finite ring [19]. This idea was recently generalized to the non-commutative setting by considering natural 
Original label:  cs.DS
Predicted label:  7
Correct label:  10
Text:  [CLS] journal of modern physics, 2013, 4, 1381 - 1392 http : / / dx. doi. org / 10. 4236 / jmp. 2013. 410166 published online october 2013 ( http : / / www. scirp. org / journal / jmp ) identification of structural model for chaotic systems evgeny v. nikulchev, oleg v. kozlov moscow technological institute, moscow, russia email : nikulchev @ mail. ru received august 5, 2013 ; revised september 6, 2013 ; accepted september 28, 2013 copyright © 2013 evgeny v. nikulchev, oleg v. kozlov. this is an open access article distributed under the creative commons attribution license, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. abstract this article is talking about the study constructive method of structural identification systems with chaotic dynamics. it is shown that the reconstructed attractors are a source of information not only about the dynamics but also on the basis of the attractors which can be identified and the mere sight of models. it is known that the knowledge of the symmetry group allows you to specify the form of a minimal system. forming a group transformation can be found in the reconstructed attractor. the affine system as the basic model is selected. type of a nonlinear system is the subject of calculations. a theoretical analysis is performed and proof of the possibility of constructing models in the central invariant manifold reduced. this developed algorithm for determining the observed symmetry in the attractor. the results of identification used in real systems are an application. keywords : chaotic dynamics ; attractors ; symmetry ; identification 1. introduction the first work on the reconstruction of the strange attractor from the time series has been publishing the results on hydrodynamics [ 1 ]. the article shows that you can get a satisfactory picture of the strange attractor of the geometric dimensions of a small, if the variables x, appearing in the equations of the dynamical system dx dt f x, use the m - dimensional vectors, derived from the elements of time series of the same principle, which in the problems of autoregression. that same year, f. takens reported on his theorem, which was published a year later [ 2 ]. that it is the basis of all algorithms for time series analysis methods of nonlinear dynamics. the problem of determining the form of a dynamical system from its one - dimensional realization belongs to a class of incorrect problems. unlike the problem [SEP]
Text from DS:  Journal of Modern Physics, 2013, 4, 1381-1392
http://dx.doi.org/10.4236/jmp.2013.410166 Published Online October 2013 (http://www.scirp.org/journal/jmp)

Identification of Structural Model for Chaotic Systems
Evgeny V. Nikulchev, Oleg V. Kozlov
Moscow Technological Institute, Moscow, Russia
Email: nikulchev@mail.ru
Received August 5, 2013; revised September 6, 2013; accepted September 28, 2013
Copyright © 2013 Evgeny V. Nikulchev, Oleg V. Kozlov. This is an open access article distributed under the Creative Commons
Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is
properly cited.

ABSTRACT
This article is talking about the study constructive method of structural identification systems with chaotic dynamics. It
is shown that the reconstructed attractors are a source of information not only about the dynamics but also on the basis
of the attractors which can be identified and the mere sight of models. It is kn
Original label:  cs.CE
Predicted label:  9
Correct label:  5
Text:  [CLS] hardware counted profile - guided optimization baptiste wicht ( eia - fr ) baptiste. wicht @ gmail. com roberto a. vitillo ra. vitillo @ gmail. com dehao chen ( google ) dehao @ google. com arxiv : 1411. 6361v1 [ ] 24 nov 2014 david levinthal ( google ) levinth @ google. com abstract tion to achieve minimal cacheline usage. branches can be reordered based on their frequency to avoid branch misprediction. loops working on arrays causing data cache misses can be improved to make better use of the cache. as the dynamic profile, unlike the static profile, captures execution frequency, this can result in impressive speedups for non io - intensive applications. compilers currently support instrumentation - based pgo. in this variant, the compiler must first generate a special version of the application in which instructions are inserted at specific locations to generate the profile. during the execution, counters are incremented by these instructions and finally, the profile is generated into a file. after that, the program is compiled again, this time with pgo flags, to use the profile and optimize the binary for the final version. this approach has several drawbacks : profile - guided optimization ( pgo ) is an excellent means to improve the performance of a compiled program. indeed, the execution path data it provides helps the compiler to generate better code and better cacheline packing. at the time of this writing, compilers only support instrumentation - based pgo. this proved effective for optimizing programs. however, few projects use it, due to its complicated dual - compilation model and its high overhead. our solution of sampling hardware performance counters overcome these drawbacks. in this paper, we propose a pgo solution for gcc by sampling last branch record ( lbr ) events and using debug symbols to recreate source locations of binary instructions. by using lbr - sampling, the generated profiles are very accurate. this solution achieved an average of 83 % of the gains obtained with instrumentation - based pgo and 93 % on c + + benchmarks only. the profiling overhead is only 1. 06 % on average whereas instrumentation incurs a 16 % overhead on average. • the instructions inserted into the program slow it down. an instrumented binary can be much slower than its optimized counterpart. this has been reported to incurs between 9 % and 105 % overhead [ 1, 2 ]. in practice, [SEP]
Text from DS:  Hardware Counted Profile-Guided Optimization
Baptiste Wicht (EIA-FR)
baptiste.wicht@gmail.com

Roberto A. Vitillo
ra.vitillo@gmail.com

Dehao Chen (Google)
dehao@google.com

arXiv:1411.6361v1 [] 24 Nov 2014

David Levinthal (Google)
levinth@google.com

Abstract

tion to achieve minimal cacheline usage. Branches can
be reordered based on their frequency to avoid branch
misprediction. Loops working on arrays causing Data
Cache misses can be improved to make better use of the
cache. As the dynamic profile, unlike the static profile,
captures execution frequency, this can result in impressive speedups for non IO-intensive applications.
Compilers currently support instrumentation-based
PGO. In this variant, the compiler must first generate a
special version of the application in which instructions
are inserted at specific locations to generate the profile. During the execution, counters are incremented by
these instructions and finally, the profile is generated
into a file. After that, the 
Original label:  cs.CE
Predicted label:  10
Correct label:  8
Text:  [CLS] arxiv : 1009. 1977v2 [ cs. lo ] 14 jan 2011 fixpoint & proof - theoretic semantics for clp with qualification and proximity ∗ technical report sic - 1 - 10 mario rodriguez - artalejo and carlos a. romero - diaz departamento de sistemas informaticos y computacion, universidad complutense facultad de informatica, 28040 madrid, spain ( e - mail : mario @ sip. ucm. es, cromdia @ fdi. ucm. es ) abstract uncertainty in logic programming has been investigated during the last decades, dealing with various extensions of the classical lp paradigm and different applications. existing proposals rely on different approaches, such as clause annotations based on uncertain truth values, qualification values as a generalization of uncertain truth values, and unification based on proximity relations. on the other hand, the clp scheme has established itself as a powerful extension of lp that supports efficient computation over specialized domains while keeping a clean declarative semantics. in this report we propose a new scheme sqclp designed as an extension of clp that supports qualification values and proximity relations. we show that several previous proposals can be viewed as particular cases of the new scheme, obtained by partial instantiation. we present a declarative semantics for sqclp that is based on observables, providing fixpoint and proof - theoretical characterizations of least program models as well as an implementation - independent notion of goal solutions. keywords : constraint logic programming, qualification domains and values, proximity relations. 1 introduction many extensions of logic programming ( shortly lp ) to deal with uncertainty have been proposed in the last decades. a line of research not related to this report is based on probabilistic extensions of lp such as ( ng and subrahmanian 1992 ). other proposals in the field replace classical two - valued logic by some kind of many - valued logic whose truth values can be attached to computed answers and are usually interpreted as certainty degrees. the next paragraphs summarize some relevant approaches of this kind. there are extensions of lp using annotations in program clauses to compute a certainty degree for the head atom from the certainty degrees previously computed ∗ this work has been partially supported by the spanish projects stamp ( tin2008 - 06622 - c0301 ), prometidos – cm ( s2009tic - 1465 ) and gpd – ucm ( ucm – bsch – gr58 / 08 [SEP]
Text from DS:  arXiv:1009.1977v2 [cs.LO] 14 Jan 2011

Fixpoint & Proof-theoretic Semantics
for CLP with Qualification and Proximity ∗
Technical Report SIC-1-10
MARIO RODRÍGUEZ-ARTALEJO and CARLOS A. ROMERO-DÍAZ
Departamento de Sistemas Informáticos y Computación, Universidad Complutense
Facultad de Informática, 28040 Madrid, Spain
(e-mail: mario@sip.ucm.es, cromdia@fdi.ucm.es)

Abstract
Uncertainty in Logic Programming has been investigated during the last decades, dealing
with various extensions of the classical LP paradigm and different applications. Existing
proposals rely on different approaches, such as clause annotations based on uncertain truth
values, qualification values as a generalization of uncertain truth values, and unification
based on proximity relations. On the other hand, the CLP scheme has established itself as
a powerful extension of LP that supports efficient computation over specialized domains
while keeping a clean declarative semantics. In this report we propose a new sch
Original label:  math.GR
Predicted label:  3
Correct label:  7
Text:  [CLS] arxiv : 1709. 09441v1 [ ] 27 sep 2017 doubly hurwitz beauville groups gareth a. jones and emilio pierro september 28, 2017 abstract if s is a beauville surface ( c1 × c2 ) / g, then the hurwitz bound implies that | g | ≤ 1764 χ ( s ), with equality if and only if the beauville group g acts as a hurwitz group on both curves ci. equivalently, g has two generating triples of type ( 2, 3, 7 ), such that no generator in one triple is conjugate to a power of a generator in the other. we show that this property is satisfied by alternating groups an, their double covers 2. an, and special linear groups sln ( q ) if n is sufficiently large, but by no sporadic simple groups or simple groups ln ( q ) ( n ≤ 7 ), 2 g2 ( 3e ), 2 f4 ( 2e ), 2 f4 ( 2 ) ′, g2 ( q ) or 3 d4 ( q ) of small lie rank. msc2010 classifications : 14h37, 14j29, 20b25, 20d05, 20f05, 30f10. 1 introduction a beauville surface is a complex algebraic surface of general type, of the form s = ( c1 × c2 ) / g where c1 and c2 are the algebraic curves underlying regular dessins r1 and r2 of genera g1, g2 > 1, which have the same automorphism g which acts freely on their product. ( this construction was introduced by beauville in [ 2 ] ; for further details see the surveys [ 17, 26 ] or [ 28, chapter 11 ]. ) a finite group g arises in this way ( and is then called a beauville group ) if and only if it has generating triples ( xi, yi, zi ) of hyperbolic types for i = 1, 2, such that no non - identity element of g has fixed points on both curves, or equivalently no non - identity power of x1, y1 or z1 is conjugate in g to a power of x2, y2 or z2. in this situation, s has euler characteristic χ ( s ) = 4 ( g1 − 1 ) ( g2 − 1 ) χ ( c1 ) χ ( c2 ) =. | g | | g | 1 using the hurwitz bound [SEP]
Text from DS:  arXiv:1709.09441v1 [] 27 Sep 2017

Doubly Hurwitz Beauville groups
Gareth A. Jones and Emilio Pierro
September 28, 2017
Abstract
If S is a Beauville surface (C1 × C2 )/G, then the Hurwitz bound
implies that |G| ≤ 1764 χ(S), with equality if and only if the Beauville
group G acts as a Hurwitz group on both curves Ci . Equivalently, G
has two generating triples of type (2, 3, 7), such that no generator in
one triple is conjugate to a power of a generator in the other. We show
that this property is satisfied by alternating groups An , their double
covers 2.An , and special linear groups SLn (q) if n is sufficiently large,
but by no sporadic simple groups or simple groups Ln (q) (n ≤ 7),
2
G2 (3e ), 2 F4 (2e ), 2 F4 (2)′ , G2 (q) or 3 D4 (q) of small Lie rank.

MSC2010 Classifications: 14H37, 14J29, 20B25, 20D05, 20F05, 30F10.

1

Introduction

A Beauville surface is a complex algebraic surface of general type, of the
form
S = (C1 × C2 )/G
where C1 and C2 are the algebraic curves underlyin
Original label:  math.AC
Predicted label:  2
Correct label:  9
Text:  [CLS] arxiv : 1610. 00260v2 [ ] 12 oct 2016 non - koszul quadratic gorenstein toric rings kazunori matsuda abstract. koszulness of gorenstein quadratic algebras of small socle degree is studied. in this note, we construct non - koszul gorenstein quadratic toric ring such that its socle degree is more than 3 by using stable set polytopes. introduction let k be a field and s = k [ x1,..., xn ] a polynomial ring over k. let r = s / i be a standard graded k - algebra with respect to the grading deg xi = 1 for all 1 ≤ i ≤ n, where i is a homogeneous ideal of s. let r + denote the homogeneous maximal ideal of r. for an r - module m, we denote βijr ( m ) by the ( i, j ) - th graded betti number of m as an r - module. the koszul algebra was originally introduced by priddy [ 29 ]. a standard graded k - algebra r is said to be koszul if the residue field k = r / r + has a linear rr free resolution as an r - module, that is, βijr ( k ) = 0 if i 6 = j. since β2j ( k ) = 0 for all j > 2, hence koszul algebras are quadratic, where r = s / i is said to be quadratic if i is generated by homogeneous elements of degree 2. every quadratic complete intersection is koszul by tate ’ s theorem [ 35 ]. moreover, r = s / i is koszul if i has a quadratic grobner bases by froberg ’ s theorem [ 10 ] and the fact that ′ βijr ( k ) ≤ βijr ( k ) for all i, j and for all monomial order < on s, where r ′ = s / in < ( i ). the notion of koszul algebra has played an important role in the research on graded k - algebras, and various koszul - like algebras have been introduced, e. g., universally koszul [ 5 ], strongly koszul [ 12 ], initially koszul [ 2 ], sequentially koszul [ 1 ], etc. koszulness of toric rings of integral convex polytopes is studied. let p [SEP]
Text from DS:  arXiv:1610.00260v2 [] 12 Oct 2016

NON-KOSZUL QUADRATIC GORENSTEIN TORIC RINGS
KAZUNORI MATSUDA
Abstract. Koszulness of Gorenstein quadratic algebras of small socle degree is
studied. In this note, we construct non-Koszul Gorenstein quadratic toric ring
such that its socle degree is more than 3 by using stable set polytopes.

Introduction
Let K be a field and S = K[x1 , . . . , xn ] a polynomial ring over K. Let R = S/I be
a standard graded K-algebra with respect to the grading deg xi = 1 for all 1 ≤ i ≤ n,
where I is a homogeneous ideal of S. Let R+ denote the homogeneous maximal ideal
of R. For an R-module M, we denote βijR (M) by the (i, j)-th graded betti number
of M as an R-module.
The Koszul algebra was originally introduced by Priddy [29]. A standard graded
K-algebra R is said to be Koszul if the residue field K = R/R+ has a linear RR
free resolution as an R-module, that is, βijR (K) = 0 if i 6= j. Since β2j
(K) = 0
for all j > 2, hence Koszul algebras are quadratic, where R = S
Original label:  math.ST
Predicted label:  6
Correct label:  5
Text:  [CLS] bootstrap for change point detection nazar buzun, valeriy avanesov { buzun, avanesov } @ wias - berlin. de arxiv : 1710. 07285v1 [ ] 19 oct 2017 october 23, 2017 1 introduction the problem of change point detection appears each time one needs to explore a set of random data and make a decision about homogeneity of its structure. in other words, the problem can be stated as two following questions : were there any structural changes in the nature of observed data? at which moments, if so? the present work mainly focuses on the sequential or online change point detection. in this case the data is aggregated from running random process. formally a time moment τ is a change point, if stochastic properties of the observed signal { yt } nt = 1 have undergone changes in its distribution : ( yt v ip1 t < τ, yt v ip2 t ≥ τ. the goal is to find such structural breaks as soon as possible. such problem arises across many scientific areas : quality control lai ( 1995 ), cybersecurity blazek and kim ( 2001 ), wang et al. ( 2004 ), econometrics spokoiny ( 2009 ), mikosch and starica ( 2004 ), geodesy e. t. c. article shiryaev ( 1963 ) describes classical results in change point detection theory. overview of the state - of - art methods are presented in polunchenko and tartakovsky ( 2011 ) and shiryaev ( 2010 ). this research considers sequential hypothesis testing, in which each hypothesis ( ip1 = ip2 ) monitors the presence of change point through likelihood ratio test ( lrt ) using sliding window. at each time step the procedure extracts a data slice, splits it in two parts of equal size and executes lrt on it. high values of lrt indicate possible distribution difference in the window parts ( ip1 6 = ip2 ). procedures with lrt are rather popular in related literature. the work quandt ( 1960 ) proposes application of lrt for detection of breaks in linear regression model. it was further developed by many authors, e. g. haccou et al. ( 1987 ), srivastava and worsley ( 1986 ). papers liu et al. ( 2008 ), zou et al. ( 2007 ) investigate lrt for change point detection for nonparametric case. nonparametric approaches are [SEP]
Text from DS:  Bootstrap for change point detection
Nazar Buzun, Valeriy Avanesov
{buzun,avanesov}@wias-berlin.de

arXiv:1710.07285v1 [] 19 Oct 2017

October 23, 2017

1

Introduction

The problem of change point detection appears each time one needs to explore a set of random
data and make a decision about homogeneity of its structure. In other words, the problem can
be stated as two following questions: were there any structural changes in the nature of observed
data? At which moments, if so? The present work mainly focuses on the sequential or online
change point detection. In this case the data is aggregated from running random process. Formally
a time moment τ is a change point, if stochastic properties of the observed signal {Yt }nt=1 have
undergone changes in its distribution:
(
Yt v IP1 t < τ,
Yt v IP2 t ≥ τ.
The goal is to find such structural breaks as soon as possible. Such problem arises across many
scientific areas: quality control Lai (1995), cybersecurity Blazek and Kim (2001), Wang et
Original label:  cs.NE
Predicted label:  4
Correct label:  0
Text:  [CLS] under review as a conference paper at iclr 2017 z oneout : r egularizing rnn s p reserving h idden activations by r andomly arxiv : 1606. 01305v4 [ ] 22 sep 2017 david krueger1,?, tegan maharaj2,?, janos kramar2 mohammad pezeshki1 nicolas ballas1, nan rosemary ke2, anirudh goyal1 yoshua bengio1 †, aaron courville1 ‡, christopher pal2 1 mila, universite de montreal, firstname. lastname @ umontreal. ca. 2 ecole polytechnique de montreal, firstname. lastname @ polymtl. ca.? equal contributions. † cifar senior fellow. ‡ cifar fellow. a bstract we propose zoneout, a novel method for regularizing rnns. at each timestep, zoneout stochastically forces some hidden units to maintain their previous values. like dropout, zoneout uses random noise to train a pseudo - ensemble, improving generalization. but by preserving instead of dropping hidden units, gradient information and state information are more readily propagated through time, as in feedforward stochastic depth networks. we perform an empirical investigation of various rnn regularizers, and find that zoneout gives significant performance improvements across tasks. we achieve competitive results with relatively simple models in character - and word - level language modelling on the penn treebank and text8 datasets, and combining with recurrent batch normalization ( cooijmans et al., 2016 ) yields state - of - the - art results on permuted sequential mnist. 1 i ntroduction regularizing neural nets can significantly improve performance, as indicated by the widespread use of early stopping, and success of regularization methods such as dropout and its recurrent variants ( hinton et al., 2012 ; srivastava et al., 2014 ; zaremba et al., 2014 ; gal, 2015 ). in this paper, we address the issue of regularization in recurrent neural networks ( rnns ) with a novel method called zoneout. rnns sequentially construct fixed - length representations of arbitrary - length sequences by folding new observations into their hidden state using an input - dependent transition operator. the repeated application of the same transition operator at the different time steps of the sequence, however, can make the dynamics of [SEP]
Text from DS:  Under review as a conference paper at ICLR 2017

Z ONEOUT: R EGULARIZING RNN S
P RESERVING H IDDEN ACTIVATIONS

BY

R ANDOMLY

arXiv:1606.01305v4 [] 22 Sep 2017

David Krueger1,? , Tegan Maharaj2,? , János Kramár2
Mohammad Pezeshki1 Nicolas Ballas1 , Nan Rosemary Ke2 , Anirudh Goyal1
Yoshua Bengio1† , Aaron Courville1‡ , Christopher Pal2
1
MILA, Université de Montréal, firstname.lastname@umontreal.ca.
2
École Polytechnique de Montréal, firstname.lastname@polymtl.ca.
?
Equal contributions. † CIFAR Senior Fellow. ‡ CIFAR Fellow.

A BSTRACT
We propose zoneout, a novel method for regularizing RNNs. At each timestep,
zoneout stochastically forces some hidden units to maintain their previous values.
Like dropout, zoneout uses random noise to train a pseudo-ensemble, improving
generalization. But by preserving instead of dropping hidden units, gradient
information and state information are more readily propagated through time, as
in feedforward stochastic depth networks. We perform an empiric
Original label:  math.AC
Predicted label:  5
Correct label:  9
Text:  [CLS] on bounds for the effective differential nullstellensatz omar leon sanchez department of mathematics and statistics, mcmaster university, 1280 main st w, hamilton, on l8s 4l8, canada alexey ovchinnikov1 arxiv : 1508. 07508v1 [ ] 29 aug 2015 department of mathematics, cuny queens college, 65 - 30 kissena blvd, queens, ny 11367, usa ph. d. program in mathematics, cuny graduate center, 365 fifth avenue, new york, new york 10016, usa abstract understanding bounds for the effective differential nullstellensatz is a central problem in differential algebraic geometry. recently, several bounds have been obtained using dicksonian and antichains sequences ( with a given growth rate ). in the present paper, we make these bounds more explicit and, therefore, more applicable to understanding the computational complexity of the problem, which is essential to designing more efficient algorithms. keywords : effective differential nullstellensatz, antichain sequences 2010 msc : primary 12h05, secondary 14q20 1. introduction the effective differential nullstellensatz problem can be stated as follows : given a system of algebraic partial differential equations f = 0 where f = f1,..., fs, can one effectively determine if the system is consistent? in other words, is there an effective procedure to determine if 1 belongs or not to the differential ideal generated by f in the ring of differential polynomials? to determine if 1 belongs to an ideal in a polynomial ring, one can use algebraic effective methods ( for instance, [ 1, 6 ] ). thus, the problem reduces to finding an effective bound b such that 1 is in the differential ideal generated by f if and only if 1 is in the ideal generated by f and its derivatives of order at most b. let us rephrase the above problem in more technical terms. let m, n, ℓ, d be positive integers. an upper bound for the effective differential nullstellensatz is an effectively determined function b = b ( m, n, ℓ, d ) that is minimal with respect to the following property : for any differential field ( k, ∂1,..., ∂m ) of characteristic zero with m commuting derivations, and any finite set f ⊂ k { x1,..., xn } of differential polynomials over k in n differential indeterminates of order and degree bounded by ℓ and d, [SEP]
Text from DS:  On bounds for the effective differential Nullstellensatz
Omar León Sánchez
Department of Mathematics and Statistics, McMaster University, 1280 Main St W, Hamilton, ON L8S 4L8, Canada

Alexey Ovchinnikov1

arXiv:1508.07508v1 [] 29 Aug 2015

Department of Mathematics, CUNY Queens College, 65-30 Kissena Blvd, Queens, NY 11367, USA
Ph.D. Program in Mathematics, CUNY Graduate Center, 365 Fifth Avenue, New York, New York 10016, USA

Abstract
Understanding bounds for the effective differential Nullstellensatz is a central problem in differential algebraic geometry. Recently, several bounds have been obtained using Dicksonian and antichains sequences (with a given growth
rate). In the present paper, we make these bounds more explicit and, therefore, more applicable to understanding the
computational complexity of the problem, which is essential to designing more efficient algorithms.
Keywords: Effective differential Nullstellensatz, antichain sequences
2010 MSC: primary 12H05, secondary 14Q2
Original label:  math.AC
Predicted label:  8
Correct label:  10
Text:  [CLS] arxiv : 1103. 4780v2 [ ] 26 sep 2012 a degree map on unimodular rows j. fasel abstract. let k be a field and let ( an − 0 ) be the punctured affine space. we associate to any morphism g : ( an − 0 ) → ( an − 0 ) an element in the witt group w ( k ) that we call the degree of g. we then use this degree map to give a negative answer to a question of m. v. nori about unimodular rows. introduction let r be a ring and let p be a projective r - module such that p ⊕ r [UNK] rn + 1 for some n ∈ n. the obvious question is to know if such an isomorphism yields an isomorphism p [UNK] rn. in general, this is not the case and finding general conditions for the answer to be positive is an important an extensively studied problem. recall that one can associate to a projective p module as above a unimodular row of length n + 1, i. e. a row ( a0,..., an ) such that rai = r. let u mn + 1 ( r ) be the set of unimodular rows of length n + 1. it is clear that gln + 1 ( r ) acts on u mn + 1 ( r ) by right multiplication, and therefore so does any subgroup of gln + 1 ( r ). in general, one is particularly interested by the groups en + 1 ( r ) generated by elementary matrices and sln + 1 ( r ), because u mn + 1 ( r ) / en + 1 ( r ) corresponds to some cohomotopy group in the topological situation and then carries a groups structure when n is " reasonable " compared to the krull dimension of d ( [ 19, theorem 4. 1 ] ) and because u mn + 1 ( r ) / sln + 1 ( r ) classifies up to isomorphism projective modules p such that p ⊕r [UNK] rn + 1. one says that a unimodular row v is completable if v ∈ e1 sln + 1 ( r ) where e1 = ( 1, 0,..., 0 ). thus the question to know if p ⊕r [UNK] rn + 1 implies p [UNK] rn reduces to the question to know if the associated unimodular row is completable. the first general condition on unimo [SEP]
Text from DS:  arXiv:1103.4780v2 [] 26 Sep 2012

A DEGREE MAP ON UNIMODULAR ROWS
J. FASEL
Abstract. Let k be a field and let (An − 0) be the punctured affine space.
We associate to any morphism g : (An − 0) → (An − 0) an element in the Witt
group W (k) that we call the degree of g. We then use this degree map to give
a negative answer to a question of M. V. Nori about unimodular rows.

Introduction
Let R be a ring and let P be a projective R-module such that P ⊕ R ≃ Rn+1
for some n ∈ N. The obvious question is to know if such an isomorphism yields an
isomorphism P ≃ Rn . In general, this is not the case and finding general conditions
for the answer to be positive is an important an extensively studied problem. Recall
that one can associate to a projective P
module as above a unimodular row of length
n+1, i.e. a row (a0 , . . . , an ) such that Rai = R. Let U mn+1 (R) be the set of unimodular rows of length n+ 1. It is clear that GLn+1 (R) acts on U mn+1 (R) by right
multiplication, and therefore so d
Original label:  cs.NE
Predicted label:  1
Correct label:  7
Text:  [CLS] end - to - end differentiable proving arxiv : 1705. 11040v2 [ ] 4 dec 2017 tim rocktaschel university of oxford tim. rocktaschel @ cs. ox. ac. uk sebastian riedel university college london & bloomsbury ai s. riedel @ cs. ucl. ac. uk abstract we introduce neural networks for end - to - end differentiable proving of queries to knowledge bases by operating on dense vector representations of symbols. these neural networks are constructed recursively by taking inspiration from the backward chaining algorithm as used in prolog. specifically, we replace symbolic unification with a differentiable computation on vector representations of symbols using a radial basis function kernel, thereby combining symbolic reasoning with learning subsymbolic vector representations. by using gradient descent, the resulting neural network can be trained to infer facts from a given incomplete knowledge base. it learns to ( i ) place representations of similar symbols in close proximity in a vector space, ( ii ) make use of such similarities to prove queries, ( iii ) induce logical rules, and ( iv ) use provided and induced logical rules for multi - hop reasoning. we demonstrate that this architecture outperforms complex, a state - of - the - art neural link prediction model, on three out of four benchmark knowledge bases while at the same time inducing interpretable function - free first - order logic rules. 1 introduction current state - of - the - art methods for automated knowledge base ( kb ) completion use neural link prediction models to learn distributed vector representations of symbols ( i. e. subsymbolic representations ) for scoring fact triples [ 1 – 7 ]. such subsymbolic representations enable these models to generalize to unseen facts by encoding similarities : if the vector of the predicate symbol grandfatherof is similar to the vector of the symbol grandpaof, both predicates likely express a similar relation. likewise, if the vector of the constant symbol lisa is similar to maggie, similar relations likely hold for both constants ( e. g. they live in the same city, have the same parents etc. ). this simple form of reasoning based on similarities is remarkably effective for automatically completing large kbs. however, in practice it is often important to capture more complex reasoning patterns that involve several inference steps. for example, if abe is the father of homer and homer is a parent of bart, we would like to infer that abe is a grandfather of bart. such transitive reasoning is inherently hard for neural link prediction [SEP]
Text from DS:  End-to-End Differentiable Proving

arXiv:1705.11040v2 [] 4 Dec 2017

Tim Rocktäschel
University of Oxford
tim.rocktaschel@cs.ox.ac.uk

Sebastian Riedel
University College London & Bloomsbury AI
s.riedel@cs.ucl.ac.uk

Abstract
We introduce neural networks for end-to-end differentiable proving of queries to
knowledge bases by operating on dense vector representations of symbols. These
neural networks are constructed recursively by taking inspiration from the backward
chaining algorithm as used in Prolog. Specifically, we replace symbolic unification
with a differentiable computation on vector representations of symbols using a
radial basis function kernel, thereby combining symbolic reasoning with learning
subsymbolic vector representations. By using gradient descent, the resulting neural
network can be trained to infer facts from a given incomplete knowledge base.
It learns to (i) place representations of similar symbols in close proximity in a
vector space, (ii) make use of such simila
Original label:  cs.CV
Predicted label:  3
Correct label:  8
Text:  [CLS] end - to - end video classification with knowledge graphs fang yuan, zhe wang, jie lin, luis fernando d ’ haro, kim jung jae, zeng zeng, vijay chandrasekhar arxiv : 1711. 01714v1 [ ] 6 nov 2017 yfang @ i2r. a - star. edu. sg, mark. wangzhe @ gmail. com, luisdhe @ i2r. a - star. edu. sg, jjkim @ i2r. a - star. edu. sg zengz @ i2r. a - star. edu. sg, vijay @ i2r. a - star. edu. sg institute for infocomm research, singapore abstract video understanding has attracted much research attention especially since the recent availability of large - scale video benchmarks. in this paper, we address the problem of multilabel video classification. we first observe that there exists a significant knowledge gap between how machines and humans learn. that is, while current machine learning approaches including deep neural networks largely focus on the representations of the given data, humans often look beyond the data at hand and leverage external knowledge to make better decisions. towards narrowing the gap, we propose to incorporate external knowledge graphs into video classification. in particular, we unify traditional “ knowledgeless ” machine learning models and knowledge graphs in a novel endto - end framework. the framework is flexible to work with most existing video classification algorithms including stateof - the - art deep models. finally, we conduct extensive experiments on the largest public video dataset youtube - 8m. the results are promising across the board, improving mean average precision by up to 2. 9 %. introduction since the advent of neural networks and deep learning, major breakthroughs have been made in many artificial intelligence tasks ranging from computer vision to natural language processing. however, a significant knowledge gap still exist between machine and human intelligence. in particular, humans often relate to and make use of semantic knowledge outside of the task - specific data to make better decisions. on the other hand, most machine learning algorithms including state - of - the - art deep methods, only focus on the representation of the given data, without leveraging any external knowledge that could benefit the given task. consider the surfing man example in figure 1 ( a ). by only analyzing the pixels of the image ( i. e., given data ), it is difficult to conclude that the man is on a surfboard since most of it [SEP]
Text from DS:  End-to-End Video Classification with Knowledge Graphs
Fang Yuan, Zhe Wang, Jie Lin, Luis Fernando D’Haro, Kim Jung Jae, Zeng Zeng, Vijay Chandrasekhar

arXiv:1711.01714v1 [] 6 Nov 2017

yfang@i2r.a-star.edu.sg, mark.wangzhe@gmail.com, luisdhe@i2r.a-star.edu.sg, jjkim@i2r.a-star.edu.sg
zengz@i2r.a-star.edu.sg, vijay@i2r.a-star.edu.sg
Institute for Infocomm Research, Singapore

Abstract
Video understanding has attracted much research attention
especially since the recent availability of large-scale video
benchmarks. In this paper, we address the problem of multilabel video classification. We first observe that there exists a significant knowledge gap between how machines and
humans learn. That is, while current machine learning approaches including deep neural networks largely focus on the
representations of the given data, humans often look beyond
the data at hand and leverage external knowledge to make
better decisions. Towards narrowing the gap, we propose to
incorporate external know
Original label:  math.AC
Predicted label:  10
Correct label:  9
Text:  [CLS] arxiv : 1708. 07983v1 [ ] 26 aug 2017 pointwise minimal extensions gabriel picavet and martine picavet - l ’ hermitte abstract. we characterize pointwise minimal extensions of rings, introduced by p. - j. cahen, d. e. dobbs and t. g. lucas in a special context. we also define and characterize pointwise minimal pairs of rings and co - pointwise minimal extensions. we examine the links of the above notions with lattices and their atoms. 1. introduction and notation we consider the category of commutative and unital rings and its epimorphisms. a local ring is here what is called elsewhere a quasilocal ring. as usual, spec ( r ) and max ( r ) are the sets of prime and maximal ideals of a ring r. the characteristic of an integral domain k is denoted by c ( k ). finally, ⊂ denotes proper inclusion, | x | the cardinality of a set x and p the set of all prime numbers. the conductor of a ( ring ) extension r ⊆ s is denoted by ( r : s ), the set of all r - subalgebras of s by [ r, s ] and the integral closure of r in s by r. any writing [ r, s ] is relative to some extension r ⊆ s. clearly, ( [ r, s ], ⊆ ) is a lattice since it is stable under the formation of arbitrary intersections ( meets ) and compositums ( joins ). if [ r, s ] has some property p of lattices, we say that r ⊆ s has the property p. an extension r ⊆ s is called an afffine pair ( or strongly affine ) if each r - subalgebra of s is of finite type. we say that an extension r ⊆ s is finite if the r - module s is finitely generated. the extension r ⊆ s is said to have fip ( or is called an fip extension ) ( for the “ finitely many intermediate algebras property ” ) if [ r, s ] is finite. a chain of r - subalgebras of s is a set of elements of [ r, s ] that are pairwise comparable with respect to inclusion. we say that an extension r ⊆ s has fcp ( or is called an fcp extension ) ( for the “ finite chain property ” ) if each chain in [ r, s ] [SEP]
Text from DS:  arXiv:1708.07983v1 [] 26 Aug 2017

POINTWISE MINIMAL EXTENSIONS
GABRIEL PICAVET AND MARTINE PICAVET-L’HERMITTE
Abstract. We characterize pointwise minimal extensions of rings,
introduced by P.-J. Cahen, D. E. Dobbs and T. G. Lucas in a special context. We also define and characterize pointwise minimal
pairs of rings and co-pointwise minimal extensions. We examine
the links of the above notions with lattices and their atoms.

1. Introduction and Notation
We consider the category of commutative and unital rings and its
epimorphisms. A local ring is here what is called elsewhere a quasilocal ring. As usual, Spec(R) and Max(R) are the sets of prime and
maximal ideals of a ring R. The characteristic of an integral domain
k is denoted by c(k). Finally, ⊂ denotes proper inclusion, |X| the
cardinality of a set X and P the set of all prime numbers.
The conductor of a (ring) extension R ⊆ S is denoted by (R : S),
the set of all R-subalgebras of S by [R, S] and the integral closure of
R in S by R
Original label:  cs.SY
Predicted label:  2
Correct label:  9
Text:  [CLS] interpretable policies for reinforcement learning by genetic programming daniel heina, b, ∗, steffen udluftb, thomas a. runklera, b a technical university of munich, department of informatics, boltzmannstr. 3, 85748 garching, germany b siemens ag, corporate technology, otto - hahn - ring 6, 81739 munich, germany arxiv : 1712. 04170v2 [ ] 4 apr 2018 abstract the search for interpretable reinforcement learning policies is of high academic and industrial interest. especially for industrial systems, domain experts are more likely to deploy autonomously learned controllers if they are understandable and convenient to evaluate. basic algebraic equations are supposed to meet these requirements, as long as they are restricted to an adequate complexity. here we introduce the genetic programming for reinforcement learning ( gprl ) approach based on model - based batch reinforcement learning and genetic programming, which autonomously learns policy equations from pre - existing default state - action trajectory samples. gprl is compared to a straight - forward method which utilizes genetic programming for symbolic regression, yielding policies imitating an existing well - performing, but non - interpretable policy. experiments on three reinforcement learning benchmarks, i. e., mountain car, cart - pole balancing, and industrial benchmark, demonstrate the superiority of our gprl approach compared to the symbolic regression method. gprl is capable of producing well - performing interpretable reinforcement learning policies from pre - existing default trajectory data. keywords : interpretable, reinforcement learning, genetic programming, model - based, symbolic regression, industrial benchmark 1. introduction this work introduces a genetic programming ( gp ) approach for autonomously learning interpretable reinforcement learning ( rl ) policies from previously recorded state transitions. despite the search of interpretable rl policies being of high academic and industrial interest, little has been published concerning human interpretable and understandable policies trained by data driven learning methods ( maes, fonteneau, wehenkel, and ernst, 2012 ). recent research results show that using fuzzy rules in batch rl settings can be considered an adequate solution to this task ( hein, hentschel, runkler, and udluft, 2017b ). however, in many cases the successful use of fuzzy rules requires prior knowledge about the shape of the membership functions, the number of fuzzy rules, the relevant state features, etc. moreover, for some problems the policy representation as a set of fuzzy rules might be generally unfavorable by some domain experts. [SEP]
Text from DS:  Interpretable Policies for Reinforcement Learning by Genetic Programming
Daniel Heina,b,∗, Steffen Udluftb , Thomas A. Runklera,b
a Technical

University of Munich, Department of Informatics, Boltzmannstr. 3, 85748 Garching, Germany
b Siemens AG, Corporate Technology, Otto-Hahn-Ring 6, 81739 Munich, Germany

arXiv:1712.04170v2 [] 4 Apr 2018

Abstract
The search for interpretable reinforcement learning policies is of high academic and industrial interest. Especially for
industrial systems, domain experts are more likely to deploy autonomously learned controllers if they are understandable
and convenient to evaluate. Basic algebraic equations are supposed to meet these requirements, as long as they are
restricted to an adequate complexity. Here we introduce the genetic programming for reinforcement learning (GPRL)
approach based on model-based batch reinforcement learning and genetic programming, which autonomously learns policy
equations from pre-existing default state-action trajectory
Original label:  cs.CE
Predicted label:  1
Correct label:  2
Text:  [CLS] engineering record and replay for deployability extended technical report arxiv : 1705. 05937v1 [ ] 16 may 2017 robert o ’ callahan∗ chris jones∗ albert noll∗ swisscom ag abstract the ability to record and replay program executions with low overhead enables many applications, such as reverse - execution debugging, debugging of hard - toreproduce test failures, and “ black box ” forensic analysis of failures in deployed systems. existing record - andreplay approaches limit deployability by recording an entire virtual machine ( heavyweight ), modifying the os kernel ( adding deployment and maintenance costs ), requiring pervasive code instrumentation ( imposing significant performance and complexity overhead ), or modifying compilers and runtime systems ( limiting generality ). we investigated whether it is possible to build a practical record - and - replay system avoiding all these issues. the answer turns out to be yes — if the cpu and operating system meet certain non - obvious constraints. fortunately modern intel cpus, linux kernels and user - space frameworks do meet these constraints, although this has only become true recently. with some novel optimizations, our system rr records and replays real - world lowparallelism workloads with low overhead, with an entirely user - space implementation, using stock hardware, compilers, runtimes and operating systems. rr forms the basis of an open - source reverse - execution debugger seeing significant use in practice. we present the design and implementation of rr, describe its performance on a variety of workloads, and identify constraints on hardware and operating system design required to support our approach. 1 introduction the ability to record a program execution with low overhead and play it back precisely has many applications [ 17, 18, 22 ] and has received significant attention in the research community. it has even been implemented in products such as vmware workstation [ 31 ], simics [ 23 ], ∗ majority of work carried out while supported by mozilla research. nathan froyd mozilla corporation kyle huey∗ nimrod partush∗ technion undodb [ 3 ] and totalview [ 25 ]. unfortunately, deployment of these techniques has been limited, for various reasons. some approaches [ 20, 23, 31 ] require recording and replaying an entire virtual machine, which is heavyweight — users must set up and manage the virtual machine, and the state that must be recorded and replayed encompasses an entire operating system, when the user often only cares about some specific process ( es ) [SEP]
Text from DS:  Engineering Record And Replay For Deployability
Extended Technical Report

arXiv:1705.05937v1 [] 16 May 2017

Robert O’Callahan∗

Chris Jones∗
Albert Noll∗
Swisscom AG

Abstract
The ability to record and replay program executions
with low overhead enables many applications, such
as reverse-execution debugging, debugging of hard-toreproduce test failures, and “black box” forensic analysis of failures in deployed systems. Existing record-andreplay approaches limit deployability by recording an entire virtual machine (heavyweight), modifying the OS
kernel (adding deployment and maintenance costs), requiring pervasive code instrumentation (imposing significant performance and complexity overhead), or modifying compilers and runtime systems (limiting generality).
We investigated whether it is possible to build a practical record-and-replay system avoiding all these issues.
The answer turns out to be yes — if the CPU and operating system meet certain non-obvious constraints. Fortunately mode
Original label:  cs.CE
Predicted label:  3
Correct label:  5
Text:  [CLS] dataflow graphs as matrices and programming with higher - order matrix elements arxiv : 1601. 01050v1 [ ] 6 jan 2016 michael bukatin1 and steve matthews2 1 nokia corporation burlington, massachusetts, usa bukatin @ cs. brandeis. edu 2 department of computer science university of warwick coventry, uk steve. matthews @ warwick. ac. uk abstract we consider dataflow architecture for two classes of computations which admit taking linear combinations of execution runs : probabilistic sampling and generalized animation. we improve the earlier technique of almost continuous program transformations by adopting a discipline of bipartite graphs linking nodes obtained via general transformations and nodes obtained via linear transformations which makes it possible to develop and evolve dataflow programs over these classes of computations by continuous program transformations. the use of bipartite graphs allows us to represent the dataflow programs from this class as matrices of real numbers and evolve and modify programs by continuous change of these numbers. we develop a formalism for higher - order dataflow programming for this class of dataflow graphs based on the higher - order matrix elements. some of our software experiments are briefly discussed. 1 introduction because probabilistic sampling and generalized animation are both stream - based, dataflow programming is a natural framework for this situation. earlier we were able to leverage the ability to take linear combinations of execution runs to obtain the notion of almost continuous transformation of dataflow programs [ 1 ]. there were three main sources of benign discontinuities in [ 1 ] : addition of new subgraphs via an operation of limited deep copy, insertion of a new vertex and an edge during the first stage of s - insert, and insertion of an edge during the second stage of s - insert. we now allow to decorate subgraphs with weights and require that new subgraphs created by limited deep copy appear initially with zero weight subject to subsequent continuous evolution. we also introduce the discipline of arranging and linking vertices as a bipartite graph, namely that general transforms of fixed arity must point only at linear transforms of unlimited arity, and vice versa. this allows to eliminate the benign discontinuities mentioned above and obtain continuous program transformations. 1. 1 dataflow graphs as matrices it is convenient to have a situation where for any trajectory of program development or evolution all parts of the program which might emerge preexist in a silent way. the discipline of bipartite graphs actually makes this possible. we fix a particular signature by taking a finite number of operations, each with its own [SEP]
Text from DS:  Dataflow Graphs as Matrices
and Programming with Higher-order Matrix Elements

arXiv:1601.01050v1 [] 6 Jan 2016

Michael Bukatin1 and Steve Matthews2
1 Nokia Corporation
Burlington, Massachusetts, USA
bukatin@cs.brandeis.edu
2 Department of Computer Science
University of Warwick
Coventry, UK
Steve.Matthews@warwick.ac.uk

Abstract
We consider dataflow architecture for two classes of computations which admit taking linear combinations of execution runs: probabilistic sampling and generalized animation. We improve the earlier
technique of almost continuous program transformations by adopting a discipline of bipartite graphs
linking nodes obtained via general transformations and nodes obtained via linear transformations
which makes it possible to develop and evolve dataflow programs over these classes of computations by continuous program transformations. The use of bipartite graphs allows us to represent the
dataflow programs from this class as matrices of real numbers and evolve and modi
Original label:  cs.NE
Predicted label:  10
Correct label:  8
Text:  [CLS] 1402 challenges of the knowledge society. it in social sciences time series forecasting using neural networks bogdan oancea * stefan cristian ciucu * * abstract recent studies have shown the classification and prediction power of the neural networks. it has been demonstrated that a nn can approximate any continuous function. neural networks have been successfully used for forecasting of financial data series. the classical methods used for time series prediction like box - jenkins or arima assumes that there is a linear relationship between inputs and outputs. neural networks have the advantage that can approximate nonlinear functions. in this paper we compared the performances of different feed forward and recurrent neural networks and training algorithms for predicting the exchange rate eur / ron and usd / ron. we used data series with daily exchange rates starting from 2005 until 2013. keywords : neural networks, time series, forecasting, exchange rate, predicting introduction classical statistical and econometric models used for forecasting in the field of financial time series fails to efficiently handle uncertainty nature of foreign exchange data series. one of the largest and more volatile financial market is the foreign exchange market, exchange rates being among the most used and important economic indices. forecasting the exchange rates is a difficult problem from both theoretical and practical point of view because the exchange rates are influenced by many economic and political factors. during the time, many statistical and econometric models have been developed by researchers for the purpose of forecasting exchange rates but this problem remains one of the major challenges in the field of forecasting methods. recent studies have shown the classification and prediction power of the artificial neural networks. it has been demonstrated that a neural network can approximate any continuous function. neural networks have been successfully used for forecasting of financial data series. the classical methods used for time series prediction like box - jenkins, arma or arima assumes that there is a linear relationship between inputs and outputs. neural networks have the advantage that can approximate any nonlinear functions without any apriori information about the properties of the data series. in this paper we compared the performances of different feed forward and recurrent neural networks and training algorithms for predicting the exchange rate eur / ron and usd / ron. we used data series with daily exchange rates starting from 2005 until 2013 provided by the national bank of romania. we developed two different kinds of neural networks, a feed forward network and a recurrent network and compared their performances for foreign exchange rate prediction. the feed forward network was trained by the classical backpropagation method, by the resilient backpropa [SEP]
Text from DS:  1402

Challenges of the Knowledge Society. IT in Social Sciences

TIME SERIES FORECASTING USING NEURAL NETWORKS
BOGDAN OANCEA*
ŞTEFAN CRISTIAN CIUCU**
Abstract
Recent studies have shown the classification and prediction power of the Neural Networks. It has been
demonstrated that a NN can approximate any continuous function. Neural networks have been successfully used
for forecasting of financial data series. The classical methods used for time series prediction like Box-Jenkins or
ARIMA assumes that there is a linear relationship between inputs and outputs. Neural Networks have the
advantage that can approximate nonlinear functions. In this paper we compared the performances of different
feed forward and recurrent neural networks and training algorithms for predicting the exchange rate EUR/RON
and USD/RON. We used data series with daily exchange rates starting from 2005 until 2013.
Keywords: neural networks, time series, forecasting, exchange rate, predicting

Introduction
Classical st
Original label:  cs.SY
Predicted label:  3
Correct label:  5
Text:  [CLS] 1 state estimation for the individual and the population in mean field control with application to demand dispatch arxiv : 1504. 00088v3 [ ] 30 may 2016 yue chen, ana busic, and sean meyn abstract — this paper concerns state estimation problems in a mean field control setting. in a finite population model, the goal is to estimate the joint distribution of the population state and the state of a typical individual. the observation equations are a noisy measurement of the population. the general results are applied to demand dispatch for regulation of the power grid, based on randomized local control algorithms. in prior work by the authors it is shown that local control can be designed so that the aggregate of loads behaves as a controllable resource, with accuracy matching or exceeding traditional sources of frequency regulation. the operational cost is nearly zero in many cases. the information exchange between grid and load is minimal, but it is assumed in the overall control architecture that the aggregate power consumption of loads is available to the grid operator. it is shown that the kalman filter can be constructed to reduce these communication requirements, and to provide the grid operator with accurate estimates of the mean and variance of quality of service ( qos ) for an individual load. i. i ntroduction mean field models are a valuable tool for design and performance approximation for certain classes of interacting systems [ 1 ] – [ 3 ]. the infinite - population mean - field equations provide tremendous insight, but ultimately we must translate this insight to address a finite - population reality. in this paper we propose algorithms based on the kalman filter to obtain estimates of first and second order statistics of the population and a typical individual, based on noisy observations of the population. while the potential applications are far broader than power systems, for ease of exposition it is convenient to restrict attention to one application. renewable energy sources such as wind and solar power have a high degree of unpredictability and time variation, which complicates balancing supply and demand. one possible way to address this challenge is to harness the inherent flexibility in demand of many types of loads. demand response is traditionally meant as a reduction in load in response to some grid - level event. it is in use today for peak - shaving ( smoothing demand ), and for contingency reserves ( load - shedding following generation loss ). it is argued in [ 4 ] – [ 6 ] that the value of demand - side flexibility is far greater than this. loads can supply a range of grid research supported by ns [SEP]
Text from DS:  1

State Estimation for the Individual and the
Population in Mean Field Control
with Application to Demand Dispatch

arXiv:1504.00088v3 [] 30 May 2016

Yue Chen, Ana Bušić, and Sean Meyn

Abstract—This paper concerns state estimation problems in a
mean field control setting. In a finite population model, the goal
is to estimate the joint distribution of the population state and
the state of a typical individual. The observation equations are
a noisy measurement of the population.
The general results are applied to demand dispatch for
regulation of the power grid, based on randomized local control
algorithms. In prior work by the authors it is shown that local
control can be designed so that the aggregate of loads behaves
as a controllable resource, with accuracy matching or exceeding
traditional sources of frequency regulation. The operational cost
is nearly zero in many cases.
The information exchange between grid and load is minimal,
but it is assumed in the overall control archite
Original label:  cs.CV
Predicted label:  7
Correct label:  8
Text:  [CLS] enhancing the performance of convolutional neural networks on quality degraded datasets jonghwa yim kyung - ah sohn department of computer engineering ajou university suwon, republic of korea jonhwayim @ ajou. ac. kr department of software and computer engineering ajou university suwon, republic of korea kasohn @ ajou. ac. kr abstract — despite the appeal of deep neural networks that largely replace the traditional handmade filters, they still suffer from isolated cases that cannot be properly handled only by the training of convolutional filters. abnormal factors, including real - world noise, blur, or other quality degradations, ruin the output of a neural network. these unexpected problems can produce critical complications, and it is surprising that there has only been minimal research into the effects of noise in the deep neural network model. therefore, we present an exhaustive investigation into the effect of noise in image classification and suggest a generalized architecture of a dual - channel model to treat quality degraded input images. we compare the proposed dualchannel model with a simple single model and show it improves the overall performance of neural networks on various types of quality degraded input datasets. keywords — image classification, quality distortion, noisy input, deep neural network, convolutional network, image preprocessing i. introduction recently, emerging convolutional neural networks ( cnns ) have outpaced previous approaches in many problems in computer vision, including image classification, object detection, and object segmentation problems. the deep neural network model became possible due to powerful gpus, which allow us to stack deep layers and process various features from the image data. owing to the high performance of convolutional networks, the deep neural network model is applied to many practical problems ; some of these require high confidence and extremely low error rates. this includes the real - time classification of autonomous cars or face recognition in a security system. until now, the existing imaging solutions cannot be used to replace human resources completely due to unexpected errors. despite the current achievements in the use of deep convolutional networks for image classification or object detection tasks, and that theoretically these networks outpace human recognition accuracy, their use in real - world applications is error - prone as their real performance is yet to be confirmed and particularly on quality degraded input images. moreover, in previous research [ 1 ], the performance of the existing popular convolutional network model was severely affected by quality degraded input images, [SEP]
Text from DS:  Enhancing the Performance of Convolutional
Neural Networks on Quality Degraded Datasets
Jonghwa Yim

Kyung-Ah Sohn

Department of Computer Engineering
Ajou University
Suwon, Republic of Korea
jonhwayim@ajou.ac.kr

Department of Software and Computer Engineering
Ajou University
Suwon, Republic of Korea
kasohn@ajou.ac.kr

Abstract—Despite the appeal of deep neural networks that largely
replace the traditional handmade filters, they still suffer from isolated
cases that cannot be properly handled only by the training of
convolutional filters. Abnormal factors, including real-world noise,
blur, or other quality degradations, ruin the output of a neural network.
These unexpected problems can produce critical complications, and it
is surprising that there has only been minimal research into the effects
of noise in the deep neural network model. Therefore, we present an
exhaustive investigation into the effect of noise in image classification
and suggest a generalized architecture of a dual-c
Original label:  cs.PL
Predicted label:  10
Correct label:  7
Text:  [CLS] 1 stable recovery of structured signals from corrupted sub - gaussian measurements jinchi chen∗ and yulong liu∗ ∗ school of physics, beijing institute of technology, beijing 100081, china arxiv : 1709. 05827v1 [ ] 18 sep 2017 abstract this paper studies the problem of accurately recovering a structured signal from a small number of corrupted sub - gaussian measurements. we consider three different procedures to reconstruct signal and corruption when different kinds of prior knowledge are available. in each case, we provide conditions ( in terms of the number of measurements ) for stable signal recovery from structured corruption with added unstructured noise. our results theoretically demonstrate how to choose the regularization parameters in both partially and fully penalized recovery procedures and shed some light on the relationships among the three procedures. the key ingredient in our analysis is an extended matrix deviation inequality for isotropic sub - gaussian matrices, which implies a tight lower bound for the restricted singular value of the extended sensing matrix. numerical experiments are presented to verify our theoretical results. index terms corrupted sensing, compressed sensing, signal separation, signal demixing, sub - gaussian, gaussian width, gaussian complexity, gaussian squared distance, extended matrix deviation inequality. i. i ntroduction corrupted sensing concerns the problem of recovering a structured signal from a relatively small number of corrupted measurements y = φx? + v? + z, m×n? n ( 1 )? m where φ ∈ r is the sensing matrix, x ∈ r is the structured signal, v ∈ r is the structured corruption, and z ∈ rm is the unstructured observation noise. the goal is to estimate x? and v? from given knowledge of y and φ. this problem has received increasing attention recently with many interesting practical applications as well as theoretical consideration. examples of applications include face recognition [ 2 ], subspace clustering [ 3 ], sensor network [ 4 ], latent variable modeling [ 5 ], and so on. on the theoretical side, performance guarantees include sparse signal recovery from sparse corruption [ 6 ], [ 7 ], [ 8 ], [ 9 ], [ 10 ], [ 11 ], [ 12 ], [ 13 ], low - rank matrix recovery from sparse corruption [ 5 ], [ 14 ], [ 15 ], [ 16 ], and structured signal recovery from structured corruption [ 17 ]. it is worth noting that this model ( 1 ) also includes the signal separation ( or demixing [SEP]
Text from DS:  1

Stable Recovery of Structured Signals From
Corrupted Sub-Gaussian Measurements
Jinchi Chen∗ and Yulong Liu∗
∗ School of Physics, Beijing Institute of Technology, Beijing 100081, China

arXiv:1709.05827v1 [] 18 Sep 2017

Abstract
This paper studies the problem of accurately recovering a structured signal from a small number of corrupted sub-Gaussian
measurements. We consider three different procedures to reconstruct signal and corruption when different kinds of prior knowledge
are available. In each case, we provide conditions (in terms of the number of measurements) for stable signal recovery from
structured corruption with added unstructured noise. Our results theoretically demonstrate how to choose the regularization
parameters in both partially and fully penalized recovery procedures and shed some light on the relationships among the three
procedures. The key ingredient in our analysis is an extended matrix deviation inequality for isotropic sub-Gaussian matrices,
which implies a
Original label:  math.ST
Predicted label:  0
Correct label:  10
Text:  [CLS] noname manuscript no. ( will be inserted by the editor ) nonparametric estimation of multivariate distribution function for truncated and censored lifetime data arxiv : 1710. 07468v1 [ stat. me ] 20 oct 2017 valery baskakov · anna bartunova received : 03 - 05 - 2017 / accepted : date abstract in this article we consider a number of models for the statistical data generation in different areas of insurance, including life, pension and non - life insurance. insurance statistics are usually truncated and censored, and often are multidimensional. there are algorithms for estimating the distribution function for such data but they are applicable for one - dimensional case. the most effective of them are implemented, for example, in sas system. we propose a nonparametric estimation of the distribution function for multidimensional truncated - censored data in the form of quasi - empirical distribution and a simple iterative algorithm for its calculating. the accuracy of estimating the distribution function was verified by the monte carlo method. a comparative analysis of the quasi - empirical distribution with alternative estimates showed that in the one - dimensional case the proposed estimate almost coincides with the estimates calculated using the hpseverity procedure, which is a part of sas / ets. we didn ’ t make the comparative analysis in the multidimensional case due to the lack of analogues of such algorithms. but our algorithm has passed years of testing in the valuation of employees liabilities in accordance with ias 19 ” employee benefits ”. as an example, the article provides an assessment of the joint function of distribution of workers age and seniority of a large russian energy enterprise. the proposed estimates can also be used in other areas, such as medicine, biology, demography, reliability, etc. keywords nonparametric estimation · censored and truncated data · multivariate distribution function · survival analysis · iterative algorithm international actuarial advisory company, llc khoroshevskoe shosse 22 - 132, moscow, 123007, russia v. baskakov tel. : + 7 - 903 - 100 - 2660 e - mail : chief @ actuaries. ru a. bartunova tel. : + 44 - 7376 - 183291 e - mail : bartunovaanna @ gmail. com 2 valery baskakov, anna bartunova 1 introduction indicators of the loss amount and the level of insurance risk represent the greatest interest for an insurance actuary. [SEP]
Text from DS:  Noname manuscript No.
(will be inserted by the editor)

Nonparametric estimation of multivariate
distribution function for truncated and censored
lifetime data

arXiv:1710.07468v1 [stat.ME] 20 Oct 2017

Valery Baskakov · Anna Bartunova

Received: 03-05-2017 / Accepted: date

Abstract In this article we consider a number of models for the statistical
data generation in different areas of insurance, including life, pension and
non-life insurance. Insurance statistics are usually truncated and censored,
and often are multidimensional. There are algorithms for estimating the distribution function for such data but they are applicable for one-dimensional
case. The most effective of them are implemented, for example, in SAS system. We propose a nonparametric estimation of the distribution function for
multidimensional truncated-censored data in the form of quasi-empirical distribution and a simple iterative algorithm for its calculating. The accuracy of
estimating the distribution function w
Original label:  cs.IT
Predicted label:  2
Correct label:  6
Text:  [CLS] arxiv : 1710. 01620v1 [ ] 4 oct 2017 celestial walk : a terminating oblivious walk for convex subdivisions wouter kuijper nedap n. v. victor ermolaev nedap n. v. olivier devillers loria, inria, cnrs, universite de lorraine, france. october 5, 2017 abstract we present a new oblivious walking strategy for convex subdivisions. our walk is faster than the straight walk and more generally applicable than the visiblity walk. to prove termination of our walk we use a novel monotonically decreasing distance measure. 1 introduction point location in a convex subdivision is a classical problem of computational geometry for which several data structures have been designed with good complexities in the worst case [ 11, 4, 15 ]. these intricate solutions are often unused in favor of simpler algorithms based on traversal of the planar subdivisions using neighborhood relations between faces, also known as walking algorithms [ 2, 3, 9 ]. these walking algorithms can also be used as a building block in randomized data structures for point location [ 14, 6 ]. figure 1 : celestial walk ( obtuse angles marked by orange dots ). 1 figure 2 : straight ( left ) and visibility ( right ) walks amongst convex subdivisions, delaunay triangulations received a lot of attention because of their practical importance. for delaunay triangulations, essentially two walking strategies are used : the straight walk and the visibility walk [ 9 ]. the straight walk visits all faces crossed by a line segment between a known face and the query point, while the visibility walk goes from a face to another if the query point is on the side of the new face with respect to the supporting line of the edge common to the two faces ( cf. figure 2 ). the straight walk trivially terminates in the face containing the query point and generalizes to any planar subdivision but with the inconvenience of not being oblivious : the starting face of the walk must be remembered during the whole walk. the visibility walk is oblivious, but proving its termination requires the use of particular properties of the delaunay triangulation, and actually the visibility walk may loop in other subdivisions [ 9 ] ( cf. figure 3 ). regarding √ performance, both walks may visit all triangles in the worst case and visit o ( n ) triangles when the points are evenly distributed [ 10, 8 ]. from a practical point of view, the visibility walk is simpler to implement and a bit faster in practice because it [SEP]
Text from DS:  arXiv:1710.01620v1 [] 4 Oct 2017

Celestial Walk: A Terminating Oblivious Walk
for Convex Subdivisions
Wouter Kuijper
Nedap N.V.

Victor Ermolaev
Nedap N.V.

Olivier Devillers
Loria, Inria, CNRS, Université de Lorraine, France.
October 5, 2017
Abstract
We present a new oblivious walking strategy for convex subdivisions.
Our walk is faster than the straight walk and more generally applicable
than the visiblity walk. To prove termination of our walk we use a novel
monotonically decreasing distance measure.

1

Introduction

Point location in a convex subdivision is a classical problem of computational
geometry for which several data structures have been designed with good complexities in the worst case [11, 4, 15]. These intricate solutions are often unused
in favor of simpler algorithms based on traversal of the planar subdivisions using
neighborhood relations between faces, also known as walking algorithms [2, 3, 9].
These walking algorithms can also be used as a building block in ran
Original label:  cs.SY
Predicted label:  1
Correct label:  7
Text:  [CLS] a double - layered framework for distributed coordination in solving linear equations arxiv : 1711. 10947v1 [ ] 29 nov 2017 xuan wang, shaoshuai mou, and brian. d. o. anderson ∗ november 30, 2017 abstract this paper proposes a double - layered framework ( or form of network ) to integrate two mechanisms, termed consensus and conservation, achieving distributed solution of a linear equation. the multi - agent framework considered in the paper is composed of clusters ( which serve as a form of aggregating agent ) and each cluster consists of a sub - network of agents. by achieving consensus and conservation through agent - agent communications in the same cluster and clustercluster communications, distributed algorithms are devised for agents to cooperatively achieve a solution to the overall linear equation. these algorithms outperform existing consensus - based algorithms, including but not limited to the following aspects : first, each agent does not have to know as much as a complete row or column of the overall equation ; second, each agent only needs to control as few as two scalar states when the number of clusters and the number of agents are sufficiently large ; third, the dimensions of agents ’ states in the proposed algorithms do not have to be the same ( while in contrast, algorithms based on the idea of standard consensus inherently require all agents ’ states to be of the same dimension ). both analytical proof and simulation results are provided to validate exponential convergence of the proposed distributed algorithms in solving linear equations. 1 introduction distributed control of multi - agent networks has recently received a significant amount of research attention, the goal of which is to accomplish global objectives through local coordinations [ 1 ]. consensus, which drives all agents in the network to reach an agreement regarding a certain quantity [ 2 – 7 ], has served as a basis in deriving many distributed algorithms for optimization [ 8 – 12 ], synchronization of coupled oscillators [ 13 ], multi - robot formation control [ 14 ], cooperative sensing [ 15 ], and so on. most recently consensus has motivated distributed algorithms for solving linear algebraic equations [ 16 – 20 ], which achieve efficiency by decomposing a large system of linear equations into smaller ones that can be cooperatively solved by a network of agents. elegant as the idea of consensus is, it has also limited application of consensus - based algorithms into situations when coordination among agents requires more than reaching consensus, especially when conservation requirements are involved. different from consensus, conservation is a constraint that the sum of functions of agents ’ [SEP]
Text from DS:  A Double-Layered Framework for Distributed Coordination in
Solving Linear Equations

arXiv:1711.10947v1 [] 29 Nov 2017

Xuan Wang, Shaoshuai Mou, and Brian. D. O. Anderson

∗

November 30, 2017

Abstract
This paper proposes a double-layered framework (or form of network) to integrate two mechanisms, termed consensus and conservation, achieving distributed solution of a linear equation.
The multi-agent framework considered in the paper is composed of clusters (which serve as a
form of aggregating agent) and each cluster consists of a sub-network of agents. By achieving
consensus and conservation through agent-agent communications in the same cluster and clustercluster communications, distributed algorithms are devised for agents to cooperatively achieve
a solution to the overall linear equation. These algorithms outperform existing consensus-based
algorithms, including but not limited to the following aspects: first, each agent does not have
to know as much as a complete row or column o
Original label:  cs.SY
Predicted label:  6
Correct label:  3
Text:  [CLS] 1 the proximal augmented lagrangian method for nonsmooth composite optimization arxiv : 1610. 04514v3 [ math. oc ] 4 mar 2018 neil k. dhingra, sei zhen khong, and mihailo r. jovanovic abstract — we study a class of optimization problems in which the objective function is given by the sum of a differentiable but possibly nonconvex component and a nondifferentiable convex regularization term. we introduce an auxiliary variable to separate the objective function components and utilize the moreau envelope of the regularization term to derive the proximal augmented lagrangian – a continuously differentiable function obtained by constraining the augmented lagrangian to the manifold that corresponds to the explicit minimization over the variable in the nonsmooth term. this function is used to develop customized algorithms based on the method of multipliers ( mm ) and a primal - descent dual - ascent gradient method in order to compute optimal primal - dual pairs. mm algorithm is applicable to a broader class of problems than proximal gradient methods and it has stronger convergence guarantees and a more refined step - size update rules than the alternating direction method of multipliers. these features make it an attractive option for solving structured optimal control problems. when the differentiable component of the objective function is ( strongly ) convex and the regularization term is convex, we prove global ( exponential ) asymptotic stability of the primal - descent dual - ascent algorithm. finally, we solve the edge addition in directed consensus networks and optimal placement problems to demonstrate the merits and the effectiveness of our approach. i. i ntroduction we study a class of composite optimization problems in which the objective function is a sum of a differentiable but possibly nonconvex component and a convex nondifferentiable component. problems of this form are encountered in diverse fields including compressive sensing [ 1 ], machine learning [ 2 ], statistics [ 3 ], image processing [ 4 ], and control [ 5 ]. in feedback synthesis, they typically arise when a traditional performance metric ( such as the h2 or h∞ norm ) is augmented with a regularization function to promote certain structural properties in the optimal controller. for example, the ` 1 norm and the nuclear norm are commonly used nonsmooth convex regularizers that encourage sparse and low - rank optimal solutions, respectively. the lack of a differentiable objective function precludes the use of standard descent methods [SEP]
Text from DS:  1

The proximal augmented Lagrangian method
for nonsmooth composite optimization

arXiv:1610.04514v3 [math.OC] 4 Mar 2018

Neil K. Dhingra, Sei Zhen Khong, and Mihailo R. Jovanović

Abstract—We study a class of optimization problems in which the
objective function is given by the sum of a differentiable but possibly nonconvex component and a nondifferentiable convex regularization term.
We introduce an auxiliary variable to separate the objective function
components and utilize the Moreau envelope of the regularization term
to derive the proximal augmented Lagrangian – a continuously differentiable function obtained by constraining the augmented Lagrangian
to the manifold that corresponds to the explicit minimization over
the variable in the nonsmooth term. This function is used to develop
customized algorithms based on the method of multipliers (MM) and
a primal-descent dual-ascent gradient method in order to compute
optimal primal-dual pairs. MM algorithm is applicable to a broader

Original label:  cs.NE
Predicted label:  2
Correct label:  9
Text:  [CLS] a high - level model of neocortical feedback based on an event window segmentation algorithm jerry r. van aken abstract : the author previously presented an event window segmentation ( ews ) algorithm [ 5 ] that uses purely statistical methods to learn to recognize recurring patterns in an input stream of events. in the following discussion, the ews algorithm is first extended to make predictions about future events. next, this extended algorithm is used to construct a high - level, simplified model of a neocortical hierarchy. an event stream enters at the bottom of the hierarchy, and drives processing activity upward in the hierarchy. successively higher regions in the hierarchy learn to recognize successively deeper levels of patterns in these events as they propagate from the bottom of the hierarchy. the lower levels in the hierarchy use the predictions from the levels above to strengthen their own predictions. a c + + source code listing of the model implementation and test program is included as an appendix. in a previous paper [ 5 ], the author presented a segmentation algorithm that uses purely statistical methods to learn to recognize recurring patterns in an input stream of events. this algorithm will be referred to here as the event window segmentation ( ews ) algorithm. an event is the arrival of an integer value ( for example, a character code ) in the input stream. for the purposes of this paper, the events in the input stream can be considered as ordered in time, but with possibly nonuniform intervals between successive events. a recurring pattern is an ordered set of adjacent events that occurs at a statistical frequency that is significantly higher than that expected for a random ordering of events. the initial presentation of the ews algorithm in [ 5 ] made no mention of the potential to use the statistical information acquired by the algorithm to make predictions about future events. the following discussion will focus on methods for extending the ews algorithm to make such predictions. this work was inspired by the description of the memory - prediction framework by hawkins and blakeslee [ 4 ], who theorize that the basis of human intelligence is the ability of each small region of the neocortex to learn to recognize recurring patterns. they propose that the primary function of the neocortex is to use the patterns stored in these regions to continuously make reliable predictions about future events. furthermore, by connecting several such regions to form a hierarchy, successively higher regions in the hierarchy learn to recognize successively deeper levels of patterns in the event streams that enter the regions located at the bottom of the hierarchy. each region in the hierarchy then uses [SEP]
Text from DS:  A High-Level Model of Neocortical Feedback
Based on an Event Window Segmentation Algorithm
Jerry R. Van Aken
ABSTRACT: The author previously presented an event window segmentation (EWS) algorithm [5] that uses
purely statistical methods to learn to recognize recurring patterns in an input stream of events. In the following
discussion, the EWS algorithm is first extended to make predictions about future events. Next, this extended
algorithm is used to construct a high-level, simplified model of a neocortical hierarchy. An event stream enters
at the bottom of the hierarchy, and drives processing activity upward in the hierarchy. Successively higher
regions in the hierarchy learn to recognize successively deeper levels of patterns in these events as they
propagate from the bottom of the hierarchy. The lower levels in the hierarchy use the predictions from the
levels above to strengthen their own predictions. A C++ source code listing of the model implementation and
test program is includ
Original label:  cs.IT
Predicted label:  7
Correct label:  3
Text:  [CLS] time - space trade - offs for triangulations and voronoi diagrams matias korman1, wolfgang mulzer∗, 2, andre van renssen3, 4, marcel roeloffzen3, 4, paul seiferth∗, 2, and yannik stein∗, 2 arxiv : 1507. 03403v2 [ cs. cg ] 8 nov 2016 1 tohoku university, sendai, japan., mati @ dais. is. tohoku. ac. jp 2 institut fur informatik, freie universitat berlin, germany. { mulzer, pseiferth, yannikstein } @ inf. fu - berlin. de 3 national institute of informatics ( nii ), tokyo, japan., { andre, marcel } @ nii. ac. jp 4 jst, erato, kawarabayashi large graph project. abstract let s be a planar n - point set. a triangulation for s is a maximal plane straight - line graph with vertex set s. the voronoi diagram for s is the subdivision of the plane into cells such that all points in a cell have the same nearest neighbor in s. classically, both structures can be computed in o ( n log n ) time and o ( n ) space. we study the situation when the available workspace is limited : given a parameter s ∈ { 1,..., n }, an s - workspace algorithm has readonly access to an input array with the points from s in arbitrary order, and it may use only o ( s ) additional words of θ ( log n ) bits for reading and writing intermediate data. the output should then be written to a write - only structure. we describe a deterministic s - workspace algorithm for computing an arbitrary triangulation of s in time o ( n2 / s + n log n log s ) and a randomized s - workspace algorithm for finding the voronoi diagram of s in expected time o ( ( n2 / s ) log s + n log s log∗ s ). 1 introduction since the early days of computer science, a major concern has been to cope with strong memory constraints. this started in the ’ 70s [ 22 ] when memory was expensive. nowadays, a major motivation comes from a proliferation of small embedded devices where large memory is neither feasible nor desirable ( e. g., due to constraints on budget [SEP]
Text from DS:  Time-Space Trade-offs for Triangulations and Voronoi Diagrams
Matias Korman1 , Wolfgang Mulzer∗,2 , André van Renssen3,4 , Marcel Roeloffzen3,4 , Paul
Seiferth∗,2 , and Yannik Stein∗,2

arXiv:1507.03403v2 [cs.CG] 8 Nov 2016

1

Tohoku University, Sendai, Japan., mati@dais.is.tohoku.ac.jp
2
Institut für Informatik, Freie Universität Berlin, Germany.
{mulzer,pseiferth,yannikstein}@inf.fu-berlin.de
3
National Institute of Informatics (NII), Tokyo, Japan., {andre,marcel}@nii.ac.jp
4
JST, ERATO, Kawarabayashi Large Graph Project.

Abstract
Let S be a planar n-point set. A triangulation for S is a maximal plane straight-line graph
with vertex set S. The Voronoi diagram for S is the subdivision of the plane into cells such
that all points in a cell have the same nearest neighbor in S. Classically, both structures can
be computed in O(n log n) time and O(n) space. We study the situation when the available
workspace is limited: given a parameter s ∈ {1, . . . , n}, an s-workspace algorithm has 
Original label:  cs.CE
Predicted label:  10
Correct label:  9
Text:  [CLS] arxiv : 1603. 00087v1 [ cs. cr ] 29 feb 2016 journal of computer security 0 ( 0 ) 1 ios press 1 effective sequential protocol composition in maude - npa sonia santiago a, c, santiago escobar a, catherine meadows b, jose meseguer c a dsic - elp, universitat politecnica de valencia, camino de vera, s / n 46022 valencia spain e - mail : { ssantiago, sescobar } @ dsic. upv. es b naval research laboratory, 4555 overlook ave sw, washington, dc 20375, usa e - mail : meadows @ itd. nrl. navy. mil c department of computer science, university of illinois at urbana - champaign, the thomas m. siebel center for computer science 201 n. goodwin ave. urbana, il 61801 - 2302, usa e - mail : meseguer @ cs. uiuc. edu abstract. protocols do not work alone, but together, one protocol relying on another to provide needed services. many of the problems in cryptographic protocols arise when such composition is done incorrectly or is not well understood. in this paper we discuss an extension to the maude - npa syntax and its operational semantics to support dynamic sequential composition of protocols, so that protocols can be specified separately and composed when desired. this allows one to reason about many different compositions with minimal changes to the specification, as well as improving, in terms of both performance and ease of specification, on an earlier composition extension we presented in [ 18 ]. we show how compositions can be defined and executed symbolically in maude - npa using the compositional syntax and semantics. we also provide an experimental analysis of the performance of maude - npa using the compositional syntax and semantics, and compare it to the performance of a syntax and semantics for composition developed in earlier research. finally, in the conclusion we give some lessons learned about the best ways of extending narrowing - based state reachability tools, as well as comparison with related work and future plans. keywords : cryptographic protocols, formal verification of secure systems, sequential protocol composition, protocol verification, maude - npa 1. introduction the area of formal analysis of cryptographic protocols has been an active one since the mid 1980 ’ s. the idea is to verify protocols that use cryptography to guarantee security against an attacker — commonly called the dolev - yao attacker [ 13 ] — who has complete [SEP]
Text from DS:  arXiv:1603.00087v1 [cs.CR] 29 Feb 2016

Journal of Computer Security 0 (0) 1
IOS Press

1

Effective Sequential Protocol Composition in
Maude-NPA
Sonia Santiago a,c , Santiago Escobar a , Catherine Meadows b , José Meseguer c
a

DSIC-ELP, Universitat Politècnica de València, Camino de Vera, s/n 46022 Valencia Spain
E-mail: {ssantiago,sescobar}@dsic.upv.es
b Naval Research Laboratory, 4555 Overlook Ave SW, Washington, DC 20375, USA
E-mail: meadows@itd.nrl.navy.mil
c Department of Computer Science, University of Illinois at Urbana-Champaign, The Thomas M.
Siebel Center for Computer Science 201 N. Goodwin Ave. Urbana, IL 61801-2302, USA
E-mail: meseguer@cs.uiuc.edu

Abstract. Protocols do not work alone, but together, one protocol relying on another to provide needed services. Many of the
problems in cryptographic protocols arise when such composition is done incorrectly or is not well understood. In this paper
we discuss an extension to the Maude-NPA syntax and its operational semantics 
Original label:  math.AC
Predicted label:  5
Correct label:  8
Text:  [CLS] arxiv : 1711. 00904v1 [ ] 2 nov 2017 quadratic homogeneous polynomial maps h and keller maps x + h with 3 ≤ rk j h ≤ 4 michiel de bondt november 6, 2017 abstract we compute by hand all quadratic homogeneous polynomial maps h and all keller maps of the form x + h, for which rk j h = 3, over a field of arbitrary characteristic. furthermore, we use computer support to compute keller maps of the form x + h with rk j h = 4, namely : • all such maps in dimension 5 over fields with 21 ; • all such maps in dimension 6 over fields without 12. we use these results to prove the following over fields of arbitrary characteristic : for keller maps x + h for which rk j h ≤ 4, the rows of j h are dependent over the base field. 1 introduction let n be a positive integer and let x = ( x1, x2,..., xn ) be an n - tuple of variables. we write a | b = c for the result of substituting b by c in a. let k be any field. in the scope of this introduction, denote by l an unspecified ( but big enough ) field, which contains k or even k ( x ). for a polynomial or rational map h = ( h1, h2,..., hm ) ∈ lm, write j h or jx h for the jacobian matrix of h with respect to x. so j h = jx h = ∂ ∂x2 h1 ∂ ∂x2 h2 ∂ ∂x1 h1 ∂ ∂x1 h2... ∂ ∂x1 hm... ∂ ∂x2 hm · · · · · ·......... · · · ∂ ∂xn h1 ∂ ∂xn h2... ∂ ∂xn hm denote by rk m the rank of a matrix m, whose entries are contained in l, and write trdegk l for the transcendence degree of l over k. it is known that rk j h ≤ trdegk k ( h ) for a rational map h of any degree, with equality if k ( h ) ⊆ k ( x ) is separable, in particular if k has characteristic zero. this is proved in [ db2, th. 1. 3 ], see also [ pss, ths. 10, 13 [SEP]
Text from DS:  arXiv:1711.00904v1 [] 2 Nov 2017

Quadratic homogeneous polynomial maps H and
Keller maps x + H with 3 ≤ rk J H ≤ 4
Michiel de Bondt
November 6, 2017
Abstract
We compute by hand all quadratic homogeneous polynomial maps H
and all Keller maps of the form x + H, for which rk J H = 3, over a field
of arbitrary characteristic.
Furthermore, we use computer support to compute Keller maps of the
form x + H with rk J H = 4, namely:
• all such maps in dimension 5 over fields with 21 ;
• all such maps in dimension 6 over fields without 12 .
We use these results to prove the following over fields of arbitrary characteristic: for Keller maps x + H for which rk J H ≤ 4, the rows of J H
are dependent over the base field.

1

Introduction

Let n be a positive integer and let x = (x1 , x2 , . . . , xn ) be an n-tuple of variables.
We write a|b=c for the result of substituting b by c in a.
Let K be any field. In the scope of this introduction, denote by L an
unspecified (but big enough) field, which co
Original label:  cs.IT
Predicted label:  2
Correct label:  5
Text:  [CLS] from electrical power flows to unsplittabe flows : a qptas for opf with discrete demands in line distribution networks arxiv : 1709. 05876v1 [ ] 18 sep 2017 khaled elbassioni, chi - kin chau, majid khonji∗ abstract the ac optimal power flow ( opf ) problem is a fundamental problem in power systems engineering which has been known for decades. it is a notoriously hard problem due mainly to two reasons : ( 1 ) non - convexity of the power flow constraints and ( 2 ) the ( possible ) existence of discrete power injection constraints. recently, sufficient conditions were provided for certain convex relaxations of opf to be exact in the continuous case, thus allowing one to partially address the issue of non - convexity. in this paper we make a first step towards addressing the combinatorial issue. namely, by establishing a connection to the well - known unsplittable flow problem ( ufp ), we are able to generalize known techniques for the latter problem to provide approximation algorithms for opf with discrete demands. as an application, we give a quasipolynomial time approximation scheme for opf in line networks under some mild assumptions and a single generation source. we believe that this connection can be further leveraged to obtain approximation algorithms for more general settings, such as multiple generation sources and tree networks. 1 introduction the alternating current ( ac ) optimal power flow ( opf ) problem is a fundamental problem in power systems engineering which was introduced by carpentier in 1962 [ 1, 2 ], and since then has received considerable attention ( see e. g., [ 3, 4 ] for a survey ). in its simplest form, we are given an electrical network represented by an undirected graph, ac generators at some nodes ( called buses ) and user power demands at some other nodes. additionally, edges ( called lines ) may be associated with capacities that limit the amount of power that can flow on them. the objective is to minimize the cost of generation subject to meeting the user demands while satisfying the engineering ( e. g., line capacity ) constraints, and the physical properties of the electrical network captured by the conservation of power flow ( implied by the so - called kirchhoff laws ). opf is a notoriously hard problem to solve due mainly to the existence of : ( 1 ) non - convex constraints involving complex - valued entities of power system parameters such as current, voltage and power, and ( [SEP]
Text from DS:  From Electrical Power Flows to Unsplittabe Flows: A QPTAS for
OPF with Discrete Demands in Line Distribution Networks

arXiv:1709.05876v1 [] 18 Sep 2017

Khaled Elbassioni, Chi-Kin Chau, Majid Khonji∗

Abstract
The AC Optimal Power Flow (OPF) problem is a fundamental problem in power systems
engineering which has been known for decades. It is a notoriously hard problem due mainly
to two reasons: (1) non-convexity of the power flow constraints and (2) the (possible) existence
of discrete power injection constraints. Recently, sufficient conditions were provided for certain
convex relaxations of OPF to be exact in the continuous case, thus allowing one to partially
address the issue of non-convexity. In this paper we make a first step towards addressing the
combinatorial issue. Namely, by establishing a connection to the well-known unsplittable flow
problem (UFP), we are able to generalize known techniques for the latter problem to provide
approximation algorithms for OPF with discrete d
Original label:  cs.CE
Predicted label:  7
Correct label:  10
Text:  [CLS] perfrewrite program complexity analysis via source code instrumentation arxiv : 1409. 2089v1 [ ] 7 sep 2014 michael kruse∗, 1, inria saclay ile - de - france, parc orsay universite, 4 rue jacques monod, 91893 orsay cedex, france ∗ abstract most program profiling methods output the execution time of one specific program execution, but not its computational complexity class in terms of the big - o notation. perfrewrite is a tool based on llvm ’ s clang compiler to rewrite a program such that it tracks semantic information while the program executes and uses it to guess memory usage, communication and computational complexity. while source code instrumentation is a standard technique for profiling, using it for deriving formulas is an uncommon approach. keywords : profiling ; computational complexity ; source code instrumentation ; llvm clang 1 motivation several methods are common in order to deduce the performance characteristics of a program, usually used to identify a program ’ s bottleneck that is most worthy to optimize. we are specially interested in hpc applications used by physicists. our case study are the programs tmlqcd [ ju09 ] and dd - hmc [ lus05 ], both implementations of the lattice quantum chromodynamics ( lqcd ) simulation. the goal is to automatically derive the execution time in terms of the size of the input field. the usual approach for program complexity analysis is done statically on the source code with tools such as pips [ kac + 96 ]. unfortunately, challenges like pointer arithmetic make it near impossible for such tools to process the given programs. another idea is to use modelling program such as pamela [ vg93 ], but it requires to rewrite a program in its domain specific language and still does not support language constructs such as pointers. profiling with tools like gprof, oprofile, tau and many more is the most mature technique, but do not return the complexity in big - o notation. this drawback can be coped with by running the program multiple times with different inputs and let a statistics tool ( like gnu r ) analyse it. to get a meaningful result also large input sizes have to be sampled. in case of shared cluster systems probably someone will complain about eating computation time just to find out how long a program takes to execute. 1 e - mail : michael. kruse @ in [SEP]
Text from DS:  Perfrewrite
Program Complexity Analysis via
Source Code Instrumentation
arXiv:1409.2089v1 [] 7 Sep 2014

Michael Kruse∗,1,
INRIA Saclay Île-de-France, Parc Orsay Université, 4 rue Jacques Monod,
91893 Orsay cedex, France

∗

ABSTRACT
Most program profiling methods output the execution time of one specific program execution,
but not its computational complexity class in terms of the big-O notation. Perfrewrite is a tool
based on LLVM’s Clang compiler to rewrite a program such that it tracks semantic information
while the program executes and uses it to guess memory usage, communication and computational
complexity. While source code instrumentation is a standard technique for profiling, using it for
deriving formulas is an uncommon approach.
KEYWORDS :

profiling; computational complexity; source code instrumentation; LLVM Clang

1 Motivation
Several methods are common in order to deduce the performance characteristics of a program, usually used to identify a program’s bottleneck that i
Original label:  math.ST
Predicted label:  10
Correct label:  3
Text:  [CLS] arxiv : 1510. 08029 sharp oracle inequalities for least squares estimators in shape restricted regression pierre c. bellec ∗ arxiv : 1510. 08029v3 [ ] 8 aug 2016 ensae, 3 avenue pierre larousse, 92245 malakoff cedex, france. abstract : the performance of least squares ( ls ) estimators is studied in isotonic, unimodal and convex regression. our results have the form of sharp oracle inequalities that account for the model misspecification error. in isotonic and unimodal regression, the ls estimator achieves the nonparametric rate n−2 / 3 as well as a parametric rate of order k / n up to logarithmic factors, where k is the number of constant pieces of the true parameter. in univariate convex regression, the ls estimator satisfies an adaptive risk bound of order q / n up to logarithmic factors, where q is the number of affine pieces of the true regression function. this adaptive risk bound holds for any design points. while guntuboyina and sen [ 11 ] established that the nonparametric rate of convex regression is of order n−4 / 5 for equispaced design points, we show that the nonparametric rate of convex regression can be as slow as n−2 / 3 for some worst - case design points. this phenomenon can be explained as follows : although convexity brings more structure than unimodality, for some worst - case design points this extra structure is uninformative and the nonparametric rates of unimodal regression and convex regression are both n−2 / 3. 1. introduction assume that we have the observations yi = µi + ξi, i = 1,..., n, where µ = ( µ1,..., µn ) t ∈ rn is unknown, ξ = ( ξ1,..., ξn ) t is a noise vector with ndimensional gaussian distribution n ( 0, σ 2 in×n ) where σ > 0 and in×n is the n × n identity matrix. we will also use the notation g : = ( 1 / σ ) ξ so that y = µ + ξ = µ + σg and g [UNK] n ( 0, in×n ). denote by eµ and pµ the expectation and [SEP]
Text from DS:  arXiv: 1510.08029

Sharp oracle inequalities for Least Squares
estimators in shape restricted regression
Pierre C. Bellec

∗

arXiv:1510.08029v3 [] 8 Aug 2016

ENSAE,
3 avenue Pierre Larousse,
92245 Malakoff Cedex, France.
Abstract: The performance of Least Squares (LS) estimators is studied in isotonic, unimodal and convex regression. Our results have the form of sharp oracle
inequalities that account for the model misspecification error. In isotonic and unimodal regression, the LS estimator achieves the nonparametric rate n−2/3 as well
as a parametric rate of order k/n up to logarithmic factors, where k is the number
of constant pieces of the true parameter.
In univariate convex regression, the LS estimator satisfies an adaptive risk
bound of order q/n up to logarithmic factors, where q is the number of affine
pieces of the true regression function. This adaptive risk bound holds for any
design points. While Guntuboyina and Sen [11] established that the nonparametric
rate of convex r
Original label:  cs.CV
Predicted label:  4
Correct label:  0
Text:  [CLS] workshop track - iclr 2018 l earning via social awareness : improving sketch representations with facial feedback arxiv : 1802. 04877v1 [ cs. lg ] 13 feb 2018 natasha jaques12, jesse engel2, david ha2, fred bertsch2, rosalind picard1, douglas eck2 1 massachusetts institute of technology, cambridge, ma 02139, usa 2 google brain, mountain view, ca 94043, usa jaquesn @ mit. edu, jesseengel @ google. com, hadavid @ google. com, fredbertsch @ google. com, picard @ mit. edu, deck @ google. com a bstract in the quest towards general artificial intelligence ( ai ), researchers have explored developing loss functions that act as intrinsic motivators in the absence of external rewards. this paper argues that such research has overlooked an important and useful intrinsic motivator : social interaction. we posit that making an ai agent aware of implicit social feedback from humans can allow for faster learning of more generalizable and useful representations, and could potentially impact ai safety. we collect social feedback in the form of facial expression reactions to samples from sketch rnn, an lstm - based variational autoencoder ( vae ) designed to produce sketch drawings. we use a latent constraints gan ( lc - gan ) to learn from the facial feedback of a small group of viewers, and then show in an independent evaluation with 76 users that this model produced sketches that lead to significantly more positive facial expressions. thus, we establish that implicit social feedback can improve the output of a deep learning model. 1 i ntroduction despite the recent rapid and compelling progress in machine learning and deep learning, modern ai systems are still remarkably far from approximating the intelligence of even simple animals. a notable deficit of current techniques is the degree of explicit supervision required in order to learn, either through labeled samples or well - defined external rewards such as points in a game. the limited scope of such supervision will not enable the development of a generally intelligent ai. for this reason, some researchers have focused on intrinsic motivators, inherent drives that cause the agent to learn representations that are useful across a variety of tasks and environments. examples include curiosity ( a drive for novelty ) ( pathak et al., 2017 ), and empowerment ( a drive for the ability to manipulate the environment ) ( capdepuy et al., 2007 ). however, so far [SEP]
Text from DS:  Workshop track - ICLR 2018

L EARNING

VIA SOCIAL AWARENESS :
IMPROVING
SKETCH REPRESENTATIONS WITH FACIAL FEEDBACK

arXiv:1802.04877v1 [cs.LG] 13 Feb 2018

Natasha Jaques12 , Jesse Engel2 , David Ha2 , Fred Bertsch2 , Rosalind Picard1 , Douglas Eck2
1
Massachusetts Institute of Technology, Cambridge, MA 02139, USA
2
Google Brain, Mountain View, CA 94043, USA
jaquesn@mit.edu, jesseengel@google.com, hadavid@google.com,
fredbertsch@google.com, picard@mit.edu, deck@google.com

A BSTRACT
In the quest towards general artificial intelligence (AI), researchers have explored
developing loss functions that act as intrinsic motivators in the absence of external
rewards. This paper argues that such research has overlooked an important and
useful intrinsic motivator: social interaction. We posit that making an AI agent
aware of implicit social feedback from humans can allow for faster learning of
more generalizable and useful representations, and could potentially impact AI
safety. We collect soci
Original label:  cs.IT
Predicted label:  2
Correct label:  1
Text:  [CLS] a generic framework for engineering graph canonization algorithms jakob l. andersen ( b ) 1 - 4 and daniel merkle1 arxiv : 1711. 08289v1 [ ] 22 nov 2017 1 department of mathematics and computer science, university of southern denmark, odense m dk - 5230, denmark daniel @ imada. sdu. dk 2 research group bioinformatics and computational biology, faculty of computer science, university of vienna, 1090 vienna, austria jakob. lykke. andersen @ univie. ac. at 3 institute for theoretical chemistry, university of vienna, 1090 wien, austria 4 earth - life science institute, tokyo institute of technology, tokyo 152 - 8550, japan abstract comparing such canonical representations, which especially is useful when we want to test isomorphism against a large collection of graphs, e. g., for database querying. there is a rich literature on the complexity of both graph canonization and graph isomorphism. for longer discussion we refer to [ 15 ], and simply note that for general graphs the problems are not known to be np - complete, √ and the best bound for canonization o ( n log n ) [ 4, 6 ], while a quasi - polynomial is currently e bound for isomorphism was recently presented [ 5 ]. for practical graph canonization there has also been extensive work, with several competitive tools being published in the last decades. they are all build on the same core idea of a tree search over gradually more refined partitions of the vertex set, also called the individualization - refinement paradigm. their difference is thus essentially in the heuristics for traversing and pruning the search tree, and how partitions are being refined. one of the most successful tools is nauty [ 14 ], which not only finds a canonical representation but also computes the automorphism group, which during the canonization is used for pruning the search tree. later tools, bliss [ 9, 10 ] and traces [ 15 ], also use this technique with the latter introducing a new way to exploit the discovered automorphisms. a related tool is saucy [ 7, 11 ] which only performs computation of the automorphism group, for which it introduced new heuristics to discover them. similarly there is conauto [ 13 ] which performs isomorphism testing directly without computing a canonical form. each new tool and updated versions of tools has incorporated ideas from the other tools, with further development of he [SEP]
Text from DS:  A Generic Framework for Engineering
Graph Canonization Algorithms
Jakob L. Andersen (B)1-4 and Daniel Merkle1

arXiv:1711.08289v1 [] 22 Nov 2017

1

Department of Mathematics and Computer Science, University of Southern Denmark,
Odense M DK-5230, Denmark daniel@imada.sdu.dk
2
Research group Bioinformatics and Computational Biology, Faculty of Computer Science,
University of Vienna, 1090 Vienna, Austria jakob.lykke.andersen@univie.ac.at
3
Institute for Theoretical Chemistry, University of Vienna, 1090 Wien, Austria
4
Earth-Life Science Institute, Tokyo Institute of Technology, Tokyo 152-8550, Japan

Abstract

comparing such canonical representations, which especially is useful when we want to test isomorphism
against a large collection of graphs, e.g., for database
querying. There is a rich literature on the complexity
of both graph canonization and graph isomorphism.
For longer discussion we refer to [15], and simply note
that for general graphs the problems are not known to
be NP-comp
Original label:  math.GR
Predicted label:  2
Correct label:  7
Text:  [CLS] boundary representations of hyperbolic groups arxiv : 1404. 0903v2 [ math. ds ] 23 aug 2016 łukasz garncarek a bstract. let γ be a gromov hyperbolic group, endowed with an arbitrary left - invariant hyperbolic metric, quasi - isometric to a word metric. the action of γ on its boundary ∂γ endowed with the patterson - sullivan measure µ, after an appropriate normalization, gives rise to a faithful unitary representation of γ on l2 ( ∂γ, µ ). we show that these representations are irreducible, and give criteria for their unitary equivalence in terms of the metrics on γ. special cases include quasi - regular representations on the poisson boundary. 1. i ntroduction any action of a group g on a measure space ( x, µ ), preserving the class of µ, induces an action on the space of measurable functions on x. it can be normalized to obtain a unitary representation of g on l2 ( x, µ ). this construction generalizes the notion of a quasi - regular representation, which we obtain when x is a homogeneous space for g ; we will still refer to these representations as quasi - regular. irreducibility of such quasi - regular representations is a mixing - type condition, strictly stronger than ergodicity. indeed, for non - ergodic actions the space l2 ( x, µ ) decomposes into spaces of functions supported on the nontrivial invariant sets, and on the other hand, any ergodic action of an abelian group, such as the action of z on the circle by powers of an irrational rotation, gives a reducible representation. there are many natural examples of irreducible quasi - regular representations : • the natural action of the group of diffeomorphisms of a manifold m, or some of its subgroups preserving additional structure on m [ 31, 22 ], • the action of the thompson ’ s groups f and t on the unit interval and the unit circle [ 21, 16 ], • the action of a lattice of a lie group on its furstenberg boundary [ 4, 14 ], • the action of the automorphism group of a regular tree on its boundary [ 17 ], • the action of a free group on its boundary [ 18, 19 ], • the action of the fundamental group of a compact strictly negatively curved riemannian manifold m on the boundary of the universal cover of m [SEP]
Text from DS:  BOUNDARY REPRESENTATIONS OF HYPERBOLIC GROUPS

arXiv:1404.0903v2 [math.DS] 23 Aug 2016

ŁUKASZ GARNCAREK

A BSTRACT. Let Γ be a Gromov hyperbolic group, endowed with an arbitrary
left-invariant hyperbolic metric, quasi-isometric to a word metric. The action of
Γ on its boundary ∂Γ endowed with the Patterson-Sullivan measure µ, after an
appropriate normalization, gives rise to a faithful unitary representation of Γ on
L2 ( ∂Γ, µ ). We show that these representations are irreducible, and give criteria
for their unitary equivalence in terms of the metrics on Γ. Special cases include
quasi-regular representations on the Poisson boundary.

1. I NTRODUCTION
Any action of a group G on a measure space ( X, µ), preserving the class of µ,
induces an action on the space of measurable functions on X. It can be normalized
to obtain a unitary representation of G on L2 ( X, µ). This construction generalizes
the notion of a quasi-regular representation, which we obtain when X is a homogeneous space fo
Original label:  math.ST
Predicted label:  1
Correct label:  9
Text:  [CLS] community detection with nodal information b y h aolei w eng and yang f eng∗ arxiv : 1610. 09735v2 [ stat. me ] 10 dec 2016 columbia university community detection is one of the fundamental problems in the study of network data. most existing community detection approaches only consider edge information as inputs, and the output could be suboptimal when nodal information is available. in such cases, it is desirable to leverage nodal information for the improvement of community detection accuracy. towards this goal, we propose a flexible network model incorporating nodal information, and develop likelihood - based inference methods. for the proposed methods, we establish favorable asymptotic properties as well as efficient algorithms for computation. numerical experiments show the effectiveness of our methods in utilizing nodal information across a variety of simulated and real network data sets. 1. introduction. networked systems are ubiquitous in modern society. examples include worldwide web, gene regulatory networks, and social networks. network analysis has attracted a lot of research attention from social science, physics, computer science and mathematical science. there have been some interesting findings regarding the network structures, such as small world phenomena and power - law degree distributions ( newman, 2003 ). one of the fundamental problems in network analysis is detecting and characterizing community structure in networks. communities can be intuitively understood as groups of nodes which are densely connected within groups while sparsely connected between groups1. identifying network communities not only helps better understand structural fea∗ partially supported by nsf career grant dms - 1554804. ams 2000 subject classifications : primary 62f99 ; secondary 62p25. keywords and phrases : networks, community detection, stochastic block model, multi - logistic regression, maximum likelihood, profile likelihood, variational inference, consistency, semidefinite programming. 1 more rarely, one can encounter communities of the opposite meaning in disassortative mixing networks. 1 2 h. weng and y. feng tures of the network, but also offers practical benefits. for example, communities in social networks tend to share similar interest, which could provide useful information to build recommendation systems. existing community detection methods can be roughly divided into algorithmic and model - based ones ( zhao et al., 2012 ). algorithmic methods typically define an objective function such as modularity ( newman, 2006 ), which measures the goodness of a network partition, and design algorithms to search for the solution of the corresponding optimization problem. see fortunato ( 2010 ) for a [SEP]
Text from DS:  COMMUNITY DETECTION WITH NODAL INFORMATION
B Y H AOLEI W ENG AND YANG F ENG∗

arXiv:1610.09735v2 [stat.ME] 10 Dec 2016

Columbia University
Community detection is one of the fundamental problems in the study
of network data. Most existing community detection approaches only consider edge information as inputs, and the output could be suboptimal when
nodal information is available. In such cases, it is desirable to leverage nodal
information for the improvement of community detection accuracy. Towards
this goal, we propose a flexible network model incorporating nodal information, and develop likelihood-based inference methods. For the proposed
methods, we establish favorable asymptotic properties as well as efficient algorithms for computation. Numerical experiments show the effectiveness of
our methods in utilizing nodal information across a variety of simulated and
real network data sets.

1. Introduction. Networked systems are ubiquitous in modern society. Examples include worldwide 
Original label:  cs.NE
Predicted label:  0
Correct label:  4
Text:  [CLS] the sampling - and - learning framework : a statistical view of evolutionary algorithms yang yu∗, hong qian arxiv : 1401. 6333v2 [ ] 11 apr 2014 national key laboratory for novel software technology nanjing university, nanjing 210023, china abstract evolutionary algorithms ( eas ), a large class of general purpose optimization algorithms inspired from the natural phenomena, are widely used in various industrial optimizations and often show excellent performance. this paper presents an attempt towards revealing their general power from a statistical view of eas. by summarizing a large range of eas into the sampling - and - learning framework, we show that the framework directly admits a general analysis on the probable - absolute - approximate ( paa ) query complexity. we particularly focus on the framework with the learning subroutine being restricted as a binary classification, which results in the sampling - and - classification ( sac ) algorithms. with the help of the learning theory, we obtain a general upper bound on the paa query complexity of sac algorithms. we further compare sac algorithms with the uniform search in different situations. under the error - target independence condition, we show that sac algorithms can achieve polynomial speedup to the uniform search, but not super - polynomial speedup. under the one - side - error condition, we show that super - polynomial speedup can be achieved. this work only touches the surface of the framework. its power under other conditions is still open. key words : evolutionary algorithms, computational complexity of algorithms, stochastic optimization, heuristic search 1. introduction in many practical optimization problems, the objective functions are hidden or too complicated to be analyzed. under this kind of circumstances, direct optimization algorithms are appealing, which follows the trial - anderror style with some heuristics. evolutionary algorithms ( eas ) [ 3 ] are a large family of such algorithms. the family includes genetic algorithms [ 17 ], evolutionary programming [ 26 ], evolutionary strategies [ 5 ], and also covers other nature - inspired heuristics including particle swarm optimization [ 25 ], ant colony optimization [ 11 ], estimation of distribution algorithms [ 29 ], etc. ∗ corresponding author email addresses : yuy @ lamda. nju. edu. cn ( yang yu ), qianh @ nju. edu. cn ( hong qian ) preprint submitted for review january 22, 2018 theoretical studies of eas have been developed rapidly in the recent decades, particularly noticeable of the blooming of running time analysis [ 32 [SEP]
Text from DS:  The Sampling-and-Learning Framework:
A Statistical View of Evolutionary Algorithms
Yang Yu∗, Hong Qian

arXiv:1401.6333v2 [] 11 Apr 2014

National Key Laboratory for Novel Software Technology
Nanjing University, Nanjing 210023, China

Abstract
Evolutionary algorithms (EAs), a large class of general purpose optimization algorithms inspired from the natural phenomena, are widely used in various industrial optimizations and often show excellent performance. This
paper presents an attempt towards revealing their general power from a statistical view of EAs. By summarizing a large range of EAs into the sampling-and-learning framework, we show that the framework directly
admits a general analysis on the probable-absolute-approximate (PAA) query complexity. We particularly focus
on the framework with the learning subroutine being restricted as a binary classification, which results in the
sampling-and-classification (SAC) algorithms. With the help of the learning theory, we obtain a general u
Original label:  cs.PL
Predicted label:  2
Correct label:  1
Text:  [CLS] 1 a poisson model for entanglement optimization in the quantum internet arxiv : 1803. 02469v1 [ quant - ph ] 6 mar 2018 laszlo gyongyosi abstract — a poisson model for entanglement optimization in quantum repeater networks is defined in this paper. the nature - inspired multiobjective optimization framework fuses the fundamental concepts of quantum shannon theory with the theory of evolutionary algorithms. the optimization model aims to maximize the entanglement fidelity and relative entropy of entanglement for all entangled connections of the quantum network. the cost functions are subject of a minimization defined to cover and integrate the physical attributes of entanglement transmission, purification, and storage of entanglement in quantum memories. the method can be implemented with low complexity that allows a straightforward application in future quantum internet and quantum networking scenarios. index terms — quantum networking ; quantum repeater ; quantum entanglement ; quantum internet ; quantum shannon theory. i. i ntroduction quantum entanglement serves as a fundamental concept of long - distance quantum networks, quantum internet, and future quantum communications [ 1 ] – [ 4 ], [ 7 ]. since the nocloning theorem makes it impossible to use the “ copy - andresend ” mechanisms of traditional repeaters [ 7 ], in a quantum networking scenario the quantum repeaters have to transmit correlations in a different way [ 1 ] – [ 5 ]. the main task of quantum repeaters is to distribute quantum entanglement between distant points that will then serve as a fundamental base resource for quantum teleportation and other quantum protocols [ 1 ]. since in an experimental scenario [ 15 ] – [ 21 ] the quantum links between nodes are noisy and entanglement fidelity decreases as hop distance increases, entanglement purification is applied to improve the entanglement fidelity between nodes [ 1 ], [ 3 ] – [ 6 ]. quantum nodes also perform internal quantum error correction that is a requirement for reliability and storage in quantum memories [ 1 ], [ 5 ], [ 6 ], [ 8 ]. both entanglement purification and quantum error correction steps in local nodes are high - cost tasks that require significant minimization [ 1 ], [ 3 ] – [ 6 ], [ 15 ], [ 16 ], [ 19 ] – [ 21 ]. the shared entangled connections between nodes form entangled links. significant attributes of these entangled links this work was partially supported by the european research council through the advanced fellow grant, in [SEP]
Text from DS:  1

A Poisson Model for Entanglement Optimization in
the Quantum Internet

arXiv:1803.02469v1 [quant-ph] 6 Mar 2018

Laszlo Gyongyosi

Abstract—A Poisson model for entanglement optimization
in quantum repeater networks is defined in this paper. The
nature-inspired multiobjective optimization framework fuses the
fundamental concepts of quantum Shannon theory with the
theory of evolutionary algorithms. The optimization model aims
to maximize the entanglement fidelity and relative entropy of
entanglement for all entangled connections of the quantum
network. The cost functions are subject of a minimization
defined to cover and integrate the physical attributes of entanglement transmission, purification, and storage of entanglement in
quantum memories. The method can be implemented with low
complexity that allows a straightforward application in future
quantum Internet and quantum networking scenarios.
Index Terms—quantum networking; quantum repeater; quantum entanglement; quantum Internet; 
Original label:  math.AC
Predicted label:  3
Correct label:  5
Text:  [CLS] cluster algebras and continued fractions arxiv : 1608. 06568v3 [ math. co ] 26 sep 2016 ilke canakci and ralf schiffler abstract. we establish a combinatorial realization of continued fractions as quotients of cardinalities of sets. these sets are sets of perfect matchings of certain graphs, the snake graphs, that appear naturally in the theory of cluster algebras. to a continued fraction [ a1, a2,..., an ], we associate a snake graph g [ a1, a2,..., an ] such that the continued fraction is the quotient of the number of perfect matchings of g [ a1, a2,..., an ] and g [ a2,..., an ]. we also show that snake graphs are in bijection with continued fractions. we then apply this connection between cluster algebras and continued fractions in two directions. first, we use results from snake graph calculus to obtain new identities for the continuants of continued fractions. then, we apply the machinery of continued fractions to cluster algebras and obtain explicit direct formulas for quotients of elements of the cluster algebra as continued fractions of laurent polynomials in the initial variables. building on this formula, and using classical methods for infinite periodic continued fractions, we also study the asymptotic behavior of quotients of elements of the cluster algebra. contents 1. introduction 1 2. preliminaries 4 3. the snake graph of a continued fraction 8 4. the set of all abstract snake graphs 11 5. three formulas for continued fractions 14 6. the relation to cluster algebras 16 7. infinite continued fractions and limits of rational functions from cluster algebras 22 references 27 1. introduction cluster algebras were introduced by fomin and zelevinsky in 2002 in [ fz1 ]. originally motivated by the study of canonical bases in lie theory, the theory has gained a tremendous development over the last 15 years, and cluster algebras are now connected to various areas of mathematics and physics, including lie theory, quiver representations, combinatorics, dynamical systems, algebraic geometry, teichmuller theory, and string theory. in this paper, we add another item to this list by providing a connection between cluster algebras and continued fractions. the method of continued fractions is a classical tool that 2000 mathematics subject classification. primary : 13f60, secondary : 11a55 and [SEP]
Text from DS:  CLUSTER ALGEBRAS AND CONTINUED FRACTIONS

arXiv:1608.06568v3 [math.CO] 26 Sep 2016

ILKE CANAKCI AND RALF SCHIFFLER
Abstract. We establish a combinatorial realization of continued fractions as quotients of
cardinalities of sets. These sets are sets of perfect matchings of certain graphs, the snake
graphs, that appear naturally in the theory of cluster algebras. To a continued fraction
[a1 , a2 , . . . , an ], we associate a snake graph G[a1 , a2 , . . . , an ] such that the continued fraction
is the quotient of the number of perfect matchings of G[a1 , a2 , . . . , an ] and G[a2 , . . . , an ]. We
also show that snake graphs are in bijection with continued fractions.
We then apply this connection between cluster algebras and continued fractions in two
directions. First, we use results from snake graph calculus to obtain new identities for the
continuants of continued fractions. Then, we apply the machinery of continued fractions to
cluster algebras and obtain explicit direct formulas f
Original label:  cs.CV
Predicted label:  4
Correct label:  0
Text:  [CLS] sfcn - opi : detection and fine - grained classification of nuclei using sibling fcn with objectness prior interaction yanning zhou1, qi dou1, hao chen1, jing qin2, pheng - ann heng1 1 arxiv : 1712. 08297v1 [ ] 22 dec 2017 department of computer science and engineering, the chinese university of hong kong 2 centre for smart health, school of nursing, the hong kong polytechnic university { ynzhou, qdou, hchen, pheng } @ cse. cuhk. edu. hk, harry. qin @ polyu. edu. hk abstract cell nuclei detection and fine - grained classification have been fundamental yet challenging problems in histopathology image analysis. due to the nuclei tiny size, significant inter / intra - class variances, as well as the inferior image quality, previous automated methods would easily suffer from limited accuracy and robustness. in the meanwhile, existing approaches usually deal with these two tasks independently, which would neglect the close relatedness of them. in this paper, we present a novel method of sibling fully convolutional network with prior objectness interaction ( called sfcn - opi ) to tackle the two tasks simultaneously and interactively using a unified end - to - end framework. specifically, the sibling fcn branches share features in earlier layers while holding respective higher layers for specific tasks. more importantly, the detection branch outputs the objectness prior which dynamically interacts with the fine - grained classification sibling branch during the training and testing processes. with this mechanism, the fine - grained classification successfully focuses on regions with high confidence of nuclei existence and outputs the conditional probability, which in turn benefits the detection through back propagation. extensive experiments on colon cancer histology images have validated the effectiveness of our proposed sfcn - opi and our method has outperformed the state - of - the - art methods by a large margin. introduction in digital histopathology image analysis, cell nuclei detection and fine - grained classification are crucial prerequisites for cellular morphology processing, such as computation of size, texture, shape, as well as other imagenomics ( xing and yang 2016 ), and furthermore assisting the cancer malignancy diagnosis ( hamilton and aaltonen 2000 ). take the colon cancer, commonly originating from the glandular epithelial cells, as an example, recognizing the epithelial cells and assessing their morphologic changes [SEP]
Text from DS:  SFCN-OPI: Detection and Fine-grained Classification of Nuclei Using
Sibling FCN with Objectness Prior Interaction
Yanning Zhou1 , Qi Dou1 , Hao Chen1 , Jing Qin2 , Pheng-Ann Heng1
1

arXiv:1712.08297v1 [] 22 Dec 2017

Department of Computer Science and Engineering, The Chinese University of Hong Kong
2
Centre for Smart Health, School of Nursing, The Hong Kong Polytechnic University
{ynzhou,qdou,hchen,pheng}@cse.cuhk.edu.hk, harry.qin@polyu.edu.hk

Abstract
Cell nuclei detection and fine-grained classification have been
fundamental yet challenging problems in histopathology image analysis. Due to the nuclei tiny size, significant inter/intra-class variances, as well as the inferior image quality,
previous automated methods would easily suffer from limited accuracy and robustness. In the meanwhile, existing approaches usually deal with these two tasks independently,
which would neglect the close relatedness of them. In this paper, we present a novel method of sibling fully convolutional

Original label:  math.GR
Predicted label:  7
Correct label:  3
Text:  [CLS] a finite simple group is cca if and only if it has no element of order four arxiv : 1703. 07905v1 [ ] 23 mar 2017 luke morgan, joy morris, and gabriel verret abstract. a cayley graph for a group g is cca if every automorphism of the graph that preserves the edge - orbits under the regular representation of g is an element of the normaliser of g. a group g is then said to be cca if every connected cayley graph on g is cca. we show that a finite simple group is cca if and only if it has no element of order 4. we also show that “ many ” 2 - groups are non - cca. 1. introduction all groups and all graphs in this paper are finite. let g be a group and let s be an inverse - closed subset of g. the cayley graph cay ( g, s ) of g with respect to s is the graph with vertex - set g and, for every g ∈ g and s ∈ s, an edge { g, sg }. this graph admits a natural edge - colouring in which an edge { g, sg } is coloured { s, s−1 }. the colourpreserving automorphism group is denoted autc ( cay ( g, s ) ) and we define aut±1 ( g, s ) = { α ∈ aut ( g ) | sα ∈ { s, s−1 } for all s ∈ s }. it is easy to see that gr o aut±1 ( g, s ) 6 autc ( cay ( g, s ) ), where gr is the right - regular representation of g and, in fact, the former group is precisely the normaliser of gr in autc ( cay ( g, s ) ). definition 1. 1 ( [ 15 ] ). the cayley graph cay ( g, s ) is cca ( cayley colour automorphism ) if autc ( cay ( g, s ) ) = gr o aut±1 ( g, s ). the group g is cca if every connected cayley graph on g is cca. thus, cay ( g, s ) is cca if and only if gr is normal in autc ( cay ( g, s ) ), c. f. [ 15, remark 6. 2 ]. note that cay ( g, s ) is [SEP]
Text from DS:  A FINITE SIMPLE GROUP IS CCA IF AND ONLY IF IT HAS NO
ELEMENT OF ORDER FOUR

arXiv:1703.07905v1 [] 23 Mar 2017

LUKE MORGAN, JOY MORRIS, AND GABRIEL VERRET
Abstract. A Cayley graph for a group G is CCA if every automorphism of the graph
that preserves the edge-orbits under the regular representation of G is an element of the
normaliser of G. A group G is then said to be CCA if every connected Cayley graph on
G is CCA. We show that a finite simple group is CCA if and only if it has no element of
order 4. We also show that “many” 2-groups are non-CCA.

1. Introduction
All groups and all graphs in this paper are finite. Let G be a group and let S be an
inverse-closed subset of G. The Cayley graph Cay(G, S) of G with respect to S is the
graph with vertex-set G and, for every g ∈ G and s ∈ S, an edge {g, sg}. This graph
admits a natural edge-colouring in which an edge {g, sg} is coloured {s, s−1 }. The colourpreserving automorphism group is denoted Autc (Cay(G, S)) and we define Aut±1 (G, S
Original label:  math.GR
Predicted label:  5
Correct label:  3
Text:  [CLS] a formula for p - completion by way of the segal conjecture arxiv : 1704. 00271v1 [ math. at ] 2 apr 2017 sune precht reeh, tomer m. schlank, and nathaniel stapleton abstract. the segal conjecture describes stable maps between classifying spaces in terms of ( virtual ) bisets for the finite groups in question. along these lines, we give an algebraic formula for the p - completion functor applied to stable maps between classifying spaces purely in terms of fusion data and burnside modules. 1. introduction the p - completion of the classifying spectrum of a finite group is determined by the data of the induced fusion system on a sylow p - subgroup. that is, if g is a finite group, s ⊂ g is a sylow p - subgroup and fg is the fusion system on s determined by g, then there is an equivalence of spectra ∞ ( σ∞ bg ) ∧ p'σ bfg, where bfg is a kind of classifying space associated to the fusion system ( see section 2. 8 ). the solution to the segal conjecture provides an algebraic description of the homotopy classes of maps between suspension spectra of finite groups in terms of burnside modules. in [ rag ], a burnside module between saturated fusions systems is defined. it is a submodule of the p - complete burnside module between the sylow p - subgroups that is characterized in terms of the fusion data. it is shown that this submodule captures the stable homotopy classes of maps between the p - completions of suspension spectra of finite groups. the pcompletion functor induces a natural map of abelian groups ∞ ∞ ∧ ∞ ∧ [ σ∞ + bg, σ + bh ] → [ ( σ + bg ) p, ( σ + bh ) p ]. in this paper, we give an algebraic description of this map in terms of fusion data. let g and h be finite groups. the proof of the segal conjecture establishes a canonical natural isomorphism ∞ [UNK] ∞ a ( g, h ) ∧ ig = [ σ + bg, σ + bh ] between the completion of the burnside module of finite ( g, h ) - bisets with free h - action at the augmentation ideal of the burnside ring a ( g ) and the stable homotopy classes of maps between bg and bh. fix a [SEP]
Text from DS:  A FORMULA FOR p-COMPLETION BY WAY OF THE SEGAL
CONJECTURE

arXiv:1704.00271v1 [math.AT] 2 Apr 2017

SUNE PRECHT REEH, TOMER M. SCHLANK, AND NATHANIEL STAPLETON

Abstract. The Segal conjecture describes stable maps between classifying spaces in
terms of (virtual) bisets for the finite groups in question. Along these lines, we give an
algebraic formula for the p-completion functor applied to stable maps between classifying
spaces purely in terms of fusion data and Burnside modules.

1. Introduction
The p-completion of the classifying spectrum of a finite group is determined by the data
of the induced fusion system on a Sylow p-subgroup. That is, if G is a finite group, S ⊂ G
is a Sylow p-subgroup and FG is the fusion system on S determined by G, then there is an
equivalence of spectra
∞
(Σ∞ BG)∧
p ' Σ BFG ,
where BFG is a kind of classifying space associated to the fusion system (see Section 2.8).
The solution to the Segal conjecture provides an algebraic description of the homotopy
clas
Original label:  cs.AI
Predicted label:  2
Correct label:  3
Text:  [CLS] nag : network for adversary generation konda reddy mopuri *, utkarsh ojha *, utsav garg and r. venkatesh babu video analytics lab, computational and data sciences indian institute of science, bangalore, india arxiv : 1712. 03390v1 [ ] 9 dec 2017 kondamopuri @ iisc. ac. in, utkarsh2254 @ gmail. com, utsav002 @ e. ntu. edu. sg and venky @ iisc. ac. in abstract training data ( e. g. [ 3 ] ), etc. more importantly, the adversarial perturbations exhibit cross model generalizability. that is, the perturbations learned on one model can fool another model even if the second model has a different architecture or has been trained on a disjoint subset of training images [ 27, 9 ]. adversarial perturbations can pose a serious threat for deploying machine learning systems. recent works have shown existence of image - agnostic perturbations that can fool classifiers over most natural images. existing methods present optimization approaches that solve for a fooling objective with an imperceptibility constraint to craft the perturbations. however, for a given classifier, they generate one perturbation at a time, which is a single instance from the manifold of adversarial perturbations. also, in order to build robust models, it is essential to explore the manifold of adversarial perturbations. in this paper, we propose for the first time, a generative approach to model the distribution of adversarial perturbations. the architecture of the proposed model is inspired from that of gans and is trained using fooling and diversity objectives. our trained generator network attempts to capture the distribution of adversarial perturbations for a given classifier and readily generates a wide variety of such perturbations. our experimental evaluation demonstrates that perturbations crafted by our model ( i ) achieve state - of - the - art fooling rates, ( ii ) exhibit wide variety and ( iii ) deliver excellent cross model generalizability. our work can be deemed as an important step in the process of inferring about the complex manifolds of adversarial perturbations. recent startling findings by moosavi - dezfooli et al. [ [SEP]
Text from DS:  NAG: Network for Adversary Generation
Konda Reddy Mopuri*, Utkarsh Ojha*, Utsav Garg and R. Venkatesh Babu
Video Analytics Lab, Computational and Data Sciences
Indian Institute of Science, Bangalore, India

arXiv:1712.03390v1 [] 9 Dec 2017

kondamopuri@iisc.ac.in, utkarsh2254@gmail.com, utsav002@e.ntu.edu.sg and venky@iisc.ac.in

Abstract

training data (e.g. [3]), etc. More importantly, the adversarial perturbations exhibit cross model generalizability. That
is, the perturbations learned on one model can fool another
model even if the second model has a different architecture or has been trained on a disjoint subset of training images [27, 9].

Adversarial perturbations can pose a serious threat for
deploying machine learning systems. Recent works have
shown existence of image-agnostic perturbations that can
fool classifiers over most natural images. Existing methods
present optimization approaches that solve for a fooling objective with an imperceptibility constraint to craft the per
Original label:  math.ST
Predicted label:  10
Correct label:  8
Text:  [CLS] fitting phase – type scale mixtures to heavy – tailed data and distributions arxiv : 1705. 04357v1 [ ] 11 may 2017 mogens bladt and leonardo rojas - nandayapa a bstract. we consider the fitting of heavy tailed data and distribution with a special attention to distributions with a non – standard shape in the “ body ” of the distribution. to this end we consider a dense class of heavy tailed distributions introduced in [ 3 ], employing an em algorithm for the the maximum likelihood estimates of its parameters. we present methods for fitting to observed data, histograms, censored data, as well as to theoretical distributions. numerical examples are provided with simulated data and a benchmark reinsurance dataset. we empirically demonstrate that our model can provide excellent fits to heavy – tailed data / distributions with minimal assumptions. keywords. statistical inference, heavy – tailed, phase – type, scale mixtures, approximating distributions, em algorithm. 1. i ntroduction in this paper we consider the maximum likelihood estimation for a dense class of nonnegative heavy – tailed tailed distributions, referred to as scale mixtures of phase – type distribuitions ( nph ), which was defined in [ 3 ]. distributions in the nph class allow for the simultaneous modelling of the “ body ” and the “ tail ” of general distributions which are assumed to be absolutely continuous and nonnegative while their “ tails ” are assumed to belong to some general class of heavy tailed distributions, like for instance regularly varying or weibullian. these very general assumptions allows us to fit heavy – tailed distributions which may look distinctively different from distributions usually found in catalogues. apart from providing an adequate description of data, distributions from nph can also be seen as infinite – dimensional phase – type distributions, which to all intents and purposes are as tractable as their finite – dimensional counterparts. much of the machinery available for finite – dimensional phase – type distributions is also applicable to the extended class. algorithms are for example available for the exact calculations of properties related to renewal theory, random walks ( ladder processes ) and ruin probabilities ( see [ 3 ] for details ). the maximum likelihood estimation will be carried out employing an em algorithm similarly as for finite – dimensional phase – type distributions [ 2 ]. the main challenge we face is the algorithmic implementation resulting from the extension to infinite dimensions since we cannot make a pre – fixed cut – off in the number of dimensions as [SEP]
Text from DS:  FITTING PHASE–TYPE SCALE MIXTURES TO HEAVY–TAILED DATA AND
DISTRIBUTIONS

arXiv:1705.04357v1 [] 11 May 2017

MOGENS BLADT AND LEONARDO ROJAS-NANDAYAPA
A BSTRACT. We consider the fitting of heavy tailed data and distribution with a special attention to
distributions with a non–standard shape in the “body” of the distribution. To this end we consider a
dense class of heavy tailed distributions introduced in [3], employing an EM algorithm for the the
maximum likelihood estimates of its parameters. We present methods for fitting to observed data,
histograms, censored data, as well as to theoretical distributions. Numerical examples are provided
with simulated data and a benchmark reinsurance dataset. We empirically demonstrate that our model
can provide excellent fits to heavy–tailed data/distributions with minimal assumptions.
Keywords. Statistical inference, heavy–tailed, phase–type, scale mixtures, approximating distributions, EM algorithm.

1. I NTRODUCTION
In this paper we consider th
Original label:  cs.AI
Predicted label:  2
Correct label:  1
Text:  [CLS] navigating occluded intersections with autonomous vehicles using deep reinforcement learning arxiv : 1705. 01196v2 [ ] 27 feb 2018 david isele1, 3, reza rahimi2, akansel cosgun3, kaushik subramanian4 and kikuo fujimura3 abstract — providing an efficient strategy to navigate safely through unsignaled intersections is a difficult task that requires determining the intent of other drivers. we explore the effectiveness of deep reinforcement learning to handle intersection problems. using recent advances in deep rl, we are able to learn policies that surpass the performance of a commonly - used heuristic approach in several metrics including task completion time and goal success rate and have limited ability to generalize. we then explore a system ’ s ability to learn active sensing behaviors to enable navigating safely in the case of occlusions. our analysis, provides insight into the intersection handling problem, the solutions learned by the network point out several shortcomings of current rule - based methods, and the failures of our current deep reinforcement learning system point to future research directions. i. introduction one of the most challenging problems for autonomous vehicles is to handle unsignaled intersections in urban environments. to successfully navigate through an intersection, it is necessary to understand vehicle dynamics, interpret the intent of other drivers, resolve the blind regions in case of occlusion, and behave predictably so that other drivers can respond appropriately. learning this behavior requires optimizing multiple conflicting objectives including safety, efficiency, and minimizing the disruption of traffic. the ability to perform optimally at traffic junctions can both extend the abilities of autonomous agents and increase safety through driver assistance when a human driver is in control. several strategies have already been applied to intersection handling, including cooperative [ 1 ] and heuristic [ 2 ] approaches. cooperative approaches require vehicle - tovehicle communication and thus are not scalable to general intersection handling. the current state of the art is a rulebased method based on time - to - collision ( ttc ) [ 3 ], [ 4 ], which is a widely used heuristic as a safety indicator in the automotive industry [ 5 ]. variants of the ttc approach have been used for autonomous driving [ 6 ] and the darpa urban challenge, where hand engineered hierarchical state machines were a popular approach to handle intersections [ 7 ], [ 8 ]. ttc is currently the method we employ on our autonomous vehicle [ 9 ]. while tt [SEP]
Text from DS:  Navigating Occluded Intersections with Autonomous Vehicles
using Deep Reinforcement Learning

arXiv:1705.01196v2 [] 27 Feb 2018

David Isele1,3 , Reza Rahimi2 , Akansel Cosgun3 , Kaushik Subramanian4 and Kikuo Fujimura3
Abstract— Providing an efficient strategy to navigate safely
through unsignaled intersections is a difficult task that requires determining the intent of other drivers. We explore
the effectiveness of Deep Reinforcement Learning to handle
intersection problems. Using recent advances in Deep RL, we
are able to learn policies that surpass the performance of a
commonly-used heuristic approach in several metrics including
task completion time and goal success rate and have limited
ability to generalize. We then explore a system’s ability to learn
active sensing behaviors to enable navigating safely in the case
of occlusions. Our analysis, provides insight into the intersection
handling problem, the solutions learned by the network point
out several shortcomings of current r
Original label:  math.GR
Predicted label:  9
Correct label:  1
Text:  [CLS] arxiv : 1212. 4791v3 [ ] 31 mar 2016 geometry & topology xx ( 20xx ) 1001 – 999 1001 outer space for untwisted automorphisms of right - angled artin groups r. charney n. stambaugh k. vogtmann for a right - angled artin group aγ, the untwisted outer automorphism group u ( aγ ) is the subgroup of out ( aγ ) generated by all of the laurence - servatius generators except twists ( where a twist is an automorphisms of the form v 7→ vw with vw = wv ). we define a space σγ on which u ( aγ ) acts properly and prove that σγ is contractible, providing a geometric model for u ( aγ ) and its subgroups. we also propose a geometric model for all of out ( aγ ) defined by allowing more general markings and metrics on points of σγ. 20f65 ; 20f36, 20f28 1 introduction a free group is defined by giving a set of generators with no relations ; in particular, none of the generators commute. a free abelian group is defined by giving a set of generators which all commute, and no other relations. finitely - generated free and free abelian groups are examples of right - angled artin groups ( raags for short ) : a general raag is defined by giving a finite set of generators, some of which commute, and no other relations. a convenient way of describing a raag is by drawing a graph γ with one vertex for each generator and an edge between each pair of commuting generators ; the resulting raag is denoted aγ. raags and their subgroups are important sources of examples and counterexamples in geometric group theory ( see [ 4 ] for a survey ) and have recently played a key role in the solution of thurston ’ s conjectures on the structure of hyperbolic 3 - manifolds ( see [ 1 ] ). automorphism groups of raags have received less attention, with the notable exception of aγ = zn and aγ = fn. since it is easy to determine the center of any aγ the inner automorphisms of aγ are well - understood, so it remains to study the outer automorphism group out ( aγ ). the groups out ( fn ) and out ( zn ) = gl ( n, z ) [SEP]
Text from DS:  arXiv:1212.4791v3 [] 31 Mar 2016

Geometry & Topology XX (20XX) 1001–999

1001

Outer Space for Untwisted Automorphisms of Right-angled Artin
Groups
R. CHARNEY
N. STAMBAUGH
K. VOGTMANN
For a right-angled Artin group AΓ , the untwisted outer automorphism group U(AΓ ) is the
subgroup of Out(AΓ ) generated by all of the Laurence-Servatius generators except twists (where
a twist is an automorphisms of the form v 7→ vw with vw = wv). We define a space ΣΓ on
which U(AΓ ) acts properly and prove that ΣΓ is contractible, providing a geometric model for
U(AΓ ) and its subgroups. We also propose a geometric model for all of Out(AΓ ) defined by
allowing more general markings and metrics on points of ΣΓ .
20F65; 20F36, 20F28

1 Introduction
A free group is defined by giving a set of generators with no relations; in particular, none of
the generators commute. A free abelian group is defined by giving a set of generators which all
commute, and no other relations. Finitely-generated free and free abe
Original label:  math.ST
Predicted label:  1
Correct label:  9
Text:  [CLS] generalized network psychometrics : combining network and latent variable models arxiv : 1605. 09288v4 [ ] 11 sep 2017 sacha epskamp, 1 mijke t. rhemtulla, 2 and denny borsboom1 1. university of amsterdam : department of psychological methods 2. university of california, davis : department of psychology abstract we introduce the network model as a formal psychometric model, conceptualizing the covariance between psychometric indicators as resulting from pairwise interactions between observable variables in a network structure. this contrasts with standard psychometric models, in which the covariance between test items arises from the influence of one or more common latent variables. here, we present two generalizations of the network model that encompass latent variable structures, establishing network modeling as parts of the more general framework of structural equation modeling ( sem ). in the first generalization, we model the covariance structure of latent variables as a network. we term this framework latent network modeling ( lnm ) and show that, with lnm, a unique structure of conditional independence relationships between latent variables can be obtained in an explorative manner. in the second generalization, the residual variance - covariance structure of indicators is modeled as a network. we term this generalization residual network modeling ( rnm ) and show that, within this framework, identifiable models can be obtained in which local independence is structurally violated. these generalizations allow for a general modeling framework that can be used to fit, and compare, sem models, network models, and the rnm and lnm generalizations. this methodology has been implemented in the freeto - use software package lvnet, which contains confirmatory model testing as well as two exploratory search algorithms : stepwise search algorithms for low - dimensional datasets and penalized maximum likelihood estimation for larger datasets. we show in simulation studies that these search algorithms performs adequately in identifying the structure of the relevant residual or latent networks. we further demonstrate the utility of these generalizations in an empirical example on a personality inventory dataset. manuscript accepted for publication in psychometrika. generalized network psychometrics 2 introduction recent years have seen an emergence of network modeling in psychometrics ( borsboom, 2008 ; schmittmann et al., 2013 ), with applications in clinical psychology ( e. g., van borkulo et al. 2015 ; mcnally et [SEP]
Text from DS:  Generalized Network Psychometrics: Combining Network and
Latent Variable Models

arXiv:1605.09288v4 [] 11 Sep 2017

Sacha Epskamp,1 Mijke T. Rhemtulla,2 and Denny Borsboom1
1. University of Amsterdam: Department of Psychological Methods
2. University of California, Davis: Department of Psychology

Abstract
We introduce the network model as a formal psychometric model, conceptualizing the covariance between psychometric indicators as resulting from
pairwise interactions between observable variables in a network structure.
This contrasts with standard psychometric models, in which the covariance
between test items arises from the influence of one or more common latent
variables. Here, we present two generalizations of the network model that
encompass latent variable structures, establishing network modeling as parts
of the more general framework of Structural Equation Modeling (SEM). In
the first generalization, we model the covariance structure of latent variables
as a network. We term 
Original label:  math.ST
Predicted label:  2
Correct label:  3
Text:  [CLS] 1 topological mixture estimation steve huntsman∗ arxiv : 1712. 04487v1 [ stat. me ] 12 dec 2017 bae systems, 4301 north fairfax drive, arlington, virginia 22203 ( dated : december 14, 2017 ) density functions that represent sample data are often multimodal, i. e. they exhibit more than one maximum. typically this behavior is taken to indicate that the underlying data deserves a more detailed representation as a mixture of densities with individually simpler structure. the usual specification of a component density is quite restrictive, with log - concave the most general case considered in the literature, and gaussian the overwhelmingly typical case. it is also necessary to determine the number of mixture components a priori, and much art is devoted to this. here, we introduce topological mixture estimation, a completely nonparametric and computationally efficient solution to the one - dimensional problem where mixture components need only be unimodal. we repeatedly perturb the unimodal decomposition of baryshnikov and ghrist to produce a topologically and information - theoretically optimal unimodal mixture. we also detail a smoothing process that optimally exploits topological persistence of the unimodal category in a natural way when working directly with sample data. finally, we illustrate these techniques through examples. i. introduction let d ( rd ) denote a suitable space of continuous probability densities ( henceforth merely called densities ) on rd. p d [UNK] d m [UNK] m a mixture on r with m components is a pair ( π, p ) ∈ ∆m × d ( r ), where ∆m : = { π ∈ ( 0, 1 ] : m πm = 1 } ; we write | ( π, p ) | : = m, and note that π cannot have any components equal to zero. the corresponding mixture density pm is hπ, pi : = m = 1 πm pm. the jensen - shannon divergence of ( π, p ) is [ 15 ] j ( π, p ) : = h ( hπ, pi ) − hπ, h ( p ) i ( 1 ) r where h ( p ) m : = h ( pm ) and h ( f ) : = − f log f dx is the entropy of f. now j ( π, p ) is the mutual information between the random variables ξ [UNK] π and x [UNK] hπ, pi. since mutual information is always nonnegative, the same is true of j. the concavity of [SEP]
Text from DS:  1

Topological mixture estimation
Steve Huntsman∗

arXiv:1712.04487v1 [stat.ME] 12 Dec 2017

BAE Systems, 4301 North Fairfax Drive, Arlington, Virginia 22203
(Dated: December 14, 2017)
Density functions that represent sample data are often multimodal, i.e. they exhibit more than
one maximum. Typically this behavior is taken to indicate that the underlying data deserves a
more detailed representation as a mixture of densities with individually simpler structure. The
usual specification of a component density is quite restrictive, with log-concave the most general
case considered in the literature, and Gaussian the overwhelmingly typical case. It is also necessary
to determine the number of mixture components a priori, and much art is devoted to this. Here, we
introduce topological mixture estimation, a completely nonparametric and computationally efficient
solution to the one-dimensional problem where mixture components need only be unimodal. We repeatedly perturb the unimodal decomposi
Original label:  cs.DS
Predicted label:  9
Correct label:  3
Text:  [CLS] submit to the ieee transactions on wireless communications a multi - server scheduling framework for resource allocation in wireless multicarrier networks ying jun ( angela ) zhang, member, ieee the department of information engineering, the chinese university of hong kong shatin, new territory, hong kong email : yjzhang @ ie. cuhk. edu. hk abstract - multiuser resource allocation has recently been recognized as an effective methodology for enhancing the power and spectrum efficiency in ofdm ( orthogonal frequency division multiplexing ) systems. it is, however, not directly applicable to current packet - switched networks, because ( 1 ) most existing packet - scheduling schemes are based on a single - server model and do not serve multiple users at the same time ; and ( 2 ) the conventional separate design of mac ( medium access control ) packet scheduling and phy ( physical ) resource allocation yields inefficient resource utilization. in this paper, we propose a cross - layer resource allocation algorithm based on a novel multi - server scheduling framework to achieve overall high system power efficiency in packet - switched ofdm networks. our contribution is four fold. first, we propose and analyze a mpgps ( multi - server packetized general processor sharing ) service discipline that serves multiple users at the same time and facilitates multiuser resource allocation. second, we present a mpgps - based joint mac - phy resource allocation scheme that incorporates packet scheduling, subcarrier allocation, and power allocation in an integrated framework. third, by investigating the fundamental tradeoff between multiuser - diversity gain and queuing performance, we present an ampgps ( adaptive mpgps ) service discipline that strikes an optimal balance between power efficiency and queuing performance. finally, we extend mpgps to an o - mpgps ( opportunistic mpgps ) service discipline to further enhance the resource utilization efficiency. through analysis, we prove that the proposed mpgps, a - mpgps, and o - mpgps schemes can serve users in a way that approximates the ideal gps ( general processor sharing ) service discipline, and hence guarantee qos and fairness. through simulations, we show that the mpgps -, a - mpgps -, and o - mpgps - based cross - layer resource allocation algorithms significantly enhance system power efficiency compared to conventional resource allocation schemes. key words : cross layer optimization, ofdm, adaptive resource allocation, multi - server packet scheduling corresponding author : ying jun ( angela ) zhang email : yjzhang @ ie [SEP]
Text from DS:  Submit to the
IEEE Transactions on Wireless Communications

A Multi-server Scheduling Framework for Resource Allocation in Wireless Multicarrier Networks
Ying Jun (Angela) Zhang, Member, IEEE
The Department of Information Engineering, The Chinese University of Hong Kong
Shatin, New Territory, Hong Kong
Email: yjzhang@ie.cuhk.edu.hk

Abstract- Multiuser resource allocation has recently been recognized as an effective methodology for
enhancing the power and spectrum efficiency in OFDM (orthogonal frequency division multiplexing)
systems. It is, however, not directly applicable to current packet-switched networks, because (1) most
existing packet-scheduling schemes are based on a single-server model and do not serve multiple users at
the same time; and (2) the conventional separate design of MAC (medium access control) packet scheduling
and PHY (physical) resource allocation yields inefficient resource utilization. In this paper, we propose a
cross-layer resource allocation algorithm base
Original label:  math.GR
Predicted label:  7
Correct label:  3
Text:  [CLS] normalizers and centralizers of cyclic subgroups generated by lone axis fully irreducible outer automorphisms arxiv : 1603. 07206v3 [ ] 3 jul 2016 yael algom - kfir and catherine pfaff abstract. we let [UNK] be an ageometric fully irreducible outer automorphism so that its handelmosher [ hm11 ] axis bundle consists of a single unique axis ( as in [ mp13 ] ). we show that the centralizer cen ( [UNK] ) of the cyclic subgroup generated by [UNK] equals the stabilizer stab ( λ + [UNK] ) of the attracting lamination λ + [UNK] and is isomorphic to z. we further show, via an analogous result about the commensurator, that the normalizer n ( [UNK] ) of [UNK] is isomorphic to either z or z2 ∗ z2. 1. introduction it is well known [ mcc94 ] that, given a pseudo - anosov mapping class [UNK], the centralizer cen ( [UNK] ) and normalizer n ( [UNK] ) of the cyclic subgroup [UNK] are virtually cyclic. in fact, this property characterizes pseudo - anosov mapping classes. 1 we recall some history surrounding this problem for the outer automorphism groups out ( fr ). in [ bfh97 ], bestvina, feighn, and handel constructed for a fully irreducible outer automorphism [UNK] ∈ + + out ( fr ) the attracting lamination λ + [UNK]. they proved that the stabilizer stab ( [UNK] ) of [UNK] in out ( fr ) is virtually cyclic ( see also [ kl11, thereom 4. 4 ] ). let comm ( [UNK] ) denote the commensurator of [UNK]. whenever the lamination λ + [UNK] is defined we have [UNK] ≤ cen ( [UNK] ) ≤ stab ( λ + [UNK] ) ≤ comm ( [UNK] ) and cen ( [UNK] ) ≤ n ( [UNK] ) ≤ comm ( [UNK] ). in the fully irreducible case, the groups appearing above are all finite index subgroups of one another, and each of the inclusions may be strict ( see examples 3. 4, 3. 5, and 3. 6 ). this article is concerned with identifying the centralizer and normalizer of [UNK] when [UNK] is an ageometric lone axis fully irreducible outer automorphism, as defined in subsection 2. 6. briefly, the term “ lone axis ” is used for when the axis bundle, defined by handel and [SEP]
Text from DS:  NORMALIZERS AND CENTRALIZERS OF CYCLIC SUBGROUPS
GENERATED BY LONE AXIS FULLY IRREDUCIBLE OUTER
AUTOMORPHISMS

arXiv:1603.07206v3 [] 3 Jul 2016

YAEL ALGOM-KFIR AND CATHERINE PFAFF

Abstract. We let ϕ be an ageometric fully irreducible outer automorphism so that its HandelMosher [HM11] axis bundle consists of a single unique axis (as in [MP13]). We show that the
centralizer Cen(hϕi) of the cyclic subgroup generated by ϕ equals the stabilizer Stab(Λ+
ϕ ) of the
attracting lamination Λ+
ϕ and is isomorphic to Z. We further show, via an analogous result about
the commensurator, that the normalizer N (hϕi) of hϕi is isomorphic to either Z or Z2 ∗ Z2 .

1. Introduction
It is well known [McC94] that, given a pseudo-Anosov mapping class ϕ, the centralizer Cen(hϕi)
and normalizer N (hϕi) of the cyclic subgroup hϕi are virtually cyclic. In fact, this property characterizes pseudo-Anosov mapping classes.1
We recall some history surrounding this problem for the outer automorphism groups Out(Fr ).
Original label:  cs.IT
Predicted label:  1
Correct label:  9
Text:  [CLS] testing unateness of real - valued functions∗ roksana baleshzar † meiram murzabulatov † ramesh krishnan s. pallavoor † arxiv : 1608. 07652v1 [ ] 27 aug 2016 sofya raskhodnikova † abstract we give a unateness tester for functions of the form f : [ n ] d → r, where n, d ∈ n and r ⊆ r with query complexity o ( d log ( max ( d, n ) ) ). previously known unateness testers work only for boolean functions over the domain { 0, 1 } d. we show that every unateness tester for realvalued functions over hypergrid has query complexity ω ( min { d, | r | 2 } ). consequently, our tester is nearly optimal for real - valued functions over { 0, 1 } d. we √ also prove that every nonadaptive, 1 - sided error unateness tester for boolean functions needs ω ( d / ) queries. previously, no lower bounds for testing unateness were known. 1 introduction we study property testing unateness of functions of the form f : [ n ] d → r, where n, d ∈ n and r ⊆ r. unate functions are used in mathematics and other technical disciplines, for example in tautology checking [ 14, 15 ] and in switching theory [ 17 ]. for x, y ∈ [ n ] d, where x = x1,..., xd and n p y = y1,..., yd, we define | x − y | 1 = | xi − yi |. two points x, y are neighbours if | x − y | 1 = 1. a i = 1 function f : [ n ] d → r is unate if each dimension i ∈ [ d ] can be assigned an associated direction up or down ; the direction is up if f ( x ) ≤ f ( y ) for all neighbours x, y where yi = xi + 1 ; and the direction is down if f ( x ) ≥ f ( y ) for all such x and y. moreover, a function is monotone if the direction is up in all dimensions. thus, unateness is a generalization of monotonicity. the domain [ n ] d is called a hypergrid and the special case { 0, 1 } d is called a hypercube. the [SEP]
Text from DS:  Testing Unateness of Real-Valued Functions∗
Roksana Baleshzar†

Meiram Murzabulatov†

Ramesh Krishnan S. Pallavoor†

arXiv:1608.07652v1 [] 27 Aug 2016

Sofya Raskhodnikova†

Abstract
We give a unateness tester for functions of the form f : [n]d → R, where n, d ∈ N and
R ⊆ R with query complexity O( d log(max(d,n))
). Previously known unateness testers work only

for Boolean functions over the domain {0, 1}d . We show that every unateness tester for realvalued functions over hypergrid has query complexity Ω(min{d, |R|2 }). Consequently, our tester
is nearly optimal for real-valued functions over {0, 1}d . We √
also prove that every nonadaptive,
1-sided error unateness tester for Boolean functions needs Ω( d/) queries. Previously, no lower
bounds for testing unateness were known.

1

Introduction

We study property testing unateness of functions of the form f : [n]d → R, where n, d ∈ N and
R ⊆ R. Unate functions are used in mathematics and other technical disciplines, for example in
ta
Original label:  math.ST
Predicted label:  1
Correct label:  2
Text:  [CLS] arxiv : 1604. 03993v1 [ math. pr ] 13 apr 2016 consistency of modularity clustering on random geometric graphs erik davis and sunder sethuraman abstract. we consider a large class of random geometric graphs constructed from samples xn = { x1, x2,..., xn } of independent, identically distributed observations of an underlying probability measure ν on a bounded domain d ⊂ rd. the popular ‘ modularity ’ clustering method specifies a partition un of the set xn as the solution of an optimization problem. in this paper, under conditions on ν and d, we derive scaling limits of the modularity clustering on random geometric graphs. among other results, we show a geometric form of consistency : when the number of clusters is a priori bounded above, the discrete optimal partitions un converge in a certain sense to a continuum partition u of the underlying domain d, characterized as the solution of a type of kelvin ’ s shape optimization problem. 1. introduction one of the basic tasks in understanding the structure and function of complex networks is the identification of community structure or modular organization, where by a community we mean a subset of densely interconnected nodes, only sparsely connected to outsiders ( cf. [ 33 ], [ 66 ] ). a widely popular approach to community detection is the method of modularity clustering, introduced by newman and girvan ( cf. [ 60 ], [ 57 ] ), which specifies an optimal clustering – that is, a partition of the network – as the solution of a certain optimization problem ( see section 2 for precise definitions ). in particular, the method is used for a variety of networks arising in scientific contexts, including metabolic networks [ 44 ], epigenetic networks [ 55 ], brain networks [ 47 ], and networks encoding ecological [ 31 ] and political interactions [ 65 ]. on the other hand, a popular model of complex networks with geometric structure is the random geometric graph, where vertices are sampled from a geometric domain and edge weights are determined by a function of the distance between vertices [ 34 ], [ 54 ], [ 62 ]. we note, a well - studied case is the unweighted version, when the connectivity function is a threshold function of distance. these graphs are wellestablished mathematical models of various physical phenomena, such as continuum percolation. they have also found use in a number of applied settings, including the modeling of ad - hoc wireless networks [ 46 ], [ 11 ], [ 35 [SEP]
Text from DS:  arXiv:1604.03993v1 [math.PR] 13 Apr 2016

CONSISTENCY OF MODULARITY CLUSTERING ON RANDOM
GEOMETRIC GRAPHS
ERIK DAVIS AND SUNDER SETHURAMAN

Abstract. We consider a large class of random geometric graphs constructed
from samples Xn = {X1 , X2 , . . . , Xn } of independent, identically distributed
observations of an underlying probability measure ν on a bounded domain
D ⊂ Rd . The popular ‘modularity’ clustering method specifies a partition Un
of the set Xn as the solution of an optimization problem. In this paper, under
conditions on ν and D, we derive scaling limits of the modularity clustering
on random geometric graphs. Among other results, we show a geometric form
of consistency: When the number of clusters is a priori bounded above, the
discrete optimal partitions Un converge in a certain sense to a continuum
partition U of the underlying domain D, characterized as the solution of a
type of Kelvin’s shape optimization problem.

1. Introduction
One of the basic tasks in understandin
Original label:  cs.NE
Predicted label:  8
Correct label:  2
Text:  [CLS] workshop track - iclr 2016 s cale n ormalization arxiv : 1604. 07796v1 [ ] 26 apr 2016 henry z. lo, kevin amaral, & wei ding department of computer science university of massachusetts boston boston, ma 02155, usa { henryzlo, ding } @ cs. umb. edu, kevin. m. amaral @ gmail. com a bstract one of the difficulties of training deep neural networks is caused by improper scaling between layers. scaling issues introduce exploding / gradient problems, and have typically been addressed by careful scale - preserving initialization. we investigate the value of preserving scale, or isometry, beyond the initial weights. we propose two methods of maintaing isometry, one exact and one stochastic. preliminary experiments show that for both determinant and scale - normalization effectively speeds up learning. results suggest that isometry is important in the beginning of learning, and maintaining it leads to faster learning. 1 i ntroduction the goal of many initialization methods is to preserve the gradient signal as it goes backwards through each layer of a neural network glorot & bengio ( 2010 ) ; he et al. ( 2015 ) ; saxe et al. ( 2014 ). in rnns, not preserving this signal may lead to the well - known vanishing and exploding gradient problems hochreiter ( 1998 ). in general, learning in neural nets is much faster when the composite scales of all layers remains near a constant of the problem saxe et al. ( 2014 ). results from this line of work suggest that initially preserving scale is conducive to learning. however, any update rule which does not enforce scale - preservation will violate this condition ( isometry ) after the first iteration. does preserving scale continue to speed up learning after the first iteration? there is evidence for and against. on one hand, if scale were preserved throughout all epochs, the network would fail to learn non - isometric projections. however, there is circumstantial evidence for the benefit of preserving scale during training : • the objective most common in autoencoders produces an approximately isometric matrix w, and thus implicitly preserves scale ( singular values ) bourlard & kamp. • co - training with both unsupervised and supervised objectives leads to faster - learning and more generalizable networks rasmus et al. ( 2015 ). at least some of this result is due to the scale - preserving effect of the un [SEP]
Text from DS:  Workshop track - ICLR 2016

S CALE N ORMALIZATION

arXiv:1604.07796v1 [] 26 Apr 2016

Henry Z. Lo, Kevin Amaral, & Wei Ding
Department of Computer Science
University of Massachusetts Boston
Boston, MA 02155, USA
{henryzlo,ding}@cs.umb.edu, kevin.m.amaral@gmail.com

A BSTRACT
One of the difficulties of training deep neural networks is caused by improper
scaling between layers. Scaling issues introduce exploding / gradient problems,
and have typically been addressed by careful scale-preserving initialization. We
investigate the value of preserving scale, or isometry, beyond the initial weights.
We propose two methods of maintaing isometry, one exact and one stochastic.
Preliminary experiments show that for both determinant and scale-normalization
effectively speeds up learning. Results suggest that isometry is important in the
beginning of learning, and maintaining it leads to faster learning.

1

I NTRODUCTION

The goal of many initialization methods is to preserve the gradient signal a
Original label:  math.ST
Predicted label:  1
Correct label:  2
Text:  [CLS] testing hypotheses about mixture distributions using not identically distributed data daniel gaigall arxiv : 1602. 06383v2 [ ] 20 apr 2016 department of mathematics, heinrich - heine - university dusseldorf, universitatsstr. 1, 40225 dusseldorf, germany. abstract testing hypotheses of goodness - of - fit about mixture distributions on the basis of independent but not necessarily identically distributed random vectors is considered. the hypotheses are given by a specific distribution or by a family of distributions. moreover, testing hypotheses formulated by hadamard differentiable functionals is discussed in this situation, in particular the hypothesis of central symmetry, homogeneity and independence. kolmogorov - smirnov or cramer - von - mises type statistics are suggested as well as methods to determine critical values. the focus of the investigation is on asymptotic properties of the test statistics. further, outcomes of simulations for finite sample sizes are given. applications to models with not identically distributed errors are presented. the results imply that the tests are of asymptotically exact size and consistent. keywords : not identically distributed observations, mixture distribution, kolmogorovsmirnov statistic, cramer - von - mises statistic, empirical process, vapnik - chervonenkis class, hadamard differentiability 2000 msc : 62g10, 62g09 1 introduction not identically distributed errors are discussed in various theoretical and practical contexts, see, e. g., the works of lu et al. [ 21 ], kuljus and zwanzig [ 20 ], gornitz et al. [ 14 ], eiker [ 13 ] and delaigle and meister [ 11 ]. consider here the following situation as a motivation. suppose independent and identically distributed data are underlying, where an independent but not identically distributed noise is present. it is assumed that the difference in the distribution of the noise vanishes if the number of observations increases. the interesting statistical problem is a testing problem of goodness - of - fit formulated with the independent and identically distributed original data. more precisely, consider a sequence of independent and identically distributed real valued random variables y1, y2,... with unknown underlying distribution lpy1 q. suppose the user has to treat the testing problem of goodness - of - fit h : lpy1 q “ lpy0 q, k : [SEP]
Text from DS:  Testing hypotheses about mixture distributions using not
identically distributed data
Daniel Gaigall

arXiv:1602.06383v2 [] 20 Apr 2016

Department of Mathematics, Heinrich-Heine-University Düsseldorf,
Universitätsstr. 1, 40225 Düsseldorf, Germany.

Abstract
Testing hypotheses of goodness-of-fit about mixture distributions on the basis of
independent but not necessarily identically distributed random vectors is considered.
The hypotheses are given by a specific distribution or by a family of distributions.
Moreover, testing hypotheses formulated by Hadamard differentiable functionals is discussed in this situation, in particular the hypothesis of central symmetry, homogeneity
and independence. Kolmogorov-Smirnov or Cramér-von-Mises type statistics are suggested as well as methods to determine critical values. The focus of the investigation
is on asymptotic properties of the test statistics. Further, outcomes of simulations for
finite sample sizes are given. Applications to models w
Original label:  cs.IT
Predicted label:  6
Correct label:  2
Text:  [CLS] robust sparse estimation tasks in high dimensions arxiv : 1702. 05860v2 [ cs. lg ] 28 feb 2017 jerry li∗ eecs, mit jerryzli @ mit. edu march 2, 2017 abstract in this paper we initiate the study of whether or not sparse estimation tasks can be performed efficiently in high dimensions, in the robust setting where an ε - fraction of samples are corrupted adversarially. we study the natural robust version of two classical sparse estimation problems, namely, sparse mean estimation and sparse pca in the spiked covariance model. for both of these problems, we provide the first efficient algorithms that provide non - trivial error guarantees in the presence of noise, using only a number of samples which is similar to the number required for these problems without noise. in particular, our sample complexities are sublinear in the ambient dimension d. our work also suggests evidence for new computational - vs - statistical gaps for these problems ( similar to those for sparse pca without noise ) which only arise in the presence of noise. 1 introduction in the last couple of decades, there has been a large amount of work in machine learning and statistics on how to exploit sparsity in high dimensional data analysis. motivated by the ever - increasing quantity and dimensionality of data, the goal at a high level is to utilize the underlying sparsity of natural data to extract meaningful guarantees using a number of samples that is sublinear in the dimensionality of the data. in this paper, we will consider the unsupervised setting, where we have sample access to some distribution with some underlying sparsity, and our goal is to recover this distribution by exploiting this structure. two natural and well - studied problems in this setting that attempt to exploit sparsity are sparse mean estimation and sparse pca. in both problems, the shared theme is that we assume that one wishes to find a distinguished sparse direction of a gaussian data set. however, the algorithms inspired by this line of work tend to be quite brittle — it can be shown that they fail when the model is slightly perturbed. this connects to a major concern in high dimensional data analysis : that of model misspecification. at a high level, the worry is that our algorithms should be able to tolerate the case when our assumed model and the true model do not perfectly coincide. in the distributional setting, this ( more or less ) corresponds to the regime when a small fraction of our samples are adversarially [SEP]
Text from DS:  Robust Sparse Estimation Tasks in High Dimensions

arXiv:1702.05860v2 [cs.LG] 28 Feb 2017

Jerry Li∗
EECS, MIT
jerryzli@mit.edu
March 2, 2017

Abstract
In this paper we initiate the study of whether or not sparse estimation tasks can be performed efficiently in high
dimensions, in the robust setting where an ε-fraction of samples are corrupted adversarially. We study the natural
robust version of two classical sparse estimation problems, namely, sparse mean estimation and sparse PCA in the
spiked covariance model. For both of these problems, we provide the first efficient algorithms that provide non-trivial
error guarantees in the presence of noise, using only a number of samples which is similar to the number required for
these problems without noise. In particular, our sample complexities are sublinear in the ambient dimension d. Our
work also suggests evidence for new computational-vs-statistical gaps for these problems (similar to those for sparse
PCA without noise) which only aris
Original label:  cs.IT
Predicted label:  8
Correct label:  3
Text:  [CLS] polynomial - time algorithms for the subset feedback vertex set problem on interval graphs and permutation graphs charis papadopoulos∗ spyridon tzimas † arxiv : 1701. 04634v2 [ ] 1 feb 2017 abstract given a vertex - weighted graph g = ( v, e ) and a set s ⊆ v, a subset feedback vertex set x is a set of the vertices of g such that the graph induced by v \ x has no cycle containing a vertex of s. the subset feedback vertex set problem takes as input g and s and asks for the subset feedback vertex set of minimum total weight. in contrast to the classical feedback vertex set problem which is obtained from the subset feedback vertex set problem for s = v, restricted to graph classes the subset feedback vertex set problem is known to be np - complete on split graphs and, consequently, on chordal graphs. however as feedback vertex set is polynomially solvable for at - free graphs, no such result is known for the subset feedback vertex set problem on any subclass of at - free graphs. here we give the first polynomial - time algorithms for the problem on two unrelated subclasses of at - free graphs : interval graphs and permutation graphs. as a byproduct we show that there exists a polynomial - time algorithm for circular - arc graphs by suitably applying our algorithm for interval graphs. moreover towards the unknown complexity of the problem for at - free graphs, we give a polynomial - time algorithm for co - bipartite graphs. thus we contribute to the first positive results of the subset feedback vertex set problem when restricted to graph classes for which feedback vertex set is solved in polynomial time. 1 introduction for a given set s of vertices of a graph g, a subset feedback vertex set x is a set of vertices such that every cycle of g [ v \ x ] does not contain a vertex from s. the subset feedback vertex set problem takes as input a graph g = ( v, e ) and a set s ⊆ v and asks for the subset feedback vertex set of minimum cardinality. in the weighted version every vertex of g has a weight and the objective is to compute a subset feedback vertex set with the minimum total weight. the subset feedback vertex set problem is a generalization of the classical feedback vertex set problem in which the goal is to remove a set of vertices x such that g [ v \ x ] has no cycles. thus by setting s = v the problem coincides with the np - complete feedback vertex set problem [ [SEP]
Text from DS:  Polynomial-time Algorithms for the Subset Feedback Vertex
Set Problem on Interval Graphs and Permutation Graphs
Charis Papadopoulos∗

Spyridon Tzimas†

arXiv:1701.04634v2 [] 1 Feb 2017

Abstract
Given a vertex-weighted graph G = (V, E) and a set S ⊆ V , a subset feedback vertex
set X is a set of the vertices of G such that the graph induced by V \ X has no cycle
containing a vertex of S. The Subset Feedback Vertex Set problem takes as input
G and S and asks for the subset feedback vertex set of minimum total weight. In contrast
to the classical Feedback Vertex Set problem which is obtained from the Subset
Feedback Vertex Set problem for S = V , restricted to graph classes the Subset
Feedback Vertex Set problem is known to be NP-complete on split graphs and,
consequently, on chordal graphs. However as Feedback Vertex Set is polynomially
solvable for AT-free graphs, no such result is known for the Subset Feedback Vertex
Set problem on any subclass of AT-free graphs. Here we give the firs
Original label:  cs.AI
Predicted label:  8
Correct label:  10
Text:  [CLS] dcs 16 may 2017 dynamic move tables and long branches with backtracking in computer chess kieran greer, distributed computing systems, belfast, uk. http : / / distributedcomputingsystems. co. uk version 1. 2 abstract — the idea of dynamic move chains has been described in a preceding paper [ 10 ]. re - usi ng an earlier piece of search allows the tree to be forward - pruned, which is known to be dangerous, because it can potentially remove new information that would only be realised through a more exhaustive search process. the justification is the integrity in the position and small changes between positions make it more likely that an earlier result still applies. larger problems where exhaustive search is not possible would also like a method that can guess accurately. this pape r has added to the forward - pruning technique by using ‘ move tables ’ that can act in the same way as transposition tables, but for moves not positions. they use an efficient memory structure and have put the design into the context of short or long - term memories. the long - term memory includes simply rote - learning of other players ’ games. the forward - pruning technique can also be fortified to help to remove some potential errors. another idea is ‘ long branches ’. this plays a short move sequence, before returning to a full search at the resulting leaf nodes. therefore, with some configuration the dynamic tables can be reliably used and relatively independently of the posi ti on. this has advanced some of the future work theory of the earlier paper, and made more explicit where logical plans and more knowledge - based approaches might be applied. the author would argue that the process is a very human approach to searching for chess moves. index terms — move table, dynamic move sequence, long branch, tree search, memory, knowledge. 1 introduction the idea of dynamic move chains has been described in a preceding paper [ 10 ]. it incorporates the idea of forward - pruning the search tree, which is known to be dangerous, because it can potentially remove new information that would only be realised through a more exhaustive search process. if the decision is based on a lot of knowledge, then it might be ok, but because computer chess programs are mainly statistical, they do not typically contain enough knowledge about any single position or move, to make that assumption. the amount of ‘ knowledge ’ that the chess program contains is still limited and so it must evaluate many more positions to produce reliable results. even if evolutionary [SEP]
Text from DS:  DCS

16 May 2017

Dynamic Move Tables and Long Branches with Backtracking
in Computer Chess
Kieran Greer, Distributed Computing Systems, Belfast, UK.
http://distributedcomputingsystems.co.uk
Version 1.2

Abstract—The idea of dynamic move chains has been described in a preceding paper [10]. Re -usi ng
an earlier piece of search allows the tree to be forward-pruned, which is known to be dangerous,
because it can potentially remove new information that would only be realised through a more
exhaustive search process. The justification is the integrity in the position and small changes
between positions make it more likely that an earlier result still applies. Larger problems where
exhaustive search is not possible would also like a method that can guess accurately. This pape r has
added to the forward-pruning technique by using ‘move tables’ that can act in the same way as
Transposition Tables, but for moves not positions. They use an efficient memory structure and have
put the design into
Original label:  cs.AI
Predicted label:  10
Correct label:  5
Text:  [CLS] 1 a wl - sppim semantic model for document classification first a. ming li, second b. peilun xiao, and third c. ju zhang abstract — in this paper, we explore sppim - based text classification method, and the experiment reveals that the sppim method is equal to or even superior than sgns method in text classification task on three international and standard text datasets, namely 20newsgroups, reuters52 and webkb. comparing to sgns, although sppmi provides a better solution, it is not necessarily better than sgns in text classification tasks.. based on our analysis, sgns takes into the consideration of weight calculation during decomposition process, so it has better performance than sppim in some standard datasets. inspired by this, we propose a wl - sppim semantic model based on sppim model, and experiment shows that wl - sppim approach has better classification and higher scalability in the text classification task compared with lda, sgns and sppim approaches. index terms — lda ; sppim ; word embedding ; low frequency ; document classification — — — — — — — — — — — — — — — — — — — — 1 introduction d istribution of semantic vectors is widely used in text semantic expression, including text classification, text clustering, semantic retrieval, automatic question and answer, dictionary generation, semantic disambiguation, query expansion, text advertisements and machine translation, especially for measuring semantic relevance [ 1, 2 ]. we divided the dsms into two categories, one we called count - based models, many traditional dsms belong to this category, the other category we call prediction - based models, which are based on neural embedding among the traditional count - based models the best know is latent semantic analysis. lsa is a low dimensional semantic space for texts, and lsa derive the document vector by the use of co - occurrence information between words [ 3 ]. more recently, lda has received more and more extensive attention, as a semantic model of dsms [ 4, 5 ]. lda is a three - layer bayesian probability model proposed by blei et al in 2003, which contains the three layers structure of document, topic and word. document to topic subjects to dirichlet distribution, topic to word subjects to polynomial distribution. lda semantic model usually shows very good performance on nlp tasks, partly because it projects the document into a low - dimensional topic semantic space. word frequencies [SEP]
Text from DS:  1

A WL-SPPIM Semantic Model for Document
Classification
First A. Ming Li, Second B. Peilun Xiao, and Third C. Ju Zhang
Abstract—In this paper, we explore SPPIM-based text classification method, and the experiment reveals that the SPPIM
method is equal to or even superior than SGNS method in text classification task on three international and standard text
datasets, namely 20newsgroups, Reuters52 and WebKB. Comparing to SGNS, although SPPMI provides a better solution, it is
not necessarily better than SGNS in text classification tasks.. Based on our analysis, SGNS takes into the consideration of
weight calculation during decomposition process, so it has better performance than SPPIM in some standard datasets. Inspired
by this, we propose a WL-SPPIM semantic model based on SPPIM model, and experiment shows that WL-SPPIM approach
has better classification and higher scalability in the text classification task compared with LDA, SGNS and SPPIM approaches.
Index Terms—LDA; SPPIM; word embe
Original label:  cs.IT
Predicted label:  1
Correct label:  9
Text:  [CLS] random cluster dynamics for the ising model is rapidly mixing arxiv : 1605. 00139v1 [ ] 30 apr 2016 heng guo and mark jerrum abstract. we show that the mixing time of glauber ( single edge update ) dynamics for the random cluster model at q = 2 is bounded by a polynomial in the size of the underlying graph. as a consequence, the swendsen - wang algorithm for the ferromagnetic ising model at any temperature has the same polynomial mixing time bound. 1. introduction the ising model is perhaps the best known model in statistical physics, and it has also been widely studied from an algorithmic perspective. an instance of the model is an undirected graph g, together with a parameter β > 0. a configuration of the model is an assignment σ ∈ { 0, 1 } v of “ spins ” to the vertices of g. the weight w ( σ ) of configuration σ is β m ( σ ) where m ( σ ) is the number of monochromatic edges ( edges { i, j } with σ ( i ) = σ ( j ) ) in g. it is of importance to compute the partition function of the system, which is the sum of weights w ( σ ) over all configurations σ ∈ { 0, 1 } v. if β < 1 then the system is antiferromagnetic, and the partition function is computationally hard, even to approximate. however, when β > 1 the system is ferromagnetic, and the partition function can be approximated in polynomial time to with any specified relative error [ 17 ]. a direct approach using markov chain monte carlo ( mcmc ) on the spin configurations described above fails, as the spin model exhibits a phase transition for sufficiently large β. however, there is an equivalent formulation of the ising model in terms of “ even subgraphs ” which does form the basis for a successful application of mcmc, as was shown by jerrum and sinclair [ 17 ]. ( see sections 2 and 3 for details of the various models referred to in this introduction. ) there is a third model which is equivalent to the ising model in the sense of having the same partition function up to an easily computable factor, namely the random cluster model introduced by fortuin and kasteleyn [ 9 ]. in common with the even subgraphs model, the configurations of the random cluster model are subsets of the edge set of g. however, the random cluster model [SEP]
Text from DS:  RANDOM CLUSTER DYNAMICS FOR THE ISING MODEL IS RAPIDLY
MIXING

arXiv:1605.00139v1 [] 30 Apr 2016

HENG GUO AND MARK JERRUM
Abstract. We show that the mixing time of Glauber (single edge update) dynamics for the random
cluster model at q = 2 is bounded by a polynomial in the size of the underlying graph. As a
consequence, the Swendsen-Wang algorithm for the ferromagnetic Ising model at any temperature
has the same polynomial mixing time bound.

1. Introduction
The Ising model is perhaps the best known model in statistical physics, and it has also been
widely studied from an algorithmic perspective. An instance of the model is an undirected graph G,
together with a parameter β > 0. A configuration of the model is an assignment σ ∈ {0, 1}V of
“spins” to the vertices of G. The weight w(σ) of configuration σ is β m(σ) where m(σ) is the number
of monochromatic edges (edges {i, j} with σ(i) = σ(j)) in G. It is of importance to compute
the partition function of the system, which is the sum of 
Original label:  cs.SY
Predicted label:  5
Correct label:  3
Text:  [CLS] 1 global sensitivity analysis of battery equivalent circuit model parameters arxiv : 1604. 01293v1 [ ] 5 apr 2016 shi zhao and david a. howey department of engineering science university of oxford oxford, united kingdom shi. zhao @ eng. ox. ac. uk ; david. howey @ eng. ox. ac. uk abstract — this paper considers one of the most commonly used equivalent circuit models ( ecms ) for lithium - ion batteries and investigates the sensitivity of the model output to changes of model parameters using the morris method. experiments are carried out on a lithium - ion cell with nickel manganese cobalt oxide ( nmc ) electrode and parameters of the model are identified in the state of charge ( soc ) range [ 100 %, 10 % ]. although all the model parameters do vary with soc, global sensitivity analysis reveals that the uncertainties of some of the parameters generate very little uncertainty in the voltage output, implying that those parameters can be taken as constants without compromising the accuracy of the model. this is further confirmed by experimental validation. index terms — battery, equivalent circuit model, sensitivity analysis, morris method, monte carlo method. i. i ntroduction equivalent circuit models ( ecms ) for lithium - ion batteries are widely used for state of charge ( soc ) and state of health ( soh ) estimation in battery management systems ( bmss ) [ 1 ]. compared to electrochemical models which are derived from electrochemical principles and are characterised by partial differential equations coupled with algebraic equations ( pdaes ), ecms are low order models parameterised from time - domain or frequency domain experimental data and are computationally more efficient. in the system identification step, the parameters of the ecms are adjusted so that the model output matches the experimental measurements as closely as possible. it is recognised in the literature that the model parameters vary with soc ( and temperature1 ). therefore in order to improve the model accuracy, they are often taken as functions of soc [ 2 ]. alternatively, the parameters are set to be constants so that the complexity of the model is reduced [ 3 ]. the choice of whether the ecm parameters should be soc dependent is a tradeoff between model accuracy and efficiency. and this seems to be a binary choice from the literature : either we vary all the parameters with soc or we set all the parameters to constants. such a dilemma, which is implicitly based on the assumption that all the parameters are equally important to the model output, is probably unnecessary as the output [SEP]
Text from DS:  1

Global sensitivity analysis of battery equivalent
circuit model parameters

arXiv:1604.01293v1 [] 5 Apr 2016

Shi Zhao and David A. Howey
Department of Engineering Science
University of Oxford
Oxford, United Kingdom
shi.zhao@eng.ox.ac.uk; david.howey@eng.ox.ac.uk

Abstract—This paper considers one of the most commonly used
equivalent circuit models (ECMs) for lithium-ion batteries and
investigates the sensitivity of the model output to changes of
model parameters using the Morris method. Experiments are
carried out on a lithium-ion cell with nickel manganese cobalt
oxide (NMC) electrode and parameters of the model are identified
in the state of charge (SOC) range [100%, 10%]. Although all the
model parameters do vary with SOC, global sensitivity analysis
reveals that the uncertainties of some of the parameters generate
very little uncertainty in the voltage output, implying that those
parameters can be taken as constants without compromising the
accuracy of the model. This is furthe
Original label:  cs.PL
Predicted label:  9
Correct label:  2
Text:  [CLS] 1 colonel blotto game for secure state estimation in interdependent critical infrastructure aidin ferdowsi∗, walid saad∗, narayan b. mandayam † wireless @ vt, bradley department of electrical and computer engineering, virginia tech, blacksburg, va, usa, emails : { aidin, walids } @ vt. edu winlab, dept. of ece, rutgers university, new brunswick, nj, usa, email : narayan @ winlab. rutgers. edu ∗ arxiv : 1709. 09768v1 [ ] 28 sep 2017 † abstract — securing the physical components of a city ’ s interdependent critical infrastructure ( ici ) such as power, natural gas, and water systems is a challenging task due to their interdependence and large number of involved sensors. using a novel integrated state - space model that captures the interdependence, a two - stage cyber attack on ici is studied in which the attacker first compromises the ici ’ s sensors by decoding their messages, and, subsequently, it alters the compromised sensors ’ data to cause state estimation errors. to thwart such attacks, the administrator of the cis must assign protection levels to the sensors based on their importance in the state estimation process. to capture the interdependence between the attacker and the ici administrator ’ s actions and analyze their interactions, a colonel blotto game framework is proposed. the mixed - strategy nash equilibrium of this game is derived analytically. at this equilibrium, it is shown that the administrator can strategically randomize between the protection levels of the sensors to deceive the attacker. simulation results coupled with theoretical analysis show that, using the proposed game, the administrator can reduce the state estimation error by at least 50 % compared to any non - strategic action. the results also show that the ici ’ s administrator must consider the cis inside a city as a unified ici for security analysis instead of assigning independent protection levels to each individual ci, as is conventionally done. i. i ntroduction the services delivered by a smart city ’ s critical infrastructure ( ci ) such as power, natural gas, and water will be highly interdependent [ 1 ] – [ 4 ]. cis are cyber - physical systems ( cpss ) that encompass physical infrastructure whose performance is monitored and controlled by a cyber system, typically consisting of a massive number of sensors. these cpss exhibit close interactions between their cyber and [SEP]
Text from DS:  1

Colonel Blotto Game for Secure State Estimation in
Interdependent Critical Infrastructure
Aidin Ferdowsi∗ , Walid Saad∗ , Narayan B. Mandayam†
Wireless@VT, Bradley Department of Electrical and Computer Engineering,
Virginia Tech, Blacksburg, VA, USA, Emails: {aidin,walids}@vt.edu
WINLAB, Dept. of ECE, Rutgers University, New Brunswick, NJ, USA, Email: narayan@winlab.rutgers.edu
∗

arXiv:1709.09768v1 [] 28 Sep 2017

†

Abstract—Securing the physical components of a city’s interdependent critical infrastructure (ICI) such as power, natural
gas, and water systems is a challenging task due to their
interdependence and large number of involved sensors. Using
a novel integrated state-space model that captures the interdependence, a two-stage cyber attack on ICI is studied in which the
attacker first compromises the ICI’s sensors by decoding their
messages, and, subsequently, it alters the compromised sensors’
data to cause state estimation errors. To thwart such attacks,
the administrator
Original label:  math.ST
Predicted label:  3
Correct label:  5
Text:  [CLS] learning objectives for treatment effect estimation arxiv : 1712. 04912v1 [ stat. ml ] 13 dec 2017 xinkun nie xinkun @ stanford. edu stefan wager swager @ stanford. edu draft version december 2017 abstract we develop a general class of two - step algorithms for heterogeneous treatment effect estimation in observational studies. we first estimate marginal effects and treatment propensities to form an objective function that isolates the heterogeneous treatment effects, and then optimize the learned objective. this approach has several advantages over existing methods. from a practical perspective, our method is very flexible and easy to use : in both steps, we can use any method of our choice, e. g., penalized regression, a deep net, or boosting ; moreover, these methods can be fine - tuned by cross - validating on the learned objective. meanwhile, in the case of penalized kernel regression, we show that our method has a quasi - oracle property, whereby even if our pilot estimates for marginal effects and treatment propensities are not particularly accurate, we achieve the same regret bounds as an oracle who has a - priori knowledge of these nuisance components. we implement variants of our method based on both penalized regression and convolutional neural networks, and find promising performance relative to existing baselines. 1 introduction the problem of heterogeneous treatment effect estimation in observational studies arises in a wide variety application areas [ athey, 2017 ], ranging from personalized medicine [ obermeyer and emanuel, 2016 ] to offline evaluation of bandits [ dudık et al., 2011 ], and is also a key component of several proposals for learning decision rules [ athey and wager, 2017, hirano and porter, 2009 ]. there has been considerable interest in developing flexible and performant methods for heterogeneous treatment effect estimation. some notable recent advances include proposals based on the lasso [ imai and ratkovic, 2013 ], recursive partitioning [ athey and imbens, 2016, su et al., 2009 ], bart [ hill, 2011 ], random forests [ wager and athey, 2017 ], boosting [ powers et al., 2017 ], deep neural networks [ shalit et al., 2017 ], etc. ; see dorie et al. [ 2017 ] for a recent survey and comparisons. however, although this line of work has led to many promising [SEP]
Text from DS:  Learning Objectives for Treatment Effect Estimation

arXiv:1712.04912v1 [stat.ML] 13 Dec 2017

Xinkun Nie
xinkun@stanford.edu

Stefan Wager
swager@stanford.edu

Draft version December 2017
Abstract
We develop a general class of two-step algorithms for heterogeneous treatment effect
estimation in observational studies. We first estimate marginal effects and treatment
propensities to form an objective function that isolates the heterogeneous treatment
effects, and then optimize the learned objective. This approach has several advantages over existing methods. From a practical perspective, our method is very flexible
and easy to use: In both steps, we can use any method of our choice, e.g., penalized
regression, a deep net, or boosting; moreover, these methods can be fine-tuned by
cross-validating on the learned objective. Meanwhile, in the case of penalized kernel
regression, we show that our method has a quasi-oracle property, whereby even if our
pilot estimates for marginal effects and
Original label:  cs.PL
Predicted label:  6
Correct label:  8
Text:  [CLS] 1 on independence and capacity of multidimensional semiconstrained systems ohad elishco, student member, ieee, tom meyerovitch, moshe schwartz, senior member, ieee arxiv : 1709. 05105v1 [ math. ds ] 15 sep 2017 abstract we find a new formula for the limit of the capacity of certain sequences of multidimensional semiconstrained systems as the dimension tends to infinity. we do so by generalizing the notion of independence entropy, originally studied in the context of constrained systems, to the study of semiconstrained systems. using the independence entropy, we obtain new lower bounds on the capacity of multidimensional semiconstrained systems in general, and d - dimensional axial - product systems in particular. in the case of the latter, we prove our bound is asymptotically tight, giving the exact limiting capacity in terms of the independence entropy. we show the new bound improves upon the best - known bound in a case study of ( 0, k, p ) - rll. index terms semiconstrained systems, capacity, independence entropy, bounds i. i ntroduction e rror - correcting codes and constrained codes may be considered as two extreme ways of coping with a noisy channel. the former are usually data independent, and assume errors are a statistical phenomenon, reducing data - transmission rate to protect against such errors. constrained codes, however, assume certain patterns in the data stream are responsible for the occurrence of errors. thus, constrained codes eliminate all undesirable patterns, at the cost of reduced data - transmission rate. recently in [ 9 ], [ 10 ], semiconstrained systems ( scss ) were suggested as a generalization to constrained systems ( which we emphasize by calling fully constrained systems ). in scss we do not eliminate the undesirable patterns entirely but rather we allow them to appear with a restriction on their frequency. to illustrate, consider a binary channel in which the appearance of k - consecutive 1 ’ s is forbidden. the set of allowed words is the well known inverted ( 0, k ) - rll. however, if k - consecutive 1 ’ s are not forbidden entirely, but instead are allowed to appear in at most a fraction p of places, then the set of allowed words forms a scs called the ( 0, k, p ) - rll system. informally, a scs is defined by a set γ of probability measures over k - tuples. the [SEP]
Text from DS:  1

On Independence And Capacity of
Multidimensional Semiconstrained Systems
Ohad Elishco, Student Member, IEEE, Tom Meyerovitch, Moshe Schwartz, Senior Member, IEEE

arXiv:1709.05105v1 [math.DS] 15 Sep 2017

Abstract
We find a new formula for the limit of the capacity of certain sequences of multidimensional semiconstrained systems as the
dimension tends to infinity. We do so by generalizing the notion of independence entropy, originally studied in the context of
constrained systems, to the study of semiconstrained systems. Using the independence entropy, we obtain new lower bounds on
the capacity of multidimensional semiconstrained systems in general, and d-dimensional axial-product systems in particular. In
the case of the latter, we prove our bound is asymptotically tight, giving the exact limiting capacity in terms of the independence
entropy. We show the new bound improves upon the best-known bound in a case study of (0, k, p)-RLL.
Index Terms
Semiconstrained systems, capacity, in
Original label:  cs.DS
Predicted label:  4
Correct label:  10
Text:  [CLS] 1 multichannel linear prediction for blind reverberant audio source separation arxiv : 1702. 07713v1 [ cs. sd ] 24 feb 2017 ilker bayram and savaskan bulek abstract — a class of methods based on multichannel linear prediction ( mclp ) can achieve effective blind dereverberation of a source, when the source is observed with a microphone array. we propose an inventive use of mclp as a pre - processing step for blind source separation with a microphone array. we show theoretically that, under certain assumptions, such pre - processing reduces the original blind reverberant source separation problem to a non - reverberant one, which in turn can be effectively tackled using existing methods. we demonstrate our claims using real recordings obtained with an eight - microphone circular array in reverberant environments. index terms — microphone array, source separation, blind dereverberation, multichannel linear prediction, beamforming, post - filtering. i. i ntroduction in anechoic environments, audio source separation with a microphone array can be achieved by beamforming and postfiltering [ 7 ]. on the other hand, in reverberant environments, reverberation causes significant degradation in the quality and intelligibility of the beamformer output, especially if the room impulse responses ( rir ) are not taken into account or are not known precisely. this is a serious limitation because in practice, rirs are usually not known with precision and they can vary wildly with respect to the positions of the microphone / source pair. a related problem addressing reverberation without explicit rir knowledge is called blind dereverberation [ 17 ]. a successful class of methods for blind dereverberation fall under the framework of multi - channel linear prediction ( mclp ) [ 16 ], [ 11 ], [ 10 ]. these methods require a microphone array and employ linear prediction to extract information about the properties of reverberation. in this paper, we propose to employ mclp, which is primarily used for single source dereverberation, as a pre - processing step in source separation. we show theoretically and demonstrate numerically that such a scheme not only dereverberates the sources but also helps in the subsequent separation. in order to make this statement more precise, let us briefly discuss an mclp formulation. consider an array of microphones, recording a source in a reverberant room. recent mclp formulation [SEP]
Text from DS:  1

Multichannel Linear Prediction for Blind
Reverberant Audio Source Separation

arXiv:1702.07713v1 [cs.SD] 24 Feb 2017

İlker Bayram and Savaşkan Bulek
Abstract—A class of methods based on multichannel linear
prediction (MCLP) can achieve effective blind dereverberation of
a source, when the source is observed with a microphone array.
We propose an inventive use of MCLP as a pre-processing step
for blind source separation with a microphone array. We show
theoretically that, under certain assumptions, such pre-processing
reduces the original blind reverberant source separation problem
to a non-reverberant one, which in turn can be effectively tackled
using existing methods. We demonstrate our claims using real
recordings obtained with an eight-microphone circular array in
reverberant environments.
Index Terms—Microphone array, source separation, blind
dereverberation, multichannel linear prediction, beamforming,
post-filtering.

I. I NTRODUCTION
In anechoic environments, audio source
Original label:  cs.NE
Predicted label:  10
Correct label:  7
Text:  [CLS] 1 experimental demonstration of array - level learning with phase change synaptic devices s. burc eryilmaz1, duygu kuzum2, rakesh g. d. jeyasingh1, sangbum kim3, matthew brightsky3, chung lam3 and h. - s. philip wong1 1 2 department of electrical engineering, stanford university, stanford, ca 94305, e - mail : eryilmaz @ stanford. edu, university of pennsylvania, philadelphia, pa, 3 ibm research, t. j. watson research center, yorktown heights, ny abstract the computational performance of the biological brain has long attracted significant interest and has led to inspirations in operating principles, algorithms, and architectures for computing and signal processing. in this work, we focus on hardware implementation of brain - like learning in a brain - inspired architecture. we demonstrate, in hardware, that 2 - d crossbar arrays of phase change synaptic devices can achieve associative learning and perform pattern recognition. device and array - level studies using an experimental 10×10 array of phase change synaptic devices have shown that pattern recognition is robust against synaptic resistance variations and large variations can be tolerated by increasing the number of training iterations. our measurements show that increase in initial variation from 9 % to 60 % causes required training iterations to increase from 1 to 11. i. introduction synaptic electronics is an emerging field of research aiming to build electronic systems that mimic computational energyefficiency and fault tolerance of biological brain in a compact space [ 1 ]. to date, synaptic electronics research has primarily figure 1 : left figure is a dsi ( diffusion spectrum imaging ) scan figure 2. memory array schematic shown as a 10 - neuron recurrent neural network. the resistors represent the phase change memory cells ( pcm ). showing a fabric - like 3 - d grid structure of connections in the monkey brain ( credit : van wedeen, m. d., martinos center and dept. of radiology, massachusetts general hospital and harvard university medical school ) [ 6 ]. right figure is an electronic focused on device level implementations of synaptic plasticity implementation of 3d crossbar array with synaptic devices inspired and array or chip level simulations [ 2 - 4 ]. studies that involve onfrom grid - like structure of neuronal fibers. chip demonstration of brain - like computation with synaptic devices and integration of synaptic devices in [SEP]
Text from DS:  1

Experimental Demonstration of Array-level Learning with Phase Change
Synaptic Devices
S. Burc Eryilmaz1, Duygu Kuzum2, Rakesh G. D. Jeyasingh1, SangBum Kim3, Matthew BrightSky3,
Chung Lam3 and H.-S. Philip Wong1
1

2

Department of Electrical Engineering, Stanford University, Stanford, CA 94305, e-mail: eryilmaz@stanford.edu,
University of Pennsylvania, Philadelphia, PA, 3 IBM Research, T.J. Watson Research Center, Yorktown Heights, NY

Abstract
The computational performance of the biological brain has long attracted significant interest and has led to inspirations in
operating principles, algorithms, and architectures for computing and signal processing. In this work, we focus on hardware
implementation of brain-like learning in a brain-inspired architecture. We demonstrate, in hardware, that 2-D crossbar arrays of
phase change synaptic devices can achieve associative learning and perform pattern recognition. Device and array-level studies
using an experimental 10×10 array of phase
Original label:  cs.CE
Predicted label:  6
Correct label:  2
Text:  [CLS] checking linearizability of concurrent priority queues ahmed bouajjani1, constantin enea1, and chao wang1 1 institut de recherche en informatique fondamentale, { abou, cenea, wangch } @ irif. fr arxiv : 1707. 00639v1 [ ] 3 jul 2017 abstract efficient implementations of concurrent objects such as atomic collections are essential to modern computing. programming such objects is error prone : in minimizing the synchronization overhead between concurrent object invocations, one risks the conformance to sequential specifications – or in formal terms, one risks violating linearizability. unfortunately, verifying linearizability is undecidable in general, even on classes of implementations where the usual control - state reachability is decidable. in this work we consider concurrent priority queues which are fundamental to many multi - threaded applications such as task scheduling or discrete event simulation, and show that verifying linearizability of such implementations can be reduced to control - state reachability. this reduction entails the first decidability results for verifying concurrent priority queues in the context of an unbounded number of threads, and it enables the application of existing safety - verification tools for establishing their correctness. digital object identifier 10. 4230 / lipics... 1 introduction modern computer software is increasingly concurrent. interactive applications and services necessitate reactive asynchronous operations to handle requests immediately as they happen, rather than waiting for long - running operations to complete. furthermore, as processor manufacturers approach clock - speed limits, performance improvements are more - often achieved by parallelizing operations across multiple processor cores. multithreaded software is typically built with specialized “ concurrent objects ” like atomic integers, queues, maps, priority queues. these objects ’ methods are designed to confom to better established sequential specifications, a property known as linearizability [ 14 ], despite being optimized to avoid blocking and exploit parallelism, e. g., by using atomic machine instructions like compare - and - swap. intuitively, linearizability asks that every individual operation appears to take place instantaneously at some point between its invocation and its return. verifying linearizability is intrinsically hard, and undecidable in general [ 4 ]. however, recent work [ 5 ] has shown that for particular classes of objects, i. e., registers, mutexes, queues, and stacks, the [SEP]
Text from DS:  Checking Linearizability of Concurrent Priority
Queues
Ahmed Bouajjani1 , Constantin Enea1 , and Chao Wang1
1

Institut de Recherche en Informatique Fondamentale,
{abou,cenea,wangch}@irif.fr

arXiv:1707.00639v1 [] 3 Jul 2017

Abstract
Efficient implementations of concurrent objects such as atomic collections are essential to modern computing. Programming such objects is error prone: in minimizing the synchronization overhead between
concurrent object invocations, one risks the conformance to sequential specifications – or in formal terms,
one risks violating linearizability. Unfortunately, verifying linearizability is undecidable in general, even
on classes of implementations where the usual control-state reachability is decidable. In this work we
consider concurrent priority queues which are fundamental to many multi-threaded applications such as
task scheduling or discrete event simulation, and show that verifying linearizability of such implementations can be reduced to control-stat
Original label:  math.AC
Predicted label:  3
Correct label:  5
Text:  [CLS] arxiv : 1207. 5963v1 [ ] 25 jul 2012 on the category of profinite spaces as a reflective subcategory abolfazl tarizadeh abstract. in this paper by using the ring of real - valued continuous functions c ( x ), we prove a theorem in profinite spaces which states that for a compact hausdorff space x, the set of its connected components x / [UNK] endowed with some topology t is a profinite space. then we apply this result to give an alternative proof to the fact that the category of profinite spaces is a reflective subcategory in the category of compact hausdorff spaces. finally, under some circumstances on a space x, we compute the connected components of the space t ( x ) in terms of the ones of the space x. 1. introduction a profinite space is a compact hausdorff and totally disconnected topological space. in other words, a space x is profinite if there exists an inverse system of finite discrete spaces for which its inverse limit is homeomorphic to x, consider [ 4, section 3. 4 ]. recall that a profinite group is a topological group whose underlying space is a profinite space. there are interesting examples of profinite spaces and profinite groups which arise from algebraic geometry, galois theory and topology. for instance, for any field k its absolute galois group gal ( k s / k ) is a profinite group, or more generally the etale fundamental group π1 ( x, s ) of a connected scheme x on a geometric point s : spec ( ω ) → x is a profinite group [ 8, theorem 5. 4. 2 ]. stone ’ s duality says us that any profinite space x is of the form x = spec ( b ) for some boolean algebra b ( [ 4, theore 4. 1. 16 ] ). there is also another characterization of profinite spaces due to craven [ 5 ], where he proves that each profinite space is homeomorphic to the space x ( f ) for some formally real field f and x ( f ) denotes the set 0 2010 mathematics subject classification : 03g05, 06e25, 14g32, 18a40. key words and phrases : profinite spaces, connected components, coarser topology, reflective subcatgory. 1 2 abolfazl tarizadeh of orderings of the field [SEP]
Text from DS:  arXiv:1207.5963v1 [] 25 Jul 2012

ON THE CATEGORY OF PROFINITE SPACES AS A
REFLECTIVE SUBCATEGORY
ABOLFAZL TARIZADEH
Abstract. In this paper by using the ring of real-valued continuous functions C(X), we prove a theorem in profinite spaces
which states that for a compact Hausdorff space X, the set of its
connected components X/∼ endowed with some topology T is a
profinite space. Then we apply this result to give an alternative
proof to the fact that the category of profinite spaces is a reflective
subcategory in the category of compact Hausdorff spaces. Finally,
under some circumstances on a space X, we compute the connected
components of the space t(X) in terms of the ones of the space X.

1. Introduction
A profinite space is a compact Hausdorff and totally disconnected
topological space. In other words, a space X is profinite if there exists
an inverse system of finite discrete spaces for which its inverse limit is
homeomorphic to X, consider [4, Section 3.4]. Recall that a profinite
Original label:  cs.CV
Predicted label:  2
Correct label:  1
Text:  [CLS] be your own prada : fashion synthesis with structural coherence∗ arxiv : 1710. 07346v1 [ ] 19 oct 2017 shizhan zhu1 sanja fidler2, 3 raquel urtasun2, 3, 4 dahua lin1 chen change loy1 1 department of information engineering, the chinese university of hong kong 2 university of toronto, 3 vector institute, 4 uber advanced technologies group { szzhu, dhlin, ccloy } @ ie. cuhk. edu. hk, { fidler, urtasun } @ cs. toronto. edu abstract we present a novel and effective approach for generating new clothing on a wearer through generative adversarial learning. given an input image of a person and a sentence describing a different outfit, our model “ redresses ” the person as desired, while at the same time keeping the wearer and her / his pose unchanged. generating new outfits with precise regions conforming to a language description while retaining wearer ’ s body structure is a new challenging task. existing generative adversarial networks are not ideal in ensuring global coherence of structure given both the input photograph and language description as conditions. we address this challenge by decomposing the complex generative process into two conditional stages. in the first stage, we generate a plausible semantic segmentation map that obeys the wearer ’ s pose as a latent spatial arrangement. an effective spatial constraint is formulated to guide the generation of this semantic segmentation map. in the second stage, a generative model with a newly proposed compositional mapping layer is used to render the final image with precise regions and textures conditioned on this map. we extended the deepfashion dataset [ 8 ] by collecting sentence descriptions for 79k images. we demonstrate the effectiveness of our approach through both quantitative and qualitative evaluations. a user study is also conducted. the codes and the data are available at http : / / mmlab. ie. cuhk. edu. hk / projects / fashiongan /. 1. introduction imagine that you could be your own fashion designer, and be able to seamlessly transform your current outfit in the photo into a completely new one, by simply describing it in words ( figure 1 ). in just minutes you could design and “ try on ” hundreds of different shirts, dresses, or even styles, allowing you to easily discover what you look good in. the goal of this paper is to develop a method [SEP]
Text from DS:  Be Your Own Prada: Fashion Synthesis with Structural Coherence∗

arXiv:1710.07346v1 [] 19 Oct 2017

Shizhan Zhu1 Sanja Fidler2,3 Raquel Urtasun2,3,4
Dahua Lin1 Chen Change Loy1
1
Department of Information Engineering, The Chinese University of Hong Kong
2
University of Toronto, 3 Vector Institute, 4 Uber Advanced Technologies Group
{szzhu, dhlin, ccloy}@ie.cuhk.edu.hk, {fidler, urtasun}@cs.toronto.edu

Abstract
We present a novel and effective approach for generating
new clothing on a wearer through generative adversarial
learning. Given an input image of a person and a sentence
describing a different outfit, our model “redresses” the person as desired, while at the same time keeping the wearer
and her/his pose unchanged. Generating new outfits with
precise regions conforming to a language description while
retaining wearer’s body structure is a new challenging task.
Existing generative adversarial networks are not ideal in
ensuring global coherence of structure given both the input
ph
Original label:  cs.DS
Predicted label:  7
Correct label:  10
Text:  [CLS] directional variance adjustment : improving covariance estimates for high - dimensional portfolio optimization arxiv : 1109. 3069v3 [ q - fin. pm ] 8 mar 2012 daniel bartza, 1,, kerr hatrickb, christian w. hesseb, klaus - robert mullera, steven lemma a machine learning group, computer science dept., tu berlin, berlin b global markets equity, deutsche bank ag, london abstract robust and reliable covariance estimates play a decisive role in financial and many other applications. an important class of estimators is based on factor models. here, we show by extensive monte carlo simulations that covariance matrices derived from the statistical factor analysis model exhibit a systematic error, which is similar to the well - known systematic error of the spectrum of the sample covariance matrix. moreover, we introduce the directional variance adjustment ( dva ) algorithm, which diminishes the systematic error. in a thorough empirical study for the us, european, and hong kong market we show that our proposed method leads to improved portfolio allocation. keywords : covariance estimation, factor models, portfolio optimization 1. introduction and motivation the advent of modern finance began with markowitz and his seminal paper on portfolio optimization ( markowitz ( 1952 ) ). his theory provides a mathematical approach to diversification by directly minimizing the portfolio variance. moreover, by adding constraints to the optimization problem, we can e. g. prohibit or allow short - selling. other applications comprises the creation of portfolios which constitute optimal hedges or track indices. however, a fundamental issue in portfolio allocation is the accurate and precise estimation of the covariance matrix of asset returns from historical data. email address : daniel. bartz @ tu - berlin. de ( daniel bartz ) preprint submitted to journal of comp. statistics & data analysis march 9, 2012 covariance estimation and coping with its uncertainties have occupied both researchers and practitioners since then. one of the major difficulties with robust covariance matrix estimation arises from nonstationarity of financial time series ( see, e. g. loretan and phillips ( 1994 ), pagan and schwert ( 1990 ) ). here, changes in the data generating processes force the estimation to rely on short time windows of recent observations. on the other hand the number of parameters increases quadratically with the number of assets, i. e., for a set of n assets, the covariance matrix has 12 n ( n + 1 ) free [SEP]
Text from DS:  Directional Variance Adjustment: improving covariance
estimates for high-dimensional portfolio optimization

arXiv:1109.3069v3 [q-fin.PM] 8 Mar 2012

Daniel Bartza,1,, Kerr Hatrickb , Christian W. Hesseb , Klaus-Robert Müllera ,
Steven Lemma
a

Machine Learning Group, Computer Science Dept., TU Berlin, Berlin
b
Global Markets Equity, Deutsche Bank AG, London

Abstract
Robust and reliable covariance estimates play a decisive role in financial
and many other applications. An important class of estimators is based
on Factor models. Here, we show by extensive Monte Carlo simulations
that covariance matrices derived from the statistical Factor Analysis model
exhibit a systematic error, which is similar to the well-known systematic error
of the spectrum of the sample covariance matrix. Moreover, we introduce
the Directional Variance Adjustment (DVA) algorithm, which diminishes the
systematic error. In a thorough empirical study for the US, European, and
Hong Kong market we show that our pro
Original label:  math.ST
Predicted label:  9
Correct label:  5
Text:  [CLS] a note on central limit theorems for quadratic variation in case of endogenous observation times mathias vetter∗ tobias zwingmann † arxiv : 1605. 07056v1 [ ] 23 may 2016 april 16, 2018 abstract this paper is concerned with a central limit theorem for quadratic variation when observations come as exit times from a regular grid. we discuss the special case of a semimartingale with deterministic characteristics and finite activity jumps in detail and illustrate technical issues in more general situations. keywords and phrases : high - frequency observations ; irregular data ; quadratic variation ; realized variance ; stable convergence ams subject classification : 60f05, 60g51, 62m09 1 introduction high - frequency statistics has attracted a lot of attention in recent years. given observations of a semimartingale x, one is often interested in estimation of its quadratic variation ( or parts thereof, such as integrated volatility ) and with associated central limit theorems. a natural way is to work in a setting where observations come at regular times, that is we have data xj / n, j = 0,..., n, over the interval [ 0, 1 ], say. the most general paper on asymptotics in this setting is jacod ( 2008 ) where various ( stable ) central limit theorems for functionals of discretely observed ito semimartingales are stated, including those for realized variance rv ( x, x ) nt with rv ( x, y ) nt = bntc x ( xj / n − x ( j−1 ) / n ) ( yj / n − y ( j−1 ) / n ) j = 1 for arbitrary processes x and y ; see also jacod and protter ( 1998 ) for earlier results on related statistics in the case of levy processes. suppose, x is defined on the filtered probability space ( ω, f, ( ft ) t≥0, p ) and can be decomposed as z t z t z tz xt = x0 + as ds + σs dws + κ ( δ ( s, x ) ) ( µ − ν ) ( ds, dx ) ( 1. 1 ) 0 0 0 r z tz κ ( δ ( s, x ) ) µ ( ds, dx ), + 0 ∗ r christian - albrechts - universitat zu kiel, mathematisches seminar, ludewig - meyn - str [SEP]
Text from DS:  A note on central limit theorems for quadratic variation
in case of endogenous observation times
Mathias Vetter∗

Tobias Zwingmann†

arXiv:1605.07056v1 [] 23 May 2016

April 16, 2018

Abstract
This paper is concerned with a central limit theorem for quadratic variation
when observations come as exit times from a regular grid. We discuss the special
case of a semimartingale with deterministic characteristics and finite activity
jumps in detail and illustrate technical issues in more general situations.

Keywords and Phrases: High-frequency observations; irregular data; quadratic variation; realized variance; stable convergence
AMS Subject Classification: 60F05, 60G51, 62M09

1

Introduction

High-frequency statistics has attracted a lot of attention in recent years. Given observations of a semimartingale X, one is often interested in estimation of its quadratic
variation (or parts thereof, such as integrated volatility) and with associated central
limit theorems.
A natural way is to wor
Original label:  cs.CE
Predicted label:  1
Correct label:  9
Text:  [CLS] towards reversible computation in [UNK] naoki nishida1, adrian palacios2, [UNK], and german vidal2 arxiv : 1608. 05521v1 [ ] 19 aug 2016 1 graduate school of information science, nagoya university furo - cho, chikusa - ku, 4648603 nagoya, japan, nishida @ is. nagoya - u. ac. jp 2 mist, dsic, universitat politecnica de valencia camino de vera, s / n, 46022 valencia, spain { apalacios, gvidal } @ dsic. upv. es abstract. in a reversible language, any forward computation can be undone by a finite sequence of backward steps. reversible computing has been studied in the context of different programming languages and formalisms, where it has been used for debugging and for enforcing faulttolerance, among others. in this paper, we consider a subset of erlang, a concurrent language based on the actor model. we formally introduce a reversible semantics for this language. to the best of our knowledge, this is the first attempt to define a reversible semantics for erlang. 1 introduction let us consider that the operational semantics of a programming language is specified by a state transition relation r such that r ( s, s ′ ) holds if the state s ′ is reachable — in one step — from state s. as it is common practice, we let r∗ denote the reflexive and transitive closure of r. then, we say that a programming language ( or formalism ) is reversible if there exists a constructive algorithm that can be used to, given a computation from state s to state s ′, in symbols r∗ ( s, s ′ ), obtain the state s from s ′. in general, such a property does not hold for most programming languages and formalisms. we refer the interested reader to, e. g., [ 3, 10, 23, 24 ] for a high level account of the principles of reversible computation. the notion of reversible computation was first introduced in landauer ’ s seminal work [ 13 ] and, then, further improved by bennett [ 2 ] in order to avoid the generation of “ garbage ” data. the idea underlying these works is that any programming language or formalism can be made reversible by adding the history of the computation to each state, which is usually called a landauer ’ s embed [SEP]
Text from DS:  Towards Reversible Computation in Erlang⋆
Naoki Nishida1 , Adrián Palacios2,⋆⋆ , and Germán Vidal2

arXiv:1608.05521v1 [] 19 Aug 2016

1

Graduate School of Information Science, Nagoya University
Furo-cho, Chikusa-ku, 4648603 Nagoya, Japan,
nishida@is.nagoya-u.ac.jp
2
MiST, DSIC, Universitat Politècnica de València
Camino de Vera, s/n, 46022 Valencia, Spain
{apalacios, gvidal}@dsic.upv.es

Abstract. In a reversible language, any forward computation can be
undone by a finite sequence of backward steps. Reversible computing
has been studied in the context of different programming languages and
formalisms, where it has been used for debugging and for enforcing faulttolerance, among others. In this paper, we consider a subset of Erlang,
a concurrent language based on the actor model. We formally introduce
a reversible semantics for this language. To the best of our knowledge,
this is the first attempt to define a reversible semantics for Erlang.

1

Introduction

Let us consider that t
Original label:  math.GR
Predicted label:  5
Correct label:  2
Text:  [CLS] arxiv : 1608. 03804v1 [ ] 12 aug 2016 the uniqueness of psu3 ( 8 ) in the monster robert a. wilson abstract. as a contribution to an eventual solution of the problem of the determination of the maximal subgroups of the monster we show that there is a unique conjugacy class of subgroups isomorphic to psu3 ( 8 ). the argument depends on some computations in various subgroups, but not on computations in the monster itself. 1. introduction the maximal subgroup problem for almost simple groups became a major focus for research in group theory in the 1980s, and remains so today. in the case of the sporadic groups, a systematic attack on the problem began earlier, with livingstone and his students in the 1960s. the problem was solved in the 20th century for 25 of the 26 sporadic simple groups, and their automorphism groups, but one case, namely the fischer – griess monster group m, remains outstanding. a great deal of work on this case has already been done. the maximal p - local subgroups were classified in [ 12, 7, 8 ], and some theoretical work on non - local subgroups was accomplished in [ 9, 10 ]. following successful computer constructions of the monster [ 6, 3 ] other techniques became available, and more progress was made [ 4, 5, 2, 11, 15, 16, 17 ], including discovery of five previously unknown maximal subgroups, isomorphic to • psl2 ( 71 ), psl2 ( 59 ), psl2 ( 41 ), pgl2 ( 29 ), pgl2 ( 19 ). the cases left open by this published work are possible maximal subgroups with socle isomorphic to one of the following simple groups : • psl2 ( 8 ), psl2 ( 13 ), psl2 ( 16 ), psu3 ( 4 ), psu3 ( 8 ). of these, psl2 ( 8 ) and psl2 ( 16 ) have been classified in unpublished work of p. e. holmes, although the results seem not to be publicly available. in this paper we deal with the case psu3 ( 8 ). specifically, we show that, up to conjugacy, there is a unique subgroup psu3 ( 8 ) in the monster. its normalizer is the already known maximal subgroup ( a5 × psu3 ( 8 ) : 3 ) : 2. notation follows [ 1 [SEP]
Text from DS:  arXiv:1608.03804v1 [] 12 Aug 2016

THE UNIQUENESS OF PSU3 (8) IN THE MONSTER
ROBERT A. WILSON

Abstract. As a contribution to an eventual solution of the problem of the
determination of the maximal subgroups of the Monster we show that there is
a unique conjugacy class of subgroups isomorphic to PSU3 (8). The argument
depends on some computations in various subgroups, but not on computations
in the Monster itself.

1. Introduction
The maximal subgroup problem for almost simple groups became a major focus
for research in group theory in the 1980s, and remains so today. In the case of the
sporadic groups, a systematic attack on the problem began earlier, with Livingstone
and his students in the 1960s. The problem was solved in the 20th century for
25 of the 26 sporadic simple groups, and their automorphism groups, but one
case, namely the Fischer–Griess Monster group M, remains outstanding. A great
deal of work on this case has already been done. The maximal p-local subgroups
were classi
Original label:  cs.DS
Predicted label:  1
Correct label:  9
Text:  [CLS] the response of grandstands driven by filtered gaussian white noise processes ondrej rokosa, ∗, jirı macaa arxiv : 1509. 04250v1 [ ] 14 sep 2015 a department of mechanics, faculty of civil engineering, czech technical university in prague, thakurova 7, 166 29 prague 6, czech republic. abstract this paper presents a semi - analytical estimate of the response of a grandstand occupied by an active crowd and by a passive crowd. filtered gaussian white noise processes are used to approximate the loading terms representing an active crowd. lumped biodynamic models with a single degree of freedom are included to reflect passive spectators occupying the structure. the response is described in terms of the first two moments, employing the ito formula and the state augmentation method for the stationary time domain solution. the quality of the approximation is compared on the basis of three examples of varying complexity using monte carlo simulation based on a synthetic generator available in the literature. for comparative purposes, there is also a brief review of frequency domain estimates. keywords : grandstand response, random vibration, active crowd, white noise process, filtration 1. introduction the response of a grandstand can be resolved quite easily by linear dynamics methods, if we neglect all the randomness of the system. however, for a more accurate description, at least the most significant uncertainties need to be taken into account. the main uncertainties include • forcing terms resulting from active crowd movements, especially synchronized jumping, • the uncertainties of the parameters in discrete biodynamic models — randomness of stiffness, mass and damping matrices, • the size and spatial distribution of an active crowd and a passive crowd. further generalizations can take into account various kinds of nonlinearities, e. g. geometrical and material non - linearities and non - linearities of biodynamic models ( huang and griffin, 2008 ). however, the following restrictions will be assumed for the purposes of this paper : ∗ corresponding author. email addresses : ondrej. rokos @ fsv. cvut. cz ( ondrej rokos ), maca @ fsv. cvut. cz ( jirı maca ) preprint submitted to arxiv march 17, 2018 the material parameters of the structure are treated as deterministic, since their influence is negligible in comparison with the sources listed above and the scope of the overall response ; the spatial distribution [SEP]
Text from DS:  The response of grandstands driven by filtered Gaussian white noise
processes
Ondřej Rokoša,∗, Jiřı́ Mácaa

arXiv:1509.04250v1 [] 14 Sep 2015

a

Department of Mechanics, Faculty of Civil Engineering, Czech Technical University in Prague,
Thákurova 7, 166 29 Prague 6, Czech Republic.

Abstract
This paper presents a semi-analytical estimate of the response of a grandstand occupied
by an active crowd and by a passive crowd. Filtered Gaussian white noise processes are
used to approximate the loading terms representing an active crowd. Lumped biodynamic
models with a single degree of freedom are included to reflect passive spectators occupying
the structure. The response is described in terms of the first two moments, employing the Itô
formula and the state augmentation method for the stationary time domain solution. The
quality of the approximation is compared on the basis of three examples of varying complexity
using Monte Carlo simulation based on a synthetic generator available i
Original label:  cs.PL
Predicted label:  5
Correct label:  9
Text:  [CLS] 1 hardness results on finding leafless elementary trapping sets and elementary arxiv : 1711. 10543v1 [ ] 28 nov 2017 absorbing sets of ldpc codes ali dehghan and amir h. banihashemi, senior member, ieee department of systems and computer engineering, carleton university, ottawa, ontario, canada abstract leafless elementary trapping sets ( letss ) are known to be the problematic structures in the error floor region of low - density parity - check ( ldpc ) codes over the additive white gaussian ( awgn ) channel under iterative decoding algorithms. while problems involving the general category of trapping sets, and the subcategory of elementary trapping sets ( etss ), have been shown to be np - hard, similar results for letss, which are a subset of etss are not available. in this paper, we prove that, for a general ldpc code, finding a lets of a given size a with minimum number of unsatisfied check nodes b is np - hard to approximate with any guaranteed precision. we also prove that finding the minimum size a of a lets with a given b is np - hard to approximate. similar results are proved for elementary absorbing sets, a popular subcategory of letss. index terms : low - density parity - check ( ldpc ) codes, trapping sets ( ts ), elementary trapping sets ( ets ), leafless elementary trapping sets ( lets ), absorbing sets ( abs ), elementary absorbing sets ( eabs ), computational complexity, np - hardness. i. introduction the error floor of low - density parity - check ( ldpc ) codes under iterative decoding algorithms is attributed to certain combinatorial structures in the tanner graph of the code, collectively referred to as trapping sets. a trapping set is often classified by its size a and the number of unsatisfied check nodes b in its induced subgraph. in this case, the trapping set is said to belong to the ( a, b ) class. the problematic trapping sets that cause the error floor depend not only on the tanner graph of the code, but also on the channel model, quantization scheme and the decoding algorithm. for variable - regular ldpc codes over the additive white gaussian noise 2 ( awgn ) channel, the culprits are known to be a subcategory of trapping sets, called leafless elementary trapping sets ( letss ) [ 1 ], [ 2 ]. leafless et [SEP]
Text from DS:  1

Hardness Results on Finding Leafless
Elementary Trapping Sets and Elementary

arXiv:1711.10543v1 [] 28 Nov 2017

Absorbing Sets of LDPC Codes
Ali Dehghan and Amir H. Banihashemi, Senior Member, IEEE
Department of Systems and Computer Engineering, Carleton University, Ottawa, Ontario, Canada

Abstract
Leafless elementary trapping sets (LETSs) are known to be the problematic structures in the error
floor region of low-density parity-check (LDPC) codes over the additive white Gaussian (AWGN)
channel under iterative decoding algorithms. While problems involving the general category of trapping
sets, and the subcategory of elementary trapping sets (ETSs), have been shown to be NP-hard, similar
results for LETSs, which are a subset of ETSs are not available. In this paper, we prove that, for a
general LDPC code, finding a LETS of a given size a with minimum number of unsatisfied check nodes
b is NP-hard to approximate with any guaranteed precision. We also prove that finding the minimum
s
Original label:  math.AC
Predicted label:  2
Correct label:  10
Text:  [CLS] arxiv : 1705. 02409v1 [ ] 5 may 2017 inequalities for free multi - braid arrangements michael dipasquale abstract. we prove that, on a large cone containing the constant multiplicities, the only free multiplicities on the braid arrangement are those identified in work of abe, nuida, and numata ( 2009 ). we also give a conjecture on the structure of all free multiplicities on braid arrangements. 1. introduction let v [UNK] = kℓ + 1 be a vector space over a field k of characteristic zero, v ∗ its dual space and s = sym ( v ∗ ) [UNK] = k [ x0,..., xℓ ]. given a polynomial f ∈ s denote by v ( f ) the zero - locus of f in v. the braid arrangement of type aℓ ⊂ v is defined as aℓ = ∪0≤i < j≤ℓ hij, where hij = v ( xi − xj ). a multiplicity on aℓ is a map m : { hij } → z > 0 ; we will set mij = m ( hij ). the pair ( aℓ, m ) is called a multi - arrangement. the multi - arrangement ( aℓ, m ) is free if the corresponding module d ( aℓ, m ) of multi - derivations ( i. e., vector fields tangent to aℓ with multiplicities prescribed by m ) is a free module over the polynomial ring k [ x0,..., xℓ ]. ( see section 2 for more details. ) if ( aℓ, m ) is free, we say m is a free multiplicity. free multiplicities on braid arrangements have been studied since the introduction of the module of logarithmic differentials by saito [ 12 ], largely due to their importance in the theory of coxeter arrangements and later in connection with a conjecture of athanasiadis [ 6 ]. terao made a major breakthrough in [ 14 ], showing that the constant multiplicity on any coxeter arrangement is free and determining the corresponding exponents. subsequently, many authors studied freeness of ‘ almost - constant ’ multiplicities on coxeter and braid arrangements [ 13, 14, 16, 5 ]. in the setting of the braid arrangement, this line of inquiry resulted in a paper of abe - nuida - numata [ 2 ], where the authors classify what [SEP]
Text from DS:  arXiv:1705.02409v1 [] 5 May 2017

INEQUALITIES FOR FREE MULTI-BRAID ARRANGEMENTS
MICHAEL DIPASQUALE
Abstract. We prove that, on a large cone containing the constant multiplicities, the only free multiplicities on the braid arrangement are those identified
in work of Abe, Nuida, and Numata (2009). We also give a conjecture on the
structure of all free multiplicities on braid arrangements.

1. Introduction
Let V ∼
= Kℓ+1 be a vector space over a field K of characteristic zero, V ∗ its
dual space and S = Sym(V ∗ ) ∼
= K[x0 , . . . , xℓ ]. Given a polynomial f ∈ S denote
by V (f ) the zero-locus of f in V . The braid arrangement of type Aℓ ⊂ V is defined as Aℓ = ∪0≤i<j≤ℓ Hij , where Hij = V (xi − xj ). A multiplicity on Aℓ is a
map m : {Hij } → Z>0 ; we will set mij = m(Hij ). The pair (Aℓ , m) is called
a multi-arrangement. The multi-arrangement (Aℓ , m) is free if the corresponding
module D(Aℓ , m) of multi-derivations (i.e., vector fields tangent to Aℓ with multiplicities prescribed by 
Original label:  cs.IT
Predicted label:  8
Correct label:  2
Text:  [CLS] average - case reconstruction for the deletion channel : subpolynomially many traces suffice arxiv : 1708. 00854v1 [ ] 1 aug 2017 yuval peres ∗ alex zhai † august 3, 2017 abstract the deletion channel takes as input a bit string x ∈ { 0, 1 } n, and deletes each bit independently with probability q, yielding a shorter string. the trace reconstruction problem is to recover an unknown string x from many independent outputs ( called “ traces ” ) of the deletion channel applied to x. 1 / 2 we show that if x is drawn uniformly at random and q < 1 / 2, then eo ( log n ) traces suffice to reconstruct x with high probability. the previous best bound, established in 2008 by holenstein, mitzenmacher, panigrahy, and wieder [ 5 ], uses no ( 1 ) traces and only applies for q less than a smaller threshold ( it seems that q < 0. 07 is needed ). our algorithm combines several ideas : 1 ) an alignment scheme for “ greedily ” fitting the output of the deletion channel as a subsequence of the input ; 2 ) a version of the idea of “ anchoring ” used in [ 5 ] ; and 3 ) complex analysis techniques from recent work of nazarov and peres [ 9 ] and de, o ’ donnell, and servedio [ 3 ]. ∗ † microsoft research ; peres @ microsoft. com stanford university ; azhai @ stanford. edu 1 1 introduction the deletion channel takes as input a bit string x ∈ { 0, 1 } n. each bit of x is ( independently of other bits ) retained with probability p and deleted with probability q : = 1 − p. the channel then outputs the concatenation of the retained bits ; such an output is called a trace. suppose that the input x is unknown. the trace reconstruction problem asks the following : how many i. i. d. traces from the deletion channel do we need to observe in order to determine x with high probability? there are two basic variants of this problem, which we will call the “ worst case ” and “ average case ”. in the worst case variant, the problem is to provide bounds that hold uniformly over all possible input strings x. the average case variant supposes that the input is chosen uniformly at random. in particular, we are allowed to ignore some “ [SEP]
Text from DS:  Average-case reconstruction for the deletion channel:
subpolynomially many traces suffice
arXiv:1708.00854v1 [] 1 Aug 2017

Yuval Peres

∗

Alex Zhai

†

August 3, 2017

Abstract
The deletion channel takes as input a bit string x ∈ {0, 1}n , and deletes
each bit independently with probability q, yielding a shorter string. The trace
reconstruction problem is to recover an unknown string x from many independent
outputs (called “traces”) of the deletion channel applied to x.
1/2
We show that if x is drawn uniformly at random and q < 1/2, then eO(log n)
traces suffice to reconstruct x with high probability. The previous best bound,
established in 2008 by Holenstein, Mitzenmacher, Panigrahy, and Wieder [5],
uses nO(1) traces and only applies for q less than a smaller threshold (it seems
that q < 0.07 is needed).
Our algorithm combines several ideas: 1) an alignment scheme for “greedily”
fitting the output of the deletion channel as a subsequence of the input; 2) a
version of the idea of “an
Original label:  math.AC
Predicted label:  1
Correct label:  9
Text:  [CLS] on bergeron ’ s positivity problem for q - binomial coefficients arxiv : 1709. 06187v1 [ math. co ] 18 sep 2017 fabrizio zanello a + d abstract. f. bergeron recently asked the intriguing question whether b + c b q− d q has nonnegative coefficients as a polynomial in q, whenever a, b, c, d are positive integers, a is the smallest, and ad = bc. we conjecture that, in fact, this polynomial is also always unimodal, and combinatorially show our conjecture for a ≤ 3 and any b, c ≥ 4. the main ingredient will be a novel ( and rather technical ) application of zeilberger ’ s koh theorem. 1. introduction an interesting problem recently posed by f. bergeron [ 1 ], which naturally arose in his studies of the q - foulkes conjecture, is whether the coefficients of the symmetric polynomial b + c a + d − always form a nonnegative sequence, for any choice of positive integers a, b, c, d b q d q where a is the smallest and ad = bc. here, m + n as usual denotes the q - binomial coefficient m q ( 1 − q ) ( 1 − q 2 ) · · · ( 1 − q m + n ). ( 1 − q ) ( 1 − q 2 ) · · · ( 1 − q m ) · ( 1 − q ) ( 1 − q 2 ) · · · ( 1 − q n ) it is easily seen that m + n is a symmetric polynomial in q of degree mn. m q in this note, we conjecture the following stronger fact, and provide a combinatorial proof of our conjecture for a ≤ 3 and any b, c ≥ 4. recall that a sequence of numbers is unimodal if it does not increase strictly after a strict decrease. conjecture 1. 1. fix any positive integers a, b, c, d such that a is the smallest and ad = bc. then the coefficients of the symmetric polynomial a + d b + c − d b q q are nonnegative and unimodal. notice that symmetry is clear, since both b + c and a + d are symmetric polynomials of b q d q the same degree, bc = ad. also note that the case a = 1 of the conjecture is trivial, thanks to the unimodality of b + c ( see e. g. [ 3, [SEP]
Text from DS:  ON BERGERON’S POSITIVITY PROBLEM
FOR q-BINOMIAL COEFFICIENTS

arXiv:1709.06187v1 [math.CO] 18 Sep 2017

FABRIZIO ZANELLO


a+d
Abstract. F. Bergeron recently asked the intriguing question whether b+c
b q−
d q has
nonnegative coefficients as a polynomial in q, whenever a, b, c, d are positive integers, a is the
smallest, and ad = bc. We conjecture that, in fact, this polynomial is also always unimodal,
and combinatorially show our conjecture for a ≤ 3 and any b, c ≥ 4. The main ingredient
will be a novel (and rather technical) application of Zeilberger’s KOH theorem.

1. Introduction
An interesting problem recently posed by F. Bergeron [1], which naturally arose in his
studies of the q-Foulkes conjecture, is whether the coefficients of the symmetric polynomial


b+c
a+d
−
always form a nonnegative sequence, for any choice of positive integers a, b, c, d
b q
d q

where a is the smallest and ad = bc. Here, m+n
as usual denotes the q-binomial coefficient
m q

(1 − q)(1 − q 2 ) · · · (
Original label:  math.AC
Predicted label:  1
Correct label:  9
Text:  [CLS] a commutative bezout domain in which every maximal ideal is principal is an elementary divisor ring arxiv : 1210. 8104v1 [ math. ra ] 30 oct 2012 zabavsky bogdan department of algebra and logic, ivan franko national university of l ’ viv, ukraine october, 2012 abstract : in this article we revisit a problem regarding bezout domains, namely, whether every bezout domain is an elementary divisor domain. we prove that a bezout domain in which every maximal ideal is principal is an elementary divisor ring. all rings considered will be commutative and have the identity. a ring is a bezout ring if every its finitely generated ideal is a principal. kaplansky [ 1 ] defined the class of elementary divisor rings as those rings r for which every matrix m over r admits a diagonal reduction, that is there exist invertible ( unimodular ) matrices p and q such that p mq is a diagonal matrix d = ( dii ), which the property that every dii is a divisor of di + 1, i + 1. he showed that if r is an elementary divisor domain, then every finitely presented module over r is a direct sum of cyclic modules. it was later shown in [ 2 ] that the converse is true answering a question of warfield [ 3 ]. a ring r is fractionaly regular if for every non - zero element a from r the classical quotient ring qcl ( r / rad ( ar ) ) is regular [ 4 ]. we say the ring r has stable range 2 if whenever ar + br + cr = r, then there are x, y ∈ r such that ( a + cx ) r + ( b + cy ) r = r [ 4 ]. we say r is a reduced ring if it has no nilpotent elements other than 0. of course, this is equivalent to saying that the intersection of the minimal prime ideals of r is 0. for every ideal i in r we define the annihilator of i by i [UNK] = { x ∈ r | ix = 0, [UNK] ∈ i }. the nilradical of r is denoted by rad ( r ) and we denote by qcl ( r ) the classical ring of quotients of r. following faith [ 5 ] a ring r is zip if i is an ideal and if i [UNK] = 0 [SEP]
Text from DS:  A commutative Bezout domain in which every maximal ideal is
principal is an elementary divisor ring

arXiv:1210.8104v1 [math.RA] 30 Oct 2012

Zabavsky Bogdan
Department of Algebra and Logic, Ivan Franko National University of L’viv, Ukraine
October, 2012
Abstract: In this article we revisit a problem regarding Bezout domains, namely, whether
every Bezout domain is an elementary divisor domain. We prove that a Bezout domain
in which every maximal ideal is principal is an elementary divisor ring.

All rings considered will be commutative and have the identity. A ring is
a Bezout ring if every its finitely generated ideal is a principal.
Kaplansky [1] defined the class of elementary divisor rings as those rings
R for which every matrix M over R admits a diagonal reduction, that is there
exist invertible (unimodular) matrices P and Q such that P MQ is a diagonal
matrix D = (dii ), which the property that every dii is a divisor of di+1,i+1 .
He showed that if R is an elementary divisor doma
Original label:  cs.DS
Predicted label:  2
Correct label:  3
Text:  [CLS] paolo magrassi 2010 - creative commons attribution - non - commercial - share alike 3. 0 how complexity will transform enterprise information systems paolo magrassi - march, 2010 – v4. 1 info @ magrassi. net abstract one “ problem ” with the 21st century world, particularly the economic and business worlds, is the phenomenal and increasing number of interconnections between economic agents ( consumers, firms, banks, markets, national economies ). this implies that such agents are all interacting and consequently giving raise to enormous degrees of non - linearity, a. k. a. complexity. complexity often brings with it unexpected phenomena, such as chaos and emerging behaviour, that can become challenges for the survival of economic agents and systems. developing econophysics approaches are beginning to apply, to the “ economic web ”, methods and models that have been used in physics and / or systems theory to tackle non - linear domains. the paper gives an account of the research in progress in this field and shows its implications for enteprise information systems, anticipating the emergence of software that will allow to reflect the complexity of the business world, as holistic risk management becomes a mandate for financial institutions and business organizations. keywords : complexity – nonlinearity – econophysics – rational expectations – risk – business intelligence – corporate performance management linearity the “ systems ” and the “ problems ” that are encountered in nature are essentially non - linear. however, to simplify the studies or for application purposes, one often resorts to linearity as a first - order approximation : if the effects of non - linearity can be considered negligible, a mathematical model can be built that represents the system as if it were linear. this approach is fecund in many situations. as an example : an audio amplifier is intrinsically nonlinear but, within certain frequency limits, it will behave in a linear fashion and be useful for hi - fi ; hence, its description throughout audio and hi - fi literature will always be that of a linear system, even if in principle it is not. linear models are useful because subject to the hypothesis of linearity many natural systems resemble one another : their behaviour can be described with the same equations even if the contexts are very different, such as mechanics, electronics, chemistry, biology, economics, and so on. a linear oscillator is a model described by the same mathematical equation, whether it be a metal spring, an electric circuit or a standalone el nino. ( complex systems, on the contrary, [SEP]
Text from DS:  Paolo Magrassi 2010 - Creative Commons Attribution-Non-Commercial-Share Alike 3.0

How Complexity Will Transform Enterprise Information Systems
Paolo Magrassi - March, 2010 – v4.1
info@magrassi.net

Abstract
One “problem” with the 21st century world, particularly the economic and business worlds, is the phenomenal and
increasing number of interconnections between economic agents (consumers, firms, banks, markets, national economies).
This implies that such agents are all interacting and consequently giving raise to enormous degrees of non-linearity, a.k.a.
complexity. Complexity often brings with it unexpected phenomena, such as chaos and emerging behaviour, that can become
challenges for the survival of economic agents and systems. Developing econophysics approaches are beginning to apply, to
the “economic web”, methods and models that have been used in physics and/or systems theory to tackle non-linear domains.
The paper gives an account of the research in progress in this field and 
Original label:  cs.NE
Predicted label:  10
Correct label:  7
Text:  [CLS] arxiv : 1804. 00815v1 [ cs. lg ] 3 apr 2018 convolutional neural networks regularized by correlated noise shamak dutta, bryan tripp graham w. taylor systems design engineering & center for theoretical neuroscience university of waterloo waterloo, canada { s7dutta, bptripp } @ uwaterloo. ca school of engineering, university of guelph vector institute for artificial intelligence canadian institute for advanced research gwtaylor @ uoguelph. ca abstract — neurons in the visual cortex are correlated in their variability. the presence of correlation impacts cortical processing because noise cannot be averaged out over many neurons. in an effort to understand the functional purpose of correlated variability, we implement and evaluate correlated noise models in deep convolutional neural networks. inspired by the cortex, correlation is defined as a function of the distance between neurons and their selectivity. we show how to sample from high - dimensional correlated distributions while keeping the procedure differentiable, so that back - propagation can proceed as usual. the impact of correlated variability is evaluated on the classification of occluded and non - occluded images with and without the presence of other regularization techniques, such as dropout. more work is needed to understand the effects of correlations in various conditions, however in 10 / 12 of the cases we studied, the best performance on occluded images was obtained from a model with correlated noise. index terms — correlated variability, convolutional neural networks, regularization, stochastic neurons i. i ntroduction convolutional neural networks ( cnn ) trained for object recognition tasks are similar to the visual cortex in many ways. for example, early layers show gabor - like receptive fields similar to v1 [ 1 ], late layers that are highly predictive of v4, and inferior temporal cortex ( it ) responses [ 2 ]. however, these networks lack the correlated variability of neuron responses in the human brain, among other major differences. in this paper, we discuss methods to incorporate correlated variability into deep convolutional networks and analyze its effect on recognition performance. studying stochastic neurons is interesting because the effect of stochasticity on learning and computation in artificial neural systems may help us in modeling biological neurons. in population coding schemes in the brain, the joint activities of many neurons encode the value of a quantity. one advantage of population coding is that the noise can be averaged out [SEP]
Text from DS:  arXiv:1804.00815v1 [cs.LG] 3 Apr 2018

Convolutional Neural Networks Regularized by
Correlated Noise
Shamak Dutta, Bryan Tripp

Graham W. Taylor

Systems Design Engineering & Center for Theoretical Neuroscience
University of Waterloo
Waterloo, Canada
{s7dutta,bptripp}@uwaterloo.ca

School of Engineering, University of Guelph
Vector Institute for Artificial Intelligence
Canadian Institute for Advanced Research
gwtaylor@uoguelph.ca

Abstract—Neurons in the visual cortex are correlated in
their variability. The presence of correlation impacts cortical
processing because noise cannot be averaged out over many
neurons. In an effort to understand the functional purpose of
correlated variability, we implement and evaluate correlated
noise models in deep convolutional neural networks. Inspired
by the cortex, correlation is defined as a function of the distance
between neurons and their selectivity. We show how to sample
from high-dimensional correlated distributions while keeping the
procedure
Original label:  cs.CV
Predicted label:  1
Correct label:  2
Text:  [CLS] neural 3d mesh renderer hiroharu kato1, yoshitaka ushiku1, and tatsuya harada1, 2 1 the university of tokyo, 2 riken arxiv : 1711. 07566v1 [ ] 20 nov 2017 { kato, ushiku, harada } @ mi. t. u - tokyo. ac. jp neural renderer mesh generator abstract for modeling the 3d world behind 2d images, which 3d representation is most appropriate? a polygon mesh is a promising candidate for its compactness and geometric properties. however, it is not straightforward to model a polygon mesh from 2d images using neural networks because the conversion from a mesh to an image, or rendering, involves a discrete operation called rasterization, which prevents back - propagation. therefore, in this work, we propose an approximate gradient for rasterization that enables the integration of rendering into neural networks. using this renderer, we perform single - image 3d mesh reconstruction with silhouette image supervision and our system outperforms the existing voxel - based approach. additionally, we perform gradient - based 3d mesh editing operations, such as 2d - to - 3d style transfer and 3d deepdream, with 2d supervision for the first time. these applications demonstrate the potential of the integration of a mesh renderer into neural networks and the effectiveness of our proposed renderer. image 3d mesh silhouette ground - truth loss backprop neural renderer 3d mesh style image image backprop new mesh loss figure 1. pipelines for single - image 3d mesh reconstruction ( upper ) and 2d - to - 3d style transfer ( lower ). are 3d extensions of pixels, are the most widely used format in machine learning because they can be processed by cnns [ 2, 17, 20, 24, 30, 31, 34, 35, 36 ]. however, it is difficult to process high resolution voxels because they are regularly sampled from 3d space and their memory efficiency is poor. the scalability of point clouds, which are sets of 3d points, is relatively high because point clouds are based on irregular sampling. however, textures and lighting are difficult to apply because point clouds do not have surfaces. polygon meshes, which consist of sets of vertices and surfaces, are promising because they are scalable and have surfaces. therefore, in this work, we use the polygon mesh as our 3d format. one advantage of polygon meshes over other representations in 3d understanding is its compactness. for example, to represent a large triangle, a [SEP]
Text from DS:  Neural 3D Mesh Renderer
Hiroharu Kato1 , Yoshitaka Ushiku1 , and Tatsuya Harada1,2
1
The University of Tokyo, 2 RIKEN

arXiv:1711.07566v1 [] 20 Nov 2017

{kato,ushiku,harada}@mi.t.u-tokyo.ac.jp

Neural
Renderer

Mesh
Generator

Abstract
For modeling the 3D world behind 2D images, which
3D representation is most appropriate? A polygon mesh
is a promising candidate for its compactness and geometric
properties. However, it is not straightforward to model a
polygon mesh from 2D images using neural networks because the conversion from a mesh to an image, or rendering, involves a discrete operation called rasterization,
which prevents back-propagation. Therefore, in this work,
we propose an approximate gradient for rasterization that
enables the integration of rendering into neural networks.
Using this renderer, we perform single-image 3D mesh reconstruction with silhouette image supervision and our system outperforms the existing voxel-based approach. Additionally, we perform gradient-based
Original label:  cs.PL
Predicted label:  5
Correct label:  8
Text:  [CLS] exploring content - based artwork recommendation with metadata and visual features pablo messina pontificia universidad catolica de chile santiago, chile pamessina @ uc. cl vicente dominguez pontificia universidad catolica de chile santiago, chile vidominguez @ uc. cl arxiv : 1706. 05786v3 [ cs. ir ] 23 oct 2017 christoph trattner modul university vienna, austria christoph. trattner @ modul. ac. at abstract compared to other areas, artwork recommendation has received little attention, despite the continuous growth of the artwork market. previous research has relied on ratings and metadata to make artwork recommendations, as well as visual features extracted with deep neural networks ( dnn ). however, these features have no direct interpretation to explicit visual features ( e. g. brightness, texture ) which might hinder explainability and user - acceptance. in this work, we study the impact of artwork metadata as well as visual features ( dnn - based and attractiveness - based ) for physical artwork recommendation, using images and transaction data from the ugallery online artwork store. our results indicate that : ( i ) visual features perform better than manually curated data, ( ii ) dnn - based visual features perform better than attractiveness - based ones, and ( iii ) a hybrid approach improves the performance further. our research can inform the development of new artwork recommenders relying on diverse content data. keywords recommender systems, artwork recommendation, visual features, deep neural networks acm reference format : pablo messina, vicente dominguez, denis parra, christoph trattner, and alvaro soto. 2017. exploring content - based artwork recommendation with metadata and visual features. in proceedings of acm conference, washington, dc, usa, july 2017 ( conference ’ 17 ), 3 pages. doi : 10. 475 / 123 4 1 introduction compared to markets affected by 2008 ’ s financial crisis, online artwork sales are booming due to social media and new consumption behavior of millennials. online art sales reached $ 3. 27 billions in 2015, and at the current grow rate, they will reach $ 9. 58 billion by 2020 [ 5 ]. notably, although many online businesses utilize permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. copyrights for third - party components of this work must be [SEP]
Text from DS:  Exploring Content-based Artwork Recommendation with
Metadata and Visual Features
Pablo Messina

Pontificia Universidad Catolica de
Chile
Santiago, Chile
pamessina@uc.cl

Vicente Dominguez

Pontificia Universidad Catolica de
Chile
Santiago, Chile
vidominguez@uc.cl

arXiv:1706.05786v3 [cs.IR] 23 Oct 2017

Christoph Trattner

Modul University
Vienna, Austria
christoph.trattner@modul.ac.at

ABSTRACT
Compared to other areas, artwork recommendation has received
little attention, despite the continuous growth of the artwork market. Previous research has relied on ratings and metadata to make
artwork recommendations, as well as visual features extracted with
deep neural networks (DNN). However, these features have no
direct interpretation to explicit visual features (e.g. brightness,
texture) which might hinder explainability and user-acceptance.
In this work, we study the impact of artwork metadata as well
as visual features (DNN-based and attractiveness-based) for physical artwork recommenda
Original label:  cs.PL
Predicted label:  2
Correct label:  9
Text:  [CLS] 1 fdd massive mimo : efficient downlink probing and uplink feedback via active channel sparsification arxiv : 1710. 07993v1 [ ] 22 oct 2017 mahdi barzegar khalilsarai∗, saeid haghighatshoar∗, xinping yi †, giuseppe caire∗ ∗ communications and information theory group, technische universitat berlin † department of electrical engineering and electronics, university of liverpool emails : ∗ { m. barzegarkhalilsarai, saeid. haghighatshoar, caire } @ tu - berlin. de, † xinping. yi @ liverpool. ac. uk abstract — in this paper, we propose a novel method for efficient implementation of a massive multiple - input multipleoutput ( massive mimo ) system with frequency division duplexing ( fdd ) operation. our main objective is to reduce the large overhead incurred by downlink ( dl ) common training and uplink ( ul ) feedback needed to obtain channel state information ( csi ) at the base station. our proposed scheme relies on the fact that the underlying angular distribution of a channel vector, also known as the angular scattering function, is a frequency - invariant entity yielding a ul - dl reciprocity and has a limited angular support. we estimate this support from ul csi and interpolate it to obtain the corresponding angular support of the dl channel. finally we exploit the estimated support of the dl channel of all the users to design an efficient channel probing and feedback scheme that maximizes the total spectral efficiency of the system. our method is different from the existing compressed - sensing ( cs ) based techniques in the literature. using support information helps reduce the feedback overhead from o ( s log m ) in cs techniques to o ( s ) in our proposed method, with s and m being sparsity order of the channel vectors and the number of base station antennas, respectively. furthermore, in order to control the channel sparsity and therefore the dl common training and ul feedback overhead, we introduce the novel concept of active channel sparsification. in brief, when the fixed pilot dimension is less than the required amount for reliable channel estimation, we introduce a pre - beamforming matrix that artificially reduces the effective channel dimension of each user to be not larger than the dl pilot dimension, while maximizing both the number of served users and the number of probed angles. we provide numerical experiments to assess the performance of our method and [SEP]
Text from DS:  1

FDD Massive MIMO: Efficient Downlink
Probing and Uplink Feedback via Active Channel
Sparsification

arXiv:1710.07993v1 [] 22 Oct 2017

Mahdi Barzegar Khalilsarai∗ , Saeid Haghighatshoar∗ , Xinping Yi† , Giuseppe Caire∗
∗ Communications and Information Theory Group, Technische Universität Berlin
† Department of Electrical Engineering and Electronics, University of Liverpool
Emails: ∗ {m.barzegarkhalilsarai, saeid.haghighatshoar, caire}@tu-berlin.de, † xinping.yi@liverpool.ac.uk

Abstract—In this paper, we propose a novel method for
efficient implementation of a massive Multiple-Input MultipleOutput (massive MIMO) system with Frequency Division Duplexing (FDD) operation. Our main objective is to reduce the
large overhead incurred by Downlink (DL) common training
and Uplink (UL) feedback needed to obtain channel state
information (CSI) at the base station. Our proposed scheme
relies on the fact that the underlying angular distribution
of a channel vector, also known as the angular sca
Original label:  math.GR
Predicted label:  8
Correct label:  10
Text:  [CLS] arxiv : 1510. 00897v3 [ math. rt ] 15 oct 2016 on spectra of koopman, groupoid and quasi - regular representations. artem dudko stony brook university, stony brook, ny, usa artem. dudko @ stonybrook. edu rostislav grigorchuk texas a & m university, college station, tx, usa grigorch @ math. tamu. edu 1 introduction. the study of spectra of operators of unitary group representations has a long history, remarkable achievements and numerous applications. for instance, the famous kadison - kaplanski conjecture which was proven for the case of amenable groups by higson and kasparov in [ 32 ] asserts that for a torsion free group g and an element m ∈ c [ g ] of the group algebra of g the spectrum of λg ( m ) is connected, where λg is the left regular representation of g. the remarkable kesten ’ s criterion of amenability and the fundamental property ( t ) of kazhdan can be formulated in terms of spectral properties of operators of the form λg ( m ). the topic in discussion is related to the spectral theory of graphs and networks, random walks, theory of operator algebras, discrete potential theory, abstract harmonic analysis etc. there are three important types of unitary representations associated to a measure class preserving action of a countable group g on a probability space ( x, µ ) : quasi - regular, koopman and groupoid representations. the goal of this article is to show that there is a close relation between spectral properties of these three types of representations. for a subgroup h < g the quasi - regular representation ρg / h acting on l2 ( g / h ) is a natural generalization of the regular representation λg. in the case of a group action ( g, x, µ ) such representations appear as permutational representations ρx in l2 ( gx ) for the action of g on orbits gx, x ∈ x. spectra of quasi - regular representations play an both authors were supported by the swiss national science foundation the second author was supported by nsf grant dms - 1207699 and nsa grant h98230 - 15 - 1 - 0328 1 important role in random walks on groups and schreier graphs ( see e. g. [ 37 ] ). quasiregular representations naturally give rise to hecke algebras and their [SEP]
Text from DS:  arXiv:1510.00897v3 [math.RT] 15 Oct 2016

On spectra of Koopman, groupoid and quasi-regular
representations.
Artem Dudko
Stony Brook University, Stony Brook, NY, USA
artem.dudko@stonybrook.edu
Rostislav Grigorchuk
Texas A&M University, College Station, TX, USA
grigorch@math.tamu.edu

1

Introduction.

The study of spectra of operators of unitary group representations has a long history, remarkable achievements and numerous applications. For instance, the famous
Kadison-Kaplanski Conjecture which was proven for the case of amenable groups by
Higson and Kasparov in [32] asserts that for a torsion free group G and an element
m ∈ C[G] of the group algebra of G the spectrum of λG (m) is connected, where λG is
the left regular representation of G. The remarkable Kesten’s criterion of amenability
and the fundamental property (T ) of Kazhdan can be formulated in terms of spectral
properties of operators of the form λG (m). The topic in discussion is related to the
spectral theory of graphs and
Original label:  cs.PL
Predicted label:  10
Correct label:  0
Text:  [CLS] 1 a conditional information inequality and its combinatorial applications tarik kaced, andrei romashchenko, and nikolay vereshchagin arxiv : 1501. 04867v4 [ ] 13 sep 2017 abstract we show that the inequality h ( a | b, x ) + h ( a | b, y ) 6 h ( a | b ) for jointly distributed random variables a, b, x, y, which does not hold in general case, holds under some natural condition on the support of the probability distribution of a, b, x, y. this result generalizes a version of the conditional ingleton inequality : if for some distribution i ( x : y | a ) = h ( a | x, y ) = 0, then i ( a : b ) 6 i ( a : b | x ) + i ( a : b | y ) + i ( x : y ). we present two applications of our result. the first one is the following easy - to - formulate theorem on edge colorings of bipartite graphs : assume that the edges of a bipartite graph are colored in k colors so that each two edges sharing a vertex have different colors and for each pair ( left vertex x, right vertex y ) there is at most one color a such both x and y are incident to edges with color a ; assume further that the degree of each left vertex is at least l and the degree of each right vertex is at least r. then k > lr. the second application is a new method to prove lower bounds for biclique cover of bipartite graphs. keywords shannon entropy, conditional information inequalities, non shannon type information inequalities, biclique cover, edge coloring i. i ntroduction the most general and fundamental properties of shannon ’ s entropy can be expressed in the language of linear inequalities. the usual universal information inequalities ( the linear inequalities that hold for shannon ’ s entropies of jointly distributed tuples of random variables for every distribution ) have many equivalent characterizations and interpretations in very different areas — these inequalities can be equivalently reformulated in the settings of kolmogorov complexity and group theory ; they give characterizations of the network coding capacity rates, of the cardinalities of projections of finite sets, etc., see the surveys in [ 11 ], [ 22 ]. the parallel and interplay between different “ incarnations ” of information in [SEP]
Text from DS:  1

A Conditional Information Inequality and its
Combinatorial Applications
Tarik Kaced, Andrei Romashchenko, and Nikolay Vereshchagin

arXiv:1501.04867v4 [] 13 Sep 2017

Abstract
We show that the inequality H(A|B, X) + H(A|B, Y ) 6 H(A|B) for jointly distributed random variables A, B, X, Y , which
does not hold in general case, holds under some natural condition on the support of the probability distribution of A, B, X, Y . This
result generalizes a version of the conditional Ingleton inequality: if for some distribution I(X : Y |A) = H(A|X, Y ) = 0, then
I(A : B) 6 I(A : B|X) + I(A : B|Y ) + I(X : Y ).
We present two applications of our result. The first one is the following easy-to-formulate theorem on edge colorings of bipartite
graphs: assume that the edges of a bipartite graph are colored in K colors so that each two edges sharing a vertex have different
colors and for each pair (left vertex x, right vertex y) there is at most one color a such both x and y are incident to edges wi
Original label:  math.GR
Predicted label:  2
Correct label:  1
Text:  [CLS] on the quasi - isometric classification of locally compact groups arxiv : 1212. 2229v3 [ ] 11 jun 2016 yves cornulier abstract. this ( quasi - ) survey addresses the quasi - isometry classification of locally compact groups, with an emphasis on amenable hyperbolic locally compact groups. this encompasses the problem of quasi - isometry classification of homogeneous negatively curved manifolds. a main conjecture provides a general description ; an extended discussion reduces this conjecture to more specific statements. in the course of the paper, we provide statements of quasi - isometric rigidity for general symmetric spaces of noncompact type and also discuss accessibility issues in the realm of compactly generated locally compact groups. 1. introduction 1. a. locally compact groups as geometric objects. it has long been well understood in harmonic analysis ( notably in the study of unitary representations ) that locally compact groups are the natural objects unifying the setting of connected lie groups and discrete groups. in the context of geometric group theory, this is still far from universal. for a long period, notably in the 70s, this unifying point of view was used essentially by herbert abels, and, more occasionally, some other people including behr, guivarc ’ h, houghton. the considerable influence of gromov ’ s work paradoxically favored the bipolar point of view discrete vs continuous, although gromov ’ s ideas were applicable to the setting of locally compact groups and were sometimes stated ( especially in [ gr87 ] ) in an even greater generality. if a locally compact group is generated by a compact subset s, it can be endowed with the word length with respect to s, and with the corresponding left - invariant distance. while this distance depends on the choice of s, the metric space ( g, ds ) — or the 1 - skeleton of the corresponding cayley graph — is uniquely determined by g up to quasi - isometry, in the sense that if t is another compact generating subset, the identity map ( g, ds ) → ( g, dt ) is a quasi - isometry. we use the usual notion of gromov - hyperbolicity [ gr87 ] for geodesic metric spaces, which we simply call “ hyperbolic ” ; this is a quasi - isometry invariant. a locally compact group is called hyperbolic if it is compactly generated and if its cayley graph with respect to some / any compact generating subset is hyperbolic. this paper is mainly concerned with the quasi - [SEP]
Text from DS:  ON THE QUASI-ISOMETRIC CLASSIFICATION OF LOCALLY
COMPACT GROUPS

arXiv:1212.2229v3 [] 11 Jun 2016

YVES CORNULIER
Abstract. This (quasi-)survey addresses the quasi-isometry classification of locally compact groups, with an emphasis on amenable hyperbolic locally compact
groups. This encompasses the problem of quasi-isometry classification of homogeneous negatively curved manifolds. A main conjecture provides a general description; an extended discussion reduces this conjecture to more specific statements.
In the course of the paper, we provide statements of quasi-isometric rigidity for
general symmetric spaces of noncompact type and also discuss accessibility issues
in the realm of compactly generated locally compact groups.

1. Introduction
1.A. Locally compact groups as geometric objects. It has long been well
understood in harmonic analysis (notably in the study of unitary representations)
that locally compact groups are the natural objects unifying the setting of connected
Lie grou
Original label:  math.AC
Predicted label:  2
Correct label:  1
Text:  [CLS] dimensional differences between faces of the cones of nonnegative polynomials and sums of squares arxiv : 1305. 0642v1 [ math. ag ] 3 may 2013 grigoriy blekherman, sadik iliman, martina kubitzke abstract. we study dimensions of the faces of the cone of nonnegative polynomials and the cone of sums of squares ; we show that there are dimensional differences between corresponding faces of these cones. these dimensional gaps occur in all cases where there exist nonnegative polynomials that are not sums of squares. the gaps occur generically, they are not the product of selecting special faces of the cones. for ternary forms and quaternary quartics, we completely characterize when these differences are observed. moreover, we provide an explicit description for these differences in the two smallest cases, in which the cone of nonnegative polynomials and the cone of sums of squares are different. our results follow from more general results concerning the relationship between the second ordinary power and the second symbolic power of the vanishing ideal of points in projective space. 1. introduction let hn, 2d denote the set of homogeneous polynomials ( forms ) in n variables of degree 2d over r and let rpn−1 resp. cpn−1 denote the ( n − 1 ) - dimensional real resp. complex projective space. for a fixed number of variables n and degree 2d, nonnegative polynomials and sums of squares form closed convex cones in hn, 2d. we call these cones pn, 2d and σn, 2d, respectively, i. e., pn, 2d = p ∈ hn, 2d | p ( x ) ≥ 0 for all x ∈ rpn−1, n o x σn, 2d = p ∈ pn, 2d | p ( x ) = qi2 for some qi ∈ hn, d. the relationship between the cone of nonnegative polynomials and the cone of sums of squares has been studied since hilbert ’ s seminal paper in 1888 [ 11 ]. in this article, hilbert showed that a nonnegative form in n variables of even degree 2d has to be a sum of squares of forms only in the following cases : the form is bivariate, i. e., n = 2, the form is quadratic, i. e., 2d = 2, or the form is a ternary quartic, i. e., n = 3 and 2d = 4. in all other cases, he proved existence [SEP]
Text from DS:  DIMENSIONAL DIFFERENCES BETWEEN FACES OF THE CONES OF
NONNEGATIVE POLYNOMIALS AND SUMS OF SQUARES

arXiv:1305.0642v1 [math.AG] 3 May 2013

GRIGORIY BLEKHERMAN, SADIK ILIMAN, MARTINA KUBITZKE
Abstract. We study dimensions of the faces of the cone of nonnegative polynomials and the cone
of sums of squares; we show that there are dimensional differences between corresponding faces of
these cones. These dimensional gaps occur in all cases where there exist nonnegative polynomials
that are not sums of squares. The gaps occur generically, they are not the product of selecting special
faces of the cones. For ternary forms and quaternary quartics, we completely characterize when
these differences are observed. Moreover, we provide an explicit description for these differences
in the two smallest cases, in which the cone of nonnegative polynomials and the cone of sums
of squares are different. Our results follow from more general results concerning the relationship
between the second ordinary p
Original label:  cs.SY
Predicted label:  6
Correct label:  8
Text:  [CLS] accepted for publication in ieee transactions on power systems 1 convex relaxations of chance constrained ac optimal power flow arxiv : 1702. 08372v3 [ ] 4 oct 2017 andreas venzke, student member, ieee, lejla halilbasic, student member, ieee, uros markovic, student member, ieee, gabriela hug, senior member, ieee, and spyros chatzivasileiadis, member, ieee abstract — high penetration of renewable energy sources and the increasing share of stochastic loads require the explicit representation of uncertainty in tools such as the optimal power flow ( opf ). current approaches follow either a linearized approach or an iterative approximation of non - linearities. this paper proposes a semidefinite relaxation of a chance constrained ac - opf which is able to provide guarantees for global optimality. using a piecewise affine policy, we can ensure tractability, accurately model large power deviations, and determine suitable corrective control policies for active power, reactive power, and voltage. we state a tractable formulation for two types of uncertainty sets. using a scenario - based approach and making no prior assumptions about the probability distribution of the forecast errors, we obtain a robust formulation for a rectangular uncertainty set. alternatively, assuming a gaussian distribution of the forecast errors, we propose an analytical reformulation of the chance constraints suitable for semidefinite programming. we demonstrate the performance of our approach on the ieee 24 and 118 bus system using realistic day - ahead forecast data and obtain tight near - global optimality guarantees. index terms — ac optimal power flow, convex optimization, chance constraints, semidefinite programming, uncertainty. i. i ntroduction p ower system operators have to deal with higher degrees of uncertainty in operation and planning. if uncertainty is not explicitly considered, increasing shares of unpredictable renewable generation and stochastic loads, such as electric vehicles, can lead to higher costs and jeopardize system security. the scope of this work is to introduce a convex ac optimal power flow ( opf ) formulation which is able to accurately model the effect of forecast errors on the power flow, can define a - priori suitable corrective control policies for active power, reactive power, and voltage, and can provide near - global optimality guarantees. chance constraints are included in the opf formulation to account for uncertainty in power injections, defining a maximum allowable probability of constraint violation. it is generally agreed that the non - linear nature of the ac [SEP]
Text from DS:  ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON POWER SYSTEMS

1

Convex Relaxations of Chance Constrained
AC Optimal Power Flow

arXiv:1702.08372v3 [] 4 Oct 2017

Andreas Venzke, Student Member, IEEE, Lejla Halilbasic, Student Member, IEEE, Uros Markovic, Student
Member, IEEE, Gabriela Hug, Senior Member, IEEE, and Spyros Chatzivasileiadis, Member, IEEE

Abstract—High penetration of renewable energy sources and
the increasing share of stochastic loads require the explicit representation of uncertainty in tools such as the optimal power flow
(OPF). Current approaches follow either a linearized approach or
an iterative approximation of non-linearities. This paper proposes
a semidefinite relaxation of a chance constrained AC-OPF which
is able to provide guarantees for global optimality. Using a
piecewise affine policy, we can ensure tractability, accurately
model large power deviations, and determine suitable corrective
control policies for active power, reactive power, and voltage.
We 
Original label:  math.AC
Predicted label:  0
Correct label:  4
Text:  [CLS] arxiv : 1802. 03035v1 [ ] 8 feb 2018 on the lex - plus - powers conjecture giulio caviglia and alessio sammartano abstract. let s be a polynomial ring over a field and i ⊆ s a homogeneous ideal containing a regular sequence of forms of degrees d1,..., dc. in this paper we prove the lex - plus - powers conjecture when the field has characteristic 0 p for all regular sequences such that di ≥ i−1 j = 1 ( dj − 1 ) + 1 for each i ; that is, we show that the betti table of i is bounded above by the betti table of the lex - plus - powers ideal of i. 1. introduction let s be a polynomial ring over a field. the celebrated theorem of macaulay [ 22 ] asserts the existence of a one - to - one correspondence between hilbert functions of homogeneous ideals in s and lex ideals, i. e. ideals which in each degree are generated by an initial segment of monomials in the lexicographic order. the result may be phrased equivalently in terms of bounds for the growth of the graded components of an ideal, or as the statement that lex ideals have the largest number of minimal generators β0, j allowed by their hilbert function in each degree j. an elegant generalization of this result is the bigatti - hulett - pardue theorem [ 2, 21, 28 ], which states that in fact lex ideals have the largest possible graded betti numbers βi, j in every homological degree i and internal degree j, yielding thus a unique maximal element in the poset of betti tables for each hilbert function. a crucial tool in both theorems is the use of grobner deformations, which allow to build a flat family connecting an arbitrary homogeneous ideal to a monomial ideal fixed under the action of the borel group. in several geometric situations, related e. g. to questions about configurations of points in pm or hilbert schemes of projective varieties other than pm, it is desirable to have refinements of these two theorems which take into account not just the numerical data of an ideal, but more precise information about its structure. with these regards, there are two long standing conjectures on the graded invariants of a homogeneous ideal containing a regular sequence of known degrees : the eisenbudgreen - harris conjecture and the lex - plus - powers conjecture. the first conjecture was proposed in [ 12, 13 ] with the [SEP]
Text from DS:  arXiv:1802.03035v1 [] 8 Feb 2018

ON THE LEX-PLUS-POWERS CONJECTURE
GIULIO CAVIGLIA AND ALESSIO SAMMARTANO
Abstract. Let S be a polynomial ring over a field and I ⊆ S a homogeneous
ideal containing a regular sequence of forms of degrees d1 , . . . , dc . In this paper
we prove the Lex-plus-powers Conjecture when the field has characteristic 0
P
for all regular sequences such that di ≥ i−1
j=1 (dj − 1) + 1 for each i; that is,
we show that the Betti table of I is bounded above by the Betti table of the
lex-plus-powers ideal of I.

1. Introduction
Let S be a polynomial ring over a field. The celebrated theorem of Macaulay
[22] asserts the existence of a one-to-one correspondence between Hilbert functions
of homogeneous ideals in S and lex ideals, i.e. ideals which in each degree are
generated by an initial segment of monomials in the lexicographic order. The
result may be phrased equivalently in terms of bounds for the growth of the graded
components of an ideal, or as the statement that
Original label:  cs.CE
Predicted label:  7
Correct label:  3
Text:  [CLS] logical methods in computer science vol. 9 ( 4 : 23 ) 2013, pp. 1 – 36 www. lmcs - online. org submitted published oct. 20, 2011 dec. 17, 2013 handling algebraic effects ∗ gordon d. plotkin a and matija pretnar b a laboratory for foundations of computer science, school of informatics, university of edinburgh, scotland e - mail address : gdp @ inf. ed. ac. uk b faculty of mathematics and physics, university of ljubljana, slovenia e - mail address : matija. pretnar @ fmf. uni - lj. si abstract. algebraic effects are computational effects that can be represented by an equational theory whose operations produce the effects at hand. the free model of this theory induces the expected computational monad for the corresponding effect. algebraic effects include exceptions, state, nondeterminism, interactive input / output, and time, and their combinations. exception handling, however, has so far received no algebraic treatment. we present such a treatment, in which each handler yields a model of the theory for exceptions, and each handling construct yields the homomorphism induced by the universal property of the free model. we further generalise exception handlers to arbitrary algebraic effects. the resulting programming construct includes many previously unrelated examples from both theory and practice, including relabelling and restriction in milner ’ s ccs, timeout, rollback, and stream redirection. introduction in seminal work [ 13 ], moggi proposed a uniform representation of computational effects by monads [ 1 ]. for example, working in the category of sets, a computation that returns values from a set a is modelled by an element of t a for a suitable monad t. examples of such effects include exceptions, state, nondeterminism, interactive input / output, time, continuations, and combinations of them. later, plotkin and power proposed to represent effects by ( 1 ) a set of operations that represent the sources of effects ; and ( 2 ) an equational theory for these operations that describes their properties [ 19 ]. the basic operational intuition is that each computation either returns a value or performs an operation with an outcome that determines a continuation of the computation. the arguments of the operation represent the possible continuations. for example, using a 2012 acm ccs : [ theory of computation ] : semantics and reasoning — program constructs ; semantics and reasoning — program semantics — algebraic semantics. key words and phrases : algebraic effects, exception [SEP]
Text from DS:  Logical Methods in Computer Science
Vol. 9(4:23)2013, pp. 1–36
www.lmcs-online.org

Submitted
Published

Oct. 20, 2011
Dec. 17, 2013

HANDLING ALGEBRAIC EFFECTS ∗
GORDON D. PLOTKIN a AND MATIJA PRETNAR b
a

Laboratory for Foundations of Computer Science, School of Informatics, University of Edinburgh,
Scotland
e-mail address: gdp@inf.ed.ac.uk

b

Faculty of Mathematics and Physics, University of Ljubljana, Slovenia
e-mail address: matija.pretnar@fmf.uni-lj.si
Abstract. Algebraic effects are computational effects that can be represented by an equational theory whose operations produce the effects at hand. The free model of this theory
induces the expected computational monad for the corresponding effect. Algebraic effects
include exceptions, state, nondeterminism, interactive input/output, and time, and their
combinations. Exception handling, however, has so far received no algebraic treatment.
We present such a treatment, in which each handler yields a model of the theory for exception
Original label:  cs.AI
Predicted label:  9
Correct label:  3
Text:  [CLS] multiagent bidirectionally - coordinated nets emergence of human - level coordination in learning to play starcraft combat games∗ peng peng \, ying wen § †, yaodong yang §, yuan quan \, zhenkun tang \, haitao long \, jun wang § arxiv : 1703. 10069v4 [ ] 14 sep 2017 § university college london, \ alibaba group abstract many artificial intelligence ( ai ) applications often require multiple intelligent agents to work in a collaborative effort. efficient learning for intra - agent communication and coordination is an indispensable step towards general ai. in this paper, we take starcraft combat game as a case study, where the task is to coordinate multiple agents as a team to defeat their enemies. to maintain a scalable yet effective communication protocol, we introduce a multiagent bidirectionallycoordinated network ( bicnet [ ’ biknet ] ) with a vectorised extension of actor - critic formulation. we show that bicnet can handle different types of combats with arbitrary numbers of ai agents for both sides. our analysis demonstrates that without any supervisions such as human demonstrations or labelled data, bicnet could learn various types of advanced coordination strategies that have been commonly used by experienced game players. in our experiments, we evaluate our approach against multiple baselines under different scenarios ; it shows state - of - the - art performance, and possesses potential values for large - scale real - world applications. introduction the last decade has witnessed massive progresses in the field of artificial intelligence ( ai ). with supervision from labelled data, machines have, to some extent, exceeded humanlevel perception on visual recognitions and speech recognitions, while fed with feedback reward, single ai units ( aka agents ) defeat humans in various games including atari video games ( mnih et al. 2015 ), go game ( silver et al. 2016 ), and card game ( brown and sandholm 2017 ). yet, true human intelligence embraces social and collective wisdom which lays an essential foundation for reaching the grand goal of artificial general intelligence ( agi ) ( goertzel and pennachin 2007 ). as demonstrated by crowd sourcing, aggregating efforts collectively from the public would solve the problem that otherwise is unthinkable by a single person. even social animals like a brood of well - organised ants could accomplish challenging tasks such as hunting, building a kingdom, and even waging a war, although each ant by itself is weak and limited. interesting [SEP]
Text from DS:  Multiagent Bidirectionally-Coordinated Nets
Emergence of Human-level Coordination in Learning to Play StarCraft Combat Games∗
Peng Peng\ , Ying Wen§† , Yaodong Yang§ , Yuan Quan\ , Zhenkun Tang\ , Haitao Long\ , Jun Wang§

arXiv:1703.10069v4 [] 14 Sep 2017

§

University College London, \ Alibaba Group

Abstract
Many artificial intelligence (AI) applications often require
multiple intelligent agents to work in a collaborative effort.
Efficient learning for intra-agent communication and coordination is an indispensable step towards general AI. In this
paper, we take StarCraft combat game as a case study, where
the task is to coordinate multiple agents as a team to defeat
their enemies. To maintain a scalable yet effective communication protocol, we introduce a Multiagent BidirectionallyCoordinated Network (BiCNet [’bIknet]) with a vectorised
extension of actor-critic formulation. We show that BiCNet
can handle different types of combats with arbitrary numbers
of AI agents for both sides
Original label:  cs.CV
Predicted label:  6
Correct label:  2
Text:  [CLS] joint voxel and coordinate regression for accurate 3d facial landmark localization hongwen zhang † ‡, qi li †, zhenan sun † ‡ § † center arxiv : 1801. 09242v1 [ ] 28 jan 2018 for research on intelligent perception and computing ( cripac ) † national laboratory of pattern recognition ( nlpr ) † institute of automation, chinese academy of sciences ( casia ) ‡ university of chinese academy of sciences ( ucas ) § center for excellence in brain science and intelligence technology ( cebsit ), cas email : hongwen. zhang @ cripac. ia. ac. cn, { qli, znsun } @ nlpr. ia. ac. cn abstract — 3d face shape is more expressive and viewpointconsistent than its 2d counterpart. however, 3d facial landmark localization in a single image is challenging due to the ambiguous nature of landmarks under 3d perspective. existing approaches typically adopt a suboptimal two - step strategy, performing 2d landmark localization followed by depth estimation. in this paper, we propose the joint voxel and coordinate regression ( jvcr ) method for 3d facial landmark localization, addressing it more effectively in an end - to - end fashion. first, a compact volumetric representation is proposed to encode the per - voxel likelihood of positions being the 3d landmarks. the dimensionality of such a representation is fixed regardless of the number of target landmarks, so that the curse of dimensionality could be avoided. then, a stacked hourglass network is adopted to estimate the volumetric representation from coarse to fine, followed by a 3d convolution network that takes the estimated volume as input and regresses 3d coordinates of the face shape. in this way, the 3d structural constraints between landmarks could be learned by the neural network in a more efficient manner. moreover, the proposed pipeline enables end - to - end training and improves the robustness and accuracy of 3d facial landmark localization. the effectiveness of our approach is validated on the 3dfaw and aflw2000 - 3d datasets. experimental results show that the proposed method achieves state - of - the - art performance in comparison with existing methods. i. i ntroduction facial landmark localization has been extensively studied in the last decades and significant progress has been made on solving this problem. though impressive performance is achieved in 2d face alignment recently [ 1 ], [ 2 ], 3d landmark localization in a single image remains challenging due to the ambiguous nature of [SEP]
Text from DS:  Joint Voxel and Coordinate Regression for Accurate
3D Facial Landmark Localization
Hongwen Zhang†‡ , Qi Li† , Zhenan Sun†‡§
† Center

arXiv:1801.09242v1 [] 28 Jan 2018

for Research on Intelligent Perception and Computing (CRIPAC)
† National Laboratory of Pattern Recognition (NLPR)
† Institute of Automation, Chinese Academy of Sciences (CASIA)
‡ University of Chinese Academy of Sciences (UCAS)
§ Center for Excellence in Brain Science and Intelligence Technology (CEBSIT), CAS
Email: hongwen.zhang@cripac.ia.ac.cn, {qli, znsun}@nlpr.ia.ac.cn

Abstract—3D face shape is more expressive and viewpointconsistent than its 2D counterpart. However, 3D facial landmark
localization in a single image is challenging due to the ambiguous
nature of landmarks under 3D perspective. Existing approaches
typically adopt a suboptimal two-step strategy, performing 2D
landmark localization followed by depth estimation. In this paper,
we propose the Joint Voxel and Coordinate Regression (JVCR)
method for 3D fac
Original label:  math.ST
Predicted label:  2
Correct label:  1
Text:  [CLS] asymptotic properties of maximum likelihood estimator for the growth rate for a jump - type cir process based on continuous time observations matyas barczy∗, [UNK], mohamed ben alaya∗∗, arxiv : 1609. 05865v4 [ ] 10 aug 2017 ahmed kebaier∗∗ and gyula pap∗∗∗ * mta - szte analysis and stochastics research group, bolyai institute, university of szeged, aradi vertanuk tere 1, h – 6720 szeged, hungary. * * universite paris 13, sorbonne paris cite, laga, cnrs ( umr 7539 ), villetaneuse, france. * * * bolyai institute, university of szeged, aradi vertanuk tere 1, h – 6720 szeged, hungary. e – mails : barczy. matyas @ inf. unideb. hu ( m. barczy ), mba @ math. univ - paris13. fr ( m. ben alaya ), kebaier @ math. univ - paris13. fr ( a. kebaier ), papgy @ math. u - szeged. hu ( g. pap ). [UNK] corresponding author. abstract we consider a jump - type cox – ingersoll – ross ( cir ) process driven by a standard wiener process and a subordinator, and we study asymptotic properties of the maximum likelihood estimator ( mle ) for its growth rate. we distinguish three cases : subcritical, critical and supercritical. in the subcritical case we prove weak consistency and asymptotic normality, and, under an additional moment assumption, strong consistency as well. in the supercritical case, we prove strong consistency and mixed normal ( but non - normal ) asymptotic behavior, while in the critical case, weak consistency and non - standard asymptotic behavior are described. we specialize our results to socalled basic affine jump - diffusions as well. concerning the asymptotic behavior of the mle in the supercritical case, we derive a stochastic representation of the limiting mixed normal distribution, where the almost sure limit of an appropriately scaled jump - type supercritical cir process comes into play. this is a new phenomenon, compared to the critical case, where [SEP]
Text from DS:  Asymptotic properties of maximum likelihood estimator
for the growth rate for a jump-type CIR process
based on continuous time observations
Mátyás Barczy∗,⋄ , Mohamed Ben Alaya∗∗ ,

arXiv:1609.05865v4 [] 10 Aug 2017

Ahmed Kebaier∗∗ and Gyula Pap∗∗∗
* MTA-SZTE Analysis and Stochastics Research Group, Bolyai Institute, University of Szeged, Aradi
vértanúk tere 1, H–6720 Szeged, Hungary.
** Université Paris 13, Sorbonne Paris Cité, LAGA, CNRS (UMR 7539), Villetaneuse, France.
*** Bolyai Institute, University of Szeged, Aradi vértanúk tere 1, H–6720 Szeged, Hungary.
e–mails: barczy.matyas@inf.unideb.hu (M. Barczy),
mba@math.univ-paris13.fr (M. Ben Alaya),
kebaier@math.univ-paris13.fr (A. Kebaier),
papgy@math.u-szeged.hu (G. Pap).
⋄ Corresponding author.
Abstract
We consider a jump-type Cox–Ingersoll–Ross (CIR) process driven by a standard Wiener process and a subordinator, and we study asymptotic properties of the maximum likelihood estimator
(MLE) for its growth rate. We distingu
Original label:  cs.AI
Predicted label:  5
Correct label:  10
Text:  [CLS] a delta debugger for ilp query execution arxiv : cs / 0701105v1 [ ] 17 jan 2007 remko [UNK] and gerda janssens katholieke universiteit leuven, dept. of computer science, celestijnenlaan 200a, b - 3001 leuven, belgium { remko, gerda } @ cs. kuleuven. be abstract. because query execution is the most crucial part of inductive logic programming ( ilp ) algorithms, a lot of effort is invested in developing faster execution mechanisms. these execution mechanisms typically have a low - level implementation, making them hard to debug. moreover, other factors such as the complexity of the problems handled by ilp algorithms and size of the code base of ilp data mining systems make debugging at this level a very difficult job. in this work, we present the trace - based debugging approach currently used in the development of new execution mechanisms in hipp, the engine underlying the ace data mining system. this debugger uses the delta debugging algorithm to automatically reduce the total time needed to expose bugs in ilp execution, thus making manual debugging step much lighter. 1 introduction data mining [ 9 ] is the process of finding patterns that describe a large set of data best. inductive logic programming ( ilp ) [ 12 ] is a multi - relational data mining approach, which uses the logic programming paradigm as its basis. ilp uses a generate - and - test approach, where in each iteration a large set of hypotheses ( or ‘ queries ’ ) has to be evaluated on the data ( also called ‘ examples ’ ). based on the results of this evaluation, the ilp process selects the “ best ” hypotheses and refines them further. due to the size of the data of the problems handled by ilp, the underlying query evaluation engine ( e. g. a prolog system ) is a crucial part of a real life ilp system. hence, a lot of effort is invested in optimizing the engine to yield faster evaluation time through the use of new execution mechanisms, different internal data representations, etc. the development of new execution mechanisms for ilp happens mainly in the engine of the ilp system. these optimized execution strategies typically require a low level implementation to yield significant benefits. for example, the query pack [ 3 ] and adpack [ 17 ] execution mechanisms require the introduction of [SEP]
Text from DS:  A Delta Debugger for ILP Query Execution

arXiv:cs/0701105v1 [] 17 Jan 2007

Remko Tronçon⋆ and Gerda Janssens
Katholieke Universiteit Leuven, Dept. of Computer Science,
Celestijnenlaan 200A, B-3001 Leuven, Belgium
{remko,gerda}@cs.kuleuven.be

Abstract. Because query execution is the most crucial part of Inductive Logic Programming (ILP) algorithms, a lot of effort is invested in
developing faster execution mechanisms. These execution mechanisms
typically have a low-level implementation, making them hard to debug.
Moreover, other factors such as the complexity of the problems handled
by ILP algorithms and size of the code base of ILP data mining systems
make debugging at this level a very difficult job. In this work, we present
the trace-based debugging approach currently used in the development
of new execution mechanisms in hipP, the engine underlying the ACE
Data Mining system. This debugger uses the delta debugging algorithm
to automatically reduce the total time needed to expose
Original label:  cs.DS
Predicted label:  0
Correct label:  4
Text:  [CLS] title : green scale research tool for multi - criteria and multi - metric energy analysis performed during the architectural design process authors : holly t. ferguson b, aimee. p. c. buccellato a, samuel paolucci c, na yu c, charles f. vardeman ii b affiliations : a b c university of notre dame : school of architecture 110 bond hall, notre dame, in 46556 e - mail : abuccellato @ nd. edu university of notre dame, university of notre dame : center for research computing 111 information technology center notre dame, in 46556 e - mail : hfergus2 @ nd. edu, cvardema @ nd. edu university of notre dame : college of engineering 257 fitzpatrick hall notre dame, in 46556 e - mail : paolucci @ nd. edu, nyu @ nd. edu corresponding author ’ s details : aimee. p. c. buccellato, university of notre dame : school of architecture 314 bond hall, notre dame, in 46556. phone : ( 574 ) 631 - 1431, e - mail : abuccellato @ nd. edu name of publication : arxiv. org abstract : prevailing computational tools available to and used by architecture and engineering professionals purport to gather and present thorough and accurate perspectives of the environmental impacts associated with their contributions to the built environment. the presented research of building modeling and analysis software used by the architecture, engineering, construction, and operations ( aeco ) industry reveals that many of the most heavily relied - upon industry tools are isolated in functionality, utilize incomplete models and data, and are disruptive to normative design and building optimization workflows. this paper describes the current models and tools, their primary functions and limitations, and presents our concurrent research to develop more advanced models to assess lifetime building energy consumption alongside operating energy use. a series of case studies describes the current state - of - the - art in tools and building energy analysis followed by the research models and novel design and analysis tool that the green scale research group has developed in response. a fundamental goal of this effort is to increase the use and efficacy of building impact studies conducted by architects, engineers, and building owners and operators during the building design process. keywords : building energy analysis model ( beam ), embodied energy, lca, sustainability, sustainable data, and building information modeling ( bim ), comparative design analysis 1. introduction [SEP]
Text from DS:  Title: Green Scale Research Tool for Multi-Criteria and Multi-Metric Energy Analysis Performed During the
Architectural Design Process
Authors: Holly T. Ferguson b, Aimee. P. C. Buccellato a, Samuel Paolucci c, Na Yu c, Charles F. Vardeman II b
Affiliations:
a

b

c

University of Notre Dame: School of Architecture 110 Bond Hall, Notre Dame, IN 46556
E-mail: abuccellato@nd.edu
University of Notre Dame, University of Notre Dame: Center for Research Computing 111 Information
Technology Center Notre Dame, IN 46556
E-mail: hfergus2@nd.edu, cvardema@nd.edu
University of Notre Dame: College of Engineering 257 Fitzpatrick Hall Notre Dame, IN 46556
E-mail: paolucci@nd.edu, nyu@nd.edu

Corresponding Author’s Details: Aimee. P. C. Buccellato, University of Notre Dame: School of Architecture
314 Bond Hall, Notre Dame, IN 46556. Phone: (574) 631-1431, E-mail: abuccellato@nd.edu
Name of Publication: arXiv.org
Abstract:
Prevailing computational tools available to and used by architecture and enginee
Original label:  math.GR
Predicted label:  9
Correct label:  7
Text:  [CLS] inverted orbits of exclusion processes, diffuse - extensive - amenability and ( non -? ) amenability of the interval exchanges arxiv : 1804. 01981v1 [ ] 5 apr 2018 christophe garban abstract. the recent breakthrough works [ 6, 8, 9 ] which established the amenability for new classes of groups, lead to the following question : is the action w ( zd ) y zd extensive - amenable? ( where w ( zd ) is the wobbling group of permutations σ : zd → zd with bounded range ). this is equivalent to asking d d whether the action ( z / 2z ) ( z ) o w ( zd ) y ( z / 2z ) ( z ) is amenable. the d = 1 and d = 2 and have been settled respectively in [ 6, 8 ]. by [ 9 ], a positive answer to this question would imply the amenability of the iet group. in this work, we give a partial answer to this question by introducing a natural strengthening of the notion of extensive - amenability which we call diffuse - extensive - amenability. our main result is that for any bounded degree graph x, the action w ( x ) y x is diffuse - extensive - amenable if and only if x is recurrent. our proof is based on the construction of suitable stochastic processes ( τt ) t≥0 on w ( x ) < s ( zd ) whose inverted orbits [ ot ( x0 ) = { x ∈ x, [UNK] ≤ t, τs ( x ) = x0 } = τs−1 ( { x0 } ) 0≤s≤t are exponentially unlikely to be sub - linear when x is transient. this result leads us to conjecture that the action w ( zd ) y zd is not extensive - amenable when d ≥ 3 and that a different route towards the ( non -? ) amenability of the iet group may be needed. 1. introduction 1. 1. iet group, wobbling group w ( zd ) and criteria of amenability. the iet group ( = group of interval exchanges transformations ) is the group of cadlag piecewise - translation bijections g from t = r / z → r / z s. t. the set t ( g ) : = { g ( x ) − x mod 1, x ∈ t } ⊆ t [SEP]
Text from DS:  INVERTED ORBITS OF EXCLUSION PROCESSES,
DIFFUSE-EXTENSIVE-AMENABILITY AND
(NON-?)AMENABILITY OF THE INTERVAL EXCHANGES

arXiv:1804.01981v1 [] 5 Apr 2018

CHRISTOPHE GARBAN

Abstract. The recent breakthrough works [6, 8, 9] which established the
amenability for new classes of groups, lead to the following question: is the
action W (Zd ) y Zd extensive-amenable? (Where W (Zd ) is the wobbling group
of permutations σ : Zd → Zd with bounded range). This is equivalent to asking
d
d
whether the action (Z/2Z)(Z ) o W (Zd ) y (Z/2Z)(Z ) is amenable. The d = 1
and d = 2 and have been settled respectively in [6, 8]. By [9], a positive answer
to this question would imply the amenability of the IET group. In this work, we
give a partial answer to this question by introducing a natural strengthening of
the notion of extensive-amenability which we call diffuse-extensive-amenability.
Our main result is that for any bounded degree graph X, the action W (X) y
X is diffuse-extensive-amenable if and only
Original label:  math.ST
Predicted label:  8
Correct label:  10
Text:  [CLS] arxiv : 1802. 04838v1 [ stat. ml ] 13 feb 2018 network estimation from point process data benjamin mark1, 4, garvesh raskutti2, 4, and rebecca willett3, 4 1 department of mathematics, 2 department of statistics, 3 department of electrical and computer engineering 4 wisconsin institute for discovery university of wisconsin - madison february 15, 2018 abstract consider observing a collection of discrete events within a network that reflect how network nodes influence one another. such data are common in spike trains recorded from biological neural networks, interactions within a social network, and a variety of other settings. data of this form may be modeled as self - exciting point processes, in which the likelihood of future events depends on the past events. this paper addresses the problem of estimating self - excitation parameters and inferring the underlying functional network structure from self - exciting point process data. past work in this area was limited by strong assumptions which are addressed by the novel approach here. specifically, in this paper we ( 1 ) incorporate saturation in a point process model which both ensures stability and models non - linear thresholding effects ; ( 2 ) impose general low - dimensional structural assumptions that include sparsity, group sparsity and low - rankness that allows bounds to be developed in the high - dimensional setting ; and ( 3 ) incorporate long - range memory effects through moving average and higher - order auto - regressive components. using our general framework, we provide a number of novel theoretical guarantees for high - dimensional self - exciting point processes that reflect the role played by the underlying network structure and long - term memory. we also provide simulations and real data examples to support our methodology and main results. 1 1 introduction in a variety of settings, our only glimpse of a network ’ s structure is through the lens of discrete time series observations. for instance, in a social network, we may observe a time series of members ’ activities, such as posts on social media. in electrical systems, cascading chains of power failures reveal critical information about the underlying power distribution network. during epidemics, networks of computers or of a population are reflected by the time at which each node becomes infected. in biological neural networks, firing neurons can trigger or inhibit the firing of their neighbors, so that information about the network structure is embedded within spike train observations. this paper focuses on estimating the influence network which models the extent to which one node ’ s activity stimulates or inhibits activity in another node. for instance [SEP]
Text from DS:  arXiv:1802.04838v1 [stat.ML] 13 Feb 2018

Network Estimation from Point Process Data
Benjamin Mark1,4 , Garvesh Raskutti2,4 , and Rebecca Willett3,4
1
Department of Mathematics, 2 Department of Statistics,
3
Department of Electrical and Computer Engineering
4
Wisconsin Institute for Discovery
University of Wisconsin-Madison
February 15, 2018
Abstract
Consider observing a collection of discrete events within a network that
reflect how network nodes influence one another. Such data are common in
spike trains recorded from biological neural networks, interactions within a
social network, and a variety of other settings. Data of this form may be modeled as self-exciting point processes, in which the likelihood of future events
depends on the past events. This paper addresses the problem of estimating
self-excitation parameters and inferring the underlying functional network
structure from self-exciting point process data. Past work in this area was
limited by strong assumptions which are a
Original label:  cs.CE
Predicted label:  9
Correct label:  3
Text:  [CLS] synthesis of recursive adt transformations from reusable templates jeevana priya inala1, nadia polikarpova1, xiaokang qiu2, benjamin s. lerner3, and armando solar - lezama1 arxiv : 1507. 05527v3 [ ] 16 apr 2017 1 mit 3 { jinala, polikarn, asolar } @ csail. mit. edu 2 purdue university xkqiu @ purdue. edu northeastern university blerner @ ccs. neu. edu abstract. recent work has proposed a promising approach to improving scalability of program synthesis by allowing the user to supply a syntactic template that constrains the space of potential programs. unfortunately, creating templates often requires nontrivial effort from the user, which impedes the usability of the synthesizer. we present a solution to this problem in the context of recursive transformations on algebraic datatypes. our approach relies on polymorphic synthesis constructs : a small but powerful extension to the language of syntactic templates, which makes it possible to define a program space in a concise and highly reusable manner, while at the same time retains the scalability benefits of conventional templates. this approach enables end - users to reuse predefined templates from a library for a wide variety of problems with little effort. the paper also describes a novel optimization that further improves the performance and the scalability of the system. we evaluated the approach on a set of benchmarks that most notably includes desugaring functions for lambda calculus, which force the synthesizer to discover church encodings for pairs and boolean operations. 1 introduction recent years have seen remarkable advances in tools and techniques for automated synthesis of recursive programs [ 8, 1, 13, 4, 16 ]. these tools take as input some form of correctness specification that describes the intended program behavior, and a set of building blocks ( or components ). the synthesizer then performs a search in the space of all programs that can be built from the given components until it finds one that satisfies the specification. the biggest obstacle to practical program synthesis is that this search space grows extremely fast with the size of the program and the number of available components. as a result, these tools have been able to tackle only relatively simple tasks, such as textbook data structure manipulations. syntax - guided synthesis ( sygus ) [ 2 ] has emerged as a promising way to address this problem [SEP]
Text from DS:  Synthesis of Recursive ADT Transformations
from Reusable Templates
Jeevana Priya Inala1 , Nadia Polikarpova1 , Xiaokang Qiu2 , Benjamin S. Lerner3 ,
and Armando Solar-Lezama1

arXiv:1507.05527v3 [] 16 Apr 2017

1

MIT
3

{jinala, polikarn, asolar}@csail.mit.edu
2
Purdue University xkqiu@purdue.edu
Northeastern University blerner@ccs.neu.edu

Abstract. Recent work has proposed a promising approach to improving
scalability of program synthesis by allowing the user to supply a syntactic
template that constrains the space of potential programs. Unfortunately,
creating templates often requires nontrivial effort from the user, which
impedes the usability of the synthesizer. We present a solution to this
problem in the context of recursive transformations on algebraic datatypes. Our approach relies on polymorphic synthesis constructs: a small but
powerful extension to the language of syntactic templates, which makes it
possible to define a program space in a concise and highly reusable manner
Original label:  cs.IT
Predicted label:  1
Correct label:  5
Text:  [CLS] algebraic multigrid support vector machines arxiv : 1611. 05487v2 [ stat. ml ] 24 nov 2016 ehsan sadrfaridpour1, sandeep jeereddy2, ken kennedy2, andre luckow2 talayeh razzaghi1, ilya safro1 1 - clemson university, school of computing, clemson sc, usa 2 - innovation lab, bmw group it research center, information management americas greenville sc, usa november 28, 2016 abstract the support vector machine is a flexible optimization - based technique widely used for classification problems. in practice, its training part becomes computationally expensive on large - scale data sets because of such reasons as the complexity and number of iterations in parameter fitting methods, underlying optimization solvers, and nonlinearity of kernels. we introduce a fast multilevel framework for solving support vector machine models that is inspired by the algebraic multigrid. significant improvement in the running has been achieved without any loss in the quality. the proposed technique is highly beneficial on imbalanced sets. we demonstrate computational results on publicly available and industrial data sets. 1 introduction support vector machine ( svm ) is one of the most well - known supervised classification methods. the optimal classifier is achieved through solving a convex optimization model. when the data is big, the training of svm becomes highly time - consuming. one of the reasons for that is a time complexity of the underlying optimization solver required for the training. the second reason is related to finding best parameters ( the model selection stage ) for svm models. while training the classifier is a common phase in all svms, the model selection phase is usually applied on difficult data sets ( e. g., when the data is noisy, imbalanced, and incomplete ) in order to tune the parameters. on the one hand, svm models are often much more flexible than other supervised classification methods. on the other hand, the flexibility comes with the price of finding the best model through tuning. typically, the complexity of convex quadratic programming ( qp ) svm algorithms is between o ( n2 ) to o ( n3 ) [ 11 ]. for example, the solver we compare our algorithm with, namely, libsvm [ 4 ], which is one of the most popular qp solvers for svm, scales between o ( nf ns 2 ) to o ( nf ns 3 ) subject to how effectively the cache is exploited in practice, where the numbers of features [SEP]
Text from DS:  Algebraic multigrid support vector machines

arXiv:1611.05487v2 [stat.ML] 24 Nov 2016

Ehsan Sadrfaridpour1 , Sandeep Jeereddy2 , Ken Kennedy2, Andre Luckow2
Talayeh Razzaghi1 , Ilya Safro1
1- Clemson University, School of Computing, Clemson SC, USA
2- Innovation Lab, BMW Group IT Research Center, Information Management Americas
Greenville SC, USA
November 28, 2016
Abstract
The support vector machine is a flexible optimization-based technique widely used for classification problems. In practice, its training part becomes computationally expensive on large-scale data sets
because of such reasons as the complexity and number of iterations in parameter fitting methods, underlying optimization solvers, and nonlinearity of kernels. We introduce a fast multilevel framework for
solving support vector machine models that is inspired by the algebraic multigrid. Significant improvement in the running has been achieved without any loss in the quality. The proposed technique is highly
beneficial o
Original label:  cs.AI
Predicted label:  6
Correct label:  2
Text:  [CLS] arxiv : 1803. 07729v1 [ ] 21 mar 2018 look before you leap : bridging model - free and model - based reinforcement learning for planned - ahead vision - and - language navigation xin wang?, wenhan xiong?, hongmin wang, william yang wang university of california, santa barbara { xwang, xwhan, hongmin wang, william } @ cs. ucsb. edu abstract. existing research studies on vision and language grounding for robot navigation focus on improving model - free deep reinforcement learning ( drl ) models in synthetic environments. however, model - free drl models do not consider the dynamics in the real - world environments, and they often fail to generalize to new scenes. in this paper, we take a radical approach to bridge the gap between synthetic studies and real - world practices — we propose a novel, planned - ahead hybrid reinforcement learning model that combines model - free and model - based reinforcement learning to solve a real - world vision - language navigation task. our look - ahead module tightly integrates a look - ahead policy model with an environment model that predicts the next state and the reward. experimental results suggest that our proposed method significantly outperforms the baselines and achieves the best on the real - world roomto - room dataset. moreover, our scalable method is more generalizable when transferring to unseen environments, and the relative success rate is increased by 15. 5 % on the unseen test set. keywords : vision - and - language navigation, first - person view video, model - based reinforcement learning 1 introduction it is rather trivial for a human to follow the instruction “ walk beside the outside doors and behind the chairs across the room. turn right and walk up the stairs... ”, but teaching robots to navigate with such instructions is a very challenging task. the complexities arise from not just the linguistic variations of instructions, but also the noisy visual signals from the real - world environments that have rich dynamics. robot navigation via visual and language grounding is also a fundamental goal in computer vision and artificial intelligence, and it is beneficial for many practical applications as well, such as in - home robots, hazard removal, and personal assistants.? equal contribution 2 xin wang?, wenhan xiong?, hongmin wang, william yang wang ( 1 ) ( 2 ) ( 3 ) ( 4 ) ( 5 ) ( 6 ) walk beside the outside doors and behind the chairs across the room. turn right and walk up [SEP]
Text from DS:  arXiv:1803.07729v1 [] 21 Mar 2018

Look Before You Leap:
Bridging Model-Free and Model-Based
Reinforcement Learning for Planned-Ahead
Vision-and-Language Navigation
Xin Wang? , Wenhan Xiong? , Hongmin Wang, William Yang Wang
University of California, Santa Barbara
{xwang,xwhan,hongmin wang,william}@cs.ucsb.edu

Abstract. Existing research studies on vision and language grounding
for robot navigation focus on improving model-free deep reinforcement
learning (DRL) models in synthetic environments. However, model-free
DRL models do not consider the dynamics in the real-world environments, and they often fail to generalize to new scenes. In this paper,
we take a radical approach to bridge the gap between synthetic studies
and real-world practices—We propose a novel, planned-ahead hybrid reinforcement learning model that combines model-free and model-based
reinforcement learning to solve a real-world vision-language navigation
task. Our look-ahead module tightly integrates a look-ahead poli
Original label:  math.GR
Predicted label:  3
Correct label:  5
Text:  [CLS] a nonamenable “ factor ” of a euclidean space adam timar alfred renyi institute of mathematics arxiv : 1712. 08210v1 [ math. pr ] 21 dec 2017 realtanoda u. 13 - 15., h - 1053 budapest madaramit [ at ] gmail. com abstract answering a question of benjamini, we present an isometry - invariant random partition of the euclidean space r3 into infinite connected indinstinguishable pieces, such that the adjacency graph defined on the pieces is the 3 - regular infinite tree. along the way, it is proved that any finitely generated amenable cayley graph ( or more generally, amenable unimodular random graph ) can be represented in r3 as an isometry - invariant random collection of polyhedral domains ( tiles ). a new technique is developed to prove indistinguishability for certain constructions, connecting this notion to factor of iid ’ s. 1 introduction definition 1. let g be a finite or infinite graph. say that the set p is a tiling of rd that represents g ( or a representation by tiles, or tiling representation of g ), if the following hold. 1. every element of p is a connected open polytope ( a tile ) in r3. a polytope may be unbounded, with infinitely many hyperfaces. 2. the elements of p are pairwise disjoint, the union of their closures is r3. 3. every ball in rd intersects finitely many elements of p. 4. say that two elements of p are adjacent, if their closures share a d − 1 - dimensional face. then the graph defined on p this way is isomorphic to g. we call the elements of p pieces or tiles of p. representing a cayley graph of a countable group g as a periodic tiling of rd is not possible for most g. a natural relaxation of periodicity is to take a random tiling, whose distribution is invariant under the isometries of rd. instead of congruent tiles, one can ask for the probabilistic analogue of congruence, and require the tiles to be indistinguishable. this research was supported by a marie curie intra european fellowship within the 7th european community framework programme, by the hungarian national research, development and innovation office, nkfih grant k109684, and by grant lp 2016 [SEP]
Text from DS:  A nonamenable “factor” of a euclidean space
Ádám Timár
Alfréd Rényi Institute of Mathematics

arXiv:1712.08210v1 [math.PR] 21 Dec 2017

Reáltanoda u. 13-15.,
H-1053 Budapest
madaramit[at]gmail.com

Abstract
Answering a question of Benjamini, we present an isometry-invariant random partition of the euclidean space R3 into infinite connected indinstinguishable pieces, such that the adjacency graph defined
on the pieces is the 3-regular infinite tree. Along the way, it is proved that any finitely generated amenable
Cayley graph (or more generally, amenable unimodular random graph) can be represented in R3 as an
isometry-invariant random collection of polyhedral domains (tiles). A new technique is developed to
prove indistinguishability for certain constructions, connecting this notion to factor of iid’s.

1

Introduction

Definition 1. Let G be a finite or infinite graph. Say that the set P is a tiling of Rd that represents G (or
a representation by tiles, or tiling representation o
Original label:  math.GR
Predicted label:  2
Correct label:  9
Text:  [CLS] arxiv : 1802. 06961v1 [ math. ra ] 20 feb 2018 on classification of ( n + 5 ) - dimensional nilpotent n - lie algebra of class two zahra hoseini1, farshid saeedi1, and hamid darabi2 abstract. in this paper, we classify ( n + 5 ) - dimensional nilpotent n - lie algebras of class two over the arbitrary field, when n ≥ 3. 1. introduction and preliminaries the classification of low dimensional lie algebras is one of the fundamental issues in lie algebras theory. the classification of lie algebras can be found in many books and papers. in 1950 morozov [ 11 ] proposed a classification of sixdimensional nilpotent lie algebras over fields of characteristic 0. the classification of the 6 - dimensional lie algebras on the arbitrary field was shown by cicalo et al. [ 4 ]. moreover, the 7 - dimensional nilpotent lie algebras over algebraically closed fields and real number field were classified in [ 9 ]. in 1985, filippov [ 8 ] introduced the n - lie algebras as a non - symmetrical linear vector space which satisfies the following jacobian identity : n x [ x1,..., xi−1, [ xi, y2,..., yn ], xi + 1,..., xn ] [ [ x1, x2,..., xn ], y2,..., yn ] = i = 1 for all xi, yj ∈ l, 1 ≤ i ≤ n, 2 ≤ j ≤ n. he also classified n - lie algebras of dimensions n and n + 1 on the algebraically closed field with characteristic zero. in 2008, bai et al. [ 2 ] classified n - lie algebras of dimension n + 1 on fields of characteristic two. then, bai [ 1 ] classified n - lie algebras of dimension n + 2 on the algebraically closed fields with characteristic zero. assume that a1,..., an are the subalgebra of n - lie algebra a. then, subalgebra a generated by all vectors [ x1,..., xn ] ( xi ∈ ai ) will be represented by the symbol [ a1,..., an ]. the subalgebra a2 = [ a,..., a ] is called derived [SEP]
Text from DS:  arXiv:1802.06961v1 [math.RA] 20 Feb 2018

ON CLASSIFICATION OF (n + 5)-DIMENSIONAL NILPOTENT
n-LIE ALGEBRA OF CLASS TWO
ZAHRA HOSEINI1 , FARSHID SAEEDI1 , AND HAMID DARABI2
Abstract. In this paper, we classify (n + 5)-dimensional nilpotent n-Lie algebras of class two over the arbitrary field, when n ≥ 3.

1. Introduction and Preliminaries
The classification of low dimensional Lie algebras is one of the fundamental
issues in Lie algebras Theory. The classification of Lie algebras can be found in
many books and papers. In 1950 Morozov [11] proposed a classification of sixdimensional nilpotent Lie algebras over fields of characteristic 0. The classification
of the 6-dimensional Lie algebras on the arbitrary field was shown by Cicalo et
al. [4]. Moreover, the 7-dimensional nilpotent Lie algebras over algebraically closed
fields and real number field were classified in [9]. In 1985, Filippov [8] introduced the
n-Lie algebras as a non-symmetrical linear vector space which satisfies the follo
Original label:  cs.IT
Predicted label:  6
Correct label:  2
Text:  [CLS] arxiv : 1702. 03657v1 [ ] 13 feb 2017 trie compression for gpu accelerated multi - pattern matching xavier bellekens amar seeam christos tachtatzis & robert atkinson division of computing and mathematics abertay university dundee, scotland email : x. bellekens @ abertay. ac. uk department of computer science middlesex university mauritius campus email : a. seeam @ mdx. ac. uk eee department university of strathclyde glasgow, scotland email : name. surname @ strath. ac. uk abstract — graphics processing units ( gpu ) allow for running massively parallel applications offloading the central processing unit ( cpu ) from computationally intensive resources. however gpus have a limited amount of memory. in this paper, a trie compression algorithm for massively parallel pattern matching is presented demonstrating 85 % less space requirements than the original highly efficient parallel failure - less aho - corasick, whilst demonstrating over 22 gbps throughput. the algorithm presented takes advantage of compressed row storage matrices as well as shared and texture memory on the gpu. keywords – pattern matching algorithm ; trie compression ; searching ; data compression ; gpu i. i ntroduction pattern matching algorithms are used in a plethora of fields, ranging from bio - medical applications to cyber - security, the internet of things ( iot ), dna sequencing and anti - virus systems. the ever growing volume of data to be analysed, often in real time, demands high computational performance. the massively parallel capabilities of graphical processor units, have recently been exploited in numerous fields such as mathematics [ 1 ], physics [ 2 ], life sciences [ 3 ], computer science [ 4 ], networking [ 5 ], and astronomy [ 6 ] to increase the throughput of sequential algorithms and reduce the processing time. with the increasing number of patterns to search for and the scarcity of memory on graphics processing units data compression is important. the massively parallel capabilities allow for increasing the processing throughput and can benefit applications using string dictionaries [ 7 ], or application requiring large trees [ 8 ]. the remainder of this paper is organised as follows : section ii describes the gpu programming model, section iii provides background on multi - pattern matching algorithms while, section iv discusses the failure - less aho - corasick algorithm used within this research. section v highlights the design and implementation of the trie compression algorithms, while section vi provides details on the environment. [SEP]
Text from DS:  arXiv:1702.03657v1 [] 13 Feb 2017

Trie Compression for GPU Accelerated
Multi-Pattern Matching
Xavier Bellekens

Amar Seeam

Christos Tachtatzis & Robert Atkinson

Division of Computing and Mathematics
Abertay University
Dundee, Scotland
Email: x.bellekens@abertay.ac.uk

Department of Computer Science
Middlesex University
Mauritius Campus
Email: a.seeam@mdx.ac.uk

EEE Department
University of Strathclyde
Glasgow, Scotland
Email: name.surname@strath.ac.uk

Abstract—Graphics Processing Units (GPU) allow for running
massively parallel applications offloading the Central Processing
Unit (CPU) from computationally intensive resources. However
GPUs have a limited amount of memory. In this paper, a trie
compression algorithm for massively parallel pattern matching
is presented demonstrating 85% less space requirements than
the original highly efficient parallel failure-less Aho-Corasick,
whilst demonstrating over 22 Gbps throughput. The algorithm
presented takes advantage of compressed row st
Original label:  cs.CE
Predicted label:  0
Correct label:  4
Text:  [CLS] verification of java bytecode using analysis and transformation of logic programs e. albert1, m. gomez - zamalloa1, l. hubert2, and g. puebla2 1 arxiv : 1007. 3250v1 [ ] 19 jul 2010 2 dsic, complutense university of madrid, e - 28040 madrid, spain clip, technical university of madrid, e - 28660 boadilla del monte, madrid, spain { elvira, mzamalloa, laurent, german } @ clip. dia. fi. upm. es abstract. state of the art analyzers in the logic programming ( lp ) paradigm are nowadays mature and sophisticated. they allow inferring a wide variety of global properties including termination, bounds on resource consumption, etc. the aim of this work is to automatically transfer the power of such analysis tools for lp to the analysis and verification of java bytecode ( jvml ). in order to achieve our goal, we rely on well - known techniques for meta - programming and program specialization. more precisely, we propose to partially evaluate a jvml interpreter implemented in lp together with ( an lp representation of ) a jvml program and then analyze the residual program. interestingly, at least for the examples we have studied, our approach produces very simple lp representations of the original jvml programs. this can be seen as a decompilation from jvml to high - level lp source. by reasoning about such residual programs, we can automatically prove in the ciaopp system some non - trivial properties of jvml programs such as termination, run - time error freeness and infer bounds on its resource consumption. we are not aware of any other system which is able to verify such advanced properties of java bytecode. 1 introduction verifying programs in the ( constraint ) logic programming paradigm — ( c ) lp — offers a good number of advantages, an important one being the maturity and sophistication of the analysis tools available for it. the work presented in this paper is motivated by the existence of abstract interpretation - based analyzers [ 3 ] which infer information on programs by interpreting ( “ running ” ) them using abstract values rather than concrete ones, thus, obtaining safe approximations of programs behavior. these analyzers are parametric w. r. t. the so - called abstract domain, which provides a finite representation of possibly infinite sets of values. different domains capture different properties of the program with different levels of precision and at different computational costs [SEP]
Text from DS:  Verification of Java Bytecode using Analysis and
Transformation of Logic Programs
E. Albert1 , M. Gómez-Zamalloa1, L. Hubert2 , and G. Puebla2
1

arXiv:1007.3250v1 [] 19 Jul 2010

2

DSIC, Complutense University of Madrid, E-28040 Madrid, Spain
CLIP, Technical University of Madrid, E-28660 Boadilla del Monte, Madrid, Spain
{elvira,mzamalloa,laurent,german}@clip.dia.fi.upm.es
Abstract. State of the art analyzers in the Logic Programming (LP)
paradigm are nowadays mature and sophisticated. They allow inferring
a wide variety of global properties including termination, bounds on resource consumption, etc. The aim of this work is to automatically transfer
the power of such analysis tools for LP to the analysis and verification of
Java bytecode (jvml). In order to achieve our goal, we rely on well-known
techniques for meta-programming and program specialization. More precisely, we propose to partially evaluate a jvml interpreter implemented
in LP together with (an LP representation of) a j
Original label:  cs.DS
Predicted label:  3
Correct label:  2
Text:  [CLS] latent dirichlet allocation uncovers spectral characteristics of drought stressed plants mirwaes [UNK], kristian kersting12∗, christian bauckhage1, christoph romer2, agim ballvora3, francisco pinto4, uwe rascher4, jens leon3, lutz plumer2 1 fraunhofer iais, sankt augustin, germany. 2 institute of geodesy and geoinformation, university of bonn, germany. 3 institute of crop science and resource conservation, plant breeding, university of bonn, germany. 4 institute of bio - and geosciences, ibg - 2 : plant sciences, forschungszentrum julich, germany. abstract 4000 background 3000 understanding the adaptation process of plants to drought stress is essential in improving management practices, breeding strategies as well as engineering viable crops for a sustainable agriculture in the coming decades. hyper - spectral imaging provides a particularly promising approach to gain such understanding since it allows to discover non - destructively spectral characteristics of plants governed primarily by scattering and absorption characteristics of the leaf internal structure and biochemical constituents. several drought stress indices have been derived using hyper - spectral imaging. however, they are typically based on few hyper - spectral images only, rely on interpretations of experts, and consider few wavelengths only. in this study, we present the first data - driven approach to discovering spectral drought stress indices, treating it as an unsupervised labeling problem at massive scale. to make use of short range dependencies of spectral wavelengths, we develop an online variational bayes algorithm for latent dirichlet allocation with convolved dirichlet regularizer. this approach scales to massive datasets and, hence, provides a more objective complement to plant physiological practices. the spectral topics found conform to plant physiological knowledge and can be computed in a fraction of the time compared to existing lda approaches. 1 introduction water scarcity is a principal global problem that causes aridity and serious crop losses in agriculture. it ∗ both authors contributed equally. mirwaes. wahabzada @ iais. fraunhofer. de [UNK] contact author : leaf 2000 1000 0 0 leaf 50 100 figure 1 : what are the specific spectral characteristics of plants suffering from drought stress? ( left ) a collection of hyper - spectral images ( projected to rgb space ) within the flowering period. stressed plants are indicated by red dots, control plants by green dots. visually it is difficult to distinguish between control and stressed plant ; compare e. [SEP]
Text from DS:  Latent Dirichlet Allocation Uncovers
Spectral Characteristics of Drought Stressed Plants

Mirwaes Wahabzada1∗◦ , Kristian Kersting12∗ , Christian Bauckhage1 , Christoph Römer2 ,
Agim Ballvora3 , Francisco Pinto4 , Uwe Rascher4 , Jens Léon3 , Lutz Plümer2
1
Fraunhofer IAIS, Sankt Augustin, Germany. 2 Institute of Geodesy and Geoinformation, University of Bonn,
Germany. 3 Institute of Crop Science and Resource Conservation, Plant Breeding, University of Bonn, Germany.
4
Institute of Bio- and Geosciences, IBG-2: Plant Sciences, Forschungszentrum Jülich, Germany.

Abstract

4000

Background

3000

Understanding the adaptation process of
plants to drought stress is essential in improving management practices, breeding strategies as well as engineering viable crops
for a sustainable agriculture in the coming
decades. Hyper-spectral imaging provides
a particularly promising approach to gain
such understanding since it allows to discover
non-destructively spectral characteristics of
plants
Original label:  cs.IT
Predicted label:  3
Correct label:  2
Text:  [CLS] lower bounds for on - line graph colorings arxiv : 1404. 7259v2 [ math. co ] 9 oct 2015 grzegorz gutowski, jakub kozik, piotr micek, and xuding zhu abstract. we propose two strategies for presenter in on - line graph coloring games. the first one constructs bipartite graphs and forces any on - line coloring algorithm to use 2 log2 n − 10 colors, where n is the number of vertices in the constructed graph. this is best possible up to an additive constant. the second strategy constructs graphs that 1 contain neither c3 nor c5 as a subgraph and forces ω ( logn n 3 ) colors. 1 the best known on - line coloring algorithm for these graphs uses o ( n 2 ) colors. 1. introduction a proper coloring of a graph g is an assignment of colors to the vertices of the graph such that adjacent vertices receive distinct colors. an n - round on - line coloring game on a class of graphs g is a two - person game, played by presenter and algorithm. in each round presenter introduces a new vertex of a graph with its adjacency status to all vertices presented earlier. the only restriction for presenter is that in every moment the currently presented graph is in g. algorithm assigns colors to the incoming vertices in such a way that the coloring of the presented graph is always proper. the color for a new vertex has to be assigned before presenter introduces the next vertex. the assignment is irrevocable. the goal of algorithm is to minimize the number of different colors used during the game. throughout the paper log and ln are logarithm functions to base 2 and e, respectively. by the size of a graph we mean the number of vertices in the graph. for most classes of graphs the number of colors necessary in the corresponding on - line coloring game can not be bounded in terms of the chromatic number of the constructed graph. rare examples of classes where it is possible include interval graphs [ 8 ], more generally cocomparability graphs [ 6 ] or p5 - free graphs [ 7 ]. all of these results are covered by the main result of [ 6 ] that says that for any tree t with radius 2, the class of graphs that do not contain an induced copy of t can be colored on - line with number of colors being a function of t and chromatic number of presented graph. usually, for general enough classes of graphs, the best one can [SEP]
Text from DS:  LOWER BOUNDS FOR ON-LINE GRAPH COLORINGS

arXiv:1404.7259v2 [math.CO] 9 Oct 2015

GRZEGORZ GUTOWSKI, JAKUB KOZIK, PIOTR MICEK, AND XUDING ZHU
Abstract. We propose two strategies for Presenter in on-line graph
coloring games. The first one constructs bipartite graphs and forces any
on-line coloring algorithm to use 2 log2 n − 10 colors, where n is the
number of vertices in the constructed graph. This is best possible up
to an additive constant. The second strategy constructs graphs that
1
contain neither C3 nor C5 as a subgraph and forces Ω( logn n 3 ) colors.
1

The best known on-line coloring algorithm for these graphs uses O(n 2 )
colors.

1. Introduction
A proper coloring of a graph G is an assignment of colors to the vertices
of the graph such that adjacent vertices receive distinct colors. An n-round
on-line coloring game on a class of graphs G is a two-person game, played by
Presenter and Algorithm. In each round Presenter introduces a new vertex
of a graph with its adjacency sta
Original label:  cs.DS
Predicted label:  3
Correct label:  6
Text:  [CLS] optimized field / circuit coupling for the simulation of quenches in superconducting magnets i. cortes garcia1, s. schops1, m. maciejewski2, 3, l. bortot2, m. prioli2, b. auchmann2, 4, and a. p. verweij2 1 technische arxiv : 1702. 00958v2 [ physics. comp - ph ] 6 jul 2017 universitat darmstadt, darmstadt, germany 2 cern, geneva, switzerland 3 łodz university of technology, łodz, poland 4 paul scherrer institut, villigen, switzerland in this paper, we propose an optimized field / circuit coupling approach for the simulation of magnetothermal transients in superconducting magnets. the approach improves the convergence of the iterative coupling scheme between a magnetothermal partial differential model and an electrical lumped - element circuit. such a multi - physics, multi - rate and multi - scale problem requires a consistent formulation and a dedicated framework to tackle the challenging transient effects occurring at both circuit and magnet level during normal operation and in case of faults. we derive an equivalent magnet model at the circuit side for the linear and the non - linear settings and discuss the convergence of the overall scheme in the framework of optimized schwarz methods. the efficiency of the developed approach is illustrated by a numerical example of an accelerator dipole magnet with accompanying protection system. index terms — convergence of numerical methods, coupling circuits, eddy currents, iterative methods. i. i ntroduction uperconducting magnets produce high magnetic fields used in high - energy particle accelerators for bending particle beams. in order to reach the superconducting state, the magnets are operated at very low temperatures ( 1. 9 k ). since the heat capacity is low at cryogenic temperatures, the magnets are prone to quench due to a local energy deposition ( coupling losses in the superconducting cable, beam losses, cryogenic malfunction, mechanical movement, etc. ). a quench is a transition from the superconducting to the normal conducting state. as a consequence, the release of the magnetic energy as ohmic losses may result in a catastrophic damage in the magnet and circuit. the simulation of quench initiation, propagation, and subsequent protective measures represents a challenge in terms of the number of coupled physical domains, their highly nonlinear behavior, their geometric [SEP]
Text from DS:  Optimized Field/Circuit Coupling for the Simulation of Quenches in
Superconducting Magnets
I. Cortes Garcia1 , S. Schöps1 , M. Maciejewski2,3 , L. Bortot2 , M. Prioli2 , B. Auchmann2,4 , and A.P. Verweij2
1 Technische

arXiv:1702.00958v2 [physics.comp-ph] 6 Jul 2017

Universität Darmstadt, Darmstadt, Germany
2 CERN, Geneva, Switzerland
3 Łódź University of Technology, Łódź, Poland
4 Paul Scherrer Institut, Villigen, Switzerland

In this paper, we propose an optimized field/circuit coupling approach for the simulation of magnetothermal transients in
superconducting magnets. The approach improves the convergence of the iterative coupling scheme between a magnetothermal
partial differential model and an electrical lumped-element circuit. Such a multi-physics, multi-rate and multi-scale problem requires
a consistent formulation and a dedicated framework to tackle the challenging transient effects occurring at both circuit and magnet
level during normal operation and in case of faults
Original label:  math.ST
Predicted label:  1
Correct label:  2
Text:  [CLS] comparing population means under local differential privacy : with significance and power bolin ding, harsha nori, paul li, joshua allen arxiv : 1803. 09027v1 [ cs. cr ] 24 mar 2018 { bolind, hanori, paul. li, joshuaa } @ microsoft. com microsoft, one microsoft way, redmond, wa 98052 abstract a statistical hypothesis test determines whether a hypothesis should be rejected based on samples from populations. in particular, randomized controlled experiments ( or a / b testing ) that compare population means using, e. g., t - tests, have been widely deployed in technology companies to aid in making data - driven decisions. samples used in these tests are collected from users and may contain sensitive information. both the data collection and the testing process may compromise individuals ’ privacy. in this paper, we study how to conduct hypothesis tests to compare population means while preserving privacy. we use the notation of local differential privacy ( ldp ), which has recently emerged as the main tool to ensure each individual ’ s privacy without the need of a trusted data collector. we propose ldp tests that inject noise into every user ’ s data in the samples before collecting them ( so users do not need to trust the data collector ), and draw conclusions with bounded type - i ( significance level ) and type - ii errors ( 1− power ). our approaches can be extended to the scenario where some users require ldp while some are willing to provide exact data. we report experimental results on real - world datasets to verify the effectiveness of our approaches. introduction randomized controlled experiments ( or a / b testing ) and hypothesis tests are used by many companies, e. g., google, facebook, amazon, and microsoft, to design and improve their products and services ( tang et al. 2010 ; panger 2016 ; kohavi and round 2004 ; kohavi et al. 2012 ). these statistical techniques base business decisions on samples of actual customer data collected during experiments to draw more informed conclusions. however, such data samples usually contain sensitive information, e. g., usage statistics of certain apps or services ; in order to meet users ’ privacy expectations and tightening privacy regulations ( e. g., european gdpr law ), ensuring that these experiments and tests do not breach the privacy of individuals is an important problem. differential privacy ( dp ) ( dwork et al. 2006 ) has emerged as a standard for the privacy guarantees, and been used by, e. g [SEP]
Text from DS:  Comparing Population Means under Local Differential Privacy:
with Significance and Power
Bolin Ding, Harsha Nori, Paul Li, Joshua Allen

arXiv:1803.09027v1 [cs.CR] 24 Mar 2018

{bolind, hanori, paul.li, joshuaa}@microsoft.com
Microsoft, One Microsoft Way, Redmond, WA 98052

Abstract
A statistical hypothesis test determines whether a hypothesis should be rejected based on samples from populations. In
particular, randomized controlled experiments (or A/B testing) that compare population means using, e.g., t-tests, have
been widely deployed in technology companies to aid in making data-driven decisions. Samples used in these tests are
collected from users and may contain sensitive information.
Both the data collection and the testing process may compromise individuals’ privacy. In this paper, we study how to conduct hypothesis tests to compare population means while preserving privacy. We use the notation of local differential privacy (LDP), which has recently emerged as the main tool to

Original label:  cs.SY
Predicted label:  5
Correct label:  9
Text:  [CLS] decentralized 2 - d control of vehicular platoons under limited visual feedback arxiv : 1702. 03097v1 [ ] 10 feb 2017 christos k. verginis, charalampos p. bechlioulis, dimos v. dimarogonas and kostas j. kyriakopoulos abstract — in this paper, we consider the two dimensional ( 2 - d ) predecessor - following control problem for a platoon of unicycle vehicles moving on a planar surface. more specifically, we design a decentralized kinematic control protocol, in the sense that each vehicle calculates its own control signal based solely on local information regarding its preceding vehicle, by its on - board camera, without incorporating any velocity measurements. additionally, the transient and steady state response is a priori determined by certain designer - specified performance functions and is fully decoupled by the number of vehicles composing the platoon and the control gains selection. moreover, collisions between successive vehicles as well as connectivity breaks, owing to the limited field of view of cameras, are provably avoided. finally, an extensive simulation study is carried out in the webotstm realistic simulator, clarifying the proposed control scheme and verifying its effectiveness. i. i ntroduction during the last few decades, the 1 - d longitudinal control problem of automated highway systems ( ahs ) has become an active research area in automatic control ( see [ 1 ] – [ 5 ] and the references therein ). unlike human drivers that are not able to react quickly and accurately enough to follow each other in close proximity at high speeds, the safety and capacity of highways ( measured in vehicles / lanes / time ) is significantly increased when vehicles operate autonomously, forming large platoons at close spacing. however, realistic situations necessitate for 2 - d motion on planar surfaces ( see fig. 1 ). early works in [ 6 ] – [ 9 ] consider the lane - keeping and lanechanging control for platoons in ahs, adopting however a centralized network, where all vehicles exchange information with a central computer that determines the control protocol, making thus the overall system sensitive to delays, especially when a large number of vehicles is involved. alternatively, rigid multi - agent formations are employed in decentralized control schemes, where each vehicle utilizes relative information from its neighbors. the majority of these works consider unicycle [ 10 ] – [ 14 ] and bicycle kinematic models [ 15 ] – [SEP]
Text from DS:  Decentralized 2-D Control of Vehicular Platoons
under Limited Visual Feedback

arXiv:1702.03097v1 [] 10 Feb 2017

Christos K. Verginis, Charalampos P. Bechlioulis, Dimos V. Dimarogonas and Kostas J. Kyriakopoulos
Abstract— In this paper, we consider the two dimensional
(2-D) predecessor-following control problem for a platoon of
unicycle vehicles moving on a planar surface. More specifically,
we design a decentralized kinematic control protocol, in the
sense that each vehicle calculates its own control signal based
solely on local information regarding its preceding vehicle,
by its on-board camera, without incorporating any velocity
measurements. Additionally, the transient and steady state
response is a priori determined by certain designer-specified
performance functions and is fully decoupled by the number of
vehicles composing the platoon and the control gains selection.
Moreover, collisions between successive vehicles as well as connectivity breaks, owing to the limited field of v
Original label:  math.ST
Predicted label:  1
Correct label:  9
Text:  [CLS] submitted to the annals of statistics arxiv : 1601. 00815v4 [ ] 12 oct 2017 semi - parametric efficiency bounds for high - dimensional models by jana jankova and sara van de geer eth zurich asymptotic lower bounds for estimation play a fundamental role in assessing the quality of statistical procedures. in this paper we propose a framework for obtaining semi - parametric efficiency bounds for sparse high - dimensional models, where the dimension of the parameter is larger than the sample size. we adopt a semi - parametric point of view : we concentrate on one dimensional functions of a highdimensional parameter. we follow two different approaches to reach the lower bounds : asymptotic cramer - rao bounds and le cam ’ s type of analysis. both these approaches allow us to define a class of asymptotically unbiased or “ regular ” estimators for which a lower bound is derived. consequently, we show that certain estimators obtained by de - sparsifying ( or de - biasing ) an ℓ1 - penalized m - estimator are asymptotically unbiased and achieve the lower bound on the variance : thus in this sense they are asymptotically efficient. the paper discusses in detail the linear regression model and the gaussian graphical model. 1. introduction. following the development of numerous methods for high - dimensional estimation, more recently the need for statistical inference has emerged. a number of papers have since studied the problem and proposed constructions of estimators which are asymptotically normally distributed and hence lead to inference. these results naturally give rise to the question of their optimality. this motivates us to study the question whether we can establish asymptotic efficiency bounds in high - dimensional models and whether we can construct an estimator achieving these bounds. to introduce the setting, suppose that we observe a sample x ( 1 ),..., x ( n ) which is distributed according to a probability distribution pβ that depends on an unknown high - dimensional parameter β ∈ b ⊂ rp. the dimension p of the parameter can be much larger than the sample size n. a major structural assumption we consider in this paper is sparsity in the high - dimensional parameter. in these sparse high - dimensional settings, a common approach to estimation is based on regularized m - estimators, where the regularization is in terms of the ℓ1 - penalty. this approach has been studied extensively, and msc [SEP]
Text from DS:  Submitted to the Annals of Statistics

arXiv:1601.00815v4 [] 12 Oct 2017

SEMI-PARAMETRIC EFFICIENCY BOUNDS FOR
HIGH-DIMENSIONAL MODELS
By Jana Janková and Sara van de Geer
ETH Zürich
Asymptotic lower bounds for estimation play a fundamental role
in assessing the quality of statistical procedures. In this paper we
propose a framework for obtaining semi-parametric efficiency bounds
for sparse high-dimensional models, where the dimension of the parameter is larger than the sample size. We adopt a semi-parametric
point of view: we concentrate on one dimensional functions of a highdimensional parameter. We follow two different approaches to reach
the lower bounds: asymptotic Cramér-Rao bounds and Le Cam’s type
of analysis. Both these approaches allow us to define a class of asymptotically unbiased or “regular” estimators for which a lower bound is
derived. Consequently, we show that certain estimators obtained by
de-sparsifying (or de-biasing) an ℓ1 -penalized M-estimator are asymptotic
Original label:  cs.CE
Predicted label:  9
Correct label:  2
Text:  [CLS] refinement types for precisely named cache locations matthew a. hammer1, joshua dunfield2, dimitrios j. economou1, and monal narasimhamurthy1 1 arxiv : 1610. 00097v5 [ ] 21 oct 2017 2 university of colorado boulder queen ’ s university ( canada ) abstract. many programming language techniques for incremental computation employ programmer - specified names for cached information. at runtime, each name identifies a “ cache location ” for a dynamic data value or a sub - computation ; in sum, these cache location choices guide change propagation and incremental ( re ) execution. we call a cache location name precise when it identifies at most one value or subcomputation ; we call all other names imprecise, or ambiguous. at a minimum, cache location names must be precise to ensure that change propagation works correctly ; yet, reasoning statically about names in incremental programs remains an open problem. as a first step, this paper defines and solves the precise name problem, where we verify that incremental programs with explicit names use them precisely. to do so, we give a refinement type and effect system, and prove it sound ( every well - typed program uses names precisely ). we also demonstrate that this type system is expressive by verifying example programs that compute over efficient representations of incremental sequences and sets. beyond verifying these programs, our type system also describes their dynamic naming strategies, e. g., for library documentation purposes. 1 introduction language - based incremental computation techniques such as self - adjusting computation and nominal adapton ( hammer et al. 2015 ) strive to improve the asymptotic time complexity of programs using general - purpose incremental computing techniques that combine function call caching, dynamic dependency graphs, and change propagation ( acar 2005 ; acar et al. 2006b, a, 2009 ; acar and leywild 2009 ; hammer and acar 2008 ; hammer et al. 2009 ; ley - wild et al. 2008, 2009 ; chen et al. 2012 ). in practice, each such system ’ s cache implementation exposes a programming model where the incremental algorithm employs explicit names, where each name identifies a cache location for dynamic data ( a dynamic pointer allocation ), or a cache location for dynamic sub - computations ( e. g., the arguments, dependencies, and results of a recursive function call ). for an evaluation derivation d, [SEP]
Text from DS:  Refinement types for precisely named cache locations
Matthew A. Hammer1 , Joshua Dunfield2 ,
Dimitrios J. Economou1 , and Monal Narasimhamurthy1
1

arXiv:1610.00097v5 [] 21 Oct 2017

2

University of Colorado Boulder
Queen’s University (Canada)

Abstract. Many programming language techniques for incremental computation employ programmer-specified names for cached information.
At runtime, each name identifies a “cache location” for a dynamic data
value or a sub-computation; in sum, these cache location choices guide
change propagation and incremental (re)execution.
We call a cache location name precise when it identifies at most one value
or subcomputation; we call all other names imprecise, or ambiguous. At
a minimum, cache location names must be precise to ensure that change
propagation works correctly; yet, reasoning statically about names in
incremental programs remains an open problem.
As a first step, this paper defines and solves the precise name problem, where we verify that inc
Original label:  cs.SY
Predicted label:  3
Correct label:  7
Text:  [CLS] a class of diffusion algorithms with logarithmic cost over adaptive sparse volterra networki lu lua, haiquan zhaoa∗ a ) school of electrical engineering, southwest jiaotong university, chengdu, china. abstract in this paper, we present a novel class of diffusion algorithms that can be used to estimate the coefficients of arxiv : 1606. 08541v5 [ ] 2 may 2017 sparse volterra network ( svn ). the development of the algorithms is based on the logarithmic cost and l0 norm constraint. simulations for gaussian and impulsive scenarios are conducted to demonstrate the superior performance of the proposed algorithms as compared with the existing algorithms. keywords : distributed adaptation, volterra filter, sparse, logarithmic cost. 1. introduction the volterra filter has been widely used as a nonlinear system modelling tool with considerable success [ 1, 2, 3 ]. however, such a filter becomes very computationally expensive when a large number of coefficients are required. a second order volterra ( sov ) filter was developed to cope with the enormous amount of 5 computations needed to obtain acceptable errors [ 1, 2, 3, 4 ]. diffusion algorithms are the method for estimating parameters over adaptive networks, whose nodes can collect noisy observations related to a certain parameter of interest [ 5 ]. recently, some diffusion algorithms have been proposed [ 5, 6 ]. these algorithms aimed at enhancing the linear estimation performance have been presented in the literature, but few algorithms aimed at enhancing the nonlinear estimation capability of 10 diffusion algorithms have been investigated. particularly, in [ 7 ], an interesting trial was attempted to nonlinear adaptive learning by employing the kernel adaptive filter. unfortunately, the structure of this method grows linearly with the number of processed patterns, which prohibits its practical applications. motivated by these considerations, in this paper, we proposed a new diffusion algorithm for adaptive sparse volterra network ( svn ). the parameters of svn at every node are sparse, i. e., only a small portion of the 15 coefficients ( called active coefficients ) have large magnitude while the rest of the coefficients ( called inactive coefficients ) are close or equal to zero. the development of the algorithm is based on an innovative approach : the algorithms are introduced based on the minimization of cost functions with logarithmic dependence on the adaptation error, instead of minimizing the pth power error. moreover, these algorithms with l0 - norm constraint are proposed to achieve [SEP]
Text from DS:  A class of diffusion algorithms with logarithmic cost over adaptive sparse
Volterra networkI
Lu Lua , Haiquan Zhaoa∗
a)School of Electrical Engineering, Southwest Jiaotong University, Chengdu, China.

Abstract
In this paper, we present a novel class of diffusion algorithms that can be used to estimate the coefficients of

arXiv:1606.08541v5 [] 2 May 2017

sparse Volterra network (SVN). The development of the algorithms is based on the logarithmic cost and l0 norm constraint. Simulations for Gaussian and impulsive scenarios are conducted to demonstrate the superior
performance of the proposed algorithms as compared with the existing algorithms.
Keywords: Distributed adaptation, Volterra filter, Sparse, Logarithmic cost.

1. Introduction
The Volterra filter has been widely used as a nonlinear system modelling tool with considerable success
[1, 2, 3]. However, such a filter becomes very computationally expensive when a large number of coefficients
are required. A second order Volterra (SO
Original label:  math.GR
Predicted label:  1
Correct label:  9
Text:  [CLS] arxiv : 1310. 0285v2 [ math. ra ] 3 mar 2018 associative subalgebras of low - dimensional majorana algebras a. castillo - ramirez∗ imperial college london, department of mathematics. south kensington campus, london, sw7 2az. email address : ac1209 @ imperial. ac. uk may 2014 abstract a majorana algebra is a commutative nonassociative real algebra generated by a finite set of idempotents, called majorana axes, that satisfy some of the properties of the 2a - axes of the monster griess algebra. the term was introduced by a. a. ivanov in 2009 inspired by the work of s. sakuma and m. miyamoto. in the present paper, we revisit mayer and neutsch ’ s theorem on associative subalgebras of the griess algebra in the context of majorana theory. we apply this result to determine all the maximal associative subalgebras of some low - dimensional majorana algebras ; namely, the majorana algebras generated by two majorana axes and the majorana representations of the symmetric group of degree 4 involving 3c - algebras. keywords : majorana representation, monster group, griess algebra. 1 introduction the largest of the sporadic simple groups, the monster group m, was constructed by griess [ g82 ] as a group of automorphisms of a 196, 884 - dimensional funded by the universidad de guadalajara and an imperial college international scholarship. ∗ 1 commutative nonassociative real algebra vm. one of the major obstacles in the examination of the griess algebra is its nonassociativity. a natural approach to deal with this issue is the study of the associative subalgebras of vm ; the seminal work in this direction was done by meyer and neutsch [ mn93 ], who proved that every maximal associative subalgebra of vm has an orthogonal basis of indecomposable idempotents. furthermore, they conjectured that 48 is the largest possible dimension of an associative subalgebra of vm. by showing that the length of any idempotent of vm is at least 1 ( with respect to our scaling ), miyamoto [ mi96 ] proved this conjecture. after this, connections [SEP]
Text from DS:  arXiv:1310.0285v2 [math.RA] 3 Mar 2018

Associative Subalgebras of Low-Dimensional
Majorana Algebras
A. Castillo-Ramirez∗
Imperial College London, Department of Mathematics.
South Kensington Campus, London, SW7 2AZ.
Email address: ac1209@imperial.ac.uk

May 2014
Abstract
A Majorana algebra is a commutative nonassociative real algebra
generated by a finite set of idempotents, called Majorana axes, that
satisfy some of the properties of the 2A-axes of the Monster Griess
algebra. The term was introduced by A. A. Ivanov in 2009 inspired
by the work of S. Sakuma and M. Miyamoto. In the present paper,
we revisit Mayer and Neutsch’s theorem on associative subalgebras of
the Griess algebra in the context of Majorana theory. We apply this
result to determine all the maximal associative subalgebras of some
low-dimensional Majorana algebras; namely, the Majorana algebras
generated by two Majorana axes and the Majorana representations of
the symmetric group of degree 4 involving 3C-algebras.
Keywo
Original label:  cs.CV
Predicted label:  2
Correct label:  9
Text:  [CLS] arxiv : 1705. 00464v2 [ cs. cl ] 16 sep 2017 speech - based visual question answering ted zhang dengxin dai tinne tuytelaars ku leuven tedz. cs @ gmail. com eth zurich dai @ vision. ee. ethz. ch ku leuven tinne. tuytelaars @ esat. kuleuven. be marie - francine moens luc van gool ku leuven sien. moens @ cs. kuleuven. be eth zurich, ku leuven vangool @ vision. ee. ethz. ch abstract this paper introduces speech - based visual question answering ( vqa ), the task of generating an answer given an image and a spoken question. two methods are studied : an end - to - end, deep neural network that directly uses audio waveforms as input versus a pipelined approach that performs asr ( automatic speech recognition ) on the question, followed by text - based visual question answering. furthermore, we investigate the robustness of both methods by injecting various levels of noise into the spoken question and find both methods to be tolerate noise at similar levels. 1 asr textmod pizza what food is this? introduction the recent years have witnessed great advances in computer vision, natural language processing, and speech recognition thanks to the advances in deep learning [ 16 ] and abundance of data [ 23 ]. this is evidenced not only by the surge of academic papers, but also by the world - wide industry interests. the convincing successes in these individual fields naturally raise the potentials of further integration towards solutions to more general ai problems. much work has been done to integrate vision and language, resulting in a wide collection of successful applications such as image / video captioning [ 27 ], movie - to - book alignment [ 31 ], and visual question answering ( vqa ) [ 3 ]. however, the importance of integrating vision and speech has remained relatively unexplored. pertaining to practical applications, voice - user interface ( vui ) has become more commonplace, and people are increasingly taking advantage of its characteristics ; it is natural, hands - free, eyes - free, far more mobile and faster than typing on certain devices [ 22 ]. as many of our daily tasks are relevant to visual scenes, there is a strong need to have a vui to talk to pictures or videos directly, be it for communication, cooperation, or guidance. speech - based vqa can be used to assist blind people [SEP]
Text from DS:  arXiv:1705.00464v2 [cs.CL] 16 Sep 2017

Speech-Based Visual Question Answering
Ted Zhang

Dengxin Dai

Tinne Tuytelaars

KU Leuven
tedz.cs@gmail.com

ETH Zurich
dai@vision.ee.ethz.ch

KU Leuven
tinne.tuytelaars@esat.kuleuven.be

Marie-Francine Moens

Luc Van Gool

KU Leuven
sien.moens@cs.kuleuven.be

ETH Zurich, KU Leuven
vangool@vision.ee.ethz.ch

ABSTRACT
This paper introduces speech-based visual question answering (VQA),
the task of generating an answer given an image and a spoken question. Two methods are studied: an end-to-end, deep neural network
that directly uses audio waveforms as input versus a pipelined approach that performs ASR (Automatic Speech Recognition) on the
question, followed by text-based visual question answering. Furthermore, we investigate the robustness of both methods by injecting
various levels of noise into the spoken question and find both methods to be tolerate noise at similar levels.

1

ASR

TextMod

pizza

what food is this?

INTRODUCTION

The recent 
Original label:  cs.AI
Predicted label:  9
Correct label:  5
Text:  [CLS] arxiv : 1710. 10686v1 [ cs. lg ] 29 oct 2017 regularization for deep learning : a taxonomy jan kukacka, vladimir golkov, and daniel cremers { jan. kukacka, vladimir. golkov, cremers } @ tum. de computer vision group department of informatics technical university of munich abstract regularization is one of the crucial ingredients of deep learning, yet the term regularization has various deﬁnitions, and regularization methods are often studied separately from each other. in our work we present a systematic, unifying taxonomy to categorize existing methods. we distinguish methods that [UNK] data, network architectures, error terms, regularization terms, and optimization procedures. we do not provide all details about the listed methods ; instead, we present an overview of how the methods can be sorted into meaningful categories and sub - categories. this helps revealing links and fundamental similarities between them. finally, we include practical recommendations both for users and for developers of new regularization methods. 1 introduction regularization is one of the key elements of machine learning, particularly of deep learning ( goodfellow et al., 2016 ), allowing to generalize well to unseen data even when training on a ﬁnite training set or with an imperfect optimization procedure. in the traditional sense of optimization and also in older neural networks literature, the term “ regularization ” is reserved solely for a penalty term in the loss function ( bishop, 1995a ). recently, the term has adopted a broader meaning : goodfellow et al. ( 2016, chap. 5 ) loosely deﬁne it as “ any modification we make to a learning algorithm that is intended to reduce its test error but not its training error ”. we ﬁnd this deﬁnition slightly restrictive and present our working deﬁnition of regularization, since many techniques considered as regularization do reduce the training error ( e. g. weight decay in alexnet ( krizhevsky et al., 2012 ) ). deﬁnition 1. regularization is any supplementary technique that aims at making the model generalize better, i. e. produce better results on the test set. this can include various properties of the loss function, the loss optimization algorithm, or other techniques. note that this deﬁnition is more in line with machine learning literature than with inverse problems literature, the latter using a more restrictive deﬁnition. before we proceed to the presentation of our [SEP]
Text from DS:  arXiv:1710.10686v1 [cs.LG] 29 Oct 2017

Regularization for Deep Learning:
A Taxonomy
Jan Kukačka, Vladimir Golkov, and Daniel Cremers
{jan.kukacka, vladimir.golkov, cremers}@tum.de
Computer Vision Group
Department of Informatics
Technical University of Munich

Abstract
Regularization is one of the crucial ingredients of deep learning, yet the term
regularization has various deﬁnitions, and regularization methods are often
studied separately from each other. In our work we present a systematic,
unifying taxonomy to categorize existing methods. We distinguish methods
that aﬀect data, network architectures, error terms, regularization terms,
and optimization procedures. We do not provide all details about the listed
methods; instead, we present an overview of how the methods can be sorted
into meaningful categories and sub-categories. This helps revealing links
and fundamental similarities between them. Finally, we include practical
recommendations both for users and for developers of new
Original label:  cs.IT
Predicted label:  9
Correct label:  5
Text:  [CLS] on low - space differentially private low - rank factorization in the spectral norm arxiv : 1611. 08954v1 [ ] 28 nov 2016 jalaj upadhyay college of information science and technology pennsylvania state university jalaj @ psu. edu abstract low - rank factorization is used in many areas of computer science where one performs spectral analysis on large sensitive data stored in the form of matrices. in this paper, we study differentially private low - rank factorization of a matrix with respect to the spectral norm in the turnstile update model. in this problem, given an input matrix a ∈ rm×n updated in the turnstile manner and a target rank k, the goal is to find two rank - k orthogonal matrices uk ∈ rm×k and vk ∈ rn×k, and one positive semidefinite diagonal matrix σk ∈ rk×k such that a ≈ uk σk vkt with respect to the spectral norm. our main contributions are two computationally efficient and sub - linear space algorithms for computing a differentially private low - rank factorization. we consider two levels of privacy. in the first level of privacy, we consider two matrices neighboring if their difference has a frobenius norm at most 1. in the second level of privacy, we consider two matrices as neighboring if their difference can be represented as an outer product of two unit vectors. both these privacy levels are stronger than those studied in the earlier papers such as dwork et al. ( stoc 2014 ), hardt and roth ( stoc 2013 ), and hardt and price ( nips 2014 ). as a corollary to our results, we get non - private algorithms that compute low - rank factorization in the turnstile update model with respect to the spectral norm. we note that, prior to this work, no algorithm that outputs low - rank factorization with respect to the spectral norm in the turnstile update model was known ; i. e., our algorithm gives the first non - private low - rank factorization with respect to the spectral norm in the turnstile update mode. our algorithms generate private linear sketches of the input matrix. therefore, using the binary tree mechanism of chan et al. ( tissec : 14 ( 3 ) ) and dwork et al. ( stoc 2010 ), we get algorithms for continual release of low - rank factorization under both these privacy levels. this gives the first instance of differentially private algorithms with continual release that guarantees a stronger [SEP]
Text from DS:  On Low-Space Differentially Private Low-rank Factorization in the
Spectral Norm

arXiv:1611.08954v1 [] 28 Nov 2016

Jalaj Upadhyay
College of Information Science and Technology
Pennsylvania State University
jalaj@psu.edu

Abstract
Low-rank factorization is used in many areas of computer science where one performs spectral analysis on large sensitive data stored in the form of matrices. In this paper, we study
differentially private low-rank factorization of a matrix with respect to the spectral norm in
the turnstile update model. In this problem, given an input matrix A ∈ Rm×n updated in
the turnstile manner and a target rank k, the goal is to find two rank-k orthogonal matrices
Uk ∈ Rm×k and Vk ∈ Rn×k , and one positive semidefinite diagonal matrix Σk ∈ Rk×k such
that A ≈ Uk Σk VkT with respect to the spectral norm.
Our main contributions are two computationally efficient and sub-linear space algorithms for
computing a differentially private low-rank factorization. We consider two lev
Original label:  math.ST
Predicted label:  7
Correct label:  0
Text:  [CLS] total variation classes beyond 1d : minimax rates, and the limitations of linear smoothers arxiv : 1605. 08400v1 [ ] 26 may 2016 veeranjaneyulu sadhanala∗ yu - xiang wang∗ ryan j. tibshirani carnegie mellon university ( these authors contributed equally ) ∗ abstract we consider the problem of estimating a function defined over n locations on a d - dimensional grid ( having all side lengths equal to n1 / d ). when the function is constrained to have discrete total variation bounded by cn, we derive the minimax optimal ( squared ) ` 2 estimation error rate, parametrized by n and cn. total variation denoising, also known as the fused lasso, is seen to be rate optimal. several simpler estimators exist, such as laplacian smoothing and laplacian eigenmaps. a natural question is : can these simpler estimators perform just as well? we prove that these estimators, and more broadly all estimators given by linear transformations of the input data, are suboptimal over the class of functions with bounded variation. this extends fundamental findings of donoho and johnstone [ 1998 ] on 1 - dimensional total variation spaces to higher dimensions. the implication is that the computationally simpler methods cannot be used for such sophisticated denoising tasks, without sacrificing statistical accuracy. we also derive minimax rates for discrete sobolev spaces over d - dimensional grids, which are, in some sense, smaller than the total variation function spaces. indeed, these are small enough spaces that linear estimators can be optimal — and a few well - known ones are, such as laplacian smoothing and laplacian eigenmaps, as we show. lastly, we investigate the problem of adaptivity of the total variation denoiser to these smaller sobolev function spaces. 1 introduction let g = ( v, e ) be a d - dimensional grid graph, i. e., a lattice graph, with equal side lengths. label the nodes as v = { 1,..., n }, and edges as e = { e1,..., em }. consider data y = ( y1,..., yn ) ∈ rn observed over the nodes, from a model yi [UNK] n ( θ0, i, σ 2 ), i. i. d., for i = 1,..., n, ( 1 ) where [SEP]
Text from DS:  Total Variation Classes Beyond 1d: Minimax Rates, and the
Limitations of Linear Smoothers

arXiv:1605.08400v1 [] 26 May 2016

Veeranjaneyulu Sadhanala∗

Yu-Xiang Wang∗

Ryan J. Tibshirani

Carnegie Mellon University
( These authors contributed equally)
∗

Abstract
We consider the problem of estimating a function defined over n locations on a d-dimensional grid
(having all side lengths equal to n1/d ). When the function is constrained to have discrete total variation
bounded by Cn , we derive the minimax optimal (squared) `2 estimation error rate, parametrized by n and
Cn . Total variation denoising, also known as the fused lasso, is seen to be rate optimal. Several simpler
estimators exist, such as Laplacian smoothing and Laplacian eigenmaps. A natural question is: can these
simpler estimators perform just as well? We prove that these estimators, and more broadly all estimators
given by linear transformations of the input data, are suboptimal over the class of functions with bounded
va
Original label:  cs.AI
Predicted label:  5
Correct label:  6
Text:  [CLS] arxiv : 1711. 00536v1 [ cs. si ] 1 nov 2017 beautiful and damned. combined effect of content quality and social ties on user engagement luca m. aiello rossano schifanella miriam redi nokia bell labs luca. aiello @ nokia - bell - labs. com university of turin schifane @ di. unito. it nokia bell labs miriam. redi @ nokia - bell - labs. com stacey svetlichnaya frank liu simon osindero flickr stacey @ yahoo - inc. com flickr frank @ yahoo - inc. com flickr simon @ yahoo - inc. com published in ieee transactions on knowledge and data engineering ( volume : pp, issue : 99 ). available at https : / / doi. org / 10. 1109 / tkde. 2017. 2747552. abstract user participation in online communities is driven by the intertwinement of the social network structure with the crowd - generated content that flows along its links. these aspects are rarely explored jointly and at scale. by looking at how users generate and access pictures of varying beauty on flickr, we investigate how the production of quality impacts the dynamics of online social systems. we develop a deep learning computer vision model to score images according to their aesthetic value and we validate its output through crowdsourcing. by applying it to over 15b flickr photos, we study for the first time how image beauty is distributed over a large - scale social system. beautiful images are evenly distributed in the network, although only a small core of people get social recognition for them. to study the impact of exposure to quality on user engagement, we set up matching experiments aimed at detecting causality from observational data. exposure to beauty is double - edged : following people who produce high - quality content increases one ’ s probability of uploading better photos ; however, an excessive imbalance between the quality generated by a user and the user ’ s neighbors leads to a decline in engagement. our analysis has practical implications for improving link recommender systems. 1 introduction the user experience in online communities is mainly determined by the social network structure and by the user - generated content that members share through their social connections. the relationship between social network dynamics and user experience [ 26, 66 ], as well as the influence of quality of content consumed on user engagement [ 9, 10, 24 ] have been extensively researched. however, the relationship between network properties and the production of quality content remains largely unexplored. this [SEP]
Text from DS:  arXiv:1711.00536v1 [cs.SI] 1 Nov 2017

Beautiful and damned. Combined effect of content quality and
social ties on user engagement
Luca M. Aiello

Rossano Schifanella

Miriam Redi

Nokia Bell Labs
luca.aiello@nokia-bell-labs.com

University of Turin
schifane@di.unito.it

Nokia Bell Labs
miriam.redi@nokia-bell-labs.com

Stacey Svetlichnaya

Frank Liu

Simon Osindero

Flickr
stacey@yahoo-inc.com

Flickr
frank@yahoo-inc.com

Flickr
simon@yahoo-inc.com

Published in IEEE Transactions on Knowledge and Data Engineering (Volume: PP, Issue: 99). Available at https://doi.org/10.1109/
TKDE.2017.2747552.

ABSTRACT
User participation in online communities is driven by the intertwinement of the social network structure with the crowd-generated
content that flows along its links. These aspects are rarely explored
jointly and at scale. By looking at how users generate and access
pictures of varying beauty on Flickr, we investigate how the production of quality impacts the dynamics of online social sy
Original label:  cs.IT
Predicted label:  7
Correct label:  3
Text:  [CLS] on fixed - parameter tractability of the mixed domination problem for graphs with bounded tree - width m. rajaati1, m. r. hooshmandasl2, m. j. dinneen3, a. shakiba4 arxiv : 1612. 08234v1 [ cs. dm ] 25 dec 2016 1, 2 department of computer science, yazd university, yazd, iran. the laboratory of quantum information processing, yazd university, yazd, iran. 3 department of computer science, the university of auckland, new zealand. 4 department of computer science, vali - e - asr university of rafsanjan, rafsanjan, iran. e - mail : 1 m. rajaati @ stu. yazd. ac. ir, 2 hooshmandasl @ yazd. ac. ir, 3 m. dinneen @ auckland. ac. nz, 4 ali. shakiba @ vru. ac. ir. 1, 2, 4 abstract a mixed dominating set for a graph g = ( v, e ) is a set s ⊆ v ∪ e such that every element x ∈ ( v ∪ e ) \ s is either adjacent or incident to an element of s. the mixed domination number of a graph g, denoted by γm ( g ), is the minimum cardinality of mixed dominating sets of g and any mixed dominating set with cardinality of γm ( g ) is called a minimum mixed dominating set. the mixed domination problem is to find a minimum mixed dominating set for graph g and is known to be an npcomplete problem. in this paper, we present a novel approach to solve the mixed domination problem. our new technique of assigning power to edges and vertices, and charging vertices for edges combined 2 with with dynamic programming leads to a fixed - parameter algorithm of time o ( 3tw × tw2 × | v | ), which proves our next result, which is the mixed domination problem is fixed - parameter tractable with respect to tree - width. keywords : mixed domination ; tree decomposition ; tree - width ; fixed - parameter tractable. 1 introduction the mixed domination problem, traditionally called total cover problem, is first introduced in 1977 by alavi et. al. [ 4 ]. this problem is shown to be np - complete for general graphs in [ 18 ]. so, several approximation algorithms are proposed for solving this problem such as a 2 - factor approximation algorithm by hatami [ 12 ]. [SEP]
Text from DS:  On fixed-parameter tractability of the mixed domination
problem for graphs with bounded tree-width
M. Rajaati1 , M. R. Hooshmandasl2 , M. J. Dinneen3 , A. Shakiba4

arXiv:1612.08234v1 [cs.DM] 25 Dec 2016

1,2

Department of Computer Science, Yazd University, Yazd, Iran.
The Laboratory of Quantum Information Processing, Yazd University, Yazd, Iran.
3
Department of Computer Science, The University of Auckland, New Zealand.
4
Department of Computer Science, Vali-e-Asr University of Rafsanjan, Rafsanjan, Iran.
e-mail:1 m.rajaati@stu.yazd.ac.ir, 2 hooshmandasl@yazd.ac.ir, 3 m.dinneen@auckland.ac.nz, 4 ali.shakiba@vru.ac.ir.
1,2,4

Abstract
A mixed dominating set for a graph G = (V, E) is a set S ⊆ V ∪ E such that every element
x ∈ (V ∪ E)\S is either adjacent or incident to an element of S. The mixed domination number of a
graph G, denoted by γm (G), is the minimum cardinality of mixed dominating sets of G and any mixed
dominating set with cardinality of γm (G) is called a minimum mixed dom
Original label:  cs.NE
Predicted label:  7
Correct label:  5
Text:  [CLS] arxiv : 1509. 05982v2 [ ] 22 sep 2015 denoising without access to clean data using a partitioned autoencoder dan stowell centre for digital music school of elec. eng. and computer science queen mary university of london richard e. turner computational and biological learning lab department of engineering university of cambridge september 24, 2015 abstract training a denoising autoencoder neural network requires access to truly clean data, a requirement which is often impractical. to remedy this, we introduce a method to train an autoencoder using only noisy data, having examples with and without the signal class of interest. the autoencoder learns a partitioned representation of signal and noise, learning to reconstruct each separately. we illustrate the method by denoising birdsong audio ( available abundantly in uncontrolled noisy datasets ) using a convolutional autoencoder. 1 introduction an autoencoder ( ae ) is a neural network trained in unsupervised fashion, to encode its input to some latent representation and to decode that representation to a faithful reconstruction of its input. the autoencoder can then be used as a codec, or to convert data to its latent representation for downstream processing such as classification. the denoising autoencoder ( dae ) is a variant of this in which the inputs are combined with some corruption ( such as additive noise or masking ), and the system is trained to recover the clean, de - noised data [ 1 ]. the dae training scheme can be used in denoising applications, and is also a popular way to encourage the autoencoder to learn a more meaningful latent representation of the data. autoencoders including the dae have yielded leading results in recent years in deep learning for signal processing [ 1, 2 ]. however, there is a significant problem with the dae approach which hampers its use in practical applications : it may often be impossible to supply 1 truly clean data. this is common in our application example — natural sound recordings — but also for video, image and audio applications across many domains. in fact, objects / events are often sparsely represented in data while background and other noise are densely represented, meaning that it is often easy to provide “ noise - only ” examples while difficult to provide “ noise - free ” examples. in this paper we propose an alternative approach to train an ae so [SEP]
Text from DS:  arXiv:1509.05982v2 [] 22 Sep 2015

Denoising without access to clean data
using a partitioned autoencoder
Dan Stowell
Centre for Digital Music
School of Elec. Eng. and Computer Science
Queen Mary University of London
Richard E. Turner
Computational and Biological Learning Lab
Department of Engineering
University of Cambridge
September 24, 2015
Abstract
Training a denoising autoencoder neural network requires access to
truly clean data, a requirement which is often impractical. To remedy
this, we introduce a method to train an autoencoder using only noisy
data, having examples with and without the signal class of interest. The
autoencoder learns a partitioned representation of signal and noise, learning to reconstruct each separately. We illustrate the method by denoising
birdsong audio (available abundantly in uncontrolled noisy datasets) using
a convolutional autoencoder.

1

Introduction

An autoencoder (AE) is a neural network trained in unsupervised fashion, to
encode its input to 
Original label:  math.GR
Predicted label:  8
Correct label:  3
Text:  [CLS] global structural properties of random graphs arxiv : 1505. 01913v3 [ math. pr ] 7 nov 2016 jason behrstock, victor falgas - ravry, mark f. hagen, and tim susse abstract. we study two global structural properties of a graph γ, denoted as and cfs, which arise in a natural way from geometric group theory. we study these properties in the erdos – renyi random graph model g ( n, p ), proving the existence of a sharp threshold for a random graph to have the as property asymptotically almost surely, and giving fairly tight bounds for the corresponding threshold for the cfs property. as an application of our results, we show that for any constant p and any γ ∈ g ( n, p ), the right - angled coxeter group wγ asymptotically almost surely has quadratic divergence and thickness of order 1, generalizing and strengthening a result of behrstock – hagen – sisto [ 8 ]. indeed, we show that at a large range of densities a random right - angled coxeter group has quadratic divergence. introduction in this article, we consider two properties of graphs motivated by geometric group theory. we show that these properties are typically present in random graphs. we repay the debt to geometric group theory by applying our ( purely graph - theoretic ) results to the large - scale geometry of coxeter groups. random graphs. let g ( n, p ) be the random graph model on n vertices obtained by including each edge independently at random with probability p = p ( n ). the parameter p is often referred to as the density of g ( n, p ). the model g ( n, p ) was introduced by gilbert [ 23 ], and the resulting random graphs are usually referred to as the “ erdos – renyi random graphs ” in honor of erdos and renyi ’ s seminal contributions to the field, and we follow this convention. we say that a property p holds asymptotically almost surely ( a. a. s. ) in g ( n, p ) if for γ ∈ g ( n, p ) we have p ( γ ∈ p ) → 1 as n → ∞. in this paper we will be interested in proving that certain global properties hold a. a. s. in g ( n, p ) both for a wide range of probabilities p = p ( n ). a graph property is ( mono [SEP]
Text from DS:  GLOBAL STRUCTURAL PROPERTIES OF RANDOM GRAPHS

arXiv:1505.01913v3 [math.PR] 7 Nov 2016

JASON BEHRSTOCK, VICTOR FALGAS-RAVRY, MARK F. HAGEN, AND TIM SUSSE

Abstract. We study two global structural properties of a graph Γ, denoted AS and CFS,
which arise in a natural way from geometric group theory. We study these properties in the
Erdős–Rényi random graph model G(n, p), proving the existence of a sharp threshold for a
random graph to have the AS property asymptotically almost surely, and giving fairly tight
bounds for the corresponding threshold for the CFS property.
As an application of our results, we show that for any constant p and any Γ ∈ G(n, p),
the right-angled Coxeter group WΓ asymptotically almost surely has quadratic divergence and
thickness of order 1, generalizing and strengthening a result of Behrstock–Hagen–Sisto [8].
Indeed, we show that at a large range of densities a random right-angled Coxeter group has
quadratic divergence.

Introduction
In this article, we consider
Original label:  cs.NE
Predicted label:  5
Correct label:  8
Text:  [CLS] quantum autoencoders via quantum adders with genetic algorithms l. lamata, 1 u. alvarez - rodriguez, 1 j. d. martın - guerrero, 2 m. sanz, 1 and e. solano1, 3 arxiv : 1709. 07409v1 [ quant - ph ] 21 sep 2017 1 department of physical chemistry, university of the basque country upv / ehu, apartado 644, 48080, bilbao, spain 2 idal, electronic engineering department, university of valencia, avgda. universitat s / n, 46100 burjassot, valencia, spain 3 ikerbasque, basque foundation for science, maria diaz de haro 3, 48011, bilbao, spain the quantum autoencoder is a recent paradigm in the field of quantum machine learning, which may enable an enhanced use of resources in quantum technologies. to this end, quantum neural networks with less nodes in the inner than in the outer layers were considered. here, we propose a useful connection between approximate quantum adders and quantum autoencoders. specifically, this link allows us to employ optimized approximate quantum adders, obtained with genetic algorithms, for the implementation of quantum autoencoders for a variety of initial states. furthermore, we can also directly optimize the quantum autoencoders via genetic algorithms. our approach opens a different path for the design of quantum autoencoders in controllable quantum platforms. introduction. — quantum machine learning is an emerging field that aims at enhancing machine learning methods with quantum technologies [ 1 – 4 ]. the synergy works two - fold : either through genuine quantum effects, such as entanglement, to speed up the calculations of machine learning [ 1, 2 ], or to employ classical machine learning to improve quantum processes [ 5, 6 ]. in this respect, an advanced protocol has been considered, inspired in the classical autoencoder techniques of deep learning [ 7 ], namely, a quantum autoencoder [ 8, 9 ]. other topics related to biomimetic quantum technologies in general, which have emerged in recent years, involve quantum artificial life [ 10, 11 ], quantum reinforcement learning in quantum technologies [ 12 ], quantum memristors [ 13 – 16 ], quantum helmholtz and boltzmann machines [ 17 – 19 ], and quantum machine learning with timedelay equations [ 20, 21 ]. a quantum autoencoder, see [SEP]
Text from DS:  Quantum Autoencoders via Quantum Adders with Genetic Algorithms
L. Lamata,1 U. Alvarez-Rodriguez,1 J. D. Martı́n-Guerrero,2 M. Sanz,1 and E. Solano1, 3

arXiv:1709.07409v1 [quant-ph] 21 Sep 2017

1

Department of Physical Chemistry, University of the Basque Country UPV/EHU, Apartado 644, 48080, Bilbao, Spain
2
IDAL, Electronic Engineering Department, University of Valencia,
Avgda. Universitat s/n, 46100 Burjassot, Valencia, Spain
3
IKERBASQUE, Basque Foundation for Science, Maria Diaz de Haro 3, 48011, Bilbao, Spain
The quantum autoencoder is a recent paradigm in the field of quantum machine learning, which
may enable an enhanced use of resources in quantum technologies. To this end, quantum neural
networks with less nodes in the inner than in the outer layers were considered. Here, we propose
a useful connection between approximate quantum adders and quantum autoencoders. Specifically,
this link allows us to employ optimized approximate quantum adders, obtained with genetic algorithms
Original label:  math.AC
Predicted label:  9
Correct label:  1
Text:  [CLS] arxiv : 1404. 6939v1 [ ] 28 apr 2014 on two dimensional mixed characteristic rings of finite cohen macaulay type tony j. puthenpurakal abstract. in this paper we give a bountiful number of examples of two dimensional mixed characteristic rings of finite cohen macaulay type. for a large sub - class of these examples we give a complete description of its indecomposable maximal cohen - macaulay modules and we also compute its ar - quiver. 1. introduction let ( a, m ) be a henselian cohen - macaulay local ring of dimension d ≥ 0. as a is henselian the category of finitely generated a - modules is krull - schmidt, i. e., any finitely generated a - module is uniquely a finite direct sum of indecomposable a - modules. we say a has finite representaion type if a has only finitely many indecomposable maximal cohen - macaulay modules. there has been a lot of work towards understanding cohen - macaulay rings of finite representation type. see [ 17 ] for a very readable account of this work. we should note that although the basic theory is developed in general, most of the examples considered are equicharacteristic, i. e., a contains a field. see [ 13 ] for examples of one - dimensional hypersurfaces of mixed characteristic rings of finite representation type. let t = k [ [ x1, x2 ] ] and let g be a finite subgroup of gl2 ( k ) acting linearly on t. in a fundamental work [ 1 ], auslander proved that the ring of invariants a = t g is of finite representation type. when g has no psuedo - reflections, he gave a description of all indecomposable maximal cohen - macaulay a - modules and constructed all ar - sequences of a. furthermore he showed that the ar - quiver of a is isomorphic to the mckay graph of g. in this paper we construct examples of two dimensional mixed characteristic rings of finite cohen macaulay type. our examples also arise as invariant rings but with a twist. let ( v, π ) be a complete dvr of characteristic zero having residue field k = v / π, an algebraically closed field of characteristic p > 0. let g be a finite subgroup of gl2 ( v ). we assume that p [UNK] | g |. so | g | is a unit in v. [SEP]
Text from DS:  arXiv:1404.6939v1 [] 28 Apr 2014

ON TWO DIMENSIONAL MIXED CHARACTERISTIC RINGS
OF FINITE COHEN MACAULAY TYPE
TONY J. PUTHENPURAKAL
Abstract. In this paper we give a bountiful number of examples of two dimensional mixed characteristic rings of finite Cohen Macaulay type. For a large
sub-class of these examples we give a complete description of its indecomposable maximal Cohen-Macaulay modules and we also compute its AR-quiver.

1. introduction
Let (A, m) be a Henselian Cohen-Macaulay local ring of dimension d ≥ 0. As
A is Henselian the category of finitely generated A-modules is Krull-Schmidt, i.e.,
any finitely generated A-module is uniquely a finite direct sum of indecomposable
A-modules. We say A has finite representaion type if A has only finitely many
indecomposable maximal Cohen-Macaulay modules.
There has been a lot of work towards understanding Cohen-Macaulay rings of
finite representation type. See [17] for a very readable account of this work. We
should note that although the
Original label:  cs.PL
Predicted label:  6
Correct label:  3
Text:  [CLS] thresholds of braided convolutional codes on the awgn channel muhammad umar farooq, saeedeh moloudi, and michael lentmaier arxiv : 1802. 10540v1 [ ] 28 feb 2018 dept. of electrical and information technology, lund university, sweden emails : { muhammad. umar farooq, saeedeh. moloudi, michael. lentmaier } @ eit. lth. se abstract — in this paper, we perform a threshold analysis of braided convolutional codes ( bccs ) on the additive white gaussian noise ( awgn ) channel. the decoding thresholds are estimated by monte - carlo density evolution ( mc - de ) techniques and compared with approximate thresholds from an erasure channel prediction. the results show that, with spatial coupling, the predicted thresholds are very accurate and quickly approach capacity if the coupling memory is increased. for uncoupled ensembles with random puncturing, the prediction can be improved with help of the awgn threshold of the unpunctured ensemble. i. i ntroduction braided convolutional codes ( bccs ) [ 1 ] are a class of spatially - coupled ( sc ) turbo - like codes with regular graph structure. on the binary erasure channel ( bec ), explicit density evolution ( de ) equations have been derived for bccs in [ 4 ], which can be used to efficiently compute exact decoding thresholds for that channel. the results show that bccs have superior maximum - a - posteriori ( map ) decoding thresholds compared to parallel or serially concatenated codes on the binary erasure channel ( bec ) [ 5 ]. furthermore it has been proven analytically in [ 5 ] that threshold saturation occurs, i. e., with spatial coupling a belief propagation ( bp ) decoder can achieve the same threshold as an optimal map decoder. the aim of this paper is to compute the bp thresholds of bccs on the additive white gaussian noise ( awgn ) channel. for this channel, exact de equations are not available for turbo - like codes, and monte carlo ( mc ) methods are usually applied to estimate decoding thresholds. one of the difficulties of such an approach is that the graphs of spatially coupled systems contain a large number of edge types whose message densities have to be considered individually during de. this requires significantly larger computational efforts than classical methods, like the single [SEP]
Text from DS:  Thresholds of Braided Convolutional Codes
on the AWGN Channel
Muhammad Umar Farooq, Saeedeh Moloudi, and Michael Lentmaier

arXiv:1802.10540v1 [] 28 Feb 2018

Dept. of Electrical and Information Technology,
Lund University, Sweden
Emails: {muhammad.umar farooq, saeedeh.moloudi, michael.lentmaier}@eit.lth.se
Abstract—In this paper, we perform a threshold analysis
of braided convolutional codes (BCCs) on the additive white
Gaussian noise (AWGN) channel. The decoding thresholds are
estimated by Monte-Carlo density evolution (MC-DE) techniques
and compared with approximate thresholds from an erasure
channel prediction. The results show that, with spatial coupling,
the predicted thresholds are very accurate and quickly approach
capacity if the coupling memory is increased. For uncoupled ensembles with random puncturing, the prediction can be improved
with help of the AWGN threshold of the unpunctured ensemble.

I. I NTRODUCTION
Braided convolutional codes (BCCs) [1] are a class of
spatially
Original label:  cs.AI
Predicted label:  1
Correct label:  9
Text:  [CLS] automated flow for compressing convolution neural networks for efficient edge - computation with fpga arxiv : 1712. 06272v1 [ cs. ar ] 18 dec 2017 farhan shafiq, takato yamada, antonio t. vilchez, and sakyasingha dasgupta leapmind, inc. tokyo, japan { farhan, yamada, antonio, sakya } @ leapmind. io abstract deep convolutional neural networks ( cnn ) based solutions are the current stateof - the - art for computer vision tasks. due to the large size of these models, they are typically run on clusters of cpus or gpus. however, power requirements and cost budgets can be a major hindrance in adoption of cnn for iot applications. recent research highlights that cnn contain significant redundancy in their structure and can be quantized to lower bit - width parameters and activations, while maintaining acceptable accuracy. low bit - width and especially single bit - width ( binary ) cnn are particularly suitable for mobile applications based on fpga implementation, due to the bitwise logic operations involved in binarized cnn. moreover, the transition to lower bit - widths opens new avenues for performance optimizations and model improvement. in this paper, we present an automatic flow from trained tensorflow models to fpga system on chip implementation of binarized cnn. this flow involves quantization of model parameters and activations, generation of network and model in embedded - c, followed by automatic generation of the fpga accelerator for binary convolutions. the automated flow is demonstrated through implementation of binarized " yolov2 " on the low cost, low power cyclonev fpga device. experiments on object detection using binarized yolov2 demonstrate significant performance benefit in terms of model size and inference speed on fpga as compared to cpu and mobile cpu platforms. furthermore, the entire automated flow from trained models to fpga synthesis can be completed within one hour. 1 introduction deep convolutional neural networks ( cnn ) have achieved significant results in computer vision, speech recognition and language translation. however the computation and memory demands of recent cnn architectures require powerful gpus, distributed cpu servers, specialized asic or dsp processors. the size and power requirements of such platforms restrict the wide - spread adoption of cnn models for efficient edge computing, mobile devices and the internet of things in general. interestingly, recent results on compression of these [SEP]
Text from DS:  Automated flow for compressing convolution neural
networks for efficient edge-computation with FPGA

arXiv:1712.06272v1 [cs.AR] 18 Dec 2017

Farhan Shafiq, Takato Yamada, Antonio T. Vilchez, and Sakyasingha Dasgupta
LeapMind, Inc.
Tokyo, Japan
{farhan, yamada, antonio, sakya}@leapmind.io

Abstract
Deep convolutional neural networks (CNN) based solutions are the current stateof-the-art for computer vision tasks. Due to the large size of these models, they are
typically run on clusters of CPUs or GPUs. However, power requirements and cost
budgets can be a major hindrance in adoption of CNN for IoT applications. Recent
research highlights that CNN contain significant redundancy in their structure and
can be quantized to lower bit-width parameters and activations, while maintaining
acceptable accuracy. Low bit-width and especially single bit-width (binary) CNN
are particularly suitable for mobile applications based on FPGA implementation,
due to the bitwise logic operations involved in bin
Original label:  cs.IT
Predicted label:  8
Correct label:  6
Text:  [CLS] distributed graph clustering using modularity and map equation? arxiv : 1710. 09605v2 [ ] 22 mar 2018 michael hamann, ben strasser, dorothea wagner, and tim zeitz institute of theoretical informatics, karlsruhe institute of technology, karlsruhe, germany ; michael. hamann @ kit. edu, academia @ ben - strasser. net, dorothea. wagner @ kit. edu, and tim. zeitz @ kit. edu abstract. we study large - scale, distributed graph clustering. given an undirected graph, our objective is to partition the nodes into disjoint sets called clusters. a cluster should contain many internal edges while being sparsely connected to other clusters. in the context of a social network, a cluster could be a group of friends. modularity and map equation are established formalizations of this internally - dense - externally - sparse principle. we present two versions of a simple distributed algorithm to optimize both measures. they are based on thrill, a distributed big data processing framework that implements an extended mapreduce model. the algorithms for the two measures, dslm - mod and dslm - map, differ only slightly. adapting them for similar quality measures is straight - forward. we conduct an extensive experimental study on real - world graphs and on synthetic graph clustering benchmark graphs with up to 68 billion edges. our algorithms are fast while detecting clusterings similar to those detected by other sequential, parallel and distributed clustering algorithms. compared to the distributed gossipmap algorithm, dslm - map needs less memory and is up to an order of magnitude faster. 1 introduction graph clustering is a well researched topic [ 8, 10 ] and has many applications, such as community detection in social networks where users can be modeled as nodes and friendships as edges between them. these graphs can be huge and may not fit into the main memory of a single machine. we therefore study distributed extensions of established single machine clustering algorithms. this enables us to efficiently compute clusterings in huge graphs. we consider the problem of clustering a graph into disjoint clusters. while there is no universally accepted definition of a good clustering, it is commonly accepted that clusters should be internally densely and externally sparsely connected. our algorithms optimize two established quality measures that formalize this concept : modularity [ 19 ] and map equation [ 21 ]. other community detection formalizations have been considered. for example, egolp [ 7 ] is a distributed algorithm to find overlapping clusters [SEP]
Text from DS:  Distributed Graph Clustering using Modularity
and Map Equation ?

arXiv:1710.09605v2 [] 22 Mar 2018

Michael Hamann, Ben Strasser, Dorothea Wagner, and Tim Zeitz
Institute of Theoretical Informatics, Karlsruhe Institute of Technology, Karlsruhe,
Germany; michael.hamann@kit.edu, academia@ben-strasser.net,
dorothea.wagner@kit.edu, and tim.zeitz@kit.edu

Abstract. We study large-scale, distributed graph clustering. Given an
undirected graph, our objective is to partition the nodes into disjoint sets
called clusters. A cluster should contain many internal edges while being
sparsely connected to other clusters. In the context of a social network, a
cluster could be a group of friends. Modularity and map equation are established formalizations of this internally-dense-externally-sparse principle. We present two versions of a simple distributed algorithm to optimize
both measures. They are based on Thrill, a distributed big data processing framework that implements an extended MapReduce model
Original label:  math.ST
Predicted label:  2
Correct label:  9
Text:  [CLS] arxiv : 1804. 02811v1 [ ] 9 apr 2018 connecting dots – from local covariance to empirical intrinsic geometry and locally linear embedding john malik, chao shen, hau - tieng wu, and nan wu abstract. local covariance structure under the manifold setup has been widely applied in the machine learning society. based on the established theoretical results, we provide an extensive study of two relevant manifold learning algorithms, empirical intrinsic geometry ( eig ) and the locally linear embedding ( lle ) under the manifold setup. particularly, we show that without an accurate dimension estimation, the geodesic distance estimation by eig might be corrupted. furthermore, we show that by taking the local covariance matrix into account, we can more accurately estimate the local geodesic distance. when understanding lle based on the local covariance structure, its intimate relationship with the curvature suggests a variation of lle depending on the “ truncation scheme ”. we provide a theoretical analysis of the variation. keywords : local covariance matrix, empirical intrinsic geometry, locally linear embedding, geodesic distance 1. introduction covariance is arguably one of the most important quantities in data analysis. it has been widely studied in the past century and is still an active research topic nowadays. in this paper, we focus on the local covariance structure under the manifold setup, which has been widely applied, explicitly or implicitly, to various applications in different fields ; see, for example, a far - from - complete list [ 11, 19, 7, 4, 32, 13, 8, 20, 10, 23, 17, 14, 1 ]. in the past few years, its mathematical and statistical properties have been well established [ 23, 5, 3, 12, 28, 30 ] for different purposes. in this paper, based on the established theoretical foundation, we extensively discuss two topics in the manifold learning society – empirical intrinsic geometry ( eig ) and locally linear embedding ( lle ). eig [ 25, 26 ], or originally called non - linear independent component analysis [ 22 ], is a technique aiming to deal with the distortion underlying the collected dataset that is caused by the observation process. in many applications, the manifold structure we have interest cannot be directly accessed, but only via an observation. however, the observation process might nonlinearly deform the manifold we have interest. as a result, the information inferred from the observed data [SEP]
Text from DS:  arXiv:1804.02811v1 [] 9 Apr 2018

CONNECTING DOTS – FROM LOCAL COVARIANCE TO
EMPIRICAL INTRINSIC GEOMETRY AND LOCALLY LINEAR
EMBEDDING
JOHN MALIK, CHAO SHEN, HAU-TIENG WU, AND NAN WU

Abstract. Local covariance structure under the manifold setup has been
widely applied in the machine learning society. Based on the established theoretical results, we provide an extensive study of two relevant manifold learning
algorithms, empirical intrinsic geometry (EIG) and the locally linear embedding (LLE) under the manifold setup. Particularly, we show that without an
accurate dimension estimation, the geodesic distance estimation by EIG might
be corrupted. Furthermore, we show that by taking the local covariance matrix into account, we can more accurately estimate the local geodesic distance.
When understanding LLE based on the local covariance structure, its intimate relationship with the curvature suggests a variation of LLE depending
on the “truncation scheme”. We provide a theoretical analysi
Original label:  cs.CE
Predicted label:  2
Correct label:  9
Text:  [CLS] arxiv : cs / 0609092v1 [ ] 16 sep 2006 analysis of equality relationships for imperative programs pavel emelianov∗ institute of informatics systems, 6 avenue lavrentiev 630090 novosibirsk, russia emelianov @ iis. nsk. su march 1, 2018 abstract in this article, we discuss a flow – sensitive analysis of equality relationships for imperative programs. we describe its semantic domains, general purpose operations over abstract computational states ( term evaluation and identification, semantic completion, widening operator, etc. ) and semantic transformers corresponding to program constructs. we summarize our experiences from the last few years concerning this analysis and give attention to applications of analysis of automatically generated code. among other illustrating examples, we consider a program for which the analysis diverges without a widening operator and results of analyzing residual programs produced by some automatic partial evaluator. an example of analysis of a program generated by this evaluator is given. keywords : abstract interpretation, value numbering, equality relationships for program terms, formal grammars, semantic transformers, widening operator, automatically generated programs. introduction semantic analysis is a powerful technique for building effective and reliable programming systems. in [ 17, 18, 16 ] we presented a new kind of a semantic flow – sensitive analysis designed in the framework of abstract interpretation [ 9, 10, 11 ]. this analysis which determines an approximation of sets of invariant term equalities t1 = t2 was called the analysis of equality relationships for program terms ( hereinafter referred to as era ). most traditional static analyses of imperative programs are interested in finding the ( in ) equalities of a specific kind ( so – called value analyses ; only they are discussed here ) ∗ this work was partly done when the author was in laboratoire d ’ informatique, ecole polytechnique ( palaiseau, france ) and ecole normale superieure d ’ ingenieur ( bourges, france ). 1 describing regular approximations ( i. e. they have simple mathematical descriptions and machine representations ) of sets of values : convex polyhedrons / octahedrons / octagons [ 14, 27, 36, 8 ], affine [ 32, 25 ] and congruent [ 24, 34 ] hyper - planes, their non - relational counterparts [ 9, 43, 23, 35 ] as well, etc. they are carefully designed to be reasonable ( i. e. they express non - trivial semantic properties ) and effectively computed [SEP]
Text from DS:  arXiv:cs/0609092v1 [] 16 Sep 2006

Analysis of Equality Relationships
for Imperative Programs
Pavel Emelianov∗
Institute of Informatics Systems,
6 avenue Lavrentiev
630090 Novosibirsk, Russia
emelianov@iis.nsk.su
March 1, 2018

Abstract
In this article, we discuss a flow–sensitive analysis of equality relationships
for imperative programs. We describe its semantic domains, general purpose operations over abstract computational states (term evaluation and identification,
semantic completion, widening operator, etc.) and semantic transformers corresponding to program constructs. We summarize our experiences from the last
few years concerning this analysis and give attention to applications of analysis of
automatically generated code. Among other illustrating examples, we consider a
program for which the analysis diverges without a widening operator and results
of analyzing residual programs produced by some automatic partial evaluator. An
example of analysis of a program generated by thi
Original label:  math.ST
Predicted label:  7
Correct label:  1
Text:  [CLS] a mathematical characterization of confidence as valid belief arxiv : 1707. 00486v1 [ ] 3 jul 2017 ryan martin department of statistics north carolina state university rgmarti3 @ ncsu. edu july 4, 2017 abstract confidence is a fundamental concept in statistics, but there is a tendency to misinterpret it as probability. in this paper, i argue that an intuitively and mathematically more appropriate interpretation of confidence is through belief / plausibility functions, in particular, those that satisfy a certain validity property. given their close connection with confidence, it is natural to ask how a valid belief / plausibility function can be constructed directly. the inferential model ( im ) framework provides such a construction, and here i prove a complete - class theorem stating that, for every nominal confidence region, there exists a valid im whose plausibility regions are contained by the given confidence region. this characterization has implications for statistics understanding and communication, and highlights the importance of belief functions and the im framework. keywords and phrases : confidence distribution ; inferential model ; plausibility function ; probability ; random set. 1 introduction confidence is a fundamental concept in statistics, “ arguably the most substantive ingredient in modern model - based theory ” ( fraser 2011b ), dating back to neyman ( 1941 ) and also, indirectly, to fisher ( 1973 ), through its close ties to fiducial inference ( efron 1998 ; seidenfeld 1992 ; zabell 1992 ). however, like the controversial p - value ( e. g., ionides et al. 2017 ; trafimowa and marks 2015 ; wasserstein and lazar 2016 ), interpretation of this fundamental concept is somewhat elusive. for example, as instructors teaching confidence intervals to students in an introductory statistics course, we are careful to distinguish confidence from probability : “ 95 % confidence ” does not mean that the unknown parameter resides in the stated interval with probability 0. 95. unfortunately, there apparently is no fully satisfactory explanation of what the “ 95 % confidence ” feature of the stated interval actually does mean. in practice, a stated confidence interval is informally interpreted as a set of parameter values that, together, is “ sufficiently and justifiably believable ” or, equivalently, as a collection of parameter values that, individually, are 1 “ sufficiently and justifiably plausible. ” statisticians are reluctant to adopt the use of words like “ believable ” and “ plausible ” because of their seemingly [SEP]
Text from DS:  A mathematical characterization of confidence
as valid belief

arXiv:1707.00486v1 [] 3 Jul 2017

Ryan Martin
Department of Statistics
North Carolina State University
rgmarti3@ncsu.edu
July 4, 2017
Abstract
Confidence is a fundamental concept in statistics, but there is a tendency to misinterpret it as probability. In this paper, I argue that an intuitively and mathematically more appropriate interpretation of confidence is through belief/plausibility
functions, in particular, those that satisfy a certain validity property. Given their
close connection with confidence, it is natural to ask how a valid belief/plausibility
function can be constructed directly. The inferential model (IM) framework provides such a construction, and here I prove a complete-class theorem stating that,
for every nominal confidence region, there exists a valid IM whose plausibility
regions are contained by the given confidence region. This characterization has
implications for statistics understanding and commu
Original label:  cs.SY
Predicted label:  2
Correct label:  1
Text:  [CLS] power grid decomposition based on vertex cut sets and its applications to topology control and power trading shuai wang & john baillieul arxiv : 1803. 05860v2 [ ] 18 mar 2018 abstract it is well known that the reserves / redundancies built into the transmission grid in order to address a variety of contingencies over a long planning horizon may, in the short run, cause economic dispatch inefficiency. accordingly, power grid optimization by means of short term line switching has been proposed and is typically formulated as a mixed integer programming problem by treating the state of the transmission lines as a binary decision variable, i. e. in - service or out - of - service, in the optimal power flow problem. to handle the combinatorial explosion, a number of heuristic approaches to grid topology reconfiguration have been proposed in the literature. this paper extends our recent results on the iterative heuristics and proposes a fast grid decomposition algorithm based on vertex cut sets with the purpose of further reducing the computational cost. the paper concludes with a discussion of the possible relationship between vertex cut sets in transmission networks and power trading. i. i ntroduction siting and maintaining massive power infrastructure is not cheap [ 1 ] and therefore makes the optimal use of existing network a priority. because of the fast time constants in changing the system state and the very low costs, corrective switching operations, including transmission line switching, bus - bar switching, and shunt element switching, etc., are often the first post - contingency corrective action to be considered and implemented [ 2 ]. the focus of corrective switching has been mainly on handling line overload [ 3 ], [ 4 ] and voltage violations [ 5 ], [ 6 ], and most recently, on co - optimizing the generation along with the network topology [ 7 ], [ 8 ], [ 9 ]. based on the dc optimal power flow ( opf ) problem, such co - optimization is typically formulated as a mixed integer programming problem ( mip ) with some binary variables denoting the choices of transmission line switches. there are a number of challenges in implementing effective transmission topology control, including understanding and avoiding voltage problems, transient instability, reactive power problems [ 10 ] and, most importantly, the ability to find a good solution within a time that is short enough to be of practical use. due to the combinatorial nature of the problem and the nonlinearities inherent to networks, the approaches proposed in [SEP]
Text from DS:  Power Grid Decomposition Based on Vertex Cut Sets and Its Applications to
Topology Control and Power Trading
Shuai Wang & John Baillieul

arXiv:1803.05860v2 [] 18 Mar 2018

Abstract
It is well known that the reserves/redundancies built into the transmission grid in order to address a variety of contingencies
over a long planning horizon may, in the short run, cause economic dispatch inefficiency. Accordingly, power grid optimization
by means of short term line switching has been proposed and is typically formulated as a mixed integer programming problem
by treating the state of the transmission lines as a binary decision variable, i.e. in-service or out-of-service, in the optimal
power flow problem. To handle the combinatorial explosion, a number of heuristic approaches to grid topology reconfiguration
have been proposed in the literature. This paper extends our recent results on the iterative heuristics and proposes a fast grid
decomposition algorithm based on vertex cut sets with the
Original label:  cs.DS
Predicted label:  6
Correct label:  2
Text:  [CLS] option pricing using bayesian neural networks michael maio pires, tshilidzi marwala school of electrical and information engineering, university of the witwatersrand, 2050, south africa m. pires @ ee. wits. ac. za, t. marwala @ ee. wits. ac. za abstract options have provided a field of much study because of the complexity involved in pricing them. the black - scholes equations were developed to price options but they are only valid for european styled options. there is added complexity when trying to price american styled options and this is why the use of neural networks has been proposed. neural networks are able to predict outcomes based on past data. the inputs to the networks here are stock volatility, strike price and time to maturity with the output of the network being the call option price. there are two techniques for bayesian neural networks used. one is automatic relevance determination ( for gaussian approximation ) and one is a hybrid monte carlo method, both used with multi - layer perceptrons. 1. introduction this document deals with the use of two kinds of bayesian neural networks applied to the american options pricing problem. both bayesian techniques used were used with multlayer perceptron ( mlp ) networks. the techniques can also be used with radial basis function ( rbf ) networks [ 1 ] but they were only used with mlp networks here. the two bayesian techniques used are automatic relevance determination ( ard ) ( for gaussian approximation ) and the hybrid monte carlo method ( hmc ) which will be discussed. firstly we need to introduce the notion of an option. an option is the right ( not the obligation ) to buy or sell some underlying asset at a later date but by fixing the price of the asset now [ 2 ]. for someone to have this option, he / she has to pay a fee known as the option price. there are two kinds of options, namely a call and a put option. a call option gives the person the right to buy the underlying asset and a put option gives the person the right to sell the underlying asset [ 2 ]. the pricing of either call or put options is equally difficult and something that has brought much research interest. black et al. [ 3 ] provided equations in 1973 that provided a pricing formula for call and put options. to obtain these equations, several assumptions had to be made. the most important assumption made is that the formulas only held for european styled options [ 4 ]. european styled [SEP]
Text from DS:  Option Pricing Using Bayesian Neural
Networks
Michael Maio Pires, Tshilidzi Marwala
School of Electrical and Information Engineering, University of the Witwatersrand, 2050, South
Africa
m.pires@ee.wits.ac.za, t.marwala@ee.wits.ac.za

Abstract
Options have provided a field of much study because of the
complexity involved in pricing them. The Black-Scholes
equations were developed to price options but they are only
valid for European styled options. There is added complexity
when trying to price American styled options and this is why the
use of neural networks has been proposed. Neural Networks are
able to predict outcomes based on past data. The inputs to the
networks here are stock volatility, strike price and time to
maturity with the output of the network being the call option
price. There are two techniques for Bayesian neural networks
used. One is Automatic Relevance Determination (for Gaussian
Approximation) and one is a Hybrid Monte Carlo method, both
used with Multi-Layer Perce
Original label:  cs.DS
Predicted label:  10
Correct label:  7
Text:  [CLS] mrfalign : protein homology detection through alignment of markov random fields jianzhu ma, sheng wang, zhiyong wang and jinbo xu * toyota technological institute at chicago, 6045 kenwood. ave, 60637 chicago, illinois, usa { majianzhu, wangsheng, j3xu } @ ttic. edu abstract sequence - based protein homology detection has been extensively studied and so far the most sensitive method is based upon comparison of protein sequence profiles, which are derived from multiple sequence alignment ( msa ) of sequence homologs in a protein family. a sequence profile is usually represented as a position - specific scoring matrix ( pssm ) or an hmm ( hidden markov model ) and accordingly pssmpssm or hmm - hmm comparison is used for homolog detection. this paper presents a new homology detection method mrfalign, consisting of three key components : 1 ) a markov random fields ( mrf ) representation of a protein family ; 2 ) a scoring function measuring similarity of two mrfs ; and 3 ) an efficient admm ( alternating direction method of multipliers ) algorithm aligning two mrfs. compared to hmm that can only model very short - range residue correlation, mrfs can model long - range residue interaction pattern and thus, encode information for the global 3d structure of a protein family. consequently, mrf - mrf comparison for remote homology detection shall be much more sensitive than hmm - hmm or pssm - pssm comparison. experiments confirm that mrfalign outperforms several popular hmm or pssm - based methods in terms of both alignment accuracy and remote homology detection and that mrfalign works particularly well for mainly beta proteins. for example, tested on the benchmark scop40 ( 8353 proteins ) for homology detection, pssm - pssm and hmm - hmm succeed on 48 % and 52 % of proteins, respectively, at superfamily level, and on 15 % and 27 % of proteins, respectively, at fold level. in contrast, mrfalign succeeds on 57. 3 % and 42. 5 % of proteins at superfamily and fold level, respectively. this study implies that long - range residue interaction patterns are very helpful for sequence - based homology detection. the software is available for download at http : / / raptorx. uchicago. edu / download /. author summary sequence - based protein homology detection has been extensively studied, but it remains very challenging [SEP]
Text from DS:  MRFalign: Protein Homology Detection through Alignment of
Markov Random Fields
Jianzhu Ma, Sheng Wang, Zhiyong Wang and Jinbo Xu*
Toyota Technological Institute at Chicago, 6045 Kenwood.Ave,
60637 Chicago, Illinois, USA
{majianzhu, wangsheng, j3xu}@ttic.edu

Abstract
Sequence-based protein homology detection has been extensively studied and so far the most sensitive
method is based upon comparison of protein sequence profiles, which are derived from multiple sequence
alignment (MSA) of sequence homologs in a protein family. A sequence profile is usually represented as a
position-specific scoring matrix (PSSM) or an HMM (Hidden Markov Model) and accordingly PSSMPSSM or HMM-HMM comparison is used for homolog detection. This paper presents a new homology
detection method MRFalign, consisting of three key components: 1) a Markov Random Fields (MRF)
representation of a protein family; 2) a scoring function measuring similarity of two MRFs; and 3) an
efficient ADMM (Alternating Direction Met
Original label:  cs.CV
Predicted label:  2
Correct label:  9
Text:  [CLS] on the definition of shape parts : a dominant sets approach foteini fotopoulou + and george economou * + department of computer engineering and informatics, university of patras, 26500, greece email : fotopoulou @ ceid. upatras. gr * department of physics, university of patras, 26500, greece email : economou @ physics. upatras. gr abstract in the present paper a novel graph - based approach to the shape decomposition problem is addressed. the shape is appropriately transformed into a visibility graph enriched with local neighborhood information. a two - step diffusion process is then applied to the visibility graph that efficiently enhances the information provided, thus leading to a more robust and meaningful graph construction. inspired by the notion of a clique as a strict cluster definition, the dominant sets algorithm is invoked, slightly modified to comport with the specific problem of defining shape parts. the cluster cohesiveness and a node participation vector are two important outputs of the proposed graph partitioning method. opposed to most of the existing techniques, the final number of the clusters is determined automatically, by estimating the cluster cohesiveness on a random network generation process. experimental results on several shape databases show the effectiveness of our framework for graph based shape decomposition. keywords shape decomposition ; dominant sets ; graph clustering ; visibility graph 1. introduction identifying a shape ’ s components can be essential for object recognition, object completion, and shape matching [ 1 ], among other computer vision tasks [ 2 ]. the shape decomposition can be regarded without loss of generality as a clustering procedure, where the aim is to partition all of the boundary points into semantic groups. nowadays many popular clustering approaches are based on the use of pairwise distances and graph techniques. these algorithms treat the problem of clustering as a graph partitioning one without making specific assumptions on the form of clusters. for our problem also and despite the existence of numerous shape decomposition methods, we will focus on those that map the points to be clustered into an appropriately constructed graph. evidently constructing the right graph is of great importance since it will influence to a large degree the final partition. a common binary graph that contains essential information for the shape structure and maps the visibility relations among nodes is the visibility graph [ 3 ], which is constructed by linking the mutually visible nodes, i. e. the shape boundary points that can " see " each other. information provided by this graph is useful in shape modeling as points that are mutually visible are [SEP]
Text from DS:  On the definition of Shape Parts: a Dominant Sets Approach
Foteini Fotopoulou+ and George Economou*

+

Department of Computer Engineering and Informatics, University of Patras, 26500, Greece
Email: fotopoulou@ceid.upatras.gr

* Department of Physics, University of Patras, 26500, Greece
Email: economou@physics.upatras.gr

Abstract
In the present paper a novel graph-based approach to the shape decomposition problem is
addressed. The shape is appropriately transformed into a visibility graph enriched with local
neighborhood information. A two-step diffusion process is then applied to the visibility graph
that efficiently enhances the information provided, thus leading to a more robust and
meaningful graph construction. Inspired by the notion of a clique as a strict cluster definition,
the dominant sets algorithm is invoked, slightly modified to comport with the specific problem
of defining shape parts. The cluster cohesiveness and a node participation vector are two
important outputs of 
Original label:  cs.IT
Predicted label:  2
Correct label:  1
Text:  [CLS] parameterized complexity of fair deletion problems ii. ∗ dusan knop1, 3, tomas masarik1, and tomas toufar2 arxiv : 1803. 06878v1 [ cs. cc ] 19 mar 2018 1 department of applied mathematics, charles university, prague, czech republic { knop, masarik } @ kam. mff. cuni. cz 2 computer science institute, charles university, prague, czech republic toufi @ iuuk. mff. cuni. cz 3 department of informatics, university of bergen, bergen, norway abstract vertex deletion problems are those where given a graph g and a graph property π, the goal is to find a subset of vertices w such that g \ w satisfies property π. typically, we want to minimize size of the deletion set w. unlike this, in fair vertex deletion problems we change the objective : we minimize the maximum number of vertices deleted in neighborhood of any vertex. when the property π is expressible by an mso formula we refer to this special case as to the mso fair vertex deletion problem. we prove that there is an fpt algorithm for the mso fair vertex deletion problem parametrized by the twin cover number. we study parameterized complexity of the fair vertex cover ( fairvc ) problem. it turns out that the fairvc problem is among the simplest problems with respect to the property π ( here π describes an edgeless graph ). we prove that the fairvc problem is w [ 1 ] - hard with parameterization by both treedepth and feedback vertex set of the input graph. on the positive side, we provide an fpt algorithm for the fairvc problem parameterized by modular width. 1 introduction we study computational complexity of fair deletion problems. deletion problems are standard reformulation of some classical problems in combinatorial optimization examined by yannakakis [ 30 ]. for a graph property π we formulate a vertex deletion problem. that means, given a graph g = ( v, e ), find the smallest possible set of vertices w such that g \ w satisfies property π. many classical problems can be formulated in this way such as minimum vertex cover ( here the task is to obtain an edgeless graph ) or minimum feedback vertex set ( now the graph has to be a forest ). of course, the complexity is determined by the desired property π but most [SEP]
Text from DS:  Parameterized complexity of fair deletion problems II.∗
Dušan Knop1,3 , Tomáš Masařík1 , and Tomáš Toufar2

arXiv:1803.06878v1 [cs.CC] 19 Mar 2018

1

Department of Applied Mathematics, Charles University, Prague, Czech Republic
{knop, masarik}@kam.mff.cuni.cz
2
Computer Science Institute, Charles University, Prague, Czech Republic
toufi@iuuk.mff.cuni.cz
3
Department of Informatics, University of Bergen, Bergen, Norway

Abstract
Vertex deletion problems are those where given a graph G and a graph property π, the
goal is to find a subset of vertices W such that G \ W satisfies property π. Typically, we want
to minimize size of the deletion set W . Unlike this, in fair vertex deletion problems we change
the objective: we minimize the maximum number of vertices deleted in neighborhood of any
vertex.
When the property π is expressible by an MSO formula we refer to this special case as to
the MSO fair vertex deletion problem. We prove that there is an FPT algorithm for the
MSO fair vertex d
Original label:  cs.NE
Predicted label:  6
Correct label:  2
Text:  [CLS] on the runtime analysis of the clearing diversity - preserving mechanism edgar covantes osuna and dirk sudholt arxiv : 1803. 09715v1 [ ] 26 mar 2018 department of computer science university of sheffield, united kingdom march 28, 2018 abstract clearing is a niching method inspired by the principle of assigning the available resources among a niche to a single individual. the clearing procedure supplies these resources only to the best individual of each niche : the winner. so far, its analysis has been focused on experimental approaches that have shown that clearing is a powerful diversity - preserving mechanism. using rigorous runtime analysis to explain how and why it is a powerful method, we prove that a mutation - based evolutionary algorithm with a large enough population size, and a phenotypic distance function always succeeds in optimising all functions of unitation for small niches in polynomial time, while a genotypic distance function requires exponential time. finally, we prove that with phenotypic and genotypic distances clearing is able to find both optima for twomax and several general classes of bimodal functions in polynomial expected time. we use empirical analysis to highlight some of the characteristics that makes it a useful mechanism and to support the theoretical results. 1 introduction evolutionary algorithms ( eas ) with elitist selection are suitable to locate the optimum of unimodal functions as they converge to a single solution of the search space. this behaviour is also one of the major difficulties in a population - based ea, the premature convergence toward a suboptimal individual before the fitness landscape is explored properly. real optimisation problems, however, often lead to multimodal domains and so require the identification of multiple optima, either local or global ( sareni and krahenbuhl, 1998 ; singh and deb, 2006 ). in multimodal optimisation problems, there exist many attractors for which finding a global optimum can become a challenge to any optimisation algorithm. a diverse population can deal with multimodal functions and can explore several hills in the fitness landscape simultaneously, so they can therefore support global exploration and help to locate several local and global optima. the algorithm can offer several good solutions to the user, a feature desirable in multiobjective optimisation. also, it provides higher chances to find dissimilar individuals and to create good offspring with the possibility of enhancing the performance of other procedures such as crossover ( friedrich et al., 2009 ). diversity - preserving mechanisms [SEP]
Text from DS:  On the Runtime Analysis of the Clearing
Diversity-Preserving Mechanism
Edgar Covantes Osuna and Dirk Sudholt

arXiv:1803.09715v1 [] 26 Mar 2018

Department of Computer Science
University of Sheffield, United Kingdom

March 28, 2018
Abstract
Clearing is a niching method inspired by the principle of assigning the available resources
among a niche to a single individual. The clearing procedure supplies these resources only to
the best individual of each niche: the winner. So far, its analysis has been focused on experimental approaches that have shown that clearing is a powerful diversity-preserving mechanism.
Using rigorous runtime analysis to explain how and why it is a powerful method, we prove that
a mutation-based evolutionary algorithm with a large enough population size, and a phenotypic distance function always succeeds in optimising all functions of unitation for small niches
in polynomial time, while a genotypic distance function requires exponential time. Finally, we
prove that
Original label:  cs.CV
Predicted label:  9
Correct label:  2
Text:  [CLS] cisrdcnn : super - resolution of compressed images using deep convolutional neural networks arxiv : 1709. 06229v1 [ ] 19 sep 2017 honggang chen, xiaohai he∗, chao ren, linbo qing, qizhi teng college of electronics and information engineering, sichuan university, chengdu, china abstract in recent years, much research has been conducted on image super - resolution ( sr ). to the best of our knowledge, however, few sr methods were concerned with compressed images. the sr of compressed images is a challenging task due to the complicated compression artifacts, while many images suffer from them in practice. the intuitive solution for this difficult task is to decouple it into two sequential but independent subproblems, i. e., compression artifacts reduction ( car ) and sr. nevertheless, some useful details may be removed in car stage, which is contrary to the goal of sr and makes the sr stage more challenging. in this paper, an end - to - end trainable deep convolutional neural network is designed to perform sr on compressed images ( cisrdcnn ), which reduces compression artifacts and improves image resolution jointly. experiments on compressed images produced by jpeg ( we take the jpeg as an example in this paper ) demonstrate that the proposed cisrdcnn yields state - of - the - art sr performance on commonly used test images and imagesets. the results of cisrdcnn on real low quality web images are also very impressive, with obvious quality enhancement. further, we explore the application of the proposed sr method in low bit - rate image coding, leading to better rate - distortion performance than jpeg. keywords : super - resolution, compressed images, deep convolutional neural networks, low bit - rate coding, jpeg ∗ corresponding author. email addresses : honggang. chen @ stu. scu. edu. cn ( honggang chen ), hxh @ scu. edu. cn ( xiaohai he ), chaoren @ scu. edu. cn ( chao ren ), qing _ lb @ scu. edu. cn ( linbo qing ), qzteng @ scu. edu. cn ( qizhi teng ) preprint submitted to neurocomputing september 20, 2017 1. introduction single image super - resolution ( sisr ) refers to estimate a high - resolution ( hr ) image from a single low - resolution ( lr [SEP]
Text from DS:  CISRDCNN: Super-resolution of compressed images
using deep convolutional neural networks

arXiv:1709.06229v1 [] 19 Sep 2017

Honggang Chen, Xiaohai He∗, Chao Ren, Linbo Qing, Qizhi Teng
College of Electronics and Information Engineering, Sichuan University, Chengdu, China

Abstract
In recent years, much research has been conducted on image super-resolution
(SR). To the best of our knowledge, however, few SR methods were concerned
with compressed images. The SR of compressed images is a challenging task
due to the complicated compression artifacts, while many images suffer from
them in practice. The intuitive solution for this difficult task is to decouple it
into two sequential but independent subproblems, i.e., compression artifacts
reduction (CAR) and SR. Nevertheless, some useful details may be removed
in CAR stage, which is contrary to the goal of SR and makes the SR stage
more challenging. In this paper, an end-to-end trainable deep convolutional
neural network is designed to perf
Original label:  cs.IT
Predicted label:  3
Correct label:  9
Text:  [CLS] arxiv : 1705. 03283v1 [ cs. cc ] 9 may 2017 an exponential lower bound for individualization - refinement algorithms for graph isomorphism daniel neuen and pascal schweitzer rwth aachen university { neuen, schweitzer } @ informatik. rwth - aachen. de may 10, 2017 abstract the individualization - refinement paradigm provides a strong toolbox for testing isomorphism of two graphs and indeed, the currently fastest implementations of isomorphism solvers all follow this approach. while these solvers are fast in practice, from a theoretical point of view, no general lower bounds concerning the worst case complexity of these tools are known. in fact, it is an open question whether individualization - refinement algorithms can achieve upper bounds on the running time similar to the more theoretical techniques based on a group theoretic approach. in this work we give a negative answer to this question and construct a family of graphs on which algorithms based on the individualization - refinement paradigm require exponential time. contrary to a previous construction of miyazaki, that only applies to a specific implementation within the individualization - refinement framework, our construction is immune to changing the cell selector, or adding various heuristic invariants to the algorithm. furthermore, our graphs also provide exponential lower bounds in the case when the k - dimensional weisfeiler - leman algorithm is used to replace the standard color refinement operator and the arguments even work when the entire automorphism group of the inputs is initially provided to the algorithm. 1 introduction the individualization - refinement paradigm provides a strong toolbox for testing isomorphism of two graphs. to date, algorithms that implement the individualization - refinement paradigm constitute the fastest practical algorithms for the graph isomorphism problem and for the task of canonically labeling combinatorial objects. originally exploited by mckay ’ s software package nauty [ 14 ] as early as 1981, in a nutshell, the basic principle is to classify vertices using a refinement operator according to an isomorphisminvariant property. in a basic form one usually uses the so - called color refinement operator, also called 1 - dimensional weisfeiler - leman algorithm, for this purpose. whenever the refinement is not sufficient, vertices within a selected color class ( usually called a cell ) are individualized one by one in a backtracking manner as to artificially distinguish them from other vertices. this [SEP]
Text from DS:  arXiv:1705.03283v1 [cs.CC] 9 May 2017

An exponential lower bound for Individualization-Refinement
algorithms for Graph Isomorphism
Daniel Neuen and Pascal Schweitzer
RWTH Aachen University
{neuen,schweitzer}@informatik.rwth-aachen.de
May 10, 2017
Abstract
The individualization-refinement paradigm provides a strong toolbox for testing isomorphism
of two graphs and indeed, the currently fastest implementations of isomorphism solvers all follow
this approach. While these solvers are fast in practice, from a theoretical point of view, no general
lower bounds concerning the worst case complexity of these tools are known. In fact, it is an
open question whether individualization-refinement algorithms can achieve upper bounds on the
running time similar to the more theoretical techniques based on a group theoretic approach.
In this work we give a negative answer to this question and construct a family of graphs on
which algorithms based on the individualization-refinement paradigm require ex
Original label:  cs.NE
Predicted label:  3
Correct label:  2
Text:  [CLS] training restricted boltzmann machines via the thouless - anderson - palmer free energy marylou gabrie1, 2, eric w. tramel1 and florent krzakala1, 3 1 arxiv : 1506. 02914v2 [ cond - mat. dis - nn ] 15 jun 2015 2 laboratoire de physique statistique, umr 8550 cnrs, department of physics, ecole normale superieure and psl research university, rue lhomond, 75005 paris, france international centre for fundamental physics and its interfaces at ecole normale suprieure, 75005 paris, france 3 sorbonne universits, upmc univ paris 06, umr 8550, lps, f - 75005, paris, france ( dated : june 16, 2015 ) restricted boltzmann machines are undirected neural networks which have been shown to be effective in many applications, including serving as initializations for training deep multi - layer neural networks. one of the main reasons for their success is the existence of efficient and practical stochastic algorithms, such as contrastive divergence, for unsupervised training. we propose an alternative deterministic iterative procedure based on an improved mean field method from statistical physics known as the thouless - anderson - palmer approach. we demonstrate that our algorithm provides performance equal to, and sometimes superior to, persistent contrastive divergence, while also providing a clear and easy to evaluate objective function. we believe that this strategy can be easily generalized to other models as well as to more accurate higher - order approximations, paving the way for systematic improvements in training boltzmann machines with hidden units. i. introduction a restricted boltzmann machine ( rbm ) [ 1, 2 ] is a type of undirected neural network with surprisingly many applications. this model has been used in problems as diverse as dimensionality reduction [ 3 ], classification [ 4 ], collaborative filtering [ 5 ], feature learning [ 6 ], and topic modeling [ 7 ]. also, quite remarkably, it has been shown that generative rbms can be stacked into multi - layer neural networks, forming an initialization for discriminative deep belief nets [ 8 ]. such deep architectures are believed to be crucial for learning high - order representations and concepts. while the training procedure for rbms can be written as a log - likelihood maximization, an exact implementation of this approach is computationally [SEP]
Text from DS:  Training Restricted Boltzmann Machines via the Thouless-Anderson-Palmer Free Energy
Marylou Gabrié1,2 , Eric W. Tramel1 and Florent Krzakala1,3
1

arXiv:1506.02914v2 [cond-mat.dis-nn] 15 Jun 2015

2

Laboratoire de Physique Statistique, UMR 8550 CNRS, Department of Physics,
École Normale Supérieure and PSL Research University, Rue Lhomond, 75005 Paris, France
International Centre for Fundamental Physics and its interfaces at Ecole normale suprieure, 75005 Paris, France
3
Sorbonne Universits, UPMC Univ Paris 06, UMR 8550, LPS, F-75005, Paris, France
(Dated: June 16, 2015)
Restricted Boltzmann machines are undirected neural networks which have been shown to be effective in
many applications, including serving as initializations for training deep multi-layer neural networks. One of the
main reasons for their success is the existence of efficient and practical stochastic algorithms, such as contrastive
divergence, for unsupervised training. We propose an alternative deterministic iterat
Original label:  cs.CE
Predicted label:  5
Correct label:  6
Text:  [CLS] arxiv : cs / 0102030v1 [ ] 27 feb 2001 to appear on theory and practice of logic programming 1 soundness, idempotence and commutativity of set - sharing patricia m. hill∗ school of computer studies, university of leeds, leeds, u. k. ( e - mail : hill @ scs. leeds. ac. uk ) roberto bagnara, enea zaffanella † department of mathematics, university of parma, italy ( e - mail : { bagnara, zaffanella } @ cs. unipr. it ) abstract it is important that practical data - flow analyzers are backed by reliably proven theoretical results. abstract interpretation provides a sound mathematical framework and necessary generic properties for an abstract domain to be well - defined and sound with respect to the concrete semantics. in logic programming, the abstract domain sharing is a standard choice for sharing analysis for both practical work and further theoretical study. in spite of this, we found that there were no satisfactory proofs for the key properties of commutativity and idempotence that are essential for sharing to be well - defined and that published statements of the soundness of sharing assume the occurs - check. this paper provides a generalization of the abstraction function for sharing that can be applied to any language, with or without the occurs - check. results for soundness, idempotence and commutativity for abstract unification using this abstraction function are proven. keywords : abstract interpretation ; logic programming ; occurs - check ; rational trees ; set - sharing. 1 introduction in abstract interpretation, the concrete semantics of a program is approximated by an abstract semantics ; that is, the concrete domain is replaced by an abstract domain and each elementary operation on the concrete domain is replaced by a corresponding abstract operation on the abstract domain. assuming the global abstract procedure mimics the concrete execution procedure, each basic operation on the elements of the abstract domain must produce a safe approximation of the corresponding operation on corresponding elements of the concrete domain. for logic programming, the key elementary operation is unification that computes a solution to a set of equations. this solution can be represented by means of a ∗ this work was partly supported by epsrc under grant gr / m05645. † the work of the second and third authors has been partly supported by murst project “ certificazione automatica di programmi mediante interpretazione astratta. ” 2 p. m. hill, r. [SEP]
Text from DS:  arXiv:cs/0102030v1 [] 27 Feb 2001

To appear on Theory and Practice of Logic Programming

1

Soundness, Idempotence and Commutativity
of Set-Sharing
PATRICIA M. HILL∗
School of Computer Studies, University of Leeds, Leeds, U.K.

(e-mail: hill@scs.leeds.ac.uk)
ROBERTO BAGNARA, ENEA ZAFFANELLA†
Department of Mathematics, University of Parma, Italy

(e-mail: {bagnara,zaffanella}@cs.unipr.it)

Abstract
It is important that practical data-flow analyzers are backed by reliably proven theoretical
results. Abstract interpretation provides a sound mathematical framework and necessary
generic properties for an abstract domain to be well-defined and sound with respect to
the concrete semantics. In logic programming, the abstract domain Sharing is a standard
choice for sharing analysis for both practical work and further theoretical study. In spite
of this, we found that there were no satisfactory proofs for the key properties of commutativity and idempotence that are essential for Sharing to be w
Original label:  cs.NE
Predicted label:  1
Correct label:  2
Text:  [CLS] bank distress in the news : describing events through deep learning samuel ronnqvist1, 2 and peter sarlin3, 4 arxiv : 1603. 05670v2 [ cs. cl ] 27 dec 2016 1 turku centre for computer science – tucs department of information technologies, abo akademi university, turku, finland sronnqvi @ abo. fi? 2 applied computational linguistics lab goethe university frankfurt am main, germany 3 department of economics hanken school of economics, helsinki, finland 4 risklab finland arcada university of applied sciences, helsinki, finland peter @ risklab. fi abstract. while many models are purposed for detecting the occurrence of significant events in financial systems, the task of providing qualitative detail on the developments is not usually as well automated. we present a deep learning approach for detecting relevant discussion in text and extracting natural language descriptions of events. supervised by only a small set of event information, comprising entity names and dates, the model is leveraged by unsupervised learning of semantic vector representations on extensive text data. we demonstrate applicability to the study of financial risk based on news ( 6. 6m articles ), particularly bank distress and government interventions ( 243 events ), where indices can signal the level of bank - stress - related reporting at the entity level, or aggregated at national or european level, while being coupled with explanations. thus, we exemplify how text, as timely, widely available and descriptive data, can serve as a useful complementary source of information for financial and systemic risk analytics. 1 introduction text analytics presents both major opportunities and challenges. on the one hand, text data is rich in information and can be harnessed in traditional ways such as for prediction tasks, while its descriptive depth also supports qualitative and exploratory, yet highly data - driven, analysis. on the other hand, decoding and utilizing the expressive detail of human language is prohibitively difficult.? corresponding author 2 in computational terms, text consists of high - dimensional and often ambiguous symbolic input ( words ), the semantics of which is a product of complex interactions between parts of the sequences in which they occur ( phrases, sentences, paragraphs, etc. ). text is referred to as sparse data due to the high variability relative to number of samples, and unstructured data as the underlying linguistic structure must be inferred from the surface form as part of the analysis process. we recognize that many applications of text analytics use linguistically rather [SEP]
Text from DS:  Bank distress in the news:
Describing events through deep learning
Samuel Rönnqvist1,2 and Peter Sarlin3,4

arXiv:1603.05670v2 [cs.CL] 27 Dec 2016

1

Turku Centre for Computer Science – TUCS
Department of Information Technologies,
Åbo Akademi University, Turku, Finland
sronnqvi@abo.fi?
2

Applied Computational Linguistics Lab
Goethe University Frankfurt am Main, Germany
3

Department of Economics
Hanken School of Economics, Helsinki, Finland
4
RiskLab Finland
Arcada University of Applied Sciences, Helsinki, Finland
peter@risklab.fi

Abstract. While many models are purposed for detecting the occurrence of significant events in financial systems, the task of providing
qualitative detail on the developments is not usually as well automated.
We present a deep learning approach for detecting relevant discussion in
text and extracting natural language descriptions of events. Supervised
by only a small set of event information, comprising entity names and
dates, the model is leveraged by uns
Original label:  math.GR
Predicted label:  7
Correct label:  8
Text:  [CLS] zassenhaus conjecture on torsion units holds for sl ( 2, t ) arxiv : 1803. 05342v1 [ ] 14 mar 2018 angel del rio and mariano serrano abstract. h. j. zassenhaus conjectured that any unit of finite order in the integral group ring zg of a finite group g is conjugate in the rational group algebra qg to an element of the form ±g with g ∈ g. we prove the zassenhaus conjecture for the groups sl ( 2, t ) with t a prime. it is the first infinite family of non - solvable groups for which the zassenhaus conjecture has been proved. 1. introduction the following conjecture stated by h. j. zassenhaus [ zas74 ] ( see also [ seh93, section 37 ] ) has centered the research on torsion units of integral group rings during the last decades : zassenhaus conjecture : if g is a finite group and u is a unit of finite order in the integral group ring zg then u is conjugate in the rational group ring qg to an element of ±g. the relevance of the zassenhaus conjecture is that it describes the torsion units of the integral group ring of zg provided it holds for g. recently, eisele and margolis announced a metabelian counterexample to the zassenhaus conjecture [ em17 ]. nevertheless, the zassenhaus conjecture holds for large classes of solvable groups, e. g. for nilpotent groups [ wei91 ], groups possessing a normal sylow subgroup with abelian complement [ her06 ] or cyclic - by - abelian groups [ cmdr13 ]. in contrast with these results, the list of non - solvable groups for which the zassenhaus conjecture has been proved is very limited [ lp89, ble99, her07, her08, bkl08, sal13, bm17, bc17, drs17 ]. for example, the only non - abelian simple groups for which the zassenhaus conjecture has been verified are those isomorphic to psl ( 2, q ) with sixty - one values of q. most of these cases follow from the main result of [ mdrs17 ] which covers the case where q is a mersenne or fermat prime. recall that the problem of deciding whether there are infinitely many mersenne primes or fe [SEP]
Text from DS:  ZASSENHAUS CONJECTURE ON TORSION UNITS HOLDS FOR SL(2, t)

arXiv:1803.05342v1 [] 14 Mar 2018

ÁNGEL DEL RÍO AND MARIANO SERRANO
Abstract. H.J. Zassenhaus conjectured that any unit of finite order in the integral group ring ZG of a finite
group G is conjugate in the rational group algebra QG to an element of the form ±g with g ∈ G. We prove the
Zassenhaus Conjecture for the groups SL(2, t) with t a prime. It is the first infinite family of non-solvable groups
for which the Zassenhaus Conjecture has been proved.

1. Introduction
The following conjecture stated by H.J. Zassenhaus [Zas74] (see also [Seh93, Section 37]) has centered the
research on torsion units of integral group rings during the last decades:
Zassenhaus Conjecture: If G is a finite group and u is a unit of finite order in the integral
group ring ZG then u is conjugate in the rational group ring QG to an element of ±G.
The relevance of the Zassenhaus Conjecture is that it describes the torsion units of the integral group ri
Original label:  cs.CE
Predicted label:  7
Correct label:  1
Text:  [CLS] 1 arxiv : 1710. 03248v1 [ ] 9 oct 2017 synthesizing bijective lenses anders miltner, princeton university, usa kathleen fisher, tufts university, usa benjamin c. pierce, university of pennsylvania, usa david walker, princeton university, usa steve zdancewic, university of pennsylvania, usa bidirectional transformations between [UNK] data representations occur frequently in modern software systems. they appear as serializers and deserializers, as parsers and pretty printers, as database views and view updaters, and as a multitude of [UNK] kinds of ad hoc data converters. manually building bidirectional transformations — by writing two separate functions that are intended to be inverses — is tedious and error prone. a better approach is to use a domain - speciﬁc language in which both directions can be written as a single expression. however, these domain - speciﬁc languages can be [UNK] to program in, requiring programmers to manage ﬁddly details while working in a complex type system. we present an alternative approach. instead of coding transformations manually, we synthesize them from declarative format descriptions and examples. speciﬁcally, we present optician, a tool for type - directed synthesis of bijective string transformers. the inputs to optician are a pair of ordinary regular expressions representing two data formats and a few concrete examples for disambiguation. the output is a well - typed program in boomerang ( a bidirectional language based on the theory of lenses ). the main technical challenge involves navigating the vast program search space [UNK] enough. in particular, and unlike most prior work on type - directed synthesis, our system operates in the context of a language with a rich equivalence relation on types ( the theory of regular expressions ). consequently, program synthesis requires search in two dimensions : first, our synthesis algorithm must ﬁnd a pair of “ syntactically compatible types, ” and second, using the structure of those types, it must ﬁnd a type - and example - compliant term. our key insight is that it is possible to reduce the size of this search space without losing any computational power by deﬁning a new language of lenses designed speciﬁcally for synthesis. the new language is free from arbitrary function composition and operates only over types and terms in a new disjunctive normal form. we prove ( 1 ) our new language is just as powerful as a more natural, compositional, [SEP]
Text from DS:  1

arXiv:1710.03248v1 [] 9 Oct 2017

Synthesizing Bijective Lenses
ANDERS MILTNER, Princeton University, USA
KATHLEEN FISHER, Tufts University, USA
BENJAMIN C. PIERCE, University of Pennsylvania, USA
DAVID WALKER, Princeton University, USA
STEVE ZDANCEWIC, University of Pennsylvania, USA
Bidirectional transformations between diﬀerent data representations occur frequently in modern software
systems. They appear as serializers and deserializers, as parsers and pretty printers, as database views and
view updaters, and as a multitude of diﬀerent kinds of ad hoc data converters. Manually building bidirectional transformations—by writing two separate functions that are intended to be inverses—is tedious and
error prone. A better approach is to use a domain-speciﬁc language in which both directions can be written
as a single expression. However, these domain-speciﬁc languages can be diﬃcult to program in, requiring
programmers to manage ﬁddly details while working in a complex type system.
We
Original label:  math.AC
Predicted label:  3
Correct label:  2
Text:  [CLS] on the direct summand conjecture and its derived variant arxiv : 1608. 08882v2 [ math. ag ] 11 nov 2017 bhargav bhatt a bstract. andre recently gave a beautiful proof of hochster ’ s direct summand conjecture in commutative algebra using perfectoid spaces ; his two main results are a generalization of the almost purity theorem ( the perfectoid abhyankar lemma ) and a construction of certain faithfully flat extensions of perfectoid algebras where “ discriminants ” acquire all p - power roots. in this paper, we explain a quicker proof of hochster ’ s conjecture that circumvents the perfectoid abhyankar lemma ; instead, we prove and use a quantitative form of scholze ’ s hebbarkeitssatz ( the riemann extension theorem ) for perfectoid spaces. the same idea also leads to a proof of a derived variant of the direct summand conjecture put forth by de jong. 1. i ntroduction the first goal of this paper is to give a simpler proof of the following recent result of andre, settling the direct summand conjecture : theorem 1. 1 ( andre ). let i : a0 → b0 be a finite extension of noetherian rings. assume that a0 is regular. then the inclusion i is split as an a0 - module map. when a0 has characteristic 0, theorem 1. 1 is easy to prove using the trace map. when dim ( a0 ) ≤ 2, one can prove theorem 1. 1 using the auslander - buchsbaum formula. hochster conjectured the general case in 1969, and proved it when a0 has characteristic p in [ ho1 ]. the first general result in mixed characteristic was heitmann ’ s [ he ], settling the case of dimension 3. more on the history of this conjecture and its centrality amongst the ‘ homological conjectures ’ in commutative algebra can be found in [ ho3 ]. the result above is proven by andre [ an2 ] using [ an1 ]. in this paper, we give a proof of theorem 1. 1 that avoids [ an1 ] ( and is independent of [ an2 ] in terms of exposition ). our approach also adapts to yield the following derived variant, which was conjectured by johan de jong in the course of the author ’ s thesis work [ bh1, [SEP]
Text from DS:  ON THE DIRECT SUMMAND CONJECTURE AND ITS DERIVED VARIANT

arXiv:1608.08882v2 [math.AG] 11 Nov 2017

BHARGAV BHATT

A BSTRACT. André recently gave a beautiful proof of Hochster’s direct summand conjecture in commutative algebra using
perfectoid spaces; his two main results are a generalization of the almost purity theorem (the perfectoid Abhyankar lemma)
and a construction of certain faithfully flat extensions of perfectoid algebras where “discriminants” acquire all p-power roots.
In this paper, we explain a quicker proof of Hochster’s conjecture that circumvents the perfectoid Abhyankar lemma;
instead, we prove and use a quantitative form of Scholze’s Hebbarkeitssatz (the Riemann extension theorem) for perfectoid
spaces. The same idea also leads to a proof of a derived variant of the direct summand conjecture put forth by de Jong.

1. I NTRODUCTION
The first goal of this paper is to give a simpler proof of the following recent result of André, settling the direct
summand conjecture:

Original label:  math.AC
Predicted label:  6
Correct label:  2
Text:  [CLS] f - signature of pairs and the asymptotic behavior of frobenius splittings arxiv : 1107. 1082v2 [ ] 7 sep 2012 manuel blickle, karl schwede, kevin tucker abstract. we generalize f - signature to pairs ( r, d ) where d is a cartier subalgebra on r as defined by the first two authors. in particular, we show the existence and positivity of the f - signature for any strongly f - regular pair. in one application, we answer an open question of i. aberbach and f. enescu by showing that the f - splitting ratio of an arbitrary f - pure local ring is strictly positive. furthermore, we derive effective methods for computing the f - signature and the f - splitting ratio in the spirit of the work of r. fedder. 1. introduction when working with rings or schemes in prime characteristic p > 0, sections of the frobenius endomorphism are called f - splittings. when such a splitting exists the various iterates of frobenius must split as well, and limiting constructions often allow one to conclude numerous desirable algebraic and geometric properties [ hr74, bk05 ]. in this article, we investigate the following natural question concerning the local asymptotic behavior of the number of splittings of large iterates of frobenius. question 1. 1 ( cf. [ ae05, question 4. 9 ] ). if r is a local ring of equal characteristic p > 0, how many splittings does the e - iterated frobenius map f e : r − → r have for e [UNK] 0? we assume for simplicity in the introduction that r is a complete local domain with perfect e residue field. in this case, the module - finite inclusion r ⊆ r1 / p into the corresponding ring of pe - th roots of elements of r is naturally identified with the e - iterated frobenius. one obtains a precise measure of the number of distinct splittings of f e : r − → r by writing ⊕ae 1 / pe = r r ⊕ me as r - modules where me has no free direct summands. the number ae is independent of the corresponding direct sum decomposition and is called the e - th f - splitting number of r. if d equals the dimension of r, a well - known result of e. kunz gives that ae ≤ ped for all e > 0 with equality if [SEP]
Text from DS:  F -SIGNATURE OF PAIRS AND THE ASYMPTOTIC BEHAVIOR OF
FROBENIUS SPLITTINGS

arXiv:1107.1082v2 [] 7 Sep 2012

MANUEL BLICKLE, KARL SCHWEDE, KEVIN TUCKER

Abstract. We generalize F -signature to pairs (R, D) where D is a Cartier subalgebra on
R as defined by the first two authors. In particular, we show the existence and positivity
of the F -signature for any strongly F -regular pair. In one application, we answer an open
question of I. Aberbach and F. Enescu by showing that the F -splitting ratio of an arbitrary
F -pure local ring is strictly positive. Furthermore, we derive effective methods for computing
the F -signature and the F -splitting ratio in the spirit of the work of R. Fedder.

1. Introduction
When working with rings or schemes in prime characteristic p > 0, sections of the Frobenius endomorphism are called F -splittings. When such a splitting exists the various iterates
of Frobenius must split as well, and limiting constructions often allow one to conclude numerous desirable
Original label:  cs.PL
Predicted label:  4
Correct label:  0
Text:  [CLS] draft 1 structural characteristics of two - sender index coding arxiv : 1711. 08150v1 [ ] 22 nov 2017 chandra thapa, lawrence ong, sarah j. johnson, and min li abstract this paper studies index coding with two senders. in this setup, source messages are distributed among the senders ( possibly with overlapping of messages ). in addition, there are multiple receivers, where each receiver having some messages a priori, known as side - information, is requesting one unique message such that each message is requested by only one receiver. index coding in this setup is called two - sender unicast index coding ( tsuic ). the main goal is to find the shortest aggregate encoded messages while allowing all receivers to decode their requested messages. firstly, we form three independent sub - problems of a tsuic problem based on whether the requested messages by receivers of those sub - problems are available only in one of the senders or in both senders. then we express the optimal broadcast rate ( the shortest normalized codelength ) of the tsuic problem as a function of the optimal broadcast rates of those independent sub - problems. in this way, we devise the structural characteristics of tsuic. for the proofs of our results, we apply the notion of confusion graphs and a code - forming technique. to color a confusion graph in tsuic, we introduce a new graph - coloring approach ( different from the normal graph coloring ), called two - sender graph coloring, and propose a way of grouping the vertices to analyze the number of colors used. finally, we determine a class of tsuic instances where a certain type of side - information can be removed without affecting their optimal broadcast rates. i. i ntroduction consider a communication scenario over a noiseless channel where a sender is required to broadcast messages to multiple receivers, each caching some messages requested by other receivers a priori. the messages cached at each receiver is known as its side - information. in this scenario, if the sender is informed about the side - information available at all receivers, then it the authors are with the school of electrical engineering and computing, the university of newcastle, callaghan, nsw 2308, australia ( email : chandra. thapa @ uon. edu. au, lawrence. ong @ newcastle. edu. au, sarah. johnson @ newcastle. edu. au, min. li @ newcastle. edu. au ) [SEP]
Text from DS:  DRAFT

1

Structural Characteristics of Two-Sender Index
Coding

arXiv:1711.08150v1 [] 22 Nov 2017

Chandra Thapa, Lawrence Ong, Sarah J. Johnson, and Min Li

Abstract
This paper studies index coding with two senders. In this setup, source messages are distributed
among the senders (possibly with overlapping of messages). In addition, there are multiple receivers,
where each receiver having some messages a priori, known as side-information, is requesting one
unique message such that each message is requested by only one receiver. Index coding in this setup
is called two-sender unicast index coding (TSUIC). The main goal is to find the shortest aggregate
encoded messages while allowing all receivers to decode their requested messages. Firstly, we form three
independent sub-problems of a TSUIC problem based on whether the requested messages by receivers
of those sub-problems are available only in one of the senders or in both senders. Then we express
the optimal broadcast rate (the short
Original label:  cs.AI
Predicted label:  2
Correct label:  1
Text:  [CLS] the case for meta - cognitive machine learning : on model entropy and concept formation in deep learning arxiv : 1711. 01431v1 [ ] 4 nov 2017 johan loeckx artificial intelligence lab, vrije universiteit brussel, pleinlaan 2, 1050 brussel jloeckx @ ai. vub. ac. be abstract machine learning is usually defined in behaviourist terms, where external validation is the primary mechanism of learning. in this paper, i argue for a more holistic interpretation in which finding more probable, efficient and abstract representations is as central to learning as performance. in other words, machine learning should be extended with strategies to reason over its own learning process, leading to so - called meta - cognitive machine learning. as such, the de facto definition of machine learning should be reformulated in these intrinsically multiobjective terms, taking into account not only the task performance but also internal learning objectives. to this end, we suggest a “ model entropy function ” to be defined that quantifies the efficiency of the internal learning processes. it is conjured that the minimization of this model entropy leads to concept formation. besides philosophical aspects, some initial illustrations are included to support the claims. 1 introduction machine learning is often approached from a behaviourist perspective, in which external feedback in the form of a reinforcement signal is the major driving force of improvement. though this method has lead to many successes, it is confronted with interesting and unsolved challenges like tackling overfitting, providing comprehensibility, building reusable abstractions and concept formation, among many other [ kotsiantis et al., 2007 ; bengio, 2009 ]. the problem with these behaviourist approaches is that they ignore the central importance of internal processes when considering learning. model internals are often regarded just as a means to achieve higher performance. analogous to studying human behaviour, however, appreciating the mechanisms of learning boils down to the question : ” when have we really learnt? ” in this paper, we argue that a computer has learnt when : • the programme becomes better at the task at hand ; • the programme can perform the task more efficiently ; • the code becomes ” more structured ” and simpler. one possible analogy to better understand the above statements can be found in software engineering. when considering code that performs a specific task, we do not care only about its functionality, but also about its execution speed / efficiency and other so - called ” non - functional [SEP]
Text from DS:  The Case for Meta-Cognitive Machine Learning:
On Model Entropy and Concept Formation in Deep Learning

arXiv:1711.01431v1 [] 4 Nov 2017

Johan Loeckx
Artificial Intelligence Lab, Vrije Universiteit Brussel, Pleinlaan 2, 1050 Brussel
jloeckx@ai.vub.ac.be

Abstract
Machine learning is usually defined in behaviourist
terms, where external validation is the primary
mechanism of learning. In this paper, I argue for a
more holistic interpretation in which finding more
probable, efficient and abstract representations is as
central to learning as performance. In other words,
machine learning should be extended with strategies to reason over its own learning process, leading to so-called meta-cognitive machine learning.
As such, the de facto definition of machine learning
should be reformulated in these intrinsically multiobjective terms, taking into account not only the
task performance but also internal learning objectives. To this end, we suggest a “model entropy
function” to be defined that
Original label:  cs.CE
Predicted label:  2
Correct label:  9
Text:  [CLS] abstract interpretation of binary code with memory accesses using polyhedra arxiv : 1711. 07257v1 [ ] 20 nov 2017 clement ballabriga and julien forget and giuseppe lipari university of lille, cnrs, centrale lille, umr 9189 – cristal { name. surname } @ univ - lille1. fr abstract. in this paper1 we propose a novel methodology for static analysis of binary code using abstract interpretation. we use an abstract domain based on polyhedra and two mapping functions that associate polyhedra variables with registers and memory. we demonstrate our methodology to the problem of computing upper bounds to loop iterations in the code. this problem is particularly important in the domain of worst - case execution time ( wcet ) analysis of safety - critical real - time code. however, our approach is general and it can applied to other static analysis problems. 1 introduction in real - time systems it is important to compute upper bounds to the execution times of every function, and check that they complete before their deadlines under all possible conditions. worst - case execution time ( wcet ) analysis consists in computing ( an upper bound to ) the longest path in the code. wcet analysis is usually performed on the binary code, because it needs information on the low - level instructions executed by the hardware processor in order to compute the execution time. in this paper, we propose a static analysis of binary code based on abstract interpretation using polyhedra. our motivation is the need to enhance existing wcet analysis by improving the computation of upper bounds on the number of iterations in loops, and by detecting unfeasible paths. most analyses by abstract interpretation proposed in the literature are performed on source code. however, there are several important advantages in performing static analysis of binary code : 1 ) we analyze the code that actually runs on the machine, hence no need for additional assumptions on how the compiler works ; 2 ) by gaining access to the memory layout, we can precisely identify problems with pointers ( alias, buffer overflows, etc. ) that are not easily identified when working only on source code ; 3 ) we can perform the analysis even without access to the source code. 1 an earlier version of this paper has been submitted to tacas 2018 ( http : / / www. etaps. org / index. php / 2018 / tacas ) for peer - review. compared to the submitted paper, this version contains more up - to - date benchmarks in section 6. to the [SEP]
Text from DS:  Abstract Interpretation of Binary Code with
Memory Accesses using Polyhedra

arXiv:1711.07257v1 [] 20 Nov 2017

Clément Ballabriga and Julien Forget and Giuseppe Lipari
University of Lille, CNRS, Centrale Lille, UMR 9189 – CRIStAL
{name.surname}@univ-lille1.fr

Abstract. In this paper1 we propose a novel methodology for static
analysis of binary code using abstract interpretation. We use an abstract
domain based on polyhedra and two mapping functions that associate
polyhedra variables with registers and memory.
We demonstrate our methodology to the problem of computing upper
bounds to loop iterations in the code. This problem is particularly important in the domain of Worst-Case Execution Time (WCET) analysis
of safety-critical real-time code. However, our approach is general and it
can applied to other static analysis problems.

1

Introduction

In real-time systems it is important to compute upper bounds to the execution
times of every function, and check that they complete before t
Original label:  cs.CE
Predicted label:  2
Correct label:  9
Text:  [CLS] an analysis of introductory programming courses at uk universities ellen murphya, tom crickb, and james h. davenportc a institute for mathematical innovation, university of bath, uk b department of computing & information systems, cardiff metropolitan university, uk c department of computer science, university of bath, uk abstract context : in the context of exploring the art, science and engineering of programming, the question of which programming languages should be taught first has been fiercely debated since computer science teaching started in universities. failure to grasp programming readily almost certainly implies failure to progress in computer science. inquiry : what first programming languages are being taught? there have been regular national - scale surveys in australia and new zealand, with the only us survey reporting on a small subset of universities. this the first such national survey of universities in the uk. approach : we report the results of the first survey of introductory programming courses ( n = 80 ) taught at uk universities as part of their first year computer science ( or related ) degree programmes, conducted in the first half of 2016. we report on student numbers, programming paradigm, programming languages and environment / tools used, as well as the underpinning rationale for these choices. knowledge : the results in this first uk survey indicate a dominance of java at a time when universities are still generally teaching students who are new to programming ( and computer science ), despite the fact that python is perceived, by the same respondents, to be both easier to teach as well as to learn. grounding : we compare the results of this survey with a related survey conducted since 2010 ( as well as earlier surveys from 2001 and 2003 ) in australia and new zealand. importance : this survey provides a starting point for valuable pedagogic baseline data for the analysis of the art, science and engineering of programming, in the context of substantial computer science curriculum reform in uk schools, as well as increasing scrutiny of teaching excellence and graduate employability for uk universities. acm ccs 2012 social and professional topics → computing education programs ; computer science education ; cs1 ; computer engineering education ; software engineering education ; keywords introductory programming, programming pedagogy, programming environments, programming education, computer science education the art, science, and engineering of programming submitted december 2, 2016 published april 1, 2017 doi 10. 22152 / programming - journal. org / 2017 / 1 / 18 © ellen murphy, tom crick, and james h. davenport this work is licensed under a “ cc by 4. 0 ” license. in the art, science, and [SEP]
Text from DS:  An Analysis of Introductory Programming Courses at UK
Universities
Ellen Murphya , Tom Crickb , and James H. Davenportc
a Institute for Mathematical Innovation, University of Bath, UK
b Department of Computing & Information Systems, Cardiff Metropolitan University, UK
c

Department of Computer Science, University of Bath, UK

Abstract Context: In the context of exploring the art, science and engineering of programming, the question of which programming languages should be taught first has been fiercely debated since computer science teaching started in universities. Failure to grasp programming readily almost certainly implies failure to
progress in computer science.
Inquiry: What first programming languages are being taught? There have been regular national-scale surveys
in Australia and New Zealand, with the only US survey reporting on a small subset of universities. This the
first such national survey of universities in the UK.
Approach: We report the results of the first survey of 
Original label:  math.GR
Predicted label:  9
Correct label:  1
Text:  [CLS] symmetric cohomology of groups arxiv : 1706. 01367v2 [ ] 14 jun 2017 mariam pirashvili abstract. we investigate the relationship between the symmetric, exterior and classical cohomologies of groups. the first two theories were introduced respectively by staic and zarelua. we show in particular, that there is a map from exterior cohomology to symmetric cohomology which is a split monomorphism in general and an isomorphism in many cases, but not always. we introduce two spectral sequences which help to explain the realtionship between these cohomology groups. as a sample application we obtain that symmetric and classical cohomologies are isomorphic for torsion free groups. ams classification : 20j06 18g40. 1. introduction let g be a group and m be a g - module. in order to better understand 3 - algebras arising in lattice field theory [ 3 ], staic defined a variant of group cohomology, which he denoted by hs ∗ ( g, m ) and called symmetric cohomology of groups [ 6 ]. some aspects of this theory were later extended by singh [ 5 ] and todea [ 9 ]. there is an obvious natural transformation from the symmetric cohomology to the classical eilenberg - maclane cohomology αn : hs n ( g, m ) → h n ( g, m ), n ≥ 0. according to [ 6 ], [ 7 ], αn is an isomorphism if n = 0, 1 and is a monomorphism for n = 2. by corollary 2. 3 in [ 7 ] we know that α2 is an isomorphism if g has no elements of order two. ten years prior to this, zarelua had also defined a version of group cohomology, denoted by hλ∗ ( g, m ) and called exterior cohomology of groups [ 10 ]. it also comes together with a natural transformation βn : hλn ( g, m ) → h n ( g, m ), with similar properties. the exterior cohomology has the following striking property : if g is a finite group of order d, then hλi ( g, m ) = 0 for all i ≥ d. the aim of this work is to obtain more information about homomorphisms α∗ and β∗. we construct a natural transformation γn : hλn ( g, m ) → hs n ( g, m [SEP]
Text from DS:  SYMMETRIC COHOMOLOGY OF GROUPS

arXiv:1706.01367v2 [] 14 Jun 2017

MARIAM PIRASHVILI

Abstract. We investigate the relationship between the symmetric, exterior and classical cohomologies of groups. The first
two theories were introduced respectively by Staic and Zarelua. We show in particular, that there is a map from exterior
cohomology to symmetric cohomology which is a split monomorphism in general and an isomorphism in many cases, but not
always. We introduce two spectral sequences which help to explain the realtionship between these cohomology groups. As a
sample application we obtain that symmetric and classical cohomologies are isomorphic for torsion free groups.

AMS classification: 20J06 18G40.
1. Introduction
Let G be a group and M be a G-module. In order to better understand 3-algebras arising in lattice field theory [3],
Staic defined a variant of group cohomology, which he denoted by HS ∗ (G, M) and called symmetric cohomology of
groups [6]. Some aspects of this theory wer
Original label:  cs.CE
Predicted label:  9
Correct label:  2
Text:  [CLS] higher - order approximate relational refinement types for mechanism design and differential privacy gilles barthe [UNK] marco gaboardi ; emilio jesus gallego arias # justin hsu # aaron roth # pierre - yves strub [UNK] imdea software institute ; university of dundee, scotland # university of pennsylvania tifact eu opl * * p se * consi at e d arxiv : 1407. 6845v2 [ ] 29 oct 2014 * easy to ed r nt categories and subject descriptors d. 3. 1 [ programming languages ] : formal definitions and theory — semantics ; d. 2. 4 [ software engineering ] : software / program verification. keywords program logics ; probabilistic programming 1. introduction when designing algorithms, we usually assume that the inputs are correctly reported. however, in the real world, inputs may be provided by people who may want to influence the outcome of the algorithm. mechanism design is the field of algorithm design where the inputs to the algorithm ( often called a mechanism ) are controlled by strategic agents who may manipulate what their inputs. in this setting, it is not enough to design an algorithm which behaves correctly on correct input ; the design of the mechanism permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. copyrights for components of this work owned by others than the author ( s ) must be honored. abstracting with credit is permitted. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and / or a fee. request permissions from permissions @ acm. org. popl ’ 15, january 15 – 17, 2015, mumbai, india. copyright is held by the owner / author ( s ). publication rights licensed to acm. acm 978 - 1 - 4503 - 3300 - 9 / 15 / 01... $ 15. 00. http : / / dx. doi. org / 10. 1145 / 10. 1145 / 2676726. 2677000 ev mechanism design is the study of algorithm design where the inputs to the algorithm are controlled by strategic agents, who must be incentivized to faithfully report them. unlike typical programmatic properties, it is not sufficient for algorithms to merely satisfy the property — incentive properties [SEP]
Text from DS:  Higher-Order Approximate Relational Refinement Types
for Mechanism Design and Differential Privacy
Gilles Barthe‹
Marco Gaboardi;
Emilio Jesús Gallego Arias#
Justin Hsu#
Aaron Roth#
Pierre-Yves Strub‹
IMDEA Software Institute

;

University of Dundee, Scotland

#

University of Pennsylvania

tifact

eu

OPL *
* P se * Consi

at e d

arXiv:1407.6845v2 [] 29 Oct 2014

* Easy to
ed
R
nt

Categories and Subject Descriptors D.3.1 [Programming Languages]: Formal Definitions and Theory—Semantics; D.2.4 [Software Engineering]: Software/Program Verification.
Keywords program logics; probabilistic programming

1.

Introduction

When designing algorithms, we usually assume that the inputs
are correctly reported. However, in the real world, inputs may be
provided by people who may want to influence the outcome of
the algorithm. Mechanism design is the field of algorithm design
where the inputs to the algorithm (often called a mechanism) are
controlled by strategic agents who may manipulate what th
Original label:  cs.IT
Predicted label:  9
Correct label:  2
Text:  [CLS] stable memory allocation in the hippocampus : fundamental limits and neural realization wenlong mou∗ zhi wang † liwei wang ‡ arxiv : 1612. 04659v1 [ ] 14 dec 2016 december 15, 2016 abstract it is believed that hippocampus functions as a memory allocator in brain, the mechanism of which remains unrevealed. in valiant ’ s neuroidal model [ 19 ], the hippocampus was described as a randomly connected graph, the computation on which maps input to a set of activated neuroids with stable size. valiant proposed three requirements for the hippocampal circuit to become a stable memory allocator ( sma ) : stability, continuity and orthogonality. the functionality of sma in hippocampus is essential in further computation within cortex, according to valiant ’ s model. in this paper, we put these requirements for memorization functions into rigorous mathematical formulation and introduce the concept of capacity, based on the probability of erroneous allocation. we prove fundamental limits for the capacity and error probability of sma, in both data - independent and data - dependent settings. we also establish an example of stable memory allocator that can be implemented via neuroidal circuits. both theoretical bounds and simulation results show that the neural sma functions well. 1 introduction it is well known that the computational speed of human brain is several orders of magnitude slower than that of current computer, while almost everything human can do easily are still beyond the capability of the most powerful computers. thus, the investigation into computational mechanisms of human brains leads a promising direction for theoretical aspect of computation, machine learning and neuroscience. in particular, the formation of memory, during which the neural circuit creates a representation for an object, was not fully understood, though it has been observed that the hippocampus plays a significant role in this process. a research line developed by valiant [ 15, 16, 18, 20 ] focused on the connectivity structure of neuroids, i. e., the computational abstraction of neurons, on which local computation can be performed. this formal and conservative model assumes the brain to be a randomly connected graph of neuroids. each of them can be either active or inactive, depending on the states of neighbors that have a directed edge to it. biological constraints are also taken into consideration, such as weak synaptic connections and sparsity of graphs. with biological evidences, this model captures the capability of realistic neurons. specific supervised and un [SEP]
Text from DS:  Stable Memory Allocation in the Hippocampus:
Fundamental Limits and Neural Realization
Wenlong Mou∗

Zhi Wang†

Liwei Wang‡

arXiv:1612.04659v1 [] 14 Dec 2016

December 15, 2016

Abstract
It is believed that hippocampus functions as a memory allocator in brain, the mechanism of
which remains unrevealed. In Valiant’s neuroidal model [19], the hippocampus was described as
a randomly connected graph, the computation on which maps input to a set of activated neuroids
with stable size. Valiant proposed three requirements for the hippocampal circuit to become
a stable memory allocator (SMA): stability, continuity and orthogonality. The functionality of
SMA in hippocampus is essential in further computation within cortex, according to Valiant’s
model.
In this paper, we put these requirements for memorization functions into rigorous mathematical formulation and introduce the concept of capacity, based on the probability of erroneous
allocation. We prove fundamental limits for the capacity and 
Original label:  cs.IT
Predicted label:  6
Correct label:  2
Text:  [CLS] exploiting computation - friendly graph compression methods for adjacency - matrix multiplication arxiv : 1708. 07271v3 [ ] 18 feb 2018 alexandre p francisco∗, travis gagie †, susana ladra ‡, and gonzalo navarro § ∗ inesc - id † eit, / ist universidade de lisboa portugal aplf @ ist. utl. pt diego portales university and cebib chile travis. gagie @ gmail. com ‡ facultade de informatica / citic universidade da coruna spain sladra @ udc. es § department of computer science university of chile chile gnavarro @ dcc. uchile. cl abstract computing the product of the ( binary ) adjacency matrix of a large graph with a real - valued vector is an important operation that lies at the heart of various graph analysis tasks, such as computing pagerank. in this paper we show that some well - known web and social graph compression formats are computation - friendly, in the sense that they allow boosting the computation. in particular, we show that the format of boldi and vigna allows computing the product in time proportional to the compressed graph size. our experimental results show speedups of at least 2 on graphs that were compressed at least 5 times with respect to the original. we show that other successful graph compression formats enjoy this property as well. introduction let a be an n × n binary matrix and x ∈ irn a vector. matrix vector multiplication, either x · a or a · [UNK], is not only a fundamental operation in mathematics, but also a key operation in various graph - analysis tasks, when a is their adjacency matrix. a well - known example, which we use as a motivation, is the computation of pagerank on large web graphs. pagerank is a particular case of many network centrality measures that can be approximated through the power method [ 1 ]. most real networks, and in particular web and social graphs, have very sparse adjacency matrices [ 2 ]. while it is straightforward to compute a matrix - vector product in time proportional to the nonzero entries of a, the most successful web and social graph compression methods exploit other properties that allow them to compress the graphs well beyond what is possible by their mere sparsity. it is therefore natural to ask whether those more powerful compression formats allow us, as sparsity does, to compute the product in time proportional to the [SEP]
Text from DS:  Exploiting Computation-Friendly
Graph Compression Methods for
Adjacency-Matrix Multiplication

arXiv:1708.07271v3 [] 18 Feb 2018

Alexandre P Francisco∗ , Travis Gagie† , Susana Ladra‡ , and Gonzalo Navarro§
∗ INESC-ID

† EIT,

/ IST
Universidade de Lisboa
Portugal
aplf@ist.utl.pt

Diego Portales University
and CeBiB
Chile
travis.gagie@gmail.com

‡ Facultade

de Informática / CITIC
Universidade da Coruña
Spain
sladra@udc.es

§ Department

of Computer Science
University of Chile
Chile
gnavarro@dcc.uchile.cl

Abstract
Computing the product of the (binary) adjacency matrix of a large graph with a real-valued
vector is an important operation that lies at the heart of various graph analysis tasks, such as
computing PageRank. In this paper we show that some well-known Web and social graph
compression formats are computation-friendly, in the sense that they allow boosting the
computation. In particular, we show that the format of Boldi and Vigna allows computing
the product in time proporti
Original label:  cs.NE
Predicted label:  10
Correct label:  7
Text:  [CLS] genealogical distance as a diversity estimate in evolutionary algorithms thomas gabor lenz belzner lmu munich thomas. gabor @ ifi. lmu. de arxiv : 1704. 08774v1 [ ] 27 apr 2017 abstract the evolutionary edit distance between two individuals in a population, i. e., the amount of applications of any genetic operator it would take the evolutionary process to generate one individual starting from the other, seems like a promising estimate for the diversity between said individuals. we introduce genealogical diversity, i. e., estimating two individuals ’ degree of relatedness by analyzing large, unused parts of their genome, as a computationally efficient method to approximate that measure for diversity. ccs concepts • computing methodologies → heuristic function construction ; genetic algorithms ; acm reference format : thomas gabor and lenz belzner. 2017. genealogical distance as a diversity estimate in evolutionary algorithms. in proceedings of gecco ’ 17 companion, berlin, germany, july 15 - 19, 2017, 6 pages. doi : http : / / dx. doi. org / 10. 1145 / 3067695. 3082529 1 introduction diversity has been a central point of research in the area of evolutionary algorithms. it is a well - known fact that maintaining a certain level of diversity aids the evolutionary process in preventing premature convergence, i. e., the phenomenon that the population focuses too quickly on a local optimum at hand and never reaches more fruitful areas of the fitness landscape [ 4, 14, 16 ]. diversity thus plays a key role in adjusting the exploration - exploitation trade - off found in any kind of metaheuristic search algorithm. we encountered this problem from an industry point of view when designing learning components for a system that needs to guarantee certain levels of quality despite being subjected to the probabilistic nature of its physical environment and probabilistic behavior of its machine learning parts [ 1 ]. of course, any general solution for this kind of challenge is yet to be found. however, we believe that the engineering of ( hopefully ) reliable learning components can be supported by exposing all handles that search algorithms offer to the engineer at site. for scenarios like this one, we consider it most helpful to employ approaches that allow permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first [SEP]
Text from DS:  Genealogical Distance as a Diversity Estimate
in Evolutionary Algorithms
Thomas Gabor

Lenz Belzner

LMU Munich
thomas.gabor@ifi.lmu.de

arXiv:1704.08774v1 [] 27 Apr 2017

ABSTRACT
The evolutionary edit distance between two individuals in a population, i.e., the amount of applications of any genetic operator
it would take the evolutionary process to generate one individual
starting from the other, seems like a promising estimate for the
diversity between said individuals. We introduce genealogical diversity, i.e., estimating two individuals’ degree of relatedness by
analyzing large, unused parts of their genome, as a computationally
efficient method to approximate that measure for diversity.

CCS CONCEPTS
•Computing methodologies → Heuristic function construction; Genetic algorithms;
ACM Reference format:
Thomas Gabor and Lenz Belzner. 2017. Genealogical Distance as a Diversity
Estimate
in Evolutionary Algorithms. In Proceedings of GECCO ’17 Companion, Berlin,
Germany, July 15-19, 2017
Original label:  math.GR
Predicted label:  6
Correct label:  3
Text:  [CLS] arxiv : 1508. 00493v3 [ ] 12 jan 2017 on subgroups of r. thompson ’ s group f gili golan, mark sapir∗ january 13, 2017 abstract we provide two ways to show that the r. thompson group f has maximal subgroups of infinite index which do not fix any number in the unit interval under the natural action of f on ( 0, 1 ), thus solving a problem by d. savchuk. the first way employs jones ’ subgroup of the r. thompson group f and leads to an explicit finitely generated example. the second way employs directed 2 - complexes and 2 - dimensional analogs of stallings ’ core graphs, and gives many implicit examples. we also show that f has a decreasing sequence of finitely generated subgroups f > h1 > h2 >... such that ∩hi = { 1 } and for every i there exist only finitely many subgroups of f containing hi. 1 1. 1 introduction the stories about f recall that the r. thompson group f consists of all piecewise linear increasing homeomorphisms of the unit interval [ 0, 1 ] with a finite number of linear segments with slopes of the form 2n, n ∈ z, and endpoints of the form 2an, a, n ∈ n∪ { 0 }. the group f has a presentation with two generators and two defining relations [ 6, 17 ] ( see below ). the group f is one of the most mysterious objects in group theory. for example, almost every 6 months a new “ proof ” of amenability or non - amenability of f appears. the reason why all these proofs are wrong is that f is very counter - intuitive. statements which are “ obviously true ” turn out to be wrong. this can also be illustrated by the story of finding the dehn function of f. first it was declared exponential because a sequence of loops in the cayley graph of f was found with exponential fillings, and it was “ obviously impossible ” to find fillings of these loops with smaller area. then it was proved to be subexponential and the most probable conjecture ( for 2 the same reason as before ) was that it is something like 2log n. then a polynomial of degree 5 upper bound was found and it was conjectured that this bound is optimal. then a few lower bounds were found until guba proved that f has quadratic dehn function, the smallest ∗ the research was [SEP]
Text from DS:  arXiv:1508.00493v3 [] 12 Jan 2017

On subgroups of R. Thompson’s group F
Gili Golan, Mark Sapir∗
January 13, 2017

Abstract
We provide two ways to show that the R. Thompson group F has maximal subgroups of
infinite index which do not fix any number in the unit interval under the natural action of F
on (0, 1), thus solving a problem by D. Savchuk. The first way employs Jones’ subgroup of
the R. Thompson group F and leads to an explicit finitely generated example. The second
way employs directed 2-complexes and 2-dimensional analogs of Stallings’ core graphs, and
gives many implicit examples. We also show that F has a decreasing sequence of finitely
generated subgroups F > H1 > H2 > ... such that ∩Hi = {1} and for every i there exist
only finitely many subgroups of F containing Hi .

1
1.1

Introduction
The stories about F

Recall that the R. Thompson group F consists of all piecewise linear increasing homeomorphisms of the unit interval [0, 1] with a finite number of linear segments wit
Original label:  cs.PL
Predicted label:  9
Correct label:  7
Text:  [CLS] activated zero - error classical communication over quantum channels assisted with quantum no - signalling correlations runyao duan1, 2 and xin wang1 1 centre for quantum software and information, faculty of engineering and information technologies, arxiv : 1510. 05437v2 [ quant - ph ] 18 dec 2017 university of technology sydney, australia 2 uts - amss joint research laboratory for quantum computation and quantum information processing, academy of mathematics and systems science, chinese academy of sciences, china december 19, 2017 we study the activated quantum no - signalling - assisted zero - error classical capacity by first allowing the assistance from some noiseless forward communication channel and later paying back the cost of the helper. this activated communication model considers the additional forward noiseless channel as a catalyst for communication. first, we show that the one - shot activated capacity can be formulated as a semidefinite program and we derive a number of striking properties of this capacity. we further present a sufficient condition under which a noisy channel can be activated. second, we find that one - bit noiseless classical communication is able to fully activate any classical - quantum channel to achieve its asymptotic capacity, or the semidefinite ( or fractional ) packing number. third, we prove that the asymptotic activated capacity cannot exceed the original asymptotic capacity of any quantum channel. we also show that the asymptotic no - signalling - assisted zero - error capacity does not equal to the semidefinite packing number for quantum channels, which differs from the case of classical - quantum channels. 1 introduction a fundamental problem of information theory is to determine the capacity of a communication channel, which describes the capability of the channel for delivering information from the sender to the receiver. shannon first discussed this problem in the zero - error setting and described the zero - error capacity of a channel as the maximum rate at which it can be used to transmit information perfectly [ 1 ]. it is well - known that the shannon zero - error capacity is extremely difficult to compute even for very simple classical channels. nevertheless, this capacity is upper bounded by the lovasz [UNK] function [ 2 ] which is efficiently computable by semidefinite programming [ 3 ]. recently the zero - error information theory has been studied in the quantum setting and many interesting phenomena were observed. for instance, it was shown that shared entanglement could sometimes improve the zero - error capacity of a classical channel [ 4, 5 ], runyao du [SEP]
Text from DS:  Activated zero-error classical communication over quantum channels assisted with
quantum no-signalling correlations
Runyao Duan1,2 and Xin Wang1
1

Centre for Quantum Software and Information, Faculty of Engineering and Information Technologies,

arXiv:1510.05437v2 [quant-ph] 18 Dec 2017

University of Technology Sydney, Australia
2

UTS-AMSS Joint Research Laboratory for Quantum Computation and Quantum Information Processing,
Academy of Mathematics and Systems Science, Chinese Academy of Sciences, China
December 19, 2017

We study the activated quantum no-signalling-assisted zero-error classical
capacity by first allowing the assistance from some noiseless forward communication channel and later paying back the cost of the helper. This activated
communication model considers the additional forward noiseless channel as a
catalyst for communication. First, we show that the one-shot activated capacity can be formulated as a semidefinite program and we derive a number of
striking properti
Original label:  math.ST
Predicted label:  5
Correct label:  9
Text:  [CLS] on the consistency of inversion - free parameter estimation for gaussian random fields [UNK] hossein keshavarza, clayton scottb, a, xuanlong nguyena, b a arxiv : 1601. 03822v2 [ ] 21 jun 2016 b department of statistics, university of michigan department of electrical engineering and computer science, university of michigan abstract gaussian random fields are a powerful tool for modeling environmental processes. for high dimensional samples, classical approaches for estimating the covariance parameters require highly challenging and massive computations, such as the evaluation of the cholesky factorization or solving linear systems. recently, anitescu, chen and stein [ 2 ] proposed a fast and scalable algorithm which does not need such burdensome computations. the main focus of this article is to study the asymptotic behavior of the algorithm of anitescu et al. ( acs ) for regular and irregular grids in the increasing domain setting. consistency, minimax optimality and asymptotic normality of this algorithm are proved under mild differentiability conditions on the covariance function. despite the fact that acs ’ s method entails a non - concave maximization, our results hold for any stationary point of the objective function. a numerical study is presented to evaluate the efficiency of this algorithm for large data sets. keywords : inversion - free estimation, covariance function, stationary gaussian process, asymptotic analysis 1. introduction gaussian processes have plethora of applications, ranging from the modeling of environmental processes in geostatistics ( e. g., [ 9, 11 ] ) to supervised regression and classification in machine learning [ 5, 8, 16 ], and the simulation of complex computer models [ 18 ]. the versatility of the correlation structure of gaussian processes provides a tractable and powerful tool for the modeling of large and highly dependent environmental variables. as a common approach in the field of spatial statistics, the covariance functions of gaussian processes are assumed to belong to a parametric family. high precision estimates of the covariance parameters are pivotal for interpolating gaussian processes which is the ultimate goal in many geostatistical problems [ 9, 19 ]. in the last two decades, there has been extensive research regarding the statistical and computational facets of the estimation of the gaussian processes ’ covariance parameters. maximum likelihood estimation ( mle ) was the earliest favored algorithm in [SEP]
Text from DS:  On the consistency of inversion-free parameter
estimation for Gaussian random fields ✩
Hossein Keshavarza , Clayton Scottb,a , XuanLong Nguyena,b
a

arXiv:1601.03822v2 [] 21 Jun 2016

b

Department of Statistics, University of Michigan
Department of Electrical Engineering and Computer Science, University of Michigan

Abstract
Gaussian random fields are a powerful tool for modeling environmental processes. For high dimensional samples, classical approaches for estimating the covariance parameters require highly
challenging and massive computations, such as the evaluation of the Cholesky factorization or solving linear systems. Recently, Anitescu, Chen and Stein [2] proposed a fast and scalable algorithm
which does not need such burdensome computations. The main focus of this article is to study the
asymptotic behavior of the algorithm of Anitescu et al. (ACS) for regular and irregular grids in
the increasing domain setting. Consistency, minimax optimality and asymptotic normality of thi
Original label:  math.GR
Predicted label:  10
Correct label:  7
Text:  [CLS] arxiv : 1508. 04794v3 [ math. gt ] 17 dec 2017 convex projective structures on non - hyperbolic three - manifolds samuel a. ballas, jeffrey danciger, and gye - seon lee abstract. y. benoist proved that if a closed three - manifold m admits an indecomposable convex real projective structure, then m is topologically the union along tori and klein bottles of finitely many sub - manifolds each of which admits a complete finite volume hyperbolic structure on its interior. we describe some initial results in the direction of a potential converse to benoist ’ s theorem. we show that a cusped hyperbolic three - manifold may, under certain assumptions, be deformed to convex projective structures with totally geodesic torus boundary. such structures may be convexly glued together whenever the geometry at the boundary matches up. in particular, we prove that many doubles of cusped hyperbolic three - manifolds admit convex projective structures. 1. introduction the previous decade has seen tremendous progress in the study of threedimensional manifolds. much of that progress stems from perelman ’ s proof of thurston ’ s geometrization conjecture which states that any closed orientable prime three - manifold admits a decomposition into geometric pieces modeled on the eight homogeneous thurston geometries. however, because these geometric pieces do not glue together in any sensible geometric way, there are some questions about three - manifolds for which a thurston geometric decomposition of the manifold may not be useful. one example is the question of linearity of three - manifold groups, ie whether a three - manifold fundamental group admits a faithful linear representation and in which dimensions. while, in most cases, the thurston geometric structure on each piece of a geometric decomposition determines a faithful linear representation of its fundamental group, these representations can not be directly synthesized into a representation of the fundamental group of the entire manifold. in order to make progress on this and other problems, it is natural, given a manifold of interest, to search for a homogeneous geometry capable of describing the entire manifold all at once. this article studies properly convex real projective structures on threemanifolds. a domain ω in the real projective space rpn is called properly convex if there is an affine chart containing ω in which ω is convex and bounded. a properly convex projective n – manifold is the quotient γ \ ω of a convex domain ω by a discrete group γ of [SEP]
Text from DS:  arXiv:1508.04794v3 [math.GT] 17 Dec 2017

CONVEX PROJECTIVE STRUCTURES ON
NON-HYPERBOLIC THREE-MANIFOLDS
SAMUEL A. BALLAS, JEFFREY DANCIGER, AND GYE-SEON LEE
Abstract. Y. Benoist proved that if a closed three-manifold M admits an indecomposable convex real projective structure, then M is
topologically the union along tori and Klein bottles of finitely many
sub-manifolds each of which admits a complete finite volume hyperbolic
structure on its interior. We describe some initial results in the direction
of a potential converse to Benoist’s theorem. We show that a cusped hyperbolic three-manifold may, under certain assumptions, be deformed to
convex projective structures with totally geodesic torus boundary. Such
structures may be convexly glued together whenever the geometry at
the boundary matches up. In particular, we prove that many doubles of
cusped hyperbolic three-manifolds admit convex projective structures.

1. Introduction
The previous decade has seen tremendous progress in the 
Original label:  math.AC
Predicted label:  2
Correct label:  3
Text:  [CLS] a note on hilbert - kunz multiplicity mohsen asgharzadeh arxiv : 1603. 04297v1 [ ] 14 mar 2016 abstract. in this note we first give a new bound on ehk ( [UNK] ) the hilbert - kunz multiplicity of invariant rings, by the help of the noether ’ s bound. then, we simplify, extend and present applications of the reciprocity formulae due to l. smith. he proved the formula over polynomial rings and his result is tight in the following sense : over complete intersection rings with isolated singularity we show that the reciprocity formulae ” ehk ( r / i ) + ehk ( r / j ) = ehk ( r / f ) ” is equivalent with p. dim ( i ) < ∞ when i is an m - primary unmixed ideal linked to j along with a regular sequence f. 1. introduction throughout this note rings are of prime characteristic p > 0. let f n ( − ) be the peskineszpiro functor. the hilbert - kunz multiplicity over ∗ - local ( a, m ) with an m - primary ideal i is defined by ℓ ( f n ( a / i ) ). n→∞ pn dim a this introduced by kunz. monsky proved such a limit exists [ 7 ]. hilbert - kunz multiplicity ehk ( i, a ) : = lim encodes the singularity in prime characteristic [ 14 ], et cetera. some times computing ehk ( [UNK] ) is difficult and finding bounds may be a reasonable task. also, ehk ( [UNK] ) behaves both similar to and different from those of hilbert - samuel multiplicity. in this note we present a new sample for this behavior. we use ehk ( a ) instead of ehk ( m, a ). we denote the usual hilbert - samuel multiplicity by e ( i ). suppose a finite group g acts linearly over a polynomial ring with n variables, denote the invariant ring by a and assume that the order of g is prime to p. first we observe ( n−1 + | g | ) n ehk ( a ) ≤, as an easy application of noether ’ s bound from invariant theory. over | g | 2 - dimensional quotient singularity, this has in the simple form ehk ( k [ x, y ] g ) ≤ e ( k [ x, y ] g ) | g | [SEP]
Text from DS:  A NOTE ON HILBERT-KUNZ MULTIPLICITY
MOHSEN ASGHARZADEH

arXiv:1603.04297v1 [] 14 Mar 2016

Abstract. In this note we first give a new bound on eHK (∼) the Hilbert-Kunz multiplicity of invariant rings, by the help of the Noether’s bound. Then, we simplify, extend
and present applications of the reciprocity formulae due to L. Smith. He proved the
formula over polynomial rings and his result is tight in the following sense: Over complete intersection rings with isolated singularity we show that the reciprocity formulae
”eHK (R/I) + eHK (R/J) = eHK (R/f )” is equivalent with p. dim(I) < ∞ when I is an
m-primary unmixed ideal linked to J along with a regular sequence f .

1. Introduction
Throughout this note rings are of prime characteristic p > 0. Let F n (−) be the PeskineSzpiro functor. The Hilbert-Kunz multiplicity over ∗-local (A, m) with an m-primary ideal
I is defined by
ℓ (F n (A/I))
.
n→∞
pn dim A
This introduced by Kunz. Monsky proved such a limit exists [7]. Hilbert-Kunz multipli
Original label:  cs.AI
Predicted label:  7
Correct label:  1
Text:  [CLS] social emotion mining techniques for facebook posts reaction prediction florian krebs∗, bruno lubascher *, tobias moers *, pieter schaap *, gerasimos spanakis † arxiv : 1712. 03249v1 [ ] 8 dec 2017 department of data science and knowledge engineering, maastricht university, maastricht, netherlands email : { florian. krebs, bruno. lubascher, tobias. moers, pieter. schaap } @ student. maastrichtuniversity. nl, jerry. spanakis @ maastrichtuniversity. nl keywords : emotion mining, social media, deep learning, natural language processing abstract : as of february 2016 facebook allows users to express their experienced emotions about a post by using five so - called ‘ reactions ’. this research paper proposes and evaluates alternative methods for predicting these reactions to user posts on public pages of firms / companies ( like supermarket chains ). for this purpose, we collected posts ( and their reactions ) from facebook pages of large supermarket chains and constructed a dataset which is available for other researches. in order to predict the distribution of reactions of a new post, neural network architectures ( convolutional and recurrent neural networks ) were tested using pretrained word embeddings. results of the neural networks were improved by introducing a bootstrapping approach for sentiment and emotion mining on the comments for each post. the final model ( a combination of neural network and a baseline emotion miner ) is able to predict the reaction distribution on facebook posts with a mean squared error ( or misclassification rate ) of 0. 135. 1 introduction the ability to accurately classify the sentiment of short sentences such as facebook posts or tweets is essential to natural language understanding. in recent years, more and more users share information about their customer experience on social media pages related to ( and managed by ) the equivalent firms / companies. generated data attracts a lot of research towards sentiment analysis with many applications in political science, social sciences, business, education, etc. ( ortigosa et al., 2014 ), ( feldman, 2013 ), ( troussas et al., 2013 ). customer experience ( cx ) represents a holistic perspective on customer encounters with a firm ’ s products or services. thus, the more managers can understand about the experiences customers have with their product and service offerings, the more they can measure them again in the future to influence purchase decisions [SEP]
Text from DS:  Social Emotion Mining Techniques
for Facebook Posts Reaction Prediction
Florian Krebs∗ , Bruno Lubascher*, Tobias Moers*, Pieter Schaap*, Gerasimos Spanakis†

arXiv:1712.03249v1 [] 8 Dec 2017

Department of Data Science and Knowledge Engineering, Maastricht University, Maastricht, Netherlands
Email: {florian.krebs, bruno.lubascher, tobias.moers, pieter.schaap}@student.maastrichtuniversity.nl,
jerry.spanakis@maastrichtuniversity.nl

Keywords:

Emotion mining, Social media, Deep Learning, Natural Language Processing

Abstract:

As of February 2016 Facebook allows users to express their experienced emotions about a post by using
five so-called ‘reactions’. This research paper proposes and evaluates alternative methods for predicting these
reactions to user posts on public pages of firms/companies (like supermarket chains). For this purpose, we collected posts (and their reactions) from Facebook pages of large supermarket chains and constructed a dataset
which is available for other resear
Original label:  cs.AI
Predicted label:  5
Correct label:  9
Text:  [CLS] indexing the event calculus with kd - trees to monitor diabetes arxiv : 1710. 01275v1 [ ] 3 oct 2017 stefano bromuria, ∗, albert brugues de la torreb, fabien duboissonb, michael schumacherb a open university of the netherlands, management, science and technology, valkenburgweg 177, 6419 at, heerlen, netherlands b university of applied sciences western switzerland institute of business information systems technoark 3, ch - 3960, sierre, switzerland abstract personal health systems ( phs ) are mobile solutions tailored to monitoring patients affected by chronic non communicable diseases. a patient affected by a chronic disease can generate large amounts of events. type 1 diabetic patients generate several glucose events per day, ranging from at least 6 events per day ( under normal monitoring ) to 288 per day when wearing a continuous glucose monitor ( cgm ) that samples the blood every 5 minutes for several days. this is a large number of events to monitor for medical doctors, in particular when considering that they may have to take decisions concerning adjusting the treatment, which may impact the life of the patients for a long time. given the need to analyse such a large stream of data, doctors need a simple approach towards physiological time series that allows them to promptly transfer their knowledge into queries to identify interesting patterns in the data. achieving this with current technology is not an easy task, as on one hand it cannot be expected that medical doctors have the technical knowledge to query databases and on the other hand these time series include thousands of events, which requires to re - think the way data is indexed. in order to tackle the knowledge representation and efficiency prob∗ corresponding author email address : stefano. bromuri @ ou. nl ( stefano bromuri ) preprint submitted to. october 4, 2017 lem, this contribution presents the kd - tree cached event calculus ( ceckd ) an event calculus extension for knowledge engineering of temporal rules capable to handle many thousands events produced by a diabetic patient. ceckd is built as a support to a graphical interface to represent monitoring rules for diabetes type 1. in addition, the paper evaluates the ceckd with respect to the cached event calculus ( cec ) to show how indexing events using kd - trees improves scalability with respect to the current state of the art. keywords : diabetes type 1, event calculus, kd - trees, expert systems, rule management [SEP]
Text from DS:  Indexing the Event Calculus with Kd-trees to Monitor
Diabetes

arXiv:1710.01275v1 [] 3 Oct 2017

Stefano Bromuria,∗, Albert Brugues De la Torreb , Fabien Duboissonb ,
Michael Schumacherb
a

Open University of the Netherlands,
Management, Science and Technology,
Valkenburgweg 177, 6419 AT, Heerlen, Netherlands
b
University of Applied Sciences Western Switzerland
Institute of Business Information Systems
TechnoArk 3,
CH-3960, Sierre, Switzerland

Abstract
Personal Health Systems (PHS) are mobile solutions tailored to monitoring patients affected by chronic non communicable diseases. A patient
affected by a chronic disease can generate large amounts of events. Type
1 Diabetic patients generate several glucose events per day, ranging from
at least 6 events per day (under normal monitoring) to 288 per day when
wearing a continuous glucose monitor (CGM) that samples the blood every
5 minutes for several days. This is a large number of events to monitor for
medical doctors, in particular when
Original label:  cs.DS
Predicted label:  3
Correct label:  5
Text:  [CLS] modeling the dynamics of social networks victor v. kryssanov, frank j. rinaldo faculty of information science and engineering, ritsumeikan university, kusatsu, shiga, japan kvvictor @ is. ritsumei. ac. jp, rinaldo @ is. ritsumei. ac. jp evgeny l. kuleshov department of computer systems, the far - eastern national university, vladivostok, russia kuleshov @ lemoi. phys. dvgu. ru hitoshi ogawa department of information and communication science, ritsumeikan university, kusatsu, shiga, japan ogawa @ airlab. ics. ritsumei. ac. jp keywords : social networks, power law, human response time, consumer behavior. abstract : modeling human dynamics responsible for the formation and evolution of the so - called social networks – structures comprised of individuals or organizations and indicating connectivities existing in a community – is a topic recently attracting a significant research interest. it has been claimed that these dynamics are scale - free in many practically important cases, such as impersonal and personal communication, auctioning in a market, accessing sites on the www, etc., and that human response times thus conform to the power law. while a certain amount of progress has recently been achieved in predicting the general response rate of a human population, existing formal theories of human behavior can hardly be found satisfactory to accommodate and comprehensively explain the scaling observed in social networks. in the presented study, a novel system - theoretic modeling approach is proposed and successfully applied to determine important characteristics of a communication network and to analyze consumer behavior on the www. 1 introduction there is an increasing number of reports that human behavior underlying the development of social ( communication, entertainment, financial, and the like ) networks does not follow the poisson statistics conventionally employed to describe an individual ’ s bursty activities ( sheskin, 1997 ) but, instead, reveals the scaling dynamics conforming to the power law ( johansen, 2004 ; barabasi, 2005 ; oliveira and barabasi, 2005 ; adamic and huberman, 2000 ; scalas et al., 2006 ). striving to understand the mechanisms and factors responsible for the scalefree behavior, researchers have been quick to affiliate the dynamics of social networks with the familiar zipfian phenomena ( see newman, 2005, for a general survey, also barabasi and albert, 1999 ). there exist [SEP]
Text from DS:  MODELING THE DYNAMICS OF SOCIAL NETWORKS
Victor V. Kryssanov, Frank J. Rinaldo
Faculty of Information Science and Engineering, Ritsumeikan University, Kusatsu, Shiga, Japan
kvvictor@is.ritsumei.ac.jp, rinaldo@is.ritsumei.ac.jp

Evgeny L. Kuleshov
Department of Computer Systems, the Far-Eastern National University, Vladivostok, Russia
kuleshov@lemoi.phys.dvgu.ru

Hitoshi Ogawa
Department of Information and Communication Science, Ritsumeikan University, Kusatsu, Shiga, Japan
ogawa@airlab.ics.ritsumei.ac.jp

Keywords:

Social networks, Power law, Human response time, Consumer behavior.

Abstract:

Modeling human dynamics responsible for the formation and evolution of the so-called social networks –
structures comprised of individuals or organizations and indicating connectivities existing in a community –
is a topic recently attracting a significant research interest. It has been claimed that these dynamics are
scale-free in many practically important cases, such as impersonal and persona
Original label:  cs.SY
Predicted label:  9
Correct label:  1
Text:  [CLS] preprint version. accepted for publication in ieee transactions on instrumentation and measurement 1 best linear approximation of wiener systems using multilevel signals : theory and experiments arxiv : 1710. 07067v1 [ eess. sp ] 19 oct 2017 a. de angelis, j. schoukens, k. r. godfrey, p. carbone abstract — the problem of measuring the best linear approximation of a nonlinear system by means of multilevel excitation sequences is analyzed. a comparison between different types of sequences applied at the input of wiener systems is provided by numerical simulations and by experiments on a practical circuit including an analog filter and a clipping nonlinearity. the performance of the sequences is compared with a white gaussian noise signal for reference purposes. the theoretical characterization of the best linear approximation when using randomized constrained sequences is derived analytically for the cubic nonlinearity case. numerical and experimental results show that the randomized constrained approach for designing ternary sequences has a low sensitivity to both even and odd order nonlinearities, resulting in a response close to the actual response of the underlying linear system. index terms — nonlinear systems, best linear approximation, ternary sequences, binary pseudorandom sequences. i. i ntroduction the measurement of the frequency response function ( frf ) of a linear dynamical system is a fundamental step that is typically performed in engineering applications for modeling or control purposes. such procedure is typically performed by exciting the system under test with a properly designed input signal and measuring the output. however, many practical systems are affected by some degree of nonlinear distortion. for such systems, the frf will vary as a function of the excitation that the system is subject to. to analyze these cases, linearization is often a viable option. for this reason, the concept of best linear approximation ( bla ) of nonlinear systems is of great importance to practical applications. therefore, the bla, which is obtained by solving a least squares problem where the mean squared difference between the actual output of the system and the output of a linear model is minimized, has been thoroughly studied in the literature [ 1 ] – [ 4 ]. an analysis of the bla for several cases of the amplitude distribution of the input signal is developed in [ 5 ], considering gaussian signals and binary signals. the analysis is further this work was supported in part by the italian ministry of instruction, university and research ( miur ) through grant prin 2015c37b25. a. de angel [SEP]
Text from DS:  PREPRINT VERSION. ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT

1

Best Linear Approximation of Wiener Systems
Using Multilevel Signals: Theory and Experiments

arXiv:1710.07067v1 [eess.SP] 19 Oct 2017

A. De Angelis, J. Schoukens, K. R. Godfrey, P. Carbone

Abstract—The problem of measuring the best linear approximation of a nonlinear system by means of multilevel excitation
sequences is analyzed. A comparison between different types of
sequences applied at the input of Wiener systems is provided
by numerical simulations and by experiments on a practical
circuit including an analog filter and a clipping nonlinearity.
The performance of the sequences is compared with a white
Gaussian noise signal for reference purposes. The theoretical
characterization of the best linear approximation when using
randomized constrained sequences is derived analytically for the
cubic nonlinearity case. Numerical and experimental results show
that the randomized constra
Original label:  cs.PL
Predicted label:  2
Correct label:  6
Text:  [CLS] 1 quadratically constrained myopic adversarial channels yihan [UNK], shashank [UNK], sidharth [UNK] and anand sarwate : of information engineering, the chinese university of hong kong : dept. of electrical and computer engineering, rutgers, the state university of new jersey [UNK] dept. arxiv : 1801. 05951v1 [ ] 18 jan 2018 abstract we study communication in the presence of a jamming adversary where quadratic power constraints are imposed on the transmitter and the jammer. the jamming signal is assumed to be a function of the codebook, and a noncausal but noisy observation of the transmitted codeword. for a certain range of the noise - to - signal ratios ( nsrs ) of the transmitter and the jammer, we are able to characterize the capacity of this channel under deterministic encoding. for the remaining nsr regimes, we determine the capacity under the assumption of a small amount of common randomness ( at most oplogpnqq bits in one sub - regime, and at most opn2 q bits in the other sub - regime ) available to the encoder - decoder pair. our proof techniques involve a novel myopic list - decoding result for achievability and a plotkin - type push attack for the converse in a subregion of the nsrs, which may be of independent interest. a short video explaining our work is available at https : / / youtu. be / 0015 w xhlm. i. i ntroduction and prior work consider a point - to - point communication system where a transmitter, alice, wants to send a message to a receiver, bob, through a channel distorted by additive noise. she does so by encoding the message to a length - n codeword, which is fed into the channel. the transmitted codeword is distorted by noise. much of traditional communication and information theory has focussed on the scenario where the noise is independent of the transmitted signal and the coding scheme. we study the case where communication takes place in the presence of a malicious jammer ( whom we call james ) who tries to ensure that bob is unable to recover the transmitted message. the channel is a discrete - time, real - alphabet channel, and the codeword transmitted by alice is required to satisfy a quadratic power constraint. it is assumed that the coding scheme is known to all three parties, and james also observes a noisy version of the transmitted signal ( hence the term myop [SEP]
Text from DS:  1

Quadratically Constrained Myopic Adversarial
Channels
Yihan Zhang˚ , Shashank Vatedka˚ , Sidharth Jaggi˚ and Anand Sarwate:
of Information Engineering, The Chinese University of Hong Kong
: Dept. of Electrical and Computer Engineering, Rutgers, The State University of New Jersey
˚ Dept.

arXiv:1801.05951v1 [] 18 Jan 2018

Abstract
We study communication in the presence of a jamming adversary where quadratic power constraints are imposed on the
transmitter and the jammer. The jamming signal is assumed to be a function of the codebook, and a noncausal but noisy observation
of the transmitted codeword. For a certain range of the noise-to-signal ratios (NSRs) of the transmitter and the jammer, we are
able to characterize the capacity of this channel under deterministic encoding. For the remaining NSR regimes, we determine
the capacity under the assumption of a small amount of common randomness (at most Oplogpnqq bits in one sub-regime, and
at most Opn2 q bits in the other sub-regime) av
Original label:  cs.CV
Predicted label:  7
Correct label:  1
Text:  [CLS] arxiv : 1702. 06383v2 [ cs. ir ] 12 nov 2017 differential geometric retrieval of deep features y qian and e vazquez b sengupta cortexica vision systems limited 30 stamford street se1 9lq london, uk yu. qian @ cortexica. com cortexica vision systems limited imperial college london london, uk b. sengupta @ imperial. ac. uk abstract — comparing images to recommend items from an image - inventory is a subject of continued interest. added with the scalability of deep - learning architectures the once ‘ manual ’ job of hand - crafting features have been largely alleviated, and images can be compared according to features generated from a deep convolutional neural network. in this paper, we compare distance metrics ( and divergences ) to rank features generated from a neural network, for content - based image retrieval. specifically, after modelling individual images using approximations of mixture models or sparse covariance estimators, we resort to their information - theoretic and riemann geometric comparisons. we show that using approximations of mixture models enable us to compute a distance measure based on the wasserstein metric that requires less effort than other computationally intensive optimal transport plans ; finally, an affine invariant metric is used to compare the optimal transport metric to its riemann geometric counterpart – we conclude that although expensive, retrieval metric based on wasserstein geometry is more suitable than information theoretic comparison of images. in short, we combine gpu scalability in learning deep feature vectors with statistically efficient metrics that we foresee being utilised in a commercial setting. 1. introduction a common problem in computer vision lies in finding similarity between 2 ( or 3 ) - dimensional images ( or tensors ). this is attained by measuring distances between the two objects, primarily using normalised co - relation, euclidean distance, bhattacharyya distance, jensen - shannon divergence, amongst many others. the distances are measured after the images are encoded in some latent space wherein such a latent structure is learnt using a variety of classifiers – support vector machines ( svms ), logistic regression, etc. recently, due to the advantages of scalability, large - scale classifier frameworks based on deep - learning have been used for music recommendation [ 29 ], image recommendation [ 25 ] as well as general recommendation architectures. [ 5 ]. most of these frameworks do not take the underlying yq and bs contributed equally [SEP]
Text from DS:  arXiv:1702.06383v2 [cs.IR] 12 Nov 2017

Differential Geometric Retrieval of Deep Features
Y Qian and E Vazquez

B Sengupta

Cortexica Vision Systems Limited
30 Stamford Street SE1 9LQ
London, UK
yu.qian@cortexica.com

Cortexica Vision Systems Limited
Imperial College London
London, UK
b.sengupta@imperial.ac.uk

Abstract—Comparing images to recommend items from an
image-inventory is a subject of continued interest. Added with
the scalability of deep-learning architectures the once ‘manual’
job of hand-crafting features have been largely alleviated,
and images can be compared according to features generated
from a deep convolutional neural network. In this paper, we
compare distance metrics (and divergences) to rank features
generated from a neural network, for content-based image
retrieval. Specifically, after modelling individual images using
approximations of mixture models or sparse covariance estimators, we resort to their information-theoretic and Riemann
geometric comparisons. We 
Original label:  cs.SY
Predicted label:  5
Correct label:  8
Text:  [CLS] hamilton - jacobi reachability : a brief overview and recent advances arxiv : 1709. 07523v1 [ ] 21 sep 2017 somil bansal *, mo chen *, sylvia herbert * and claire j. tomlin abstract — hamilton - jacobi ( hj ) reachability analysis is an important formal verification method for guaranteeing performance and safety properties of dynamical systems ; it has been applied to many small - scale systems in the past decade. its advantages include compatibility with general nonlinear system dynamics, formal treatment of bounded disturbances, and the availability of well - developed numerical tools. the main challenge is addressing its exponential computational complexity with respect to the number of state variables. in this tutorial, we present an overview of basic hj reachability theory and provide instructions for using the most recent numerical tools, including an efficient gpu - parallelized implementation of a level set toolbox for computing reachable sets. in addition, we review some of the current work in high - dimensional hj reachability to show how the dimensionality challenge can be alleviated via various general theoretical and applicationspecific insights. i. i ntroduction as the systems we design grow more complex, determining whether they work according to specification becomes more difficult. consequently, verification and validation have received major attention in many fields of engineering. however, verification of systems is challenging for many reasons. first, all possible system behaviors must be accounted for. this makes most simulation - based approaches insufficient, and thus formal verification methods are needed. second, many practical systems are affected by disturbances in the environment, which can be unpredictable, and may even contain adversarial agents. in addition, these systems often have high dimensional state spaces and evolve in continuous time with complex, nonlinear dynamics. hamilton - jacobi ( hj ) reachability analysis is a verification method for guaranteeing performance and safety properties of systems, overcoming some of the above challenges. in reachability analysis, one computes the reach - avoid set, defined as the set of states from which the system can be driven to a target set while satisfying time - varying state constraints at all times. a major practical appeal of this approach stems from the availability of modern numerical tools, which can compute various definitions of reachable sets [ 1 ] – [ 4 ]. for example, these numerical tools have been successfully used to solve a variety of differential games, path planning * all authors contributed equally to this article. authors ’ names are written in the alphabetical order. all authors are with [SEP]
Text from DS:  Hamilton-Jacobi Reachability: A Brief Overview and Recent Advances

arXiv:1709.07523v1 [] 21 Sep 2017

Somil Bansal*, Mo Chen*, Sylvia Herbert* and Claire J. Tomlin

Abstract— Hamilton-Jacobi (HJ) reachability analysis is an
important formal verification method for guaranteeing performance and safety properties of dynamical systems; it has
been applied to many small-scale systems in the past decade.
Its advantages include compatibility with general nonlinear
system dynamics, formal treatment of bounded disturbances,
and the availability of well-developed numerical tools. The
main challenge is addressing its exponential computational
complexity with respect to the number of state variables. In this
tutorial, we present an overview of basic HJ reachability theory
and provide instructions for using the most recent numerical
tools, including an efficient GPU-parallelized implementation of
a Level Set Toolbox for computing reachable sets. In addition,
we review some of the current work in h
Original label:  cs.AI
Predicted label:  5
Correct label:  10
Text:  [CLS] distributed bayesian piecewise sparse linear models arxiv : 1711. 02368v1 [ ] 7 nov 2017 masato asahara nec system platform research laboratories masahara @ nec - labs. com abstract — the importance of interpretability of machine learning models has been increasing due to emerging enterprise predictive analytics, threat of data privacy, accountability of artificial intelligence in society, and so on. piecewise linear models have been actively studied to achieve both accuracy and interpretability. they often produce competitive accuracy against state - of - the - art non - linear methods. in addition, their representations ( i. e., rule - based segmentation plus sparse linear formula ) are often preferred by domain experts. a disadvantage of such models, however, is high computational cost for simultaneous determinations of the number of “ pieces ” and cardinality of each linear predictor, which has restricted their applicability to middle - scale data sets. this paper proposes a distributed factorized asymptotic bayesian ( fab ) inference of learning piece - wise sparse linear models on distributed memory architectures. the distributed fab inference solves the simultaneous model selection issue without communicating o ( n ) data where n is the number of training samples and achieves linear scale - out against the number of cpu cores. experimental results demonstrate that the distributed fab inference achieves high prediction accuracy and performance scalability with both synthetic and benchmark data. i. i ntroduction the importance of interpretability and transparency of machine learning models has been increasing due to emerging enterprise predictive analytics, threat of data privacy, accountability of artificial intelligence in society, and so on. in data mining and machine learning academic community, the workshop named fat / ml1 ( fairness, accountability and transparency in machine learning ) has been held every year since 2014. this momentum has grown by incorporating legal aspects of machine learning agents ( e. g., symposium on machine learning and the law in nips20162 ). from government point of view, european union enforces gdpr3 ( general data protection regulation ) which requires that the consequences of profiling ( i. e., how models profile individuals ) should be informed to the data subject. on the other hand, interpretable models restrict model representations, and the balance between interpretability and accuracy has been important research topics for decades [ 1 ]. piecewise linear models have been actively studied to achieve both accuracy and interpretability, which include from classical tree [ 2 ] or linear [ 3 ] ones to more advanced 1 [SEP]
Text from DS:  Distributed Bayesian Piecewise Sparse Linear Models

arXiv:1711.02368v1 [] 7 Nov 2017

Masato Asahara
NEC System Platform Research Laboratories
masahara@nec-labs.com

Abstract—The importance of interpretability of machine
learning models has been increasing due to emerging enterprise
predictive analytics, threat of data privacy, accountability of
artificial intelligence in society, and so on. Piecewise linear
models have been actively studied to achieve both accuracy
and interpretability. They often produce competitive accuracy
against state-of-the-art non-linear methods. In addition, their
representations (i.e., rule-based segmentation plus sparse linear
formula) are often preferred by domain experts. A disadvantage of such models, however, is high computational cost for
simultaneous determinations of the number of “pieces” and
cardinality of each linear predictor, which has restricted their
applicability to middle-scale data sets. This paper proposes
a distributed factorized asymptot
Original label:  cs.DS
Predicted label:  2
Correct label:  9
Text:  [CLS] arxiv : cs / 0612126v1 [ ] 22 dec 2006 the virtual reality framework for engineering objects petr r. ivankov, nikolay p. ivankov january 22, 2018 abstract a framework for virtual reality of engineering objects has been developed. this framework may simulate different equipment related to virtual reality. framework supports 6d dynamics, ordinary differential equations, finite formulas, vector and matrix operations. the framework also supports embedding of external software. 1 introduction problems of virtual reality are indissolubly connected wits other problems of science and engineering. the motion of objects in virtual reality is depended upon many different engineering related factors. more precise simulation we need, more factors should be taken into consideration. for instance, currents of artificial satellite equipment interact with magnetic field of the earth [ 1 ], so the field and currents should be simulated. then we recall that the satellite has a spin - stabilization system [ 2 ] and represent it too. if we concern with an aircraft, the influence of electromagnetic field of the earth becomes inessential, the motion is mostly depended on aerodynamics and engine ’ s control system behavior. going further, we can consider, that rockets, spacecrafts and aircrafts could are deformed, and thus elasticity should also be simulated [ 3 ] if we suppose the software to be useful for as wide circle of tasks as it possible, it should enable potential inclusion of simulation from different branches of science and engineering. is it possible? you can download and evaluate interdisciplinary software from following page http : / / www. genetibase. com / universal - engineering - framework - 7. php this reference also contains examples of applications of this code. 2 principles of the framework described framework is based on three main principles. first one is component approach. second principle is insertion of math formulas. third principle is openness of framework. so let us consider them. 1 2. 1 component approach the best method of complicated phenomenon grasping is decomposition. the best decomposition method is, in authors ’ opinion, a representation of the whole picture by objects and arrows, where latter reproduce interactions between objects. it is obvious for the reader aquainted with mathematics that the author of the project has been inspired by category theory [ 5 ]. furthermore, any object can belong to a set of domains. for example a source of physical field [ 6 ] has a geometric position. hence it is a subject of positioning domain. this object may be linked to other object of positioning domain by positioning links. if a source of a physical [SEP]
Text from DS:  arXiv:cs/0612126v1 [] 22 Dec 2006

The virtual reality framework for engineering
objects
Petr R. Ivankov, Nikolay P. Ivankov
January 22, 2018
Abstract
A framework for virtual reality of engineering objects has been developed. This framework may simulate different equipment related to
virtual reality. Framework supports 6D dynamics, ordinary differential
equations, finite formulas, vector and matrix operations. The framework
also supports embedding of external software.

1

Introduction

Problems of virtual reality are indissolubly connected wits other problems of
science and engineering. The motion of objects in virtual reality is depended
upon many different engineering related factors. More precise simulation we
need, more factors should be taken into consideration. For instance, currents
of artificial satellite equipment interact with magnetic field of the Earth [1], so
the field and currents should be simulated. Then we recall that the satellite
has a spin-stabilization system [2] 
Original label:  cs.PL
Predicted label:  2
Correct label:  6
Text:  [CLS] asymptotically mds array bp - xor codes suayb s. arslan arxiv : 1709. 07949v1 [ ] 22 sep 2017 department of computer engineering mef university maslak, istanbul 34099 email : arslans @ mef. edu. tr abstract — belief propagation or message passing on binary erasure channels ( bec ) is a low complexity decoding algorithm that allows the recovery of message symbols based on bipartite graph prunning process. recently, array xor codes have attracted attention for storage systems due to their burst error recovery performance and easy arithmetic based on exclusive or ( xor ) - only logic operations. array bp - xor codes are a subclass of array xor codes that can be decoded using bp under bec. requiring the capability of bp - decodability in addition to maximum distance separability ( mds ) constraint on the code construction process is observed to put an upper bound on the maximum achievable code block length, which leads to the code construction process to become a harder problem. in this study, we introduce asymptotically mds array bp - xor codes that are alternative to exact mds array bp - xor codes to pave the way for easier code constructions while keeping the decoding complexity low with an asymptotically vanishing coding overhead. we finally provide and analyze a simple code construction method that is based on discrete geometry to fulfill the requirements of the class of asymptotically mds array bpxor codes. i. i ntroduction array codes are linear codes defined for two dimensional data structures that are defined by both data and parity values organized in a matrix form. these codes are quite attractive candidates for burst error recovery in communication and distributed storage systems [ 1 ] and provide data reliability with optimal time / space consumption using maximum distance separability ( mds ) constraint in the code construction process. moreover, a great deal of work has been done and many improvements have been proposed for these codes over the years [ 2 ] to secure simpler math and low - complexity computations while still maintain the mds property. typically, any linear code can be represented using a bipartite graph either using the parity check matrix or the generator matrix of the code [ 3 ]. using the generator matrix representation, the corresponding bipartite graph has two types of nodes : nodes that are used to decode ( check or coded nodes ) and nodes that are deco [SEP]
Text from DS:  Asymptotically MDS Array BP-XOR Codes
Şuayb Ş. Arslan

arXiv:1709.07949v1 [] 22 Sep 2017

Department of Computer Engineering
MEF University
Maslak, Istanbul 34099
Email: arslans@mef.edu.tr

Abstract—Belief propagation or message passing on binary
erasure channels (BEC) is a low complexity decoding algorithm
that allows the recovery of message symbols based on bipartite
graph prunning process. Recently, array XOR codes have attracted attention for storage systems due to their burst error
recovery performance and easy arithmetic based on Exclusive
OR (XOR)-only logic operations. Array BP-XOR codes are a
subclass of array XOR codes that can be decoded using BP under
BEC. Requiring the capability of BP-decodability in addition
to Maximum Distance Separability (MDS) constraint on the
code construction process is observed to put an upper bound
on the maximum achievable code block length, which leads to
the code construction process to become a harder problem. In
this study, we introduce as
Original label:  cs.DS
Predicted label:  0
Correct label:  4
Text:  [CLS] arxiv : cs / 9903002v1 [ cs. se ] 1 mar 1999 an algebraic programming style for numerical software and its optimization t. b. dinesh magne haveraaen academic systems corporation university of bergen 444 castro street, mountain view, ca 94041, usa høyteknologisenteret, n - 5020 bergen, norway t dinesh @ academic. com magne. haveraaen @ ii. uib. no jan heering cwi p. o. box 94079, 1090 gb amsterdam, the netherlands jan. heering @ cwi. nl abstract the abstract mathematical theory of partial differential equations ( pdes ) is formulated in terms of manifolds, scalar fields, tensors, and the like, but these algebraic structures are hardly recognizable in actual pde solvers. the general aim of the sophus programming style is to bridge the gap between theory and practice in the domain of pde solvers. its main ingredients are a library of abstract datatypes corresponding to the algebraic structures used in the mathematical theory and an algebraic expression style similar to the expression style used in the mathematical theory. because of its emphasis on abstract datatypes, sophus is most naturally combined with object - oriented languages or other languages supporting abstract datatypes. the resulting source code patterns are beyond the scope of current compiler optimizations, but are sufficiently specific for a dedicated source - to - source optimizer. the limited, domain - specific, character of sophus is the key to success here. this kind of optimization has been tested on computationally intensive sophus style code with promising results. the general approach may be useful for other styles and in other application domains as well. 1991 computing reviews classification system : d. 1. 5, d. 2. 2, j. 2 keywords and phrases : coordinate - free numerics, object - oriented numerics, algebraic programming style, domain - specific programming style, optimization of numerical code note : submitted to scientific programming, special issue on coordinate - free numerics. this research was supported in part by the european union under esprit project 21871 ( saga — scientific computing and algebraic abstractions ), the netherlands organisation for scientific research ( nwo ) under the generic tools for program analysis and optimization project, and by a computing resources grant from the norwegian supercomputer committee. most of the work reported here was done while the first author was at cwi, amsterdam [SEP]
Text from DS:  arXiv:cs/9903002v1 [cs.SE] 1 Mar 1999

An Algebraic Programming Style for Numerical Software and its
Optimization
T.B. Dinesh

Magne Haveraaen

Academic Systems Corporation

University of Bergen

444 Castro Street, Mountain View, CA 94041, USA

Høyteknologisenteret, N-5020 Bergen, Norway

T Dinesh@academic.com

Magne.Haveraaen@ii.uib.no

Jan Heering
CWI
P.O. Box 94079, 1090 GB Amsterdam, The Netherlands
Jan.Heering@cwi.nl

ABSTRACT
The abstract mathematical theory of partial differential equations (PDEs) is formulated in terms of manifolds, scalar fields, tensors, and the like, but these algebraic structures are hardly recognizable in actual
PDE solvers. The general aim of the Sophus programming style is to bridge the gap between theory and
practice in the domain of PDE solvers. Its main ingredients are a library of abstract datatypes corresponding to the algebraic structures used in the mathematical theory and an algebraic expression style similar
to the expression style used in the m
Original label:  cs.CV
Predicted label:  9
Correct label:  2
Text:  [CLS] knowledge concentration : learning 100k object classifiers in a single cnn jiyang gao1 zijian ( james ) guo2 zhen li2 ram nevatia1 1 2 university of southern california google research arxiv : 1711. 07607v2 [ ] 23 nov 2017 jiyangga @ usc. edu, { guozj, zhenli } @ google. com, abstract nevatia @ usc. edu accuracy densenet resnet fine - grained image labels are desirable for many computer vision applications, such as visual search or mobile ai assistant. these applications rely on image classification models that can produce hundreds of thousands ( e. g. 100k ) of diversified fine - grained image labels on input images. however, training a network at this vocabulary scale is challenging, and suffers from intolerable large model size and slow training speed, which leads to unsatisfying classification performance. a straightforward solution would be training separate expert networks ( specialists ), with each specialist focusing on learning one specific vertical ( e. g. cars, birds... ). however, deploying dozens of expert networks in a practical system would significantly increase system complexity and inference latency, and consumes large amounts of computational resources. to address these challenges, we propose a knowledge concentration method, which effectively transfers the knowledge from dozens of specialists ( multiple teacher networks ) into one single model ( one student network ) to classify 100k object categories. there are three salient aspects in our method : ( 1 ) a multi - teacher single - student knowledge distillation framework ; ( 2 ) a self - paced learning mechanism to allow the student to learn from different teachers at various paces ; ( 3 ) structurally connected layers to expand the student network capacity with limited extra parameters. we validate our method on openimage and a newly collected dataset, entity - foto - tree ( eft ), with 100k categories, and show that the proposed model performs significantly better than the baseline generalist model.? inception - v2 vgg ( a ) alexnet pascalvoc imagenet jft - 300m eft 20 accuracy 1k 20k 100k? # class specialists ( b ) generalist 100m 2000m # params figure 1. ( a ) recent cnn architectures are designed and tested on 1000 - class imagenet dataset, what will happen when we apply them on much larger classification problems, e. g. 100k classes? ( b ) single generalist model ( single model handles [SEP]
Text from DS:  Knowledge Concentration: Learning 100K Object Classifiers in a Single CNN
Jiyang Gao1 Zijian (James) Guo2 Zhen Li2 Ram Nevatia1
1
2
University of Southern California
Google Research

arXiv:1711.07607v2 [] 23 Nov 2017

jiyangga@usc.edu, {guozj, zhenli}@google.com,

Abstract

nevatia@usc.edu

Accuracy
DenseNet
ResNet

Fine-grained image labels are desirable for many computer vision applications, such as visual search or mobile AI assistant. These applications rely on image classification models that can produce hundreds of thousands
(e.g. 100K) of diversified fine-grained image labels on input images. However, training a network at this vocabulary scale is challenging, and suffers from intolerable large
model size and slow training speed, which leads to unsatisfying classification performance. A straightforward solution would be training separate expert networks (specialists), with each specialist focusing on learning one specific
vertical (e.g. cars, birds...). However, deploying dozens
Original label:  cs.NE
Predicted label:  10
Correct label:  7
Text:  [CLS] biologically inspired feedforward supervised learning for deep self - organizing map networks arxiv : 1710. 09574v1 [ stat. ml ] 26 oct 2017 takashi shinozaki1, 2 1 2 cinet, national institute of information and communications technology 1 - 4 yamadaoka, suita, osaka 565 - 0871, japan, graduate school of information science and technology, osaka university 1 - 5 yamadaoka, suita, osaka 565 - 0871, japan, tshino @ nict. go. jp abstract. in this study, we propose a novel deep neural network and its supervised learning method that uses a feedforward supervisory signal. the method is inspired by the human visual system and performs human - like association - based learning without any backward error propagation. the feedforward supervisory signal that produces the correct result is preceded by the target signal and associates its confirmed label with the classification result of the target signal. it effectively uses a large amount of information from the feedforward signal, and forms a continuous and rich learning representation. the method is validated using visual recognition tasks on the mnist handwritten dataset. keywords : supervised learning, deep learning, self - organizing map 1 introduction a multilayered deep neural network is one of the most powerful methods for human - like recognition tasks, such as image [ 1 ] and speech recognition [ 2 ]. some previous studies have demonstrated great performance for supervised learning in signal classification tasks [ 3, 4 ]. gradient - based learning rules, in particular, back - propagation ( bp ) learning [ 5 ], are generally used for supervised learning in feedforward type networks. however, the amount of supervisory information in the last layer is not sufficient to supervise the entire deep neural network because the information is selected and reduced from layer to layer. this tendency is more serious in pattern discrimination tasks because the amount of information is extremely limited to the discrete values of the discriminant label output. bengio et al. proposed a stacked auto - encoder to ensure the amount of information from error signals by reconstructing the input and using layer - wise learning [ 6 ]. however, layer - wise learning requires step - by - step learning, which results in difficulties in incremental learning and online updating. some previous studies have used unsupervised learning that does not use the prior information of the data structure, and reported self - organizing behavior and good discrimination results in a very deep neural network [ 1 [SEP]
Text from DS:  Biologically Inspired
Feedforward Supervised Learning
for Deep Self-Organizing Map Networks

arXiv:1710.09574v1 [stat.ML] 26 Oct 2017

Takashi Shinozaki1,2
1

2

CiNet, National Institute of Information and Communications Technology
1-4 Yamadaoka, Suita, Osaka 565-0871, Japan,
Graduate School of Information Science and Technology, Osaka University
1-5 Yamadaoka, Suita, Osaka 565-0871, Japan,
tshino@nict.go.jp

Abstract. In this study, we propose a novel deep neural network and
its supervised learning method that uses a feedforward supervisory signal. The method is inspired by the human visual system and performs
human-like association-based learning without any backward error propagation. The feedforward supervisory signal that produces the correct
result is preceded by the target signal and associates its confirmed label with the classification result of the target signal. It effectively uses
a large amount of information from the feedforward signal, and forms
a continuous and rich le
Original label:  cs.NE
Predicted label:  5
Correct label:  9
Text:  [CLS] delta networks for optimized recurrent network computation daniel neil1, jun haeng lee1, 2, tobi delbruck1, shih - chii liu1 1 arxiv : 1612. 05571v1 [ ] 16 dec 2016 2 institute of neuroinformatics, uzh and eth zurich, zurich, switzerland samsung advanced institute of technology, samsung electronics, suwon - si, republic of korea email : daniel. l. neil @ ini. ethz. ch, junhaeng. lee @ gmail. com, tobi @ ini. ethz. ch, shih @ ini. ethz. ch abstract — many neural networks exhibit stability in their activation patterns over time in response to inputs from sensors operating under real - world conditions. by capitalizing on this property of natural signals, we propose a recurrent neural network ( rnn ) architecture called a delta network in which each neuron transmits its value only when the change in its activation exceeds a threshold. the execution of rnns as delta networks is attractive because their states must be stored and fetched at every timestep, unlike in convolutional neural networks ( cnns ). we show that a naive run - time delta network implementation offers modest improvements on the number of memory accesses and computes, but optimized training techniques confer higher accuracy at higher speedup. with these optimizations, we demonstrate a 9x reduction in cost with negligible loss of accuracy for the tidigits audio digit recognition benchmark. similarly, on the large wall street journal speech recognition benchmark even existing networks can be greatly accelerated as delta networks, and a 5. 7x improvement with negligible loss of accuracy can be obtained through training. finally, on an end - to - end cnn trained for steering angle prediction in a driving dataset, the rnn cost can be reduced by a substantial 100x. keywords — recurrent neural networks, low - precision networks, delta networks. i. i ntroduction and m otivation recurrent neural networks ( rnns ) have achieved tremendous progress in recent years, with the increased availability of large datasets, more powerful computer resources such as gpus, and improvements in their training algorithms. these combined factors have enabled breakthroughs in the use of rnns for processing of temporal sequences. applications such as natural language processing [ 1 ], speech recognition [ 2 ], [ 3 ], and attention - [SEP]
Text from DS:  Delta Networks for Optimized Recurrent Network
Computation
Daniel Neil1 , Jun Haeng Lee1,2 , Tobi Delbruck1 , Shih-Chii Liu1
1

arXiv:1612.05571v1 [] 16 Dec 2016

2

Institute of Neuroinformatics, UZH and ETH Zurich, Zurich, Switzerland
Samsung Advanced Institute of Technology, Samsung Electronics, Suwon-Si, Republic of Korea
Email: daniel.l.neil@ini.ethz.ch, junhaeng.lee@gmail.com, tobi@ini.ethz.ch, shih@ini.ethz.ch

Abstract—Many neural networks exhibit stability in their
activation patterns over time in response to inputs from sensors
operating under real-world conditions. By capitalizing on this
property of natural signals, we propose a Recurrent Neural
Network (RNN) architecture called a delta network in which each
neuron transmits its value only when the change in its activation
exceeds a threshold. The execution of RNNs as delta networks
is attractive because their states must be stored and fetched at
every timestep, unlike in convolutional neural networks (CNNs).
We show that a
Original label:  cs.SY
Predicted label:  1
Correct label:  2
Text:  [CLS] ieee transactions on smart grid 1 robust worst - case analysis of demand - side management in smart grids arxiv : 1604. 07576v2 [ math. oc ] 5 may 2016 javier zazo, member, ieee, santiago zazo, member, ieee, and sergio valcarcel macua, student member, ieee abstract — demand - side management presents significant benefits in reducing the energy load in smart grids by balancing consumption demands or including energy generation and / or storage devices in the user ’ s side. these techniques coordinate the energy load so that users minimize their monetary expenditure. however, these methods require accurate predictions in the energy consumption profiles, which make them inflexible to real demand variations. in this paper we propose a realistic model that accounts for uncertainty in these variations and calculates a robust price for all users in the smart grid. we analyze the existence of solutions for this novel scenario, propose convergent distributed algorithms to find them, and perform simulations considering energy expenditure. we show that this model can effectively reduce the monetary expenses for all users in a realtime market, while at the same time it provides a reliable production cost estimate to the energy supplier. index terms — load management, robust analysis, non - convex optimization, distributed algorithms, game theory i. i ntroduction mart grids represent the concept behind the intended evolution of the electric grid, which through information acquisition from the end users will allow for more efficient energy distribution, flexibility in network topology, adaptive load management and better integration of renewable energy plants with the consumption requirements of the users. one important concept to achieve the smart grid ’ s objectives is the demand - side management, which includes the techniques for better energy efficiency programs, distributed energy generation, energy storage and load management. the model presented in this work establishes a robust energy price one day ahead, which takes into account the production costs of energy as well as uncertainties in the expected energy loads. we also consider a real - time market, where users are charged their specific demanded energy at the robust price, permitting some deviation without any extra penalty. this model provides some flexibility to every user in their realtime consumption energy loads and calculates the energy prices in a conservative manner, taking into account production costs and possible errors. in particular, we focus on a robust analysis of the demand - side management algorithms, where the energy strategies account for worst - case error deviations s all authors are affiliated with the universidad politecnica de madrid, in av. complutense 30, madrid, [SEP]
Text from DS:  IEEE TRANSACTIONS ON SMART GRID

1

Robust Worst-Case Analysis of Demand-Side
Management in Smart Grids

arXiv:1604.07576v2 [math.OC] 5 May 2016

Javier Zazo, Member, IEEE, Santiago Zazo, Member, IEEE, and Sergio Valcarcel Macua, Student Member, IEEE

Abstract—Demand-side management presents significant benefits in reducing the energy load in smart grids by balancing
consumption demands or including energy generation and/or
storage devices in the user’s side. These techniques coordinate the
energy load so that users minimize their monetary expenditure.
However, these methods require accurate predictions in the
energy consumption profiles, which make them inflexible to real
demand variations. In this paper we propose a realistic model
that accounts for uncertainty in these variations and calculates
a robust price for all users in the smart grid. We analyze the
existence of solutions for this novel scenario, propose convergent
distributed algorithms to find them, and perform simulations

Original label:  math.AC
Predicted label:  1
Correct label:  9
Text:  [CLS] arxiv : 1212. 1841v2 [ math. ag ] 25 jan 2013 twenty points in p3 david eisenbud, robin hartshorne, and frank - olaf schreyer ∗ abstract using the possibility of computationally determining points on a finite cover of a unirational variety over a finite field, we determine all possibilities for direct gorenstein linkages between general sets of points in p3 over an algebraically closed field of characteristic 0. as a consequence we show that a general set of d points is glicci ( that is, in the gorenstein linkage class of a complete intersection ) if d ≤ 33 or d = 37, 38. computer algebra plays an essential role in the proof. the case of 20 points had been an outstanding problem in the area for a dozen years [ 8 ]. introduction the theory of liaison ( linkage ) is a powerful tool in the theory of curves in p3 with applications, for example, to the question of the unirationality of the moduli spaces of curves ( for example [ 3, 30, 27 ]. one says that two curves c, d ⊂ p3 ( say, reduced and without common components ) are directly linked if their union is a complete intersection, and evenly linked if there is a chain of curves c = c0, c1,..., c2m = d such that ci is directly linked to ci + 1 for all i. the first step in theory is the result of gaeta that any two arithmetically cohen - macaulay curves are evenly linked, and in particular are in the linkage class of a complete intersection, usually written licci. much later rao ( [ 24 ] ) showed that even linkage classes are in bijection with graded modules of finite length up to shift, leading to an avalanche of results ( reported, for example in [ 21 ] and [ 20 ] ). however, in ∗ this paper reports on work done during the commutative algebra program, 2012 - 13, at msri. we are grateful to msri for providing such an exciting environment, where a chance meeting led to the progress described here. the first author is also grateful to the national science foundation for partial support during this period. 1 codimension > 2 linkage yields an equivalence relation that seems to be very fine, and thus not so useful ; for example the scheme consisting of the 4 coordinate points in p3 is not licci. a fundamental paper of peskine and szpi [SEP]
Text from DS:  arXiv:1212.1841v2 [math.AG] 25 Jan 2013

Twenty Points in P3
David Eisenbud, Robin Hartshorne, and Frank-Olaf Schreyer ∗

Abstract
Using the possibility of computationally determining points on a finite
cover of a unirational variety over a finite field, we determine all possibilities
for direct Gorenstein linkages between general sets of points in P3 over an
algebraically closed field of characteristic 0. As a consequence we show that
a general set of d points is glicci (that is, in the Gorenstein linkage class of
a complete intersection) if d ≤ 33 or d = 37, 38. Computer algebra plays
an essential role in the proof. The case of 20 points had been an outstanding
problem in the area for a dozen years [8].

Introduction
The theory of liaison (linkage) is a powerful tool in the theory of curves in P3
with applications, for example, to the question of the unirationality of the moduli
spaces of curves (for example [3, 30, 27]. One says that two curves C, D ⊂ P3
(say, reduced and without co
Original label:  cs.AI
Predicted label:  9
Correct label:  5
Text:  [CLS] arxiv : 1709. 01215v2 [ stat. ml ] 5 nov 2017 alice : towards understanding adversarial learning for joint distribution matching chunyuan li1, hao liu2, changyou chen3, yunchen pu1, liqun chen1, ricardo henao1 and lawrence carin1 1 duke university 2 nanjing university 3 university at buffalo cl319 @ duke. edu abstract we investigate the non - identifiability issues associated with bidirectional adversarial training for joint distribution matching. within a framework of conditional entropy, we propose both adversarial and non - adversarial approaches to learn desirable matched joint distributions for unsupervised and supervised tasks. we unify a broad family of adversarial models as joint distribution matching problems. our approach stabilizes learning of unsupervised bidirectional adversarial learning methods. further, we introduce an extension for semi - supervised learning tasks. theoretical results are validated in synthetic data and real - world applications. 1 introduction deep directed generative models are a powerful framework for modeling complex data distributions. generative adversarial networks ( gans ) [ 1 ] can implicitly learn the data generating distribution ; more specifically, gan can learn to sample from it. in order to do this, gan trains a generator to mimic real samples, by learning a mapping from a latent space ( where the samples are easily drawn ) to the data space. concurrently, a discriminator is trained to distinguish between generated and real samples. the key idea behind gan is that if the discriminator finds it difficult to distinguish real from artificial samples, then the generator is likely to be a good approximation to the true data distribution. in its standard form, gan only yields a one - way mapping, i. e., it lacks an inverse mapping mechanism ( from data to latent space ), preventing gan from being able to do inference. the ability to compute a posterior distribution of the latent variable conditioned on a given observation may be important for data interpretation and for downstream applications ( e. g., classification from the latent variable ) [ 2, 3, 4, 5, 6, 7 ]. efforts have been made to simultaneously learn an efficient bidirectional model that can produce high - quality samples for both the latent and data spaces [ 3, 4, 8, 9, 10, 11 ]. among them, the recently proposed adversarially [SEP]
Text from DS:  arXiv:1709.01215v2 [stat.ML] 5 Nov 2017

ALICE: Towards Understanding Adversarial
Learning for Joint Distribution Matching

Chunyuan Li1 , Hao Liu2 , Changyou Chen3 , Yunchen Pu1 , Liqun Chen1 ,
Ricardo Henao1 and Lawrence Carin1
1
Duke University 2 Nanjing University 3 University at Buffalo
cl319@duke.edu

Abstract
We investigate the non-identifiability issues associated with bidirectional adversarial training for joint distribution matching. Within a framework of conditional
entropy, we propose both adversarial and non-adversarial approaches to learn
desirable matched joint distributions for unsupervised and supervised tasks. We
unify a broad family of adversarial models as joint distribution matching problems.
Our approach stabilizes learning of unsupervised bidirectional adversarial learning
methods. Further, we introduce an extension for semi-supervised learning tasks.
Theoretical results are validated in synthetic data and real-world applications.

1

Introduction

Deep directed 
Original label:  cs.AI
Predicted label:  5
Correct label:  3
Text:  [CLS] arxiv : 1711. 03467v1 [ ] 9 nov 2017 worm - level control through search - based reinforcement learning mathias lechner∗ tu wien austria radu grosu tu wien austria ramin m. hasani tu wien austria abstract through natural evolution, nervous systems of organisms formed near - optimal structures to express behavior. here, we propose an effective way to create control agents, by re - purposing the function of biological neural circuit models, to govern similar real world applications. we model the tap - withdrawal ( tw ) neural circuit of the nematode, c. elegans, a circuit responsible for the worm ’ s reflexive response to external mechanical touch stimulations, and learn its synaptic and neural parameters as a policy for controlling the inverted pendulum problem. for reconfiguration of the purpose of the tw neural circuit, we manipulate a search - based reinforcement learning. we show that our neural policy performs as good as existing traditional control theory and machine learning approaches. a video demonstration of the performance of our method can be accessed at https : / / youtu. be / o - ia5ivyff8. introduction the nervous system of the soil - worm, c. elegans, has entirely been mapped, demonstrating a nearoptimal wiring structure [ 13 ]. an adult hermaphrodite ’ s brain is composed of 302 neurons hard - wired by around 8000 chemical and electrical synapses [ 2 ]. function of many neural circuits within its brain has been identified [ 14, 1, 4, 6 ]. in particular, a neural circuit which is responsible for inducing a forward / backward locomotion reflex when the worm is mechanically exposed to touch stimulus on its body, has been well - characterized [ 1 ] ( see fig. 1a for an illustration of this reflex ). synaptic polarities of the circuit have then been predicted, suggesting that the circuit realizes a competitive behavior between forward and backward reflexes, in presence of touch stimulations [ 14, 15 ]. behavior of the tap - withdrawal ( tw ) reflexive response is substantially similar to the impulse response of a controller operating on an inverted pendulum [ 9 ] dynamic system, as illustrated in fig. 1a and 1b. we thought of taking advantage of such similarity and reconfigure the synaptic and neural parameters of a deterministic model of the tw neural circuit, to control the inverted pendulum within the openai ’ s roboschool environment [ [SEP]
Text from DS:  arXiv:1711.03467v1 [] 9 Nov 2017

Worm-level Control through Search-based
Reinforcement Learning
Mathias Lechner∗
TU Wien
Austria

Radu Grosu
TU Wien
Austria

Ramin M. Hasani
TU Wien
Austria

Abstract
Through natural evolution, nervous systems of organisms formed near-optimal
structures to express behavior. Here, we propose an effective way to create control agents, by re-purposing the function of biological neural circuit models, to
govern similar real world applications. We model the tap-withdrawal (TW) neural
circuit of the nematode, C. elegans, a circuit responsible for the worm’s reflexive response to external mechanical touch stimulations, and learn its synaptic
and neural parameters as a policy for controlling the inverted pendulum problem.
For reconfiguration of the purpose of the TW neural circuit, we manipulate a
search-based reinforcement learning. We show that our neural policy performs
as good as existing traditional control theory and machine learning approaches.
A video 
Original label:  cs.DS
Predicted label:  8
Correct label:  5
Text:  [CLS] pectoral muscles suppression in digital mammograms using hybridization of soft computing methods i. laurence aroquiaraj and k. thangavel abstract — breast region segmentation is an essential prerequisite in computerized analysis of mammograms. it aims at separating the breast tissue from the background of the mammogram and it includes two independent segmentations. the first segments the background region which usually contains annotations, labels and frames from the whole breast region, while the second removes the pectoral muscle portion ( present in medio lateral oblique ( mlo ) views ) from the rest of the breast tissue. in this paper we propose hybridization of connected component labeling ( ccl ), fuzzy, and straight line methods. our proposed methods worked good for separating pectoral region. after removal pectoral muscle from the mammogram, further processing is confined to the breast region alone. to demonstrate the validity of our segmentation algorithm, it is extensively tested using over 322 mammographic images from the mammographic image analysis society ( mias ) database. the segmentation results were evaluated using a mean absolute error ( mae ), hausdroff distance ( hd ), probabilistic rand index ( pri ), local consistency error ( lce ) and tanimoto coefficient ( tc ). the hybridization of fuzzy with straight line method is given more than 96 % of the curve segmentations to be adequate or better. in addition a comparison with similar approaches from the state of the art has been given, obtaining slightly improved results. experimental results demonstrate the effectiveness of the proposed approach. keywords — x - ray mammography, ccl, fuzzy, straight line. i. introduction b reast cancer is the most common of all cancers and is the leading cause of cancer deaths in women worldwide, accounting for more than 1. 6 % of deaths and case fatality rates are highest in low - resource countries. a recent study of breast cancer risk in india revealed that 1 in 28 women develop breast cancer during her lifetime. this is higher in urban areas being 1 in 22 in a lifetime compared to rural areas where this risk is relatively much lower being 1 in 60 women developing breast cancer in their lifetime. in india the average age of the high risk group in india is 43 - 46 years unlike in the west where women aged 53 - 57 years are more prone to breast cancer. as there is no effective method for its prevention, the diagnosis of breast cancer in [SEP]
Text from DS:  Pectoral Muscles Suppression in Digital
Mammograms using Hybridization of Soft
Computing Methods
I. Laurence Aroquiaraj and K. Thangavel


Abstract— Breast region segmentation is an essential prerequisite
in computerized analysis of mammograms. It aims at separating the
breast tissue from the background of the mammogram and it includes
two independent segmentations. The first segments the background
region which usually contains annotations, labels and frames from
the whole breast region, while the second removes the pectoral
muscle portion (present in Medio Lateral Oblique (MLO) views)
from the rest of the breast tissue. In this paper we propose
hybridization of Connected Component Labeling (CCL), Fuzzy, and
Straight line methods. Our proposed methods worked good for
separating pectoral region. After removal pectoral muscle from the
mammogram, further processing is confined to the breast region
alone. To demonstrate the validity of our segmentation algorithm, it
is extensively tested
Original label:  cs.CV
Predicted label:  8
Correct label:  10
Text:  [CLS] journal of latex class files, vol. 14, no. 8, august 2015 1 unsupervised end - to - end learning for deformable medical image registration arxiv : 1711. 08608v2 [ ] 20 jan 2018 siyuan shan, wen yan, xiaoqing guo, eric i - chao chang, yubo fan and yan xu * abstract — we propose a registration algorithm for 2d ct / mri medical images with a new unsupervised end - to - end strategy using convolutional neural networks. the contributions of our algorithm are threefold : ( 1 ) we transplant traditional image registration algorithms to an end - to - end convolutional neural network framework, while maintaining the unsupervised nature of image registration problems. the image - to - image integrated framework can simultaneously learn both image features and transformation matrix for registration. ( 2 ) training with additional data without any label can further improve the registration performance by approximately 10 %. ( 3 ) the registration speed is 100x faster than traditional methods. the proposed network is easy to implement and can be trained efficiently. experiments demonstrate that our system achieves state - of - the - art results on 2d brain registration and achieves comparable results on 2d liver registration. it can be extended to register other organs beyond liver and brain such as kidney, lung, and heart. index terms — image registration, unsupervised, convolutional networks, end - to - end, image - to - image i. i ntroduction m edical image registration plays an important role in medical image processing and analysis. as far as brain registration is concerned, accurate alignment of the brain boundary and corresponding structures inside the brain such as hippocampus is crucial for monitoring brain cancer development. as illustrated in figure 1, image registration refers to the process of revealing the spatial correspondence between two images. several image registration toolkits such as itk [ 1 ], ants [ 2 ] and elastix [ 3 ] have been developed to facilitate research reproduction. a wide variety of medical registration algorithms have been developed in the past [ 4 ], [ 5 ], [ 6 ], [ 3 ], [ 7 ], [ 8 ], focusing primarily on unsupervised methods. these algorithms select a transformation model, define a metric that measures the this work is supported by microsoft research under the ehealth program, the national natural science foundation in china under grant 81771910, the [SEP]
Text from DS:  JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

1

Unsupervised End-to-end Learning
for Deformable Medical Image Registration

arXiv:1711.08608v2 [] 20 Jan 2018

Siyuan Shan, Wen Yan, Xiaoqing Guo, Eric I-Chao Chang, Yubo Fan and Yan Xu*

Abstract—We propose a registration algorithm for 2D CT/MRI
medical images with a new unsupervised end-to-end strategy
using convolutional neural networks. The contributions of our
algorithm are threefold: (1) We transplant traditional image
registration algorithms to an end-to-end convolutional neural
network framework, while maintaining the unsupervised nature
of image registration problems. The image-to-image integrated
framework can simultaneously learn both image features and
transformation matrix for registration. (2) Training with additional data without any label can further improve the registration
performance by approximately 10%. (3) The registration speed
is 100x faster than traditional methods. The proposed network
is easy to im
Original label:  cs.AI
Predicted label:  8
Correct label:  9
Text:  [CLS] data set operations to hide decision tree rules dimitris kalles1 and vassilios s. verykios1 and georgios feretzakis1 and athanasios papagelis2 abstract. 1this paper focuses on preserving the privacy of sensitive patterns when inducing decision trees. we adopt a record augmentation approach for hiding sensitive classification rules in binary datasets. such a hiding methodology is preferred over other heuristic solutions like output perturbation or cryptographic techniques - which restrict the usability of the data - since the raw data itself is readily available for public use. we show some key lemmas which are related to the hiding process and we also demonstrate the methodology with an example and an indicative experiment using a prototype hiding tool. 1 introduction privacy preserving data mining [ 1 ] is a quite recent research area trying to alleviate the problems stemming from the use of data mining algorithms to the privacy of the data subjects recorded in the data and the information or knowledge hidden in these piles of data. agrawal and srinkant [ 2 ] were the first to consider the induction of decision trees from anonymized data, which had been adequately corrupted with noise to survive from privacy attacks. the generic strand of knowledge hiding research [ 3 ] has led to specific algorithms for hiding classification rules, like, for example, noise addition by a data swapping process [ 4 ]. a key target area concerns individual data privacy and aims to protect the individual integrity of database records to prevent the reidentification of individuals or characteristic groups of people from data inference attacks. another key area is sensitive rule hiding, the subject of this paper, which deals with the protection of sensitive patterns that arise from the application of data mining techniques. of course, all privacy preservation techniques strive to maintain data information quality. the main representative of statistical approaches [ 5 ] adopts a parsimonious downgrading technique to determine whether the loss of functionality associated with not downgrading the data, is worth the extra confidentiality. reconstruction techniques involve the redesign of the public dataset [ 6 ] [ 7 ] from the non - sensitive rules produced by algorithms like c4. 5 [ 8 ] and ripper [ 9 ]. perturbation based techniques involve the modification of transactions to support only non - sensitive rules [ 10 ], the removal of tuples associated with sensitive rules [ 11 ], the suppression of certain attribute values [ 12 ] and the redistribution of tuples supporting sensitive patterns so as to maintain the ordering of the rules [ 13 [SEP]
Text from DS:  Data set operations to hide decision tree rules
Dimitris Kalles1 and Vassilios S. Verykios1 and Georgios Feretzakis1 and Athanasios Papagelis2
Abstract.1This paper focuses on preserving the privacy of sensitive
patterns when inducing decision trees. We adopt a record
augmentation approach for hiding sensitive classification rules in
binary datasets. Such a hiding methodology is preferred over other
heuristic solutions like output perturbation or cryptographic
techniques - which restrict the usability of the data - since the raw
data itself is readily available for public use. We show some key
lemmas which are related to the hiding process and we also
demonstrate the methodology with an example and an indicative
experiment using a prototype hiding tool.

1

INTRODUCTION

Privacy preserving data mining [1] is a quite recent research area
trying to alleviate the problems stemming from the use of data
mining algorithms to the privacy of the data subjects recorded in the
data and the inform
Original label:  cs.NE
Predicted label:  10
Correct label:  8
Text:  [CLS] metaheuristic design of feedforward neural networks : a review of two decades of research varun kumar ojha∗1, ajith abraham2, and vaclav snasel1 arxiv : 1705. 05584v1 [ ] 16 may 2017 1 dept. of computer science, vsb - technical university of ostrava, ostrava, czech republic 2 machine intelligence research labs ( mir labs ), auburn, wa, usa abstract over the past two decades, the feedforward neural network ( fnn ) optimization has been a key interest among the researchers and practitioners of multiple disciplines. the fnn optimization is often viewed from the various perspectives : the optimization of weights, network architecture, activation nodes, learning parameters, learning environment, etc. researchers adopted such different viewpoints mainly to improve the fnn ’ s generalization ability. the gradient - descent algorithm such as backpropagation has been widely applied to optimize the fnns. its success is evident from the fnn ’ s application to numerous real - world problems. however, due to the limitations of the gradient - based optimization methods, the metaheuristic algorithms including the evolutionary algorithms, swarm intelligence, etc., are still being widely explored by the researchers aiming to obtain generalized fnn for a given problem. this article attempts to summarize a broad spectrum of fnn optimization methodologies including conventional and metaheuristic approaches. this article also tries to connect various research directions emerged out of the fnn optimization practices, such as evolving neural network ( nn ), cooperative coevolution nn, complex - valued nn, deep learning, extreme learning machine, quantum nn, etc. additionally, it provides interesting research challenges for future research to cope - up with the present information processing era. keywords : feedforward neural network ; metaheuristics ; nature - inspired algorithms ; multiobjective ; ensemble. ∗ corresponding author engineering applications of artificial intelligence 60 ( 2017 ) 97 – 116 1 1 introduction back in 1943 mcculloch and pitts [ 1 ] proposed a computational model inspired by the human brain, which initiated the research on artificial neural network ( ann ). anns are capable of learning and recognizing and can solve a broad range of complex problems. feedforward neural networks ( fnns ) are the special type of ann models. the structural representation of an fnn makes it appealing because it allows perceiving a computational model ( a function ) in a structural [SEP]
Text from DS:  Metaheuristic Design of Feedforward Neural Networks: A
Review of Two Decades of Research
Varun Kumar Ojha∗1 , Ajith Abraham2 , and Václav Snášel1

arXiv:1705.05584v1 [] 16 May 2017

1 Dept.

of Computer Science, VŠB-Technical University of Ostrava, Ostrava, Czech Republic
2 Machine Intelligence Research Labs (MIR Labs), Auburn, WA, USA

Abstract
Over the past two decades, the feedforward neural network (FNN) optimization has
been a key interest among the researchers and practitioners of multiple disciplines. The
FNN optimization is often viewed from the various perspectives: the optimization of
weights, network architecture, activation nodes, learning parameters, learning environment, etc. Researchers adopted such different viewpoints mainly to improve the FNN’s
generalization ability. The gradient-descent algorithm such as backpropagation has been
widely applied to optimize the FNNs. Its success is evident from the FNN’s application to
numerous real-world problems. However, due to
Original label:  cs.NE
Predicted label:  2
Correct label:  5
Text:  [CLS] evolutionary robotics on the web with webgl and javascript jared m. moore, anthony j. clark and philip k. mckinley arxiv : 1406. 3337v3 [ ] 11 jul 2014 dept. of computer science and engineering michigan state university, east lansing, mi, usa 48824 moore112 @ msu. edu introduction. web - based applications are highly accessible to users, providing rich, interactive content while eliminating the need to install software locally. previous online evolutionary demonstrations ( picbreeder [ secretan et al., 2008 ], endless forms [ clune and lipson, 2011 ], ludobots [ bongard et al., 2012 ], and boxcar2d ) have successfully demonstrated concepts to a broad audience. however, evolutionary robotics ( er ) has faced challenges in this domain as web - based technologies have not been amenable to 3d physics simulations. traditionally, physics - based simulations require a local installation and a high degree of user knowledge to configure an environment, but the emergence of javascript - based physics engines enables complex simulations to be executed in web browsers. these developments create opportunities for er research to reach new audiences by increasing accessibility. in this work, we introduce two web - based tools we have built to facilitate the exchange of ideas with other researchers as well as outreach to k - 12 students and the general public. the first tool is intended to distribute and exchange er research results, while the second is a completely browser - based implementation of an er environment. we use webgl [ group, 2014 ], threejs [ cabello et al., 2014 ], and physijs [ prall, 2014 ] to build online er applications. webgl - based visualizer. visualization is a powerful means to communicate concepts and discoveries. many researchers in er and artificial life produce videos of simulations to disseminate results from their research. however, videos are usually limited to what the author selects through specific angles or edits. our first tool is a webglbased visualization system that provides more capability to the viewers. rather than passively watching a video, viewers can interact with the results, exploring from new angles and focal points. a demonstration of this work can be seen at : http : / / jaredmmoore. com / webgl _ visualizer / visualizer. html. in addition to enhanced interaction with results, the webgl - based visualizer decouples the physics engine and visualization. researchers often employ different [SEP]
Text from DS:  Evolutionary Robotics on the Web with WebGL and Javascript
Jared M. Moore, Anthony J. Clark and Philip K. McKinley

arXiv:1406.3337v3 [] 11 Jul 2014

Dept. of Computer Science and Engineering
Michigan State University, East Lansing, MI, USA 48824
moore112@msu.edu

Introduction. Web-based applications are highly accessible to users, providing rich, interactive content while
eliminating the need to install software locally. Previous
online evolutionary demonstrations (PicBreeder [Secretan
et al., 2008], Endless Forms [Clune and Lipson, 2011], Ludobots [Bongard et al., 2012], and BoxCar2D) have successfully demonstrated concepts to a broad audience. However,
evolutionary robotics (ER) has faced challenges in this domain as web-based technologies have not been amenable to
3D physics simulations. Traditionally, physics-based simulations require a local installation and a high degree of user
knowledge to configure an environment, but the emergence
of Javascript-based physics engines enables 
Original label:  cs.NE
Predicted label:  9
Correct label:  2
Text:  [CLS] published as a conference paper at iclr 2018 d eep r ewiring : t raining very sparse deep networks arxiv : 1711. 05136v4 [ ] 5 feb 2018 guillaume bellec, david kappel, wolfgang maass & robert legenstein institute for theoretical computer science graz university of technology austria { bellec, kappel, maass, legenstein } @ igi. tugraz. at a bstract neuromorphic hardware tends to pose limits on the connectivity of deep networks that one can run on them. but also generic hardware and software implementations of deep learning run more efficiently for sparse networks. several methods exist for pruning connections of a neural network after it was trained without connectivity constraints. we present an algorithm, deep r, that enables us to train directly a sparsely connected neural network. deep r automatically rewires the network during supervised training so that connections are there where they are most needed for the task, while its total number is all the time strictly bounded. we demonstrate that deep r can be used to train very sparse feedforward and recurrent neural networks on standard benchmark tasks with just a minor loss in performance. deep r is based on a rigorous theoretical foundation that views rewiring as stochastic sampling of network configurations from a posterior. 1 i ntroduction network connectivity is one of the main determinants for whether a neural network can be efficiently implemented in hardware or simulated in software. for example, it is mentioned in jouppi et al. ( 2017 ) that in google ’ s tensor processing units ( tpus ), weights do not normally fit in on - chip memory for neural network applications despite the small 8 bit weight precision on tpus. memory is also the bottleneck in terms of energy consumption in tpus and fpgas ( han et al., 2017 ; iandola et al., 2016 ). for example, for an implementation of a long short term memory network ( lstm ), memory reference consumes more than two orders of magnitude more energy than alu operations ( han et al., 2017 ). the situation is even more critical in neuromorphic hardware, where either hard upper bounds on network connectivity are unavoidable ( schemmel et al., 2010 ; merolla et al., 2014 ) or fast on - chip memory of local processing cores is severely limited, for example the 96 mbyte local memory of cores in the spinnaker system ( furber et al., 2014 [SEP]
Text from DS:  Published as a conference paper at ICLR 2018

D EEP R EWIRING : T RAINING VERY SPARSE DEEP NETWORKS

arXiv:1711.05136v4 [] 5 Feb 2018

Guillaume Bellec, David Kappel, Wolfgang Maass & Robert Legenstein
Institute for Theoretical Computer Science
Graz University of Technology
Austria
{bellec,kappel,maass,legenstein}@igi.tugraz.at

A BSTRACT
Neuromorphic hardware tends to pose limits on the connectivity of deep networks
that one can run on them. But also generic hardware and software implementations of deep learning run more efficiently for sparse networks. Several methods
exist for pruning connections of a neural network after it was trained without connectivity constraints. We present an algorithm, DEEP R, that enables us to train
directly a sparsely connected neural network. DEEP R automatically rewires the
network during supervised training so that connections are there where they are
most needed for the task, while its total number is all the time strictly bounded.
We demonstrate tha
Original label:  cs.CE
Predicted label:  10
Correct label:  5
Text:  [CLS] portability analysis for weak memory models porthos : one tool for all models arxiv : 1702. 06704v2 [ ] 28 apr 2017 hernan ponce - de - [UNK], florian furbach2, keijo heljanko3, and roland [UNK] 1 fortiss gmbh, germany 2 tu kaiserslautern, germany 3 aalto university and hiit, finland 4 tu braunschweig, germany ponce @ fortiss. org, furbach @ cs. uni - kl. de, keijo. heljanko @ aalto. fi, roland. meyer @ tu - braunschweig. de abstract. we present porthos, the first tool that discovers porting bugs in performance - critical code. porthos takes as input a program and the memory models of the source architecture for which the program has been developed and the target model to which it is ported. if the code is not portable, porthos finds a bug in the form of an unexpected execution — an execution that is consistent with the target but inconsistent with the source memory model. technically, porthos implements a bounded model checking method that reduces the portability analysis problem to satisfiability modulo theories ( smt ). there are two main problems in the reduction that we present novel and efficient solutions for. first, the formulation of the portability problem contains a quantifier alternation ( consistent + inconsistent ). we introduce a formula that encodes both in a single existential query. second, the supported memory models ( e. g., power ) contain recursive definitions. we compute the required least fixed point semantics for recursion ( a problem that was left open in [ 47 ] ) efficiently in smt. finally we present the first experimental analysis of portability from tso to power. 1 introduction porting code from one architecture to another is a routine task in system development. given that no functionality has to be added, porting is rarely considered interesting from a programming point of view. at the same time, porting is non - trivial as the hardware influences both the semantics and the compilation of the code in subtle ways. the unfortunate combination of being routine and yet subtle makes porting prone to mistakes. this is particularly true for performance - critical code that interacts closely with the execution environment. such code often has data races and thus exposes the programmer to the details of the underlying hardware. when the architecture is changed, the code may have to be adapted to the primitives of the target [SEP]
Text from DS:  Portability Analysis for Weak Memory Models
porthos: One Tool for all Models

arXiv:1702.06704v2 [] 28 Apr 2017

Hernán Ponce-de-León1⋆ , Florian Furbach2 , Keijo Heljanko3 , and Roland Meyer4⋆
1

fortiss GmbH, Germany 2 TU Kaiserslautern, Germany 3 Aalto University and
HIIT, Finland 4 TU Braunschweig, Germany
ponce@fortiss.org, furbach@cs.uni-kl.de, keijo.heljanko@aalto.fi,
roland.meyer@tu-braunschweig.de
Abstract. We present porthos, the first tool that discovers porting
bugs in performance-critical code. porthos takes as input a program
and the memory models of the source architecture for which the program
has been developed and the target model to which it is ported. If the
code is not portable, porthos finds a bug in the form of an unexpected
execution — an execution that is consistent with the target but inconsistent with the source memory model. Technically, porthos implements
a bounded model checking method that reduces the portability analysis
problem to satisfiability modul
Original label:  cs.NE
Predicted label:  3
Correct label:  2
Text:  [CLS] semi - supervised learning with the deep rendering mixture model tan nguyen1, 2 wanjia liu1 ethan perez1 richard g. baraniuk1 ankit b. patel1, 2 1 2 rice university baylor college of medicine 6100 main street, houston, tx 77005 1 baylor plaza, houston, tx 77030 arxiv : 1612. 01942v1 [ stat. ml ] 6 dec 2016 { mn15, wl22, ethanperez, richb } @ rice. edu abstract ankitp @ bcm. edu recognition and image segmentation. however, dcns are still far behind humans in semi - supervised learning tasks, in which only a few labels are available. the main difficulty in semi - supervised learning in dcns is that, until recently, there has not been a mathematical framework for deep learning architectures. as a result, it is not clear how dcns encode the data distribution, making combining supervised and unsupervised learning challenging. semi - supervised learning algorithms reduce the high cost of acquiring labeled training data by using both labeled and unlabeled data during learning. deep convolutional networks ( dcns ) have achieved great success in supervised tasks and as such have been widely employed in the semi - supervised learning. in this paper we leverage the recently developed deep rendering mixture model ( drmm ), a probabilistic generative model that models latent nuisance variation, and whose inference algorithm yields dcns. we develop an em algorithm for the drmm to learn from both labeled and unlabeled data. guided by the theory of the drmm, we introduce a novel nonnegativity constraint and a variational inference term. we report state - of - the - art performance on mnist and svhn and competitive results on cifar10. we also probe deeper into how a drmm trained in a semi - supervised setting represents latent nuisance variation using synthetically rendered images. taken together, our work provides a unified framework for supervised, unsupervised, and semisupervised learning. recently, the deep rendering mixture model ( drmm ) [ 13, 14 ] has been developed as a probabilistic graphical model underlying dcns. the drmm is a hierarchical generative model in which the image is rendered via multiple levels of abstraction. it has been shown that the bottomup inference in the drmm corresponds to the feedforward propagation in the dcns. the drmm enables us [SEP]
Text from DS:  Semi-Supervised Learning with the Deep Rendering Mixture Model
Tan Nguyen1,2

Wanjia Liu1
Ethan Perez1
Richard G. Baraniuk1
Ankit B. Patel1,2
1
2
Rice University
Baylor College of Medicine
6100 Main Street, Houston, TX 77005
1 Baylor Plaza, Houston, TX 77030

arXiv:1612.01942v1 [stat.ML] 6 Dec 2016

{mn15, wl22, ethanperez, richb}@rice.edu

Abstract

ankitp@bcm.edu

recognition and image segmentation. However, DCNs are
still far behind humans in semi-supervised learning tasks,
in which only a few labels are available. The main difficulty in semi-supervised learning in DCNs is that, until
recently, there has not been a mathematical framework for
deep learning architectures. As a result, it is not clear how
DCNs encode the data distribution, making combining supervised and unsupervised learning challenging.

Semi-supervised learning algorithms reduce the high
cost of acquiring labeled training data by using both labeled and unlabeled data during learning. Deep Convolutional Networks (DCN
Original label:  cs.CV
Predicted label:  0
Correct label:  4
Text:  [CLS] efficient trimmed convolutional arithmetic encoding for lossless image compression mu li, shuhang gu, david zhang department of computing, hong kong polytechnic university arxiv : 1801. 04662v1 [ ] 15 jan 2018 csmuli @ comp. polyu. edu. hk, shuhanggu @ gmail. com, csdzhang @ comp. polyu. edu. hk wangmeng zuo∗ school of computer science and technology, harbin institute of technology cswmzuo @ gmail. com abstract 1. introduction data compression, which aims to encode the information using fewer bits, has been extensively studied for decades. compression methods can be classified into lossy and lossless ones. for lossless compression the reconstructed data is an exact replica of the original data, while for lossy compression the approximated reconstruction of the original data is allowed. even though lossy and lossless compression algorithms are designed for different objectives, they share similar compression pipeline, i. e., pre - processing ( e. g., analysis transform ), entropy coding, entropy decoding, and post - processing ( e. g., synthesis transform ). moreover, lossless compression can also be adopted as a component in lossy compression to encode the intermediate codes generated by the lossy compression system, which further indicates the indispensability of lossless compression in data compression. entropy encoding has been widely adopted for lossless compression, where each input symbol is encoded with a codeword with the length approximately proportional to the negative logarithm of the probability. according to shannon ’ s source coding theorem [ 11 ], the optimal code length for a symbol should be − logb p, where b is the number of symbols used to make output codes and p is the probability of the input symbol. following shannon ’ s theorem, several entropy encoding techniques, e. g., run length coding, huffman coding, golomb - rice coding, and arithmetic coding, have been developed. one key issue of entropy encoding is to predict the probability of the current symbol to be encoded. in image compression, several approaches have been proposed to address this issue. as for jpeg, the frequency of the symbols is directly counted and the huffman coding is used to compress the codes. in jpeg 2000, the ebcot coder [ 9 ] is employed to model the context and approximate the proba - arithmetic encoding is an essential class of coding techniques which [SEP]
Text from DS:  Efficient Trimmed Convolutional Arithmetic Encoding
for Lossless Image Compression
Mu Li, Shuhang Gu, David Zhang
Department of Computing, Hong Kong Polytechnic University

arXiv:1801.04662v1 [] 15 Jan 2018

csmuli@comp.polyu.edu.hk, shuhanggu@gmail.com, csdzhang@comp.polyu.edu.hk

Wangmeng Zuo∗
School of Computer Science and Technology, Harbin Institute of Technology
cswmzuo@gmail.com

Abstract

1. Introduction
Data compression, which aims to encode the information
using fewer bits, has been extensively studied for decades.
Compression methods can be classified into lossy and lossless ones. For lossless compression the reconstructed data
is an exact replica of the original data, while for lossy
compression the approximated reconstruction of the original data is allowed. Even though lossy and lossless compression algorithms are designed for different objectives,
they share similar compression pipeline, i.e., pre-processing
(e.g., analysis transform), entropy coding, entropy decoding, a
Original label:  cs.NE
Predicted label:  5
Correct label:  3
Text:  [CLS] this is a preprint copy that has been accepted for publication in ieee transactions on cybernetics. please cite this article as : yukun bao, tao xiong, zhongyi hu, “ pso - mismo modeling strategy for multi - step - ahead time series prediction ”. ieee transactions on cybernetics. 2013, accepted. doi : 10. 1109 / tcyb. 2013. 2265084. copyright claim : it should be noted that the copyright is reserved by ieee. this preprint copy is only for personal use. copyright © 2013 ieee. all rights reserved. > replace this line with your paper identification number ( double - click here to edit ) < 1 pso - mismo modeling strategy for multi - step - ahead time series prediction yukun bao, member, ieee, tao xiong, zhongyi hu abstract — multi - step - ahead time series prediction is one of the most challenging research topics in the field of time series modeling and prediction, and is continually under research. recently, the multiple - input several multiple - outputs ( mismo ) modeling strategy has been proposed as a promising alternative for multi - step - ahead time series prediction, exhibiting advantages compared with the two currently dominating strategies, the iterated and the direct strategies. built on the established mismo strategy, this study proposes a particle swarm optimization ( pso ) - based mismo modeling strategy, which is capable of determining the number of sub - models in a self - adaptive mode, with varying prediction horizons. rather than deriving crisp divides with equal - size s prediction horizons from the established mismo, the proposed pso - mismo strategy, implemented with neural networks, employs a heuristic to create flexible divides with varying sizes of prediction horizons and to generate corresponding sub - models, providing considerable flexibility in model construction, which has been validated with simulated and real datasets. index terms — multi - step - ahead time series prediction, multiple - output models, particle swarm optimization, genetic algorithm. i. introduction d espite intensive research efforts in time series modeling and prediction, most models continue to be limited to one - step - ahead prediction rather than multi - step - ahead prediction, primarily because of the challenges arising from increased uncertainty from longer prediction horizons. the most common modeling strategies for multi - step - ahead time series prediction rely either on iterated or direct strategies [ 1 - 3 ]. an iterated strategy first constructs a one - step - ahead prediction model, and then uses [SEP]
Text from DS:  This is a preprint copy that has been accepted for publication in IEEE
Transactions on Cybernetics.

Please cite this article as:
Yukun Bao, Tao Xiong, Zhongyi Hu, “PSO-MISMO Modeling Strategy
for Multi-Step-Ahead Time Series Prediction”. IEEE Transactions on
Cybernetics. 2013, accepted. doi:10.1109/TCYB.2013. 2265084.

Copyright Claim: It should be noted that the copyright is reserved by
IEEE. This preprint copy is only for personal use.

Copyright © 2013 IEEE. All rights reserved.

> REPLACE THIS LINE WITH YOUR PAPER IDENTIFICATION NUMBER (DOUBLE-CLICK HERE TO EDIT) <

1

PSO-MISMO Modeling Strategy for
Multi-Step-Ahead Time Series Prediction
Yukun Bao, Member, IEEE, Tao Xiong, Zhongyi Hu

Abstract—Multi-step-ahead time series prediction is one of the
most challenging research topics in the field of time series
modeling and prediction, and is continually under research.
Recently, the multiple-input several multiple-outputs (MISMO)
modeling strategy has been proposed as a promising a
Original label:  cs.CV
Predicted label:  6
Correct label:  2
Text:  [CLS] fd - mobilenet : improved mobilenet with a fast downsampling strategy zheng qin, zhaoning zhang, xiaotao chen, yuxing peng science and technology on parallel and distributed laboratory, national university of defense technology, changsha, china arxiv : 1802. 03750v1 [ ] 11 feb 2018 abstract we present fast - downsampling mobilenet ( fd - mobilenet ), an efficient and accurate network for very limited computational budgets ( e. g., 10 - 140 mflops ). our key idea is applying a fast downsampling strategy to mobilenet framework. in fd - mobilenet, we perform 32× downsampling within 12 layers, only half the layers in the original mobilenet. this design brings three advantages : ( i ) it remarkably reduces the computational cost. ( ii ) it increases the information capacity and achieves significant performance improvements. ( iii ) it is engineering - friendly and provides fast actual inference speed. experiments on ilsvrc 2012 and pascal voc 2007 datasets demonstrate that fd - mobilenet consistently outperforms mobilenet and achieves comparable results with shufflenet under different computational budgets, for instance, surpassing mobilenet by 5. 5 % on the ilsvrc 2012 top - 1 accuracy and 3. 6 % on the voc 2007 map under a complexity of 12 mflops. on an armbased device, fd - mobilenet achieves 1. 11× inference speedup over mobilenet and 1. 82× over shufflenet under the same complexity. index terms — computer vision, convolutional neural network, deep learning 1. introduction deep convolutional neural networks ( cnns ) have become one of the most important methods in computer vision tasks such as image classification [ 1, 2, 3, 4 ], object detection [ 5, 6, 7, 8 ] and semantic segmentation [ 9, 10 ]. however, state - of - the - art cnns require enormous computational resources and huge model sizes, which prevents them from being deployed on mobile or embedded devices. for this reason, the inference - time compression and acceleration of deep neural networks has attracted the attention of the deep learning community in recent years. the related work is conventionally categorized into four classes. tensor decomposition methods [ 11, 12 ] factorize a convolutional layer into several smaller convolutional layers, which reduces the overall complexity and the number of parameters. this class of methods conventionally [SEP]
Text from DS:  FD-MOBILENET: IMPROVED MOBILENET WITH A FAST DOWNSAMPLING STRATEGY
Zheng Qin, Zhaoning Zhang, Xiaotao Chen, Yuxing Peng
Science and Technology on Parallel and Distributed Laboratory,
National University of Defense Technology, Changsha, China

arXiv:1802.03750v1 [] 11 Feb 2018

ABSTRACT
We present Fast-Downsampling MobileNet (FD-MobileNet), an efficient and accurate network for very limited computational budgets
(e.g., 10-140 MFLOPs). Our key idea is applying a fast downsampling strategy to MobileNet framework. In FD-MobileNet, we
perform 32× downsampling within 12 layers, only half the layers
in the original MobileNet. This design brings three advantages: (i)
It remarkably reduces the computational cost. (ii) It increases the
information capacity and achieves significant performance improvements. (iii) It is engineering-friendly and provides fast actual inference speed. Experiments on ILSVRC 2012 and PASCAL VOC 2007
datasets demonstrate that FD-MobileNet consistently outperforms
Mobile
Original label:  cs.AI
Predicted label:  1
Correct label:  4
Text:  [CLS] arxiv : 1803. 06092v1 [ ] 16 mar 2018 a dataset and architecture for visual reasoning with a working memory ‡ guangyu robert yang1, †, ‡, *, igor ganichev2, *, xiao - jing wang1, jonathon shlens2, david sussillo2 1 center for neural science, new york university, ny, usa 2 google brain † work done as an intern at google brain present address : department of neuroscience, columbia university, new york, ny, usa * equal contribution abstract. a vexing problem in artificial intelligence is reasoning about events that occur in complex, changing visual stimuli such as in video analysis or game play. inspired by a rich tradition of visual reasoning and memory in cognitive psychology and neuroscience, we developed an artificial, configurable visual question and answer dataset ( cog ) to parallel experiments in humans and animals. cog is much simpler than the general problem of video analysis, yet it addresses many of the problems relating to visual and logical reasoning and memory – problems that remain challenging for modern deep learning architectures. we additionally propose a deep learning architecture that performs competitively on other diagnostic vqa datasets ( i. e. clevr ) as well as easy settings of the cog dataset. however, several settings of cog result in datasets that are progressively more challenging to learn. after training, the network can zero - shot generalize to many new tasks. preliminary analyses of the network architectures trained on cog demonstrate that the network accomplishes the task in a manner interpretable to humans. keywords : visual reasoning, visual question answering, recurrent network, working memory 1 introduction a major goal of artificial intelligence is to build systems that powerfully and flexibly reason about the sensory environment [ 1 ]. vision provides an extremely rich and highly applicable domain for exercising our ability to build systems that form logical inferences on complex stimuli [ 2, 3, 4, 5 ]. one avenue for studying visual reasoning has been visual question answering ( vqa ) datasets where a model learns to correctly answer challenging natural language questions about static images [ 6, 7, 8, 9 ]. while advances on these multi - modal datasets have been significant, these datasets highlight several limitations to current approaches. first, it is uncertain the degree to which models trained on vqa datasets merely follow 2 yang, ganichev, et al. green k z what is the [SEP]
Text from DS:  arXiv:1803.06092v1 [] 16 Mar 2018

A dataset and architecture for visual reasoning
with a working memory

‡

Guangyu Robert Yang1,†,‡,* , Igor Ganichev2,* , Xiao-Jing Wang1 , Jonathon
Shlens2 , David Sussillo2
1

Center for Neural Science, New York University, NY, USA
2
Google Brain
†
Work done as an intern at Google Brain
Present address: Department of Neuroscience, Columbia University, New York, NY,
USA
*
equal contribution

Abstract. A vexing problem in artificial intelligence is reasoning about
events that occur in complex, changing visual stimuli such as in video
analysis or game play. Inspired by a rich tradition of visual reasoning
and memory in cognitive psychology and neuroscience, we developed an
artificial, configurable visual question and answer dataset (COG) to parallel experiments in humans and animals. COG is much simpler than the
general problem of video analysis, yet it addresses many of the problems
relating to visual and logical reasoning and memory – problems that
r
Original label:  math.ST
Predicted label:  2
Correct label:  1
Text:  [CLS] arxiv : 1708. 02516v3 [ math. fa ] 13 mar 2018 equivalence of weak and strong modes of measures on topological vector spaces han cheng lie and t. j. sullivan abstract. modes of a probability measure on a normed space x can be defined by maximising the small - radius limit of the ratio of measures of norm balls. helin and burger weakened the definition of such modes by considering only balls whose centres differ by a vector in a topologically dense, proper subspace e of x, and posed the question of when these two types of modes coincide. we generalise these definitions, by replacing norm balls with bounded, open neighbourhoods that satisfy a boundary regularity condition, and probability measures with non - atomic measures that are finite on bounded sets. we show that a coincident limiting ratios condition is a necessary and sufficient condition for the equivalence of these two types of modes, and that this condition is satisfied under the assumption that e is dense in x. 1. introduction a probability measure µ on a topological vector space x can be described using summary statistics such as means and covariances or, as in this article, modes, meaning points of maximum µ - mass in an appropriate sense. there are multiple ways of defining such modes, particularly for infinite - dimensional vector spaces ; the strong mode of dashti et al. [ 8 ] and the weak mode of helin and burger [ 16 ] describe the notion of a point of maximum probability in a separable banach space by examining the probabilities of small norm balls in the limit as the radius tends to zero. helin and burger observed that every strong mode is a weak mode, and asked whether the converse holds [ 16, section 6 ]. here, we shall assume the following : assumption 1. 1. x is a first countable, hausdorff topological vector space over k : = r or c ; µ is a non - zero, non - atomic measure on the borel σ - algebra of x that is finite on bounded sets ; and k is a bounded, open neighbourhood of the origin. in [ 8, 16 ], x is a separable banach space, k is its unit norm ball, and µ is a borel probability measure with topological support supp ( µ ) = x. here, we do not assume that x is complete or separable, that supp ( µ ) = x, or that µ is finite on x. assumption 1. 1 implies that the topology on x is metrisable [SEP]
Text from DS:  arXiv:1708.02516v3 [math.FA] 13 Mar 2018

EQUIVALENCE OF WEAK AND STRONG MODES
OF MEASURES ON TOPOLOGICAL VECTOR SPACES
HAN CHENG LIE AND T. J. SULLIVAN
Abstract. Modes of a probability measure on a normed space X can be defined by maximising the small-radius limit of the ratio of measures of norm
balls. Helin and Burger weakened the definition of such modes by considering only balls whose centres differ by a vector in a topologically dense, proper
subspace E of X, and posed the question of when these two types of modes coincide. We generalise these definitions, by replacing norm balls with bounded,
open neighbourhoods that satisfy a boundary regularity condition, and probability measures with non-atomic measures that are finite on bounded sets.
We show that a coincident limiting ratios condition is a necessary and sufficient condition for the equivalence of these two types of modes, and that this
condition is satisfied under the assumption that E is dense in X.

1. Introduction
A prob
Original label:  cs.SY
Predicted label:  8
Correct label:  7
Text:  [CLS] international journal on soft computing, artificial intelligence and applications ( ijscai ), vol. 3, no. 3 / 4, november 2014 comparing of switching frequency on vector controlled asynchronous motor yılmaz korkmaz1, fatih korkmaz2, ismail topaloglu2, hayati mamur2 1 faculty of technology, department of electrical - electronic engineering, gazi university, ankara, turkey 2 faculty of engineering, department of electrical - electronic engineering, cankırı karatekin university, cankırı, turkey abstract nowadays, asynchronous motors have wide range use in many industrial applications. field oriented control ( foc ) and direct torque control ( dtc ) are commonly used methods in high performance vector control for asynchronous motors. therefore, it is very important to identify clearly advantages and disadvantages of both systems in the selection of appropriate control methods for many industrial applications. this paper aims to present a new and different perspective regarding the comparison of the switching behaviours on the foc and the dtc drivers. for this purpose, the experimental studies have been carried out to compare the inverter switching frequencies and torque responses of the asynchronous motor in the foc and the dtc systems under different working conditions. the dspace 1103 controller board was programmed with matlab / simulink software. as expected, the experimental studies showed that the foc controlled motors has a lessened torque ripple. on the other hand, the foc controlled motor switching frequency has about 65 - 75 % more than the dtc controlled under both loaded and unloaded working conditions. keywords asynchronous motor ; vector control ; motor drives ; switching frequency 1. introduction for many years, asynchronous motors have wide range use in industrial applications due to its simple and robust structure and low costs when compared with dc motors. furthermore, we have better high performance control options now due to development of power electronics in the last few decades. there are two noted control methods in high performance control of asynchronous motors named as : foc and dtc. blaschke proposed the foc in the 1970s. the foc was unique and only option that we had on asynchronous motors high performance control until 1980s that the dtc was introduced by takahashi. since that day, there have been continual discussions and questions about that : which one has the best performance on asynchron [SEP]
Text from DS:  International Journal on Soft Computing, Artificial Intelligence and Applications (IJSCAI), Vol.3, No. 3/4, November 2014

COMPARING OF SWITCHING FREQUENCY ON VECTOR
CONTROLLED ASYNCHRONOUS MOTOR
Yılmaz Korkmaz1, Fatih Korkmaz2, Ismail Topaloglu2, Hayati Mamur2
1

Faculty of Technology, Department of Electrical-Electronic Engineering,
Gazi University, Ankara, Turkey
2
Faculty of Engineering, Department of Electrical-Electronic Engineering,
Çankırı Karatekin University, Çankırı, Turkey

ABSTRACT
Nowadays, asynchronous motors have wide range use in many industrial applications. Field oriented
control (FOC) and direct torque control (DTC) are commonly used methods in high performance vector
control for asynchronous motors. Therefore, it is very important to identify clearly advantages and
disadvantages of both systems in the selection of appropriate control methods for many industrial
applications. This paper aims to present a new and different perspective regarding the comparison of the

Original label:  cs.PL
Predicted label:  8
Correct label:  6
Text:  [CLS] on binary matroid minors and applications to data storage over small fields matthias grezet, ragnar freij - hollanti, thomas westerback, and camilla hollanti arxiv : 1707. 00421v2 [ ] 19 feb 2018 department of mathematics and systems analysis, aalto university, finland firstname. lastname @ aalto. fi abstract. locally repairable codes for distributed storage systems have gained a lot of interest recently, and various constructions can be found in the literature. however, most of the constructions result in either large field sizes and hence too high computational complexity for practical implementation, or in low rates translating into waste of the available storage space. in this paper we address this issue by developing theory towards code existence and design over a given field. this is done via exploiting recently established connections between linear locally repairable codes and matroids, and using matroid - theoretic characterisations of linearity over small fields. in particular, nonexistence can be shown by finding certain forbidden uniform minors within the lattice of cyclic flats. it is shown that the lattice of cyclic flats of binary matroids have additional structure that significantly restricts the possible locality properties of f2 - linear storage codes. moreover, a collection of criteria for detecting uniform minors from the lattice of cyclic flats of a given matroid is given, which is interesting in its own right. keywords : binary matroids ; distributed storage systems ; lattice of cyclic flats ; locally repairable codes ; uniform minors 1 introduction the need for large - scale data storage is continuously increasing. within the past few years, distributed storage systems ( dsss ) have revolutionised our traditional ways of storing, securing, and accessing data. storage node failure is a frequent obstacle, making repair efficiency an important objective. network coding techniques for dsss were considered in [ 6 ], characterising a storage space – repair bandwidth tradeoff. a bottle - neck for repair efficiency, measured by the notion of locality [ 13 ], is the number of contacted nodes needed for repair. to this end, our motivation in this paper comes from locally repairable codes ( lrcs ), which are, informally speaking, storage systems where a small number of failing nodes can be recovered by boundedly many other ( close - by ) nodes. repair - efficient lrcs are already implemented on hdfs - xorbas used by facebook [ 14 ] and windows azure storage [ 11 ]. here, the field size is not yet a huge concern, as [SEP]
Text from DS:  On Binary Matroid Minors and Applications to
Data Storage over Small Fields
Matthias Grezet, Ragnar Freij-Hollanti, Thomas Westerbäck, and Camilla
Hollanti

arXiv:1707.00421v2 [] 19 Feb 2018

Department of Mathematics and Systems Analysis, Aalto University, Finland
firstname.lastname@aalto.fi

Abstract. Locally repairable codes for distributed storage systems have
gained a lot of interest recently, and various constructions can be found in
the literature. However, most of the constructions result in either large
field sizes and hence too high computational complexity for practical
implementation, or in low rates translating into waste of the available
storage space.
In this paper we address this issue by developing theory towards code
existence and design over a given field. This is done via exploiting recently established connections between linear locally repairable codes
and matroids, and using matroid-theoretic characterisations of linearity
over small fields. In particular, nonex
Original label:  cs.DS
Predicted label:  6
Correct label:  2
Text:  [CLS] applying a differential evolutionary algorithm to a constraint - based system to support separation of otdr superimposed signal after passive optical network splitters lima, gerson f. m ; lamounier, edgard ; barcelos, sergio ; cardoso, alexandre ; peretta, igor ; muramoto, willian ; barbara, flavio abstract — the ftth ( fiber to the home ) market currently needs new network maintenance technologies that can, economically and effectively, cope with massive fiber plants. however, operating these networks requires adequate means for an [UNK] monitoring cost. especially for troubleshooting faults that are associated with the possibility of remote identification of fiber breaks, which may exist in the network. this is of great value for operators. optical time domain reﬂectometry ( otdr ) techniques are widely used in point - to - point optical network topologies. nevertheless, it has major limitations in tree - structured pons ( passive optical networks ), where all different branches backscatter the light in just one conventional otdr trace with combined signals arriving on the olt ( optical line terminal ) side. furthermore, passive power splitters used in ftth networks input large attenuation, impoverishing the reflected signal. this makes the identification of the very branch affected by the problem practically impossible, when considering conventional analyses [ 32 ]. from this scenario, arrives the pon network operator ’ s requirement for an innovative solution that allows the precise identification of the affected branch. the use of constraint - based techniques have been applied in a large amount of applications for engineering design, where the duties imposed for graphics and equations constraints result in valued features to cad / cae software capabilities. currently, it provides a faster decision making capacity for engineers. this work applies the constraintbased approach along with a differential evolutionary algorithm to separate the superimposed otdr signals, after the splitters of a ftth passive optical networks. this research introduces a new set of algorithms performing a coupling to an optical network ( on ) cad design with its correspondent otdr measurement signal, considering its geographical distribution branches of [UNK] lengths after the splitter. results of this work are presented in a fttn ( fiber to the node ) prototype arrangement, using a 1 : 8 passive power splitter. keywords : ftth, fttn, otdr data analyzing, failure detection, differential evolution, cad / cae constraints, network monitoring, pon. 1 - introduction over the last 30 years, optical fiber communication technology has come down in price. [SEP]
Text from DS:  Applying a Differential Evolutionary Algorithm to a Constraint-based
System to support Separation of OTDR Superimposed Signal after Passive
Optical Network Splitters
Lima, Gerson F. M; Lamounier, Edgard; Barcelos, Sergio; Cardoso, Alexandre; Peretta, Igor; Muramoto, Willian; Barbara, Flavio

Abstract— The FTTH (Fiber To The Home) market currently
needs new network maintenance technologies that can,
economically and effectively, cope with massive fiber plants.
However, operating these networks requires adequate means for an
eﬀective monitoring cost. Especially for troubleshooting faults that
are associated with the possibility of remote identification of fiber
breaks, which may exist in the network. This is of great value for
operators. Optical Time Domain Reﬂectometry (OTDR)
techniques are widely used in point-to-point optical network
topologies. Nevertheless, it has major limitations in tree-structured
PONs (Passive Optical Networks), where all different branches
backscatter the light
Original label:  math.GR
Predicted label:  8
Correct label:  10
Text:  [CLS] the cycle structure of a markoff automorphism over finite fields arxiv : 1610. 07077v2 [ math. nt ] 15 mar 2018 alois cerbu, elijah gunther, michael magee, luke peilen abstract. we begin an investigation of the action of pseudo - anosov elements of out ( f2 ) on the markoff - type varieties xκ : x2 + y 2 + z 2 = xyz + 2 + κ over finite fields fp with p prime. we first make a precise conjecture about the permutation group generated by out ( f2 ) on x−2 ( fp ) that shows there is no obstruction at the level of the permutation group to a pseudo - anosov acting ‘ generically ’. we prove that this conjecture is sharp. we show that for a fixed pseudo - anosov g ∈ out ( f2 ), there is always an orbit of g of length ≥ c log p + o ( 1 ) on xκ ( fp ) where c > 0 is given in terms of the eigenvalues of g viewed as an element of gl2 ( z ). this improves on a result of silverman from [ 24 ] that applies to general morphisms of quasi - projective varieties. we have discovered that the asymptotic ( p → ∞ ) behavior of the longest orbit of a fixed pseudo - anosov g acting on x−2 ( fp ) is dictated by a dichotomy that we describe both in combinatorial terms and in algebraic terms related to gauss ’ s ambiguous binary quadratic forms, following sarnak [ 21 ]. this dichotomy is illustrated with numerics, based on which we formulate a precise conjecture in conjecture 1. 10. 1. introduction for κ ∈ z, let xκ denote the affine surface ( 1. 1 ) xκ : x2 + y 2 + z 2 = xyz + 2 + κ. when κ = −2, x−2 is markoff ’ s surface. a theorem of markoff [ 16 ] relates the integer points on x−2 to the diophantine properties of q ; in particular to the markoff spectrum. in a different vein, the real and complex points of xκ are related to moduli spaces of sl2 ( c ) - local systems on a torus with one puncture [ 11 ]. due to this connection, letting f2 denote [SEP]
Text from DS:  THE CYCLE STRUCTURE OF A MARKOFF AUTOMORPHISM
OVER FINITE FIELDS

arXiv:1610.07077v2 [math.NT] 15 Mar 2018

ALOIS CERBU, ELIJAH GUNTHER, MICHAEL MAGEE, LUKE PEILEN
Abstract. We begin an investigation of the action of pseudo-Anosov elements
of Out(F2 ) on the Markoff-type varieties
Xκ : x2 + y 2 + z 2 = xyz + 2 + κ
over finite fields Fp with p prime. We first make a precise conjecture about
the permutation group generated by Out(F2 ) on X−2 (Fp ) that shows there is
no obstruction at the level of the permutation group to a pseudo-Anosov acting ‘generically’. We prove that this conjecture is sharp. We show that for
a fixed pseudo-Anosov g ∈ Out(F2 ), there is always an orbit of g of length
≥ C log p + O(1) on Xκ (Fp ) where C > 0 is given in terms of the eigenvalues of
g viewed as an element of GL2 (Z). This improves on a result of Silverman from
[24] that applies to general morphisms of quasi-projective varieties. We have
discovered that the asymptotic (p → ∞) behavior of the longest or
Original label:  cs.AI
Predicted label:  2
Correct label:  9
Text:  [CLS] intelligible artificial intelligence gagan bansal1 daniel s. weld1, 2 1 microsoft research redmond, washington arxiv : 1803. 04263v1 [ ] 9 mar 2018 abstract since artificial intelligence ( ai ) software uses techniques like deep lookahead search and stochastic optimization of huge neural networks to fit mammoth datasets, it often results in complex behavior that is difficult for people to understand. yet organizations are deploying ai algorithms in many mission - critical settings. in order to trust their behavior, we must make it intelligible — either by using inherently interpretable models or by developing methods for explaining otherwise overwhelmingly complex decisions by local approximation, vocabulary alignment, and interactive dialog. keywords hci, artificial intelligence, machine learning, explanation, interpretability 1 introduction artificial intelligence ( ai ) systems have reached or exceeded human performance on many circumscribed tasks. as a result, they are increasingly deployed in mission critical roles — credit scoring, predicting if a bail candidate will commit another crime, selecting the news we read on social networks, and soon we may have selfdriving cars. unlike other mission critical software, it ’ s very hard to test ai systems, which are extraordinarily complex. ai decisions are context specific, often based on thousands or millions of factors. typically, ai behaviors are generated by searching vast action spaces or learned by the opaque optimization of mammoth neural networks operating over inhuman amounts of training data. almost by definition there is no deterministic method for accomplishing the ai ’ s task. unfortunately, much computer - produced behavior is alien — it can fail in unexpected ways. this lesson is most clearly seen in the performance of the latest deep neural network image analysis systems. while their accuracy at object - recognition on naturally occurring pictures is extraordinary, imperceptible changes to the input images can lead to erratic predictions, as shown in figure 1. why is the recognition system so brittle, making different predictions for apparently identical images? unintelligible behavior isn ’ t limited to machine learning — many ai programs perform search - based lookahead and inference whose complexity exceeds human abilities to verify. however, if we don ’ t understand a system ’ s behavior, it is dangerous to trust it. yet it ’ s crucial that we be able to trust deployed systems, and this requires improving robustness and developing ways to make their reasoning intelligible [ 7 ]. as a result, researchers have increasingly focused on ways for enabling ai system to explain their learned [SEP]
Text from DS:  Intelligible Artificial Intelligence
Gagan Bansal1

Daniel S. Weld1,2
1 Microsoft

Research
Redmond, Washington

arXiv:1803.04263v1 [] 9 Mar 2018

ABSTRACT
Since Artificial Intelligence (AI) software uses techniques like deep
lookahead search and stochastic optimization of huge neural networks to fit mammoth datasets, it often results in complex behavior
that is difficult for people to understand. Yet organizations are deploying AI algorithms in many mission-critical settings. In order
to trust their behavior, we must make it intelligible — either by
using inherently interpretable models or by developing methods
for explaining otherwise overwhelmingly complex decisions by
local approximation, vocabulary alignment, and interactive dialog.

KEYWORDS
HCI, artificial intelligence, machine learning, explanation, interpretability

1

INTRODUCTION

Artificial Intelligence (AI) systems have reached or exceeded human performance on many circumscribed tasks. As a result, they
are increasingly de
Original label:  math.AC
Predicted label:  9
Correct label:  5
Text:  [CLS] arxiv : 1710. 07175v1 [ math. co ] 19 oct 2017 the geometry of gaussoids tobias boege, alessio d ’ alı, thomas kahle and bernd sturmfels abstract a gaussoid is a combinatorial structure that encodes independence in probability and statistics, just like matroids encode independence in linear algebra. the gaussoid axioms of lnenicka and matus are equivalent to compatibility with certain quadratic relations among principal and almost - principal minors of a symmetric matrix. we develop the geometric theory of gaussoids, based on the lagrangian grassmannian and its symmetries. we introduce oriented gaussoids and valuated gaussoids, thus connecting to real and tropical geometry. we classify small realizable and non - realizable gaussoids. positive gaussoids are as nice as positroids : they are all realizable via graphical models. 1 introduction gaussoids are combinatorial structures that arise in statistics and are reminiscent of matroids. they were introduced by lnenicka and matus [ 23 ] to represent conditional independence relations among n gaussian random variables. the theory of matroids is ubiquitous in the mathematical sciences, as it captures the combinatorial essence of many objects in algebra and geometry. matroids of rank d on [ n ] = { 1, 2,..., n } are possible supports of plucker coordinates on the grassmannian of d - dimensional linear subspaces in a vector space k n. this article develops the geometric theory of gaussoids, with focus on parallels to matroid theory. the role of the grassmannian is played by a natural projection of the lagrangian grassmannian, namely the variety of principal and almost - principal minors of a symmetric n × n - matrix σ. gaussoids aim to characterize which almost - principal minors can simultaneously vanish provided σ is positive definite. this issue is important in statistics, where σ is the covariance matrix of a gaussian distribution on rn, and almost - principal minors measure partial correlations. the sign of a minor indicates whether the partial correlation is positive or negative. the minor is zero if and only if conditional independence holds. our goal in this paper is to carry out the program that was suggested in [ 34, § 4 ]. we assume that our readers are familiar with the geometric approach to matroids, including oriented matroids [SEP]
Text from DS:  arXiv:1710.07175v1 [math.CO] 19 Oct 2017

The Geometry of Gaussoids
Tobias Boege, Alessio D’Alı̀, Thomas Kahle and Bernd Sturmfels
Abstract
A gaussoid is a combinatorial structure that encodes independence in probability and
statistics, just like matroids encode independence in linear algebra. The gaussoid axioms of Lněnička and Matúš are equivalent to compatibility with certain quadratic
relations among principal and almost-principal minors of a symmetric matrix. We develop the geometric theory of gaussoids, based on the Lagrangian Grassmannian and its
symmetries. We introduce oriented gaussoids and valuated gaussoids, thus connecting
to real and tropical geometry. We classify small realizable and non-realizable gaussoids.
Positive gaussoids are as nice as positroids: they are all realizable via graphical models.

1

Introduction

Gaussoids are combinatorial structures that arise in statistics and are reminiscent of matroids. They were introduced by Lněnička and Matúš [23] to 
Original label:  cs.SY
Predicted label:  8
Correct label:  5
Text:  [CLS] 1 risk mitigation for dynamic state estimation against cyber attacks and unknown inputs arxiv : 1508. 07246v3 [ ] 19 may 2016 ahmad f. taha, member, ieee, junjian qi, member, ieee, jianhui wang, senior member, ieee and jitesh h. panchal, member, ieee abstract — phasor measurement units ( pmus ) can be effectively utilized for the monitoring and control of the power grid. as the cyber - world becomes increasingly embedded into power grids, the risks of this inevitable evolution become serious. in this paper, we present a risk mitigation strategy, based on dynamic state estimation, to eliminate threat levels from the grid ’ s unknown inputs and potential cyber - attacks. the strategy requires ( a ) the potentially incomplete knowledge of power system models and parameters and ( b ) real - time pmu measurements. first, we utilize a dynamic state estimator for higher order depictions of power system dynamics for simultaneous state and unknown inputs estimation. second, estimates of cyber - attacks are obtained through an attack detection algorithm. third, the estimation and detection components are seamlessly utilized in an optimization framework to determine the most impacted pmu measurements. finally, a risk mitigation strategy is proposed to guarantee the elimination of threats from attacks, ensuring the observability of the power system through available, safe measurements. case studies are included to validate the proposed approach. insightful suggestions, extensions, and open problems are also posed. index terms — cyber - attacks, cybersecurity, dynamic state estimation, phasor measurement units, risk mitigation, unknown inputs. y q, y q w, w v q, v q l r z π λ a bw cq o lq, f q, p y, y i ψr, ψi αi acronyms ca drma drmop dse ilp lmi pmu smo ui wdtl cyber - attack. dynamic risk mitigation algorithm. dynamic risk mitigation opt. problem. dynamic state estimation. integer linear program. linear matrix inequality. phasor measurement unit. sliding mode observer. unknown input. weighted deterministic threat level. n omenclature x, x e states and the estimate. state estimation error, i. e., x − x. this work was supported by the u. s. department of energy office of electricity delivery and energy reliability and by the smart grid security research grant from the utsa [SEP]
Text from DS:  1

Risk Mitigation for Dynamic State Estimation
Against Cyber Attacks and Unknown Inputs

arXiv:1508.07246v3 [] 19 May 2016

Ahmad F. Taha, Member, IEEE, Junjian Qi, Member, IEEE, Jianhui Wang, Senior Member, IEEE
and Jitesh H. Panchal, Member, IEEE

Abstract—Phasor measurement units (PMUs) can be effectively
utilized for the monitoring and control of the power grid. As the
cyber-world becomes increasingly embedded into power grids,
the risks of this inevitable evolution become serious. In this paper,
we present a risk mitigation strategy, based on dynamic state
estimation, to eliminate threat levels from the grid’s unknown
inputs and potential cyber-attacks. The strategy requires (a)
the potentially incomplete knowledge of power system models
and parameters and (b) real-time PMU measurements. First,
we utilize a dynamic state estimator for higher order depictions
of power system dynamics for simultaneous state and unknown
inputs estimation. Second, estimates of cyber-attacks are obtai
Original label:  math.GR
Predicted label:  6
Correct label:  2
Text:  [CLS] arxiv : 1707. 04643v1 [ ] 14 jul 2017 set - direct factorizations of groups dan levy and attila maroti abstract. we consider factorizations g = xy where g is a general group, x and y are normal subsets of g and any g ∈ g has a unique representation g = xy with x ∈ x and y ∈ y. this definition coincides with the customary and extensively studied definition of a direct product decomposition by subsets of a finite abelian group. our main result states that a group g has such a factorization if and only if g is a central product of hxi and hy i and the central subgroup hxi ∩ hy i satisfies certain abelian factorization conditions. we analyze some special cases and give examples. in particular, simple groups have no non - trivial set - direct factorization. 1. introduction factorizations of groups is an important topic in group theory that has many facets. the most basic and best studied type of factorization is the direct product factorization of a group into two normal subgroups. if g is a group and h and k are two normal subgroups of g then g = h × k if and only if each g ∈ g has a unique representation g = hk with h ∈ h and k ∈ k. one possibility to generalize this definition is to relax the condition that both h and k are normal. this leads to the well - known concept of a semi - direct product of subgroups ( only one of the factors is assumed to be normal ) and also to the consideration of factorizations g = hk where neither of the two subgroups h and k is normal, and even the unique representation condition is not necessarily assumed. to get a glimpse of the possibilities see the seminal classification result in [ 10 ] of maximal decompositions g = hk where g is a finite simple group and h and k are two maximal subgroups of g. another generalization arose from a geometry problem of minkowski [ 12 ]. in 1938 hajos [ 6 ] reformulated this problem as an equivalent factorization problem of a finite abelian group, where the factors need not be subgroups. more precisely, if g is an abelian group written additively then a ( set ) factorization of g is a representation of g in the form g = h + k where h and k are subsets of g and for each g ∈ g there is a unique pair h ∈ h and k ∈ k such that g = [SEP]
Text from DS:  arXiv:1707.04643v1 [] 14 Jul 2017

SET-DIRECT FACTORIZATIONS OF GROUPS
DAN LEVY AND ATTILA MARÓTI
Abstract. We consider factorizations G = XY where G is a general group,
X and Y are normal subsets of G and any g ∈ G has a unique representation
g = xy with x ∈ X and y ∈ Y . This definition coincides with the customary
and extensively studied definition of a direct product decomposition by subsets
of a finite abelian group. Our main result states that a group G has such a
factorization if and only if G is a central product of hXi and hY i and the
central subgroup hXi ∩ hY i satisfies certain abelian factorization conditions.
We analyze some special cases and give examples. In particular, simple groups
have no non-trivial set-direct factorization.

1. Introduction
Factorizations of groups is an important topic in group theory that has many
facets. The most basic and best studied type of factorization is the direct product
factorization of a group into two normal subgroups. If G is a grou
Original label:  cs.SY
Predicted label:  1
Correct label:  2
Text:  [CLS] robustness in consensus networks arxiv : 1802. 07321v2 [ ] 25 feb 2018 t. sarkar, m. roozbehani, m. a. dahleh abstract — we consider the problem of robustness in large consensus networks that occur in many areas such as distributed optimization. robustness, in this context, is the scaling of performance measures, e. g. : h2 – norm, as a function of network dimension. we provide a formal framework to quantify the relation between such performance scaling and the convergence speed of the network. specifically, we provide upper and lower bounds for the convergence speed in terms of robustness and discuss how these bounds scale with the network topology. the main contribution of this work is that we obtain tight bounds, that hold regardless of network topology. the work here also encompasses some results in convergence time analysis in previous literature. i. i ntroduction the goal of this paper to develop a general framework to assess robustness in large consensus networks. robustness quantifies how some performance measure scales with the network dimension. large networks have become ubiquitous in many socioeconomic and engineering areas, e. g. : finance, economics, transportation etc. therefore, to guarantee graceful performance scaling as a function of network dimension and its interconnections, there is a need to develop a general framework for robustness analysis. we use the ideas introduced in [ 1 ] and extend them to consensus networks. it is well known that convergence speeds of consensus networks are limited by the proximity of the second largest eigenvalue to unity. however, the precise relation between robustness and convergence speed is still unclear. it should, however, be clear intuitively that graceful performance scaling implies “ fast ” convergence. in this work our goal is to study this notion more precisely. many performance measures to capture dimension dependent scaling have been studied in [ 2 ], [ 3 ], [ 4 ]. specifically, in [ 2 ], h2 – norm based performance measures are studied. h∞ based performance scaling, known as harmonic instability, is studied in [ 3 ] for the case of one - dimensional transportation networks. a generalized framework for robustness of stable networks is provided in [ 1 ]. the focus there has been limited to stable networks. the case of robustness in consensus networks is studied in [ 5 ], [ 6 ], [ 7 ], [ 8 ]. the work in [ 6 ], [ 7 ], [ 8 ] is limited to the case of undire [SEP]
Text from DS:  Robustness in Consensus Networks

arXiv:1802.07321v2 [] 25 Feb 2018

T. Sarkar, M. Roozbehani, M. A. Dahleh

Abstract— We consider the problem of robustness in large
consensus networks that occur in many areas such as distributed optimization. Robustness, in this context, is the scaling of performance measures, e.g.: H2 –norm, as a function
of network dimension. We provide a formal framework to
quantify the relation between such performance scaling and
the convergence speed of the network. Specifically, we provide
upper and lower bounds for the convergence speed in terms of
robustness and discuss how these bounds scale with the network
topology. The main contribution of this work is that we obtain
tight bounds, that hold regardless of network topology. The
work here also encompasses some results in convergence time
analysis in previous literature.

I. I NTRODUCTION
The goal of this paper to develop a general framework to
assess robustness in large consensus networks. Robustness
quantif
Original label:  cs.CV
Predicted label:  10
Correct label:  8
Text:  [CLS] 1 face recognition via centralized coordinate learning arxiv : 1801. 05678v1 [ ] 17 jan 2018 xianbiao qi, lei zhang abstract — owe to the rapid development of deep neural network ( dnn ) techniques and the emergence of large scale face databases, face recognition has achieved a great success in recent years. during the training process of dnn, the face features and classification vectors to be learned will interact with each other, while the distribution of face features will largely affect the convergence status of network and the face similarity computing in test stage. in this work, we formulate jointly the learning of face features and classification vectors, and propose a simple yet effective centralized coordinate learning ( ccl ) method, which enforces the features to be dispersedly spanned in the coordinate space while ensuring the classification vectors to lie on a hypersphere. an adaptive angular margin is further proposed to enhance the discrimination capability of face features. extensive experiments are conducted on six face benchmarks, including those have large age gap and hard negative samples. trained only on the small - scale casia webface dataset with 460k face images from about 10k subjects, our ccl model demonstrates high effectiveness and generality, showing consistently competitive performance across all the six benchmark databases. index terms — face recognition, cross age, similar looking, large - scale face identification. f 1 i ntroduction face recognition [ 1 ], [ 2 ], [ 3 ], [ 4 ], [ 5 ], [ 6 ], [ 7 ], [ 8 ], [ 9 ], [ 10 ], [ 11 ], [ 12 ] has a broad range of applications in our daily life, including access control, video surveillance, public safety, online payment, image search and family photo album management. as a classical yet active topic, face recognition has been extensively studied. one essential problem in face recognition is how to obtain discriminative face features. in the past, handcrafted local image descriptors, such as sift [ 13 ], hog [ 14 ], lbp [ 15 ] and its variants [ 16 ], [ 17 ], have been widely used to extract local face features. meanwhile, principal component analysis ( pca ) [ 1 ], linear discriminative analysis ( lda ) [ 18 ], and sparse representation ( sr ) [ 19 ], [ 20 ], [ 21 ], [ 22 ], [ 23 ] are also popular methods to construct a global face representation. face recognition [SEP]
Text from DS:  1

Face Recognition via Centralized Coordinate
Learning

arXiv:1801.05678v1 [] 17 Jan 2018

Xianbiao Qi, Lei Zhang
Abstract—Owe to the rapid development of deep neural network (DNN) techniques and the emergence of large scale face databases,
face recognition has achieved a great success in recent years. During the training process of DNN, the face features and classification
vectors to be learned will interact with each other, while the distribution of face features will largely affect the convergence status of
network and the face similarity computing in test stage. In this work, we formulate jointly the learning of face features and classification
vectors, and propose a simple yet effective centralized coordinate learning (CCL) method, which enforces the features to be
dispersedly spanned in the coordinate space while ensuring the classification vectors to lie on a hypersphere. An adaptive angular
margin is further proposed to enhance the discrimination capability of face features. E
Original label:  cs.IT
Predicted label:  10
Correct label:  8
Text:  [CLS] dispersion of mobile robots : a study of memory - time trade - offs arxiv : 1707. 05629v3 [ cs. dc ] 16 oct 2017 john augustine∗ william k. moses jr. † abstract we introduce a new problem in the domain of mobile robots, which we term dispersion. in this problem, n robots are placed in an n node graph arbitrarily and must coordinate with each other to reach a final configuration such that exactly one robot is at each node. we study this problem through the lenses of minimizing the memory required by each robot and of minimizing the number of rounds required to achieve dispersion. dispersion is of interest due to its relationship to the problems of scattering on a graph, exploration using mobile robots, and load balancing on a graph. additionally, dispersion has an immediate real world application due to its relationship to the problem of recharging electric cars, as each car can be considered a robot and recharging stations and the roads connecting them nodes and edges of a graph respectively. since recharging is a costly affair relative to traveling, we want to distribute these cars amongst the various available recharge points where communication should be limited to car - to - car interactions. we provide lower bounds on both the memory required for robots to achieve dispersion and the minimum running time to achieve dispersion on any type of graph. we then analyze the trade - offs between time and memory for various types of graphs. we provide time optimal and memory optimal algorithms for several types of graphs and show the power of a little memory in terms of running time. keywords : dispersion, load balancing, mobile robots, collective robot exploration, scattering, uniform deployment, graph algorithms, deterministic algorithms, distributed algorithms 1 1. 1 introduction background & motivation the use of mobile robots to solve global problems in a distributed manner is a new and interesting paradigm in problem solving. in it, each robot acts individually, but collectively the robots accomplish some goal that would be infeasible to solve using a global centralized approach. many important real world problems such as toxic hazard clean - up, large maze exploration, and gathering at one place can be modeled in this paradigm. we introduce a new problem in the domain of mobile robots, which we term dispersion. in this problem, n robots are placed in an n node graph arbitrarily and must coordinate with each other to reach a ﬁnal conﬁguration such that exactly one [SEP]
Text from DS:  Dispersion of Mobile Robots: A Study of Memory-Time Trade-offs

arXiv:1707.05629v3 [cs.DC] 16 Oct 2017

John Augustine∗

William K. Moses Jr.†

Abstract
We introduce a new problem in the domain of mobile robots, which we term dispersion. In this
problem, n robots are placed in an n node graph arbitrarily and must coordinate with each other to
reach a final configuration such that exactly one robot is at each node. We study this problem through
the lenses of minimizing the memory required by each robot and of minimizing the number of rounds
required to achieve dispersion.
Dispersion is of interest due to its relationship to the problems of scattering on a graph, exploration
using mobile robots, and load balancing on a graph. Additionally, dispersion has an immediate real world
application due to its relationship to the problem of recharging electric cars, as each car can be considered
a robot and recharging stations and the roads connecting them nodes and edges of a graph respectively.

Original label:  cs.SY
Predicted label:  1
Correct label:  2
Text:  [CLS] 1 differential dissipativity theory for dominance analysis arxiv : 1710. 01721v2 [ ] 5 oct 2017 fulvio forni, rodolphe sepulchre abstract — high - dimensional systems that have a lowdimensional dominant behavior allow for model reduction and simplified analysis. we use differential analysis to formalize this important concept in a nonlinear setting. we show that dominance can be studied through linear dissipation inequalities and an interconnection theory that closely mimics the classical analysis of stability by means of dissipativity theory. in this approach, stability is seen as the limiting situation where the dominant behavior is 0 - dimensional. the generalization opens novel tractable avenues to study multistability through 1 - dominance and limit cycle oscillations through 2 - dominance. i. i ntroduction the analysis of a system is considerably simplified when it is low - dimensional. linear system analysis frequently exploits the property that a few dominant poles capture the main properties of a possibly high - dimensional system. lowdimensional models are even more critical in nonlinear system analysis. multistability or limit cycle analysis is difficult beyond the phase plane analysis of two - dimensional systems. in this paper we seek to formalize the property that a nonlinear system has low - dimensional dominant behavior. our approach is differential : we characterize the property for linear systems and then study the nonlinear system differentially, that is, along the linearized flow in the tangent bundle. the seminal example of differential analysis in control theory is contraction analysis [ 26 ], [ 34 ], [ 15 ], [ 37 ], [ 43 ], which we interpret as a differential analysis of exponential stability. the property is the contraction of a ball, characterized via a lyapunov dissipation inequality. a nonlinear system is contractive when this dissipation inequality holds infinitesimally along any of its trajectories. in the present paper, the corresponding property is 0 - dominance : it ensures that the dominant behavior of the nonlinear system is 0 - dimensional. a more recent example of differential analysis is differential positivity [ 12 ], the differential analysis of positivity. the linear property is the contraction of a cone, also characterized by a dissipation inequality. a nonlinear system is differentially positive when this dissipation inequality holds infinitesimally along any of its trajectories. in the context of the present paper, the corresponding property is 1 [SEP]
Text from DS:  1

Differential dissipativity theory
for dominance analysis

arXiv:1710.01721v2 [] 5 Oct 2017

Fulvio Forni, Rodolphe Sepulchre

Abstract—High-dimensional systems that have a lowdimensional dominant behavior allow for model reduction and
simplified analysis. We use differential analysis to formalize
this important concept in a nonlinear setting. We show that
dominance can be studied through linear dissipation inequalities
and an interconnection theory that closely mimics the classical
analysis of stability by means of dissipativity theory. In this
approach, stability is seen as the limiting situation where the dominant behavior is 0-dimensional. The generalization opens novel
tractable avenues to study multistability through 1-dominance
and limit cycle oscillations through 2-dominance.

I. I NTRODUCTION
The analysis of a system is considerably simplified when
it is low-dimensional. Linear system analysis frequently exploits the property that a few dominant poles capture the
main proper
Original label:  math.GR
Predicted label:  2
Correct label:  8
Text:  [CLS] arxiv : 1607. 07156v1 [ ] 25 jul 2016 low growth equational complexity marcel jackson abstract. the equational complexity function βv : n → n of an equational class of algebras v bounds the size of equation required to determine membership of n - element algebras in v. known examples of finitely generated varieties v with unbounded equational complexity have growth in ω ( nc ), usually for c ≥ 21. we show that much slower growth is possible, exhibiting o ( log32 ( n ) ) growth amongst varieties of semilattice ordered inverse semigroups and additive idempotent semirings. we also examine a quasivariety analogue of equational complexity, and show that a finite group has polylogarithmic quasi - equational complexity function, bounded if and only if all sylow subgroups are abelian. 1. introduction in this article, an algebra means a universal algebra, though our primary focus is on the class of finite groups and finite semilattice - ordered semigroups. for a fixed signature s of operations, an equation is an expression u ≈ v, where u and v are terms in s. the equation is satisfied in an algebra in the signature s if all interpretations θ of the variables into the universe of the algebra results in uθ = vθ. the class of all s - algebras satisfying some given system of equations is called the variety defined by the equations. a variety is always closed under homomorphisms ( h ), isomorphic copies of subalgebras ( s ) and direct products ( p ), and conversely, every h, s, p closed class of similar algebras is a variety, definable by the equations holding true in all of its members ; see birkhoff [ 3 ] or a text such as burris and sankappanavar [ 4 ]. we let v ( k ) denote the the variety generated by a class k, and write v ( a ) to denote v ( { a } ) when a is a single algebra. a challenging computational problem arises when one wishes to decide membership of a finite algebra b in a variety v : even when v = v ( a ) for a finite algebra a, this problem can be as hard as 2exptime - complete ( kozik [ 17 ] ), and even amongst almost classical algebras, such as semigroups, there are examples for which the problem is np - hard ( jackson and mckenzie [SEP]
Text from DS:  arXiv:1607.07156v1 [] 25 Jul 2016

LOW GROWTH EQUATIONAL COMPLEXITY
MARCEL JACKSON
Abstract. The equational complexity function βV : N → N of an equational
class of algebras V bounds the size of equation required to determine membership of n-element algebras in V. Known examples of finitely generated
varieties V with unbounded equational complexity have growth in Ω(nc ), usually for c ≥ 21 . We show that much slower growth is possible, exhibiting
O(log32 (n)) growth amongst varieties of semilattice ordered inverse semigroups
and additive idempotent semirings. We also examine a quasivariety analogue
of equational complexity, and show that a finite group has polylogarithmic
quasi-equational complexity function, bounded if and only if all Sylow subgroups are abelian.

1. Introduction
In this article, an algebra means a universal algebra, though our primary focus
is on the class of finite groups and finite semilattice-ordered semigroups. For a
fixed signature S of operations, an equation i
Original label:  math.GR
Predicted label:  6
Correct label:  2
Text:  [CLS] on davenport constant benjamin girard arxiv : 1709. 08033v2 [ math. nt ] 8 apr 2018 abstract. we prove that for every fixed integer r > 1 the davenport constant r ) is asymptotic to rn when n tends to infinity. an extension of this d ( cn theorem to a wider framework is also provided. for every integer n > 1, let cn be the cyclic group of order n. it is well known that every non - trivial finite abelian group g can be uniquely decomposed as a direct product of cyclic groups cn1 ⊕ · · · ⊕cnr such that 1 < n1 | · · · | nr ∈ n. the integers r and nr - sometimes also denoted by exp ( g ) - appearing in this decomposition are respectively called the rank and exponent of g. for every integer 1 6 d | exp ( g ), we denote by gd the subgroup of g consisting of all elements of order dividing d. any finite sequence s of ℓ elements of g will be called a sequence over g of length | s | = ℓ. also, we denote by σ ( s ) the sum of all elements in s. the sequence s will be referred to as a zero - sum sequence whenever σ ( s ) = 0. by d ( g ) we denote the smallest integer t > 1 such that every sequence s over g of length | s | > t contains a non - empty zero - sum subsequence. this number, which is called the davenport constant, drew over the last fifty years an ever growing interest, most notably in additive combinatorics and algebraic number theory. a detailed account on the many aspects of this invariant can be found in [ 8, 10, 13, 17 ]. to name but one striking feature, let us recall the davenport constant has the following arithmetical interpretation. given the ring of integers ok of some number field k with ideal class group g, the maximum number of prime ideals in the decomposition of an irreducible element of ok is d ( g ) [ 22 ]. the importance of this fact is best highlighted by the following generalization of the prime number theorem [ 17, theorem 9. 15 ], stating that the number f ( x ) of pairwise non - associated irreducible elements in ok whose norms do not exceed x in absolute value satisfies, x ( log log x ) d ( g ) −1, f ( x ) [UNK] c x→ + ∞ log x with a [SEP]
Text from DS:  ON DAVENPORT CONSTANT
BENJAMIN GIRARD

arXiv:1709.08033v2 [math.NT] 8 Apr 2018

Abstract. We prove that for every fixed integer r > 1 the Davenport constant
r ) is asymptotic to rn when n tends to infinity. An extension of this
D(Cn
theorem to a wider framework is also provided.

For every integer n > 1, let Cn be the cyclic group of order n. It is well known
that every non-trivial finite Abelian group G can be uniquely decomposed as a direct
product of cyclic groups Cn1 ⊕· · ·⊕Cnr such that 1 < n1 | · · · | nr ∈ N. The integers
r and nr - sometimes also denoted by exp(G) - appearing in this decomposition are
respectively called the rank and exponent of G. For every integer 1 6 d | exp(G),
we denote by Gd the subgroup of G consisting of all elements of order dividing d.
Any finite sequence S of ℓ elements of G will be called a sequence over G of
length |S| = ℓ. Also, we denote by σ(S) the sum of all elements in S. The sequence
S will be referred to as a zero-sum sequence whenever σ(S) 
Original label:  math.ST
Predicted label:  2
Correct label:  6
Text:  [CLS] relaxation of the em algorithm via quantum annealing * arxiv : 1606. 01484v1 [ stat. ml ] 5 jun 2016 hideyuki miyahara and koji tsumura abstract — the em algorithm is a novel numerical method to obtain maximum likelihood estimates and is often used for practical calculations. however, many of maximum likelihood estimation problems are nonconvex, and it is known that the em algorithm fails to give the optimal estimate by being trapped by local optima. in order to deal with this difficulty, we propose a deterministic quantum annealing em algorithm by introducing the mathematical mechanism of quantum fluctuations into the conventional em algorithm because quantum fluctuations induce the tunnel effect and are expected to relax the difficulty of nonconvex optimization problems in the maximum likelihood estimation problems. we show a theorem that guarantees its convergence and give numerical experiments to verify its efficiency. i. introduction many of practical problems in engineering or the principles to explain the phenomena of nature are reduced into nonconvex optimization ; however, the research activity for nonconvex optimization is limited compared to that on convex optimization because it is fundamentally difficult to solve or analyze the problem in a sophisticated way. in order to solve this difficulty of nonconvex optimization, motivated by the physical process of annealing, kirkpatrick et al. [ 1 ], [ 2 ] proposed simulated annealing ( sa ). sa has attracted much attention in many fields because sa has the following two remarkable properties. the first one is that sa can be applied to any nonconvex problems. the second one is that its global convergence in some sense is guaranteed by geman and geman [ 3 ]. after that, quantum annealing ( qa ) was proposed by apolloni et al. [ 4 ]. in qa, the mathematical mechanism of quantum fluctuations is introduced, and it has been reported that qa can reduce computational costs in many difficult problems [ 5 ], [ 6 ], [ 7 ], [ 8 ], [ 9 ], [ 10 ], [ 11 ], [ 12 ], [ 13 ], [ 14 ]. despite the success of sa and qa, their computational costs are still huge, because the monte carlo method is used in most of their implementations and it requires much computational costs for convergence. on the other hand, in order to solve the nonconvex problem in data clustering, rose et al. [ 15 ], [ 16 ] proposed a deterministic simulated annealing approach, and it [SEP]
Text from DS:  Relaxation of the EM Algorithm via Quantum Annealing*

arXiv:1606.01484v1 [stat.ML] 5 Jun 2016

Hideyuki Miyahara and Koji Tsumura

Abstract— The EM algorithm is a novel numerical method
to obtain maximum likelihood estimates and is often used for
practical calculations. However, many of maximum likelihood
estimation problems are nonconvex, and it is known that the EM
algorithm fails to give the optimal estimate by being trapped by
local optima. In order to deal with this difficulty, we propose a
deterministic quantum annealing EM algorithm by introducing
the mathematical mechanism of quantum fluctuations into
the conventional EM algorithm because quantum fluctuations
induce the tunnel effect and are expected to relax the difficulty
of nonconvex optimization problems in the maximum likelihood
estimation problems. We show a theorem that guarantees
its convergence and give numerical experiments to verify its
efficiency.

I. Introduction
Many of practical problems in engineering or the pr
Original label:  cs.CV
Predicted label:  9
Correct label:  2
Text:  [CLS] arxiv : 1710. 04265v1 [ cs. na ] 11 oct 2017 solutions of quadratic first - order odes applied to computer vision problems plane curve reconstruction uah david casillas - perez and daniel pizarro october 13, 2017 supervisor : daniel pizarro abstract the article proves the existence of a maximum of two possible solutions to the initial value problem composed by the planar - perspective equation and an initial condition. this initial value problem has a geometric interpretation. solutions are curves than pass trough the initial condition which is point of the plane. 1 description of the problem let c be a regular curve in the plane r2 parameterized by the perspective parameterization x ( t ) = ρ ( t ) ( t, 1 ), where t ∈ i ⊂ r is an interval and ρ : i 7−→ r is the objective function. a complete description of parametric curves is available in any generic differential geometric book as kreyszig ( 1991 ). let u ( t ) be a function of class u ( t ) ∈ c 1 ( i, r ) defined in the interval i except for a finite number of points a where the function is of class u ( t ) ∈ c ∞ ( a, r ) and where the first - order derivative of the ρ function is null. the function u ( t ) is positive function in i and it has the geometric interpretation of being the square of the modulus of the velocity vector of the curve c. it means that u ( t ) = | | ~ v ( t ) | | 2. this function u ( t ) is known. consider the next non - linear firstorder ordinary differential equation ( ode ) ( strictly speaking, the equation is a differential algebraic equation dae ) : dρ 2 ε + ρ2 = u, ( 1 ) dt where ρ ( t ) is the function that we have to find which is positive or null ρ ( t ) ≥ 0. the function ε = ( 1 + t2 ) 2 is a polynomial of degree 4. the variable t is the independent variable. we consider the initial value problem ( ivp ) ( also called the cauchy problem ) composed by the equation 1 ( also called planar - perspective reconstruction equation ) with the initial condition ρ ( t0 ) = ρ0 in a neighborhood t0 ∈ j ⊂ i. the formal description of an initial value problem appear in the book tenenbaum and pollard ( 1985 ). 1 2 hypotheses we want to prove [SEP]
Text from DS:  arXiv:1710.04265v1 [cs.NA] 11 Oct 2017

Solutions of Quadratic First-Order ODEs applied to
Computer Vision Problems
Plane Curve Reconstruction
UAH
David Casillas-Perez and Daniel Pizarro
October 13, 2017

Supervisor:

Daniel Pizarro

Abstract
The article proves the existence of a maximum of two possible solutions to the initial value
problem composed by the planar-perspective equation and an initial condition. This initial
value problem has a geometric interpretation. Solutions are curves than pass trough the initial
condition which is point of the plane.

1

Description of the problem

Let C be a regular curve in the plane R2 parameterized by the perspective parameterization X(t) =
ρ(t)(t, 1), where t ∈ I ⊂ R is an interval and ρ : I 7−→ R is the objective function. A complete
description of parametric curves is available in any generic differential geometric book as Kreyszig
(1991). Let U (t) be a function of class U (t) ∈ C 1 (I, R) defined in the interval I except for a
finite numb
Original label:  cs.SY
Predicted label:  2
Correct label:  9
Text:  [CLS] optimal periodic locomotion for a two piece worm with an asymmetric dry friction model arxiv : 1710. 08546v1 [ math. oc ] 23 oct 2017 nak - seung patrick hyun1 and erik verriest2 abstract — this paper solves the optimization problem for a simplified one - dimensional worm model when the friction force depends on the direction of the motion. the motion of the worm is controlled by the actuator force f ( t ) which is assumed to be piecewise continuous and always generates the same force in the opposite directions. the paper derives the necessary condition for the force which maximizes the average velocity or minimizes the power over a unit distance. the maximum excursion of the worm body and the force are bounded. a simulation is given at the end of the paper. in this paper, we first list the variables that are commonly used in this paper, and define the model which includes the friction model and the actuator model. second, we suggest two performance indices to be optimized and state the problem formally. third, we solve the problem analytically and find the necessary conditions for the optimal solution. lastly, we provide one simulation example to understand the solution better. ii. m odeling i. i ntroduction the locomotion for legless animals, such as a snake and a worm, has many interesting features. one of the most appealing characteristics of these types of animal is that the periodic change in its shape generates the motion in a certain direction. scales on the animal ’ s skin create different friction forces depending on the direction of the movement. due to this asymmetric friction, these types of animal, such as snake or worm, can move forward. as a result, many researchers have focused on analyzing the periodic kinematics and dynamics of the legless animal locomotion in an asymmetric friction model, verriest [ 1 ] and zimmermann [ 2 ]. even for a simplified one - dimensional worm model it is complicated to analyze its full dynamics. in the past years, a lot of research analyzed the one - dimensional toy problem in depth, zimmermann [ 3 ] and chernousko [ 4 ]. especially, the book [ 3 ] has successfully characterized the kinematics and dynamics of the one - dimensional worm problem. several researchers, figurina [ 5 ] and bolotnik [ 6 ], have attempted to solve the optimization problem for a similar one - dimensional worm problem. chernousko [ 4 ] has [SEP]
Text from DS:  Optimal periodic locomotion for a two piece worm with an asymmetric
dry friction model

arXiv:1710.08546v1 [math.OC] 23 Oct 2017

Nak-seung Patrick Hyun1 and Erik Verriest2
Abstract— This paper solves the optimization problem for a
simplified one-dimensional worm model when the friction force
depends on the direction of the motion. The motion of the worm
is controlled by the actuator force f (t) which is assumed to be
piecewise continuous and always generates the same force in the
opposite directions. The paper derives the necessary condition
for the force which maximizes the average velocity or minimizes
the power over a unit distance. The maximum excursion of the
worm body and the force are bounded. A simulation is given
at the end of the paper.

In this paper, we first list the variables that are commonly
used in this paper, and define the model which includes the
friction model and the actuator model. Second, we suggest
two performance indices to be optimized and state the
problem 
Original label:  cs.IT
Predicted label:  8
Correct label:  3
Text:  [CLS] arxiv : 1706. 04680v2 [ math. oc ] 10 feb 2018 accelerated extra - gradient descent : a novel accelerated first - order method∗ jelena diakonikolas and lorenzo orecchia computer science department, boston university email : { jelenad, orecchia } @ bu. edu abstract we provide a novel accelerated first - order method that achieves the asymptotically optimal convergence rate for smooth functions in the first - order oracle model. to this day, nesterov ’ s accelerated gradient descent ( agd ) and variations thereof were the only methods achieving acceleration in this standard blackbox model. in contrast, our algorithm is significantly different from agd, as it relies on a predictor - corrector approach similar to that used by mirror - prox [ 18 ] and extra - gradient descent [ 14 ] in the solution of convex - concave saddle point problems. for this reason, we dub our algorithm accelerated extra - gradient descent ( axgd ). its construction is motivated by the discretization of an accelerated continuous - time dynamics [ 15 ] using the classical method of implicit euler discretization. our analysis explicitly shows the effects of discretization through a conceptually novel primal - dual viewpoint. moreover, we show that the method is quite general : it attains optimal convergence rates for other classes of objectives ( e. g., those with generalized smoothness properties or that are non - smooth and lipschitz - continuous ) using the appropriate choices of step lengths. finally, we present experiments showing that our algorithm matches the performance of nesterov ’ s method, while appearing more robust to noise in some cases. 1 introduction first - order methods for convex optimization have come to play an important role in the design of algorithms and in theoretical computer science in general, with applications including numerical methods [ 13, 30 ], graph algorithms [ 12, 29 ], submodular optimization [ 8 ] and complexity theory [ 11 ]. a classical setting for convex optimization is that of smooth optimization, i. e., minimizing a convex differentiable function f over a convex set x ⊆ rn, with the smoothness assumption that the gradient of f be l - lipschitz continuous1 for some positive real l, i. e. : [UNK] x, y ∈ x, k∇f ( x ) − ∇f ( y ) k∗ ≤ l · kx − yk. in this setting, it is also assumed that the algorithm [SEP]
Text from DS:  arXiv:1706.04680v2 [math.OC] 10 Feb 2018

Accelerated Extra-Gradient Descent:
A Novel Accelerated First-Order Method∗
Jelena Diakonikolas and Lorenzo Orecchia
Computer Science Department, Boston University
email: {jelenad, orecchia}@bu.edu

Abstract
We provide a novel accelerated first-order method that achieves the asymptotically optimal convergence rate for smooth functions in the first-order oracle model. To this day, Nesterov’s Accelerated
Gradient Descent (agd) and variations thereof were the only methods achieving acceleration in
this standard blackbox model. In contrast, our algorithm is significantly different from agd, as it
relies on a predictor-corrector approach similar to that used by Mirror-Prox [18] and Extra-Gradient
Descent [14] in the solution of convex-concave saddle point problems. For this reason, we dub our
algorithm Accelerated Extra-Gradient Descent (axgd).
Its construction is motivated by the discretization of an accelerated continuous-time dynamics [15]
using 
Original label:  cs.AI
Predicted label:  6
Correct label:  2
Text:  [CLS] multimodal word distributions ben athiwaratkun cornell university pa338 @ cornell. edu arxiv : 1704. 08424v1 [ stat. ml ] 27 apr 2017 abstract word embeddings provide point representations of words containing useful semantic information. we introduce multimodal word distributions formed from gaussian mixtures, for multiple word meanings, entailment, and rich uncertainty information. to learn these distributions, we propose an energy - based max - margin objective. we show that the resulting approach captures uniquely expressive semantic information, and outperforms alternatives, such as word2vec skip - grams, and gaussian embeddings, on benchmark datasets such as word similarity and entailment. 1 introduction to model language, we must represent words. we can imagine representing every word with a binary one - hot vector corresponding to a dictionary position. but such a representation contains no valuable semantic information : distances between word vectors represent only differences in alphabetic ordering. modern approaches, by contrast, learn to map words with similar meanings to nearby points in a vector space ( mikolov et al., 2013a ), from large datasets such as wikipedia. these learned word embeddings have become ubiquitous in predictive tasks. vilnis and mccallum ( 2014 ) recently proposed an alternative view, where words are represented by a whole probability distribution instead of a deterministic point vector. specifically, they model each word by a gaussian distribution, and learn its mean and covariance matrix from data. this approach generalizes any deterministic point embedding, which can be fully captured by the mean vector of the gaussian distribution. moreover, the full distribution provides much richer information andrew gordon wilson cornell university andrew @ cornell. edu than point estimates for characterizing words, representing probability mass and uncertainty across a set of semantics. however, since a gaussian distribution can have only one mode, the learned uncertainty in this representation can be overly diffuse for words with multiple distinct meanings ( polysemies ), in order for the model to assign some density to any plausible semantics ( vilnis and mccallum, 2014 ). moreover, the mean of the gaussian can be pulled in many opposing directions, leading to a biased distribution that centers its mass mostly around one meaning while leaving the others not well represented. in this paper, we propose to represent each word with an expressive multimodal distribution, for multiple distinct meanings, en [SEP]
Text from DS:  Multimodal Word Distributions

Ben Athiwaratkun
Cornell University
pa338@cornell.edu

arXiv:1704.08424v1 [stat.ML] 27 Apr 2017

Abstract
Word embeddings provide point representations of words containing useful semantic information. We introduce multimodal
word distributions formed from Gaussian
mixtures, for multiple word meanings, entailment, and rich uncertainty information. To learn these distributions, we propose an energy-based max-margin objective. We show that the resulting approach
captures uniquely expressive semantic information, and outperforms alternatives,
such as word2vec skip-grams, and Gaussian embeddings, on benchmark datasets
such as word similarity and entailment.

1

Introduction

To model language, we must represent words.
We can imagine representing every word with a
binary one-hot vector corresponding to a dictionary position. But such a representation contains
no valuable semantic information: distances between word vectors represent only differences in
alphabet
Original label:  cs.NE
Predicted label:  3
Correct label:  8
Text:  [CLS] role of zero synapses in unsupervised feature learning haiping huang arxiv : 1703. 07943v4 [ q - bio. nc ] 10 jan 2018 riken brain science institute, wako - shi, saitama 351 - 0198, japan ( dated : january 11, 2018 ) synapses in real neural circuits can take discrete values including zero ( silent or potential ) synapses. the computational role of zero synapses in unsupervised feature learning of unlabeled noisy data is still unclear, thus it is important to understand how the sparseness of synaptic activity is shaped during learning and its relationship with receptive field formation. here, we formulate this kind of sparse feature learning by a statistical mechanics approach. we find that learning decreases the fraction of zero synapses, and when the fraction decreases rapidly around a critical data size, an intrinsically structured receptive field starts to develop. further increasing the data size refines the receptive field, while a very small fraction of zero synapses remain to act as contour detectors. this phenomenon is discovered not only in learning a handwritten digits dataset, but also in learning retinal neural activity measured in a natural - movie - stimuli experiment. pacs numbers : 02. 50. tt, 87. 19. l -, 75. 10. nr introduction sparsity in either neural activity or synaptic connectivity plays an important role in sensory information processing across brain areas [ 1, 2 ]. sparsity constraints imposed on neural activity in a sparse coding model [ 3 ] reproduce gabor - like filters ( edge detectors ), which resemble receptive fields of simple cells in the mammalian primary visual cortex. the sparse representation was also applied to deep belief networks to model hierarchical representations of natural image statistics [ 4 ], which capture higher order features at deeper levels of the cortical hierarchy. in addition, from a perspective of optimal information storage, there must exist a large fraction of silent or potential synapses [ 5 ], consistent with the existence of these synapses in cortex and cerebellum [ 6 ]. these ( zero ) synapses are vital for plasticity during learning [ 5 ]. therefore, the sparse representation in synaptic connectivity is also appealing in optimal neural computation. most artificial neural networks are trained by supervised learning, which requires a large library of images prelabeled with categories. however, unsupervised learning gives humans and [SEP]
Text from DS:  Role of zero synapses in unsupervised feature learning
Haiping Huang

arXiv:1703.07943v4 [q-bio.NC] 10 Jan 2018

RIKEN Brain Science Institute, Wako-shi, Saitama 351-0198, Japan
(Dated: January 11, 2018)
Synapses in real neural circuits can take discrete values including zero (silent or potential)
synapses. The computational role of zero synapses in unsupervised feature learning of unlabeled
noisy data is still unclear, thus it is important to understand how the sparseness of synaptic activity
is shaped during learning and its relationship with receptive field formation. Here, we formulate this
kind of sparse feature learning by a statistical mechanics approach. We find that learning decreases
the fraction of zero synapses, and when the fraction decreases rapidly around a critical data size, an
intrinsically structured receptive field starts to develop. Further increasing the data size refines the
receptive field, while a very small fraction of zero synapses remain to act as contour de
Original label:  cs.IT
Predicted label:  2
Correct label:  9
Text:  [CLS] fast and space - optimal low - rank factorization in the streaming model with application in differential privacy jalaj upadhyay∗ pennsylvania state university arxiv : 1604. 01429v3 [ ] 20 may 2016 jalaj @ psu. edu abstract in this paper, we consider the problem of computing a low - rank factorization of an m × n matrix in the general turnstile update model. we consider both the private and non - private setting. 1. in the non - private setting, we give a space - optimal algorithm that computes a low - rank factorization. our algorithm maintains three sketches of the matrix instead of five as in boutsidis et al. e ( stoc 2016 ). our algorithm takes o ( 1 ) time to update the sketch and computes the factorization in time linear in the sparsity and the dimensions of the matrix. 2. in the private setting, we study low - rank factorization in the framework of differential privacy and under turnstile updates. we give two algorithms with respect to two levels of privacy. both of our privacy levels are stronger than earlier studied privacy levels, namely that of blocki et al. ( focs 2012 ), dwork et al. ( stoc 2014 ), hardt and roth ( stoc 2012, stoc 2013 ), and hardt and price ( nips 2014 ). ( a ) in our first level of privacy, priv1, we consider two matrices as neighboring if their difference has a form uvt for some unit vectors u and v. our private algorithm with respect to priv1 matches the optimal space bound up to a logarithmic factor and is optimal in the terms of the additive error incurred. the algorithm is also efficient and takes time linear in the input sparsity of the matrix and quadratic in min { m, n }. p our bound quantitatively improve the result of hardt and roth ( stoc 2012 ) by a factor of k log ( 1 / δ ) when m ≤ n, a scenario considered by hardt and roth ( stoc 2012 ). ( b ) our second level, priv2, generalizes priv1. in priv2, we consider two matrices as neighboring if their difference has unit frobenius norm. our private algorithm with respect to priv2 is computationally more efficient than our first algorithm – it uses o ( log ( m + n ) ) time to update and computes the factorization in time [SEP]
Text from DS:  Fast and Space-optimal Low-rank Factorization in the Streaming
Model With Application in Differential Privacy
Jalaj Upadhyay∗
Pennsylvania State University

arXiv:1604.01429v3 [] 20 May 2016

jalaj@psu.edu

Abstract
In this paper, we consider the problem of computing a low-rank factorization of an m × n matrix in
the general turnstile update model. We consider both the private and non-private setting.
1. In the non-private setting, we give a space-optimal algorithm that computes a low-rank factorization. Our algorithm maintains three sketches of the matrix instead of five as in Boutsidis et al.
e
(STOC 2016). Our algorithm takes O(1)
time to update the sketch and computes the factorization
in time linear in the sparsity and the dimensions of the matrix.
2. In the private setting, we study low-rank factorization in the framework of differential privacy and
under turnstile updates. We give two algorithms with respect to two levels of privacy. Both of our
privacy levels are stronger than 
Original label:  cs.IT
Predicted label:  3
Correct label:  2
Text:  [CLS] arxiv : 1510. 02004v1 [ math. nt ] 2 oct 2015 m. levin ’ s construction of absolutely normal numbers with very low discrepancy nicolas alvarez and veronica becher abstract. among the currently known constructions of absolutely normal numbers, the one given by mordechay levin in 1979 achieves the lowest discrepancy bound. in this work we analyze this construction in terms of computability and computational complexity. we show that, under basic assumptions, it yields a computable real number. the construction does not give the digits of the fractional expansion explicitly, but it gives a sequence of increasing approximations whose limit is the announced absolutely normal −n number. the n - th approximation has an error less than 22. to obtain the n - th approximation the construction requires, in the worst case, a number of mathematical operations that is double exponential in n. we consider variants on the construction that reduce the computational complexity at the expense of an increment in discrepancy. 1. introduction normal numbers were introduced by borel in 1909 [ 8 ]. a real number α is normal to an integer base λ greater than or equal to 2 if its fractional expansion in base λ given by x dx where each dx is in { 0, 1,..., λ − 1 }, α − [UNK] α [UNK] = λx x≥1 is such that, for each positive integer k, each fixed block of digits of length k appears in ( dx ) x≥1 with asymptotic frequency λ−k. borel calls a number absolutely normal if it is normal to every integer base greater than or equal to 2. let ( ξx ) x≥0 be an arbitrary sequence of real numbers in the unit interval. the quantity d ( p, ( ξx ) x≥0 ) = sup γ∈ ( 0, 1 ] # { x : 0 ≤ x < p and ξx < γ } −γ p p −1 is the discrepancy of ( ξx ) x = 0. the sequence ( ξx ) x≥0 is uniformly distributed in the unit interval if d ( p, ( ξx ) x≥0 ) goes to 0 when p goes to infinity. by a theorem of d. wall [ 9, theorem 4. 14 ], a real number α is normal to base λ if, and only if, the sequence { αλx } x≥0, where { ξ } = [SEP]
Text from DS:  arXiv:1510.02004v1 [math.NT] 2 Oct 2015

M. LEVIN’S CONSTRUCTION OF ABSOLUTELY NORMAL
NUMBERS WITH VERY LOW DISCREPANCY
NICOLÁS ALVAREZ AND VERÓNICA BECHER

Abstract. Among the currently known constructions of absolutely normal
numbers, the one given by Mordechay Levin in 1979 achieves the lowest discrepancy bound. In this work we analyze this construction in terms of computability and computational complexity. We show that, under basic assumptions, it yields a computable real number. The construction does not give
the digits of the fractional expansion explicitly, but it gives a sequence of
increasing approximations whose limit is the announced absolutely normal
−n
number. The n-th approximation has an error less than 22 . To obtain the
n-th approximation the construction requires, in the worst case, a number of
mathematical operations that is double exponential in n. We consider variants
on the construction that reduce the computational complexity at the expense
of an increment in 
Original label:  cs.CV
Predicted label:  7
Correct label:  2
Text:  [CLS] arxiv : 1802. 02534v2 [ ] 8 feb 2018 fixatons : a collection of human fixations datasets and metrics for scanpath similarity dario zanca∗1, 2, valeria serchi3, pietro piu3, francesca rosini3, 4, and alessandra rufa3, 4 1 department of information engineering, university of florence, 2 department of information engineering and mathematics, university florence, italy of siena, siena, italy and visual application lab ( evalab ), department of medicine, surgery and neurosciences, university of siena, siena, italy 4 neurological and neurometabolic unit, department of medicine, surgery and neurosciences, university of siena, siena, italy 3 eye - tracking ∗ corresponding author : dario. zanca @ unifi. it 1 contents 1 introduction 3 2 datasets included in the collection 2. 1 siena12............... 2. 1. 1 protocol for data collection in 2. 2 other datasets............ 2. 2. 1 mit1003........... 3 3 3 5 5...... siena12............................................................................ 3 online resources 6 4 structure of the fixatons collection 7 5 software included 5. 1 list information.. 5. 2 get data ( matrices ) 5. 3 visualize data.... 5. 4 compute metrics.. 5. 5 compute statistics. 5. 6 example of use.............................................................................................................. [SEP]
Text from DS:  arXiv:1802.02534v2 [] 8 Feb 2018

FixaTons: A collection of Human Fixations
Datasets and Metrics for Scanpath Similarity
Dario Zanca∗1,2 , Valeria Serchi3 , Pietro Piu3 ,
Francesca Rosini3,4 , and Alessandra Rufa3,4
1 Department of Information Engineering, University of Florence,
2 Department of Information Engineering and Mathematics, University

Florence, Italy
of Siena, Siena, Italy
and Visual Application Lab (EVALab), Department of Medicine, Surgery and Neurosciences,
University of Siena, Siena, Italy
4 Neurological and Neurometabolic Unit, Department of Medicine, Surgery and Neurosciences, University of Siena,
Siena, Italy
3 Eye-tracking

∗

Corresponding Author: dario.zanca@unifi.it

1

Contents
1 Introduction

3

2 Datasets included in the collection
2.1 SIENA12 . . . . . . . . . . . . . . .
2.1.1 Protocol for data collection in
2.2 Other Datasets . . . . . . . . . . . .
2.2.1 MIT1003 . . . . . . . . . . .

3
3
3
5
5

. . . . . .
SIENA12
. . . . . .
. . . . . .

.
.
.
.

.
.
.

Original label:  cs.PL
Predicted label:  1
Correct label:  2
Text:  [CLS] 1 safeguarding millimeter wave communications against randomly located eavesdroppers arxiv : 1801. 09391v1 [ ] 29 jan 2018 ying ju, hui - ming wang, senior member, ieee, tong - xing zheng, member, ieee, qinye yin, and moon ho lee, life senior member, ieee abstract — millimeter wave offers a sensible solution to the capacity crunch faced by 5g wireless communications. this paper comprehensively studies physical layer security in a multi - input single - output ( miso ) millimeter wave system where multiple single - antenna eavesdroppers are randomly located. concerning the specific propagation characteristics of millimeter wave, we investigate two secure transmission schemes, namely maximum ratio transmitting ( mrt ) beamforming and artificial noise ( an ) beamforming. specifically, we first derive closed - form expressions of the connection probability for both schemes. we then analyze the secrecy outage probability ( sop ) in both non - colluding eavesdroppers and colluding eavesdroppers scenarios. also, we maximize the secrecy throughput under a sop constraint, and obtain optimal transmission parameters, especially the power allocation between an and the information signal for an beamforming. numerical results are provided to verify our theoretical analysis. we observe that the density of eavesdroppers, the spatially resolvable paths of the destination and eavesdroppers all contribute to the secrecy performance and the parameter design of millimeter wave systems. index terms — physical layer security, millimeter wave, multipath, stochastic geometry, artificial noise, secrecy outage, secrecy throughput. i. i ntroduction driven by an increasing number of smart devices and wireless data applications, an explosive growth of demand for spectrum in wireless communications appears during the past years. exploiting millimeter wave becomes a promising approach for providing plentiful spectrum resources to improve the system capacity [ 1 ], [ 2 ]. following this trend, the study on millimeter wave communications has attracted great research affords. millimeter wave channel modeling [ 3 ], [ 4 ], beamforming schemes [ 5 ] - [ 9 ] and network performance [ 10 ], [ 11 ] have been investigated intensively in the past few years. it becomes a promising candidate for the 5g cellular system. given the open feature of the wireless channels, security is a significant concern when designing wireless transmission schemes. physical layer security has become a popular way to improve the secrecy performance of wireless communication systems by utilizing wireless [SEP]
Text from DS:  1

Safeguarding Millimeter Wave Communications
Against Randomly Located Eavesdroppers

arXiv:1801.09391v1 [] 29 Jan 2018

Ying Ju, Hui-Ming Wang, Senior Member, IEEE, Tong-Xing Zheng, Member, IEEE, Qinye Yin,
and Moon Ho Lee, Life Senior Member, IEEE

Abstract—Millimeter wave offers a sensible solution to the capacity crunch faced by 5G wireless communications. This paper
comprehensively studies physical layer security in a multi-input
single-output (MISO) millimeter wave system where multiple
single-antenna eavesdroppers are randomly located. Concerning
the specific propagation characteristics of millimeter wave, we
investigate two secure transmission schemes, namely maximum
ratio transmitting (MRT) beamforming and artificial noise (AN)
beamforming. Specifically, we first derive closed-form expressions
of the connection probability for both schemes. We then analyze
the secrecy outage probability (SOP) in both non-colluding
eavesdroppers and colluding eavesdroppers scenarios. Also, we

Original label:  math.AC
Predicted label:  9
Correct label:  2
Text:  [CLS] to appear in j. pure appl. algebra on the spectrum of rings of functions arxiv : 1604. 04866v2 [ ] 8 sep 2017 sophie frisch abstract. for d a domain and e ⊆ d, we investigate the prime q spectrum of rings of functions from e to d, that is, of rings contained in e∈e d and containing d. among other things, we characterize, when m is a maximal ideal of finite index in d, thoseqprime ideals lying above m which contain the kernel of the canonical map to e∈e ( d / m ) as being precisely the prime ideals corresponding to ultrafilters on e. we give a sufficient condition for when all primes above m are of this form and thus establish a correspondence to the prime spectra of ultraproducts of residue class rings of d. as a corollary, we obtain a description using ultrafilters, differing from chabert ’ s original one which uses elements of the m - adic completion, of the prime ideals in the ring of integer - valued polynomials int ( d ) lying above a maximal ideal of finite index. 1. introduction q let d be an integral domain, e ⊆ d, and r a subring of e∈e d, containing d. the elements of r can be interpreted as functions from e to d and, consequently, we call r a ring of functions from e to d. we will investigate the prime spectra of such rings of functions. we obtain, for quite general r, a partial description of the prime spectrum, cf. theorems 3. 7 and 5. 3, and in special cases a complete characterization, cf. corollary 6. 5. our motivation is the spectrum of a ring of integer - valued polynomials : for d an integral domain with quotient ﬁeld k, let int ( d ) = { f ∈ k [ x ] | f ( d ) ⊆ d } be the ring of integer - valued polynomials on d. more generally, when k is understood, we let int ( a, b ) = { f ∈ k [ x ] | f ( a ) ⊆ b } for a, b ⊆ k. if d is a noetherian one - dimensional domain, a celebrated theorem of chabert [ 1, ch. v ] states that every prime ideal of int ( d ) lying over a maximal ideal m of ﬁnite index in d is maximal and of the form mα = { f ∈ int ( d [SEP]
Text from DS:  To appear in J. Pure Appl. Algebra

ON THE SPECTRUM OF RINGS OF FUNCTIONS

arXiv:1604.04866v2 [] 8 Sep 2017

SOPHIE FRISCH
Abstract. For D a domain and E ⊆ D, we investigate the prime
Q spectrum
of rings of functions from E to D, that is, of rings contained in e∈E D and
containing D. Among other things, we characterize, when M is a maximal
ideal of finite index in D, thoseQprime ideals lying above M which contain the
kernel of the canonical map to e∈E (D/M ) as being precisely the prime ideals
corresponding to ultrafilters on E. We give a sufficient condition for when
all primes above M are of this form and thus establish a correspondence to
the prime spectra of ultraproducts of residue class rings of D. As a corollary,
we obtain a description using ultrafilters, differing from Chabert’s original one
which uses elements of the M -adic completion, of the prime ideals in the ring of
integer-valued polynomials Int(D) lying above a maximal ideal of finite index.

1. Introduction

Q
Let D b
Original label:  cs.AI
Predicted label:  6
Correct label:  2
Text:  [CLS] knowledge graph completion via complex tensor factorization theo trouillon theo. trouillon @ imag. fr univ. grenoble alpes, 700 avenue centrale, 38401 saint martin d ’ heres, france christopher r. dance arxiv : 1702. 06879v2 [ ] 26 nov 2017 chris. dance @ xrce. xerox. com naver labs europe, 6 chemin de maupertuis, 38240 meylan, france eric gaussier eric. gaussier @ imag. fr univ. grenoble alpes, 700 avenue centrale, 38401 saint martin d ’ heres, france johannes welbl sebastian riedel j. welbl @ cs. ucl. ac. uk s. riedel @ cs. ucl. ac. uk university college london, gower st, london wc1e 6bt, united kingdom guillaume bouchard g. bouchard @ cs. ucl. ac. uk bloomsbury ai, 115 hampstead road, london nw1 3ee, united kingdom university college london, gower st, london wc1e 6bt, united kingdom abstract in statistical relational learning, knowledge graph completion deals with automatically understanding the structure of large knowledge graphs — labeled directed graphs — and predicting missing relationships — labeled edges. state - of - the - art embedding models propose different trade - offs between modeling expressiveness, and time and space complexity. we reconcile both expressiveness and complexity through the use of complex - valued embeddings and explore the link between such complex - valued embeddings and unitary diagonalization. we corroborate our approach theoretically and show that all real square matrices — thus all possible relation / adjacency matrices — are the real part of some unitarily diagonalizable matrix. this results opens the door to a lot of other applications of square matrices factorization. our approach based on complex embeddings is arguably simple, as it only involves a hermitian dot product, the complex counterpart of the standard dot product between real vectors, whereas other methods resort to more and more complicated composition functions to increase their expressiveness. the proposed complex embeddings are scalable to large data sets as it remains linear in both space and time, while consistently outperforming alternative approaches on standard link prediction benchmarks. 1 keywords : complex embeddings, tensor factorization, knowledge graph, matrix completion, statistical [SEP]
Text from DS:  Knowledge Graph Completion via Complex Tensor
Factorization
Théo Trouillon

theo.trouillon@imag.fr
Univ. Grenoble Alpes, 700 avenue Centrale, 38401 Saint Martin d’Hères, France

Christopher R. Dance

arXiv:1702.06879v2 [] 26 Nov 2017

chris.dance@xrce.xerox.com
NAVER LABS Europe, 6 chemin de Maupertuis, 38240 Meylan, France

Éric Gaussier

eric.gaussier@imag.fr
Univ. Grenoble Alpes, 700 avenue Centrale, 38401 Saint Martin d’Hères, France

Johannes Welbl
Sebastian Riedel

j.welbl@cs.ucl.ac.uk
s.riedel@cs.ucl.ac.uk
University College London, Gower St, London WC1E 6BT, United Kingdom

Guillaume Bouchard

g.bouchard@cs.ucl.ac.uk
Bloomsbury AI, 115 Hampstead Road, London NW1 3EE, United Kingdom
University College London, Gower St, London WC1E 6BT, United Kingdom

Abstract
In statistical relational learning, knowledge graph completion deals with automatically understanding the structure of large knowledge graphs—labeled directed graphs—
and predicting missing relationships—labeled edges.
Original label:  math.AC
Predicted label:  7
Correct label:  10
Text:  [CLS] arxiv : 1212. 0515v2 [ ] 23 mar 2013 apolarity for determinants and permanents of generic matrices masoumeh ( sepideh ) shafiei department of mathematics, northeastern university, boston, ma 02115, usa march 2013 abstract we show that the apolar ideals to the determinant and permanent of a generic matrix, the pfaffian of a generic skew symmetric matrix and the hafnian of a generic symmetric matrix are each generated in degree two. in each case we specify the generators and a grobner basis of the apolar ideal. as a consequence, using a result of k. ranestad and f. - o. schreyer we give lower bounds to the cactus rank and rank of each of these invariants. we compare these bounds with those obtained by j. landsberg and z. teitler. 1 introduction this paper is originally motivated by a question from zach teitler about the generating degree of the annihilator ideal of the determinant and the permanent of a generic n × n matrix. here annihilator is meant in the sense of the apolar pairing, i. e. macaulay ’ s inverse system. our main result is that the apolar ideals of the determinant and of the permanent of a generic matrix are generated in degree 2 ( theorems 2. 12 and 2. 13 ). the reason for teitler ’ s interest in this problem is the recent paper by kristian ranestad and frank - olaf schreyer [ rs ], which gives a lower bound for smoothable rank, border rank and cactus rank of a homogeneous polynomial in terms of the generating degree of the apolar ideal and the dimension of the artinian apolar algebra defined by the apolar ideal. we apply this and our result to bounding the scheme / cactus length of the determinant and the permanent of the generic matrix ( theorem 3. 5 ). in section 4 we give the analogous result for the annihilator ideal of the pfaffian of a generic skew symmetric matrix ( theorem 4. 11 ) and the annihilator of the hafnian of a generic symmetric matrix ( theorem 4. 14 ) in a sequel paper [ sh2 ] we study the apolar ideal of the determinant and permanent of the generic symmetric matrix. 1 let k be a field of characteristic zero or characteristic p > 2, and let a = ( aij ) [SEP]
Text from DS:  arXiv:1212.0515v2 [] 23 Mar 2013

Apolarity for determinants and permanents of generic
matrices
Masoumeh (Sepideh) Shafiei
Department of Mathematics, Northeastern University, Boston, MA 02115, USA

March 2013
Abstract
We show that the apolar ideals to the determinant and permanent of a generic
matrix, the Pfaffian of a generic skew symmetric matrix and the Hafnian of a generic
symmetric matrix are each generated in degree two. In each case we specify the generators and a Gröbner basis of the apolar ideal. As a consequence, using a result of
K. Ranestad and F.-O. Schreyer we give lower bounds to the cactus rank and rank of
each of these invariants. We compare these bounds with those obtained by J. Landsberg
and Z. Teitler.

1

Introduction

This paper is originally motivated by a question from Zach Teitler about the generating
degree of the annihilator ideal of the determinant and the permanent of a generic n × n
matrix. Here annihilator is meant in the sense of the apolar pairing, i.e
Original label:  cs.IT
Predicted label:  5
Correct label:  2
Text:  [CLS] arxiv : 1504. 08011v2 [ ] 17 dec 2015 a comparison of approaches for finding minimum identifying codes on graphs victoria horan ∗ air force research laboratory information directorate steve adachi † lockheed martin stanley bak ‡ air force research laboratory information directorate december 18, 2015 abstract in order to formulate mathematical conjectures likely to be true, a number of base cases must be determined. however, many combinatorial problems are np - hard and the computational complexity makes this research approach difficult using a standard brute force approach on a typical computer. one sample problem explored is that of finding a minimum identifying code. to work around the computational issues, a variety of methods are explored and consist of a parallel computing approach using matlab, an adiabatic quantum optimization approach using a d - wave quantum annealing processor, and lastly using satisfiability modulo theory ( smt ) and corresponding smt solvers. each of these methods requires the problem to be formulated in a unique manner. in this paper, we address the challenges of computing solutions to this np - hard problem with respect to each of these methods. ∗ victoria. horan. 1 @ us. af. mil, corresponding author † steven. h. adachi @ lmco. com ‡ stanley. bak. 1 @ us. af. mil approved for public release ; distribution unlimited : 88abw - 2015 - 2163, dis201511002. 1 1 problem statement and background first introduced in 1998 [ 13 ], an identifying code for a graph g is a subset of the vertices, s ⊆ v ( g ), such that for each v ∈ v ( g ) the subset of vertices of s that are adjacent to v is non - empty and unique. that is, each vertex of the graph is uniquely identifiable by the non - empty subset of vertices of s to which it is adjacent. more formally, let n ( v ) be the set of vertices adjacent to v and b ( v ) = n ( v ) ∪ { v }. then we require that any two vertices u, v ∈ v ( g ) have different identifying sets, or more precisely that we must have s ∩ b ( v ) 6 = s ∩b ( u ), and also that both s ∩b ( v ), s ∩b ( u ) 6 = ∅. the combinatorial problem of finding minimum identifying codes has been shown to be np - complete [ 6 ], but also has many potential real - world applications. [SEP]
Text from DS:  arXiv:1504.08011v2 [] 17 Dec 2015

A Comparison of Approaches for Finding
Minimum Identifying Codes on Graphs
Victoria Horan ∗
Air Force Research Laboratory
Information Directorate
Steve Adachi †
Lockheed Martin
Stanley Bak ‡
Air Force Research Laboratory
Information Directorate
December 18, 2015

Abstract
In order to formulate mathematical conjectures likely to be true, a
number of base cases must be determined. However, many combinatorial problems are NP-hard and the computational complexity makes this
research approach difficult using a standard brute force approach on a
typical computer. One sample problem explored is that of finding a minimum identifying code. To work around the computational issues, a variety
of methods are explored and consist of a parallel computing approach using Matlab, an adiabatic quantum optimization approach using a D-Wave
quantum annealing processor, and lastly using satisfiability modulo theory
(SMT) and corresponding SMT solvers. Each of these methods 
Original label:  cs.IT
Predicted label:  1
Correct label:  2
Text:  [CLS] epr - dictionaries : a practical and fast data structure for constant time searches in unidirectional and bidirectional fm - indices christopher [UNK], marcel [UNK], and knut [UNK] [UNK] [UNK] arxiv : 1608. 02413v2 [ ] 17 nov 2016 department of computer science and mathematics, freie universitat berlin, germany abstract. the unidirectional fm index was introduced by ferragina and manzini in 2000 and allows to search a pattern in the index in one direction. the bidirectional fm index ( 2fm ) was introduced by lam et al. in 2009. it allows to search for a pattern by extending an infix of the pattern arbitrarily to the left or right. the method of lam et al. can conduct one step in time o ( σ ) while needing space o ( σ · n ) using constant time rank queries on bit vectors. schnattinger and colleagues improved this time to o ( log σ ) while using o ( log σ · n ) bits of space for both, the fm and 2fm index. this is achieved by the use of binary wavelet trees. in this paper we introduce a new, practical method for conducting an exact search in a uni - and bidirectional fm index in o ( 1 ) time per step while using o ( log σ · n ) + o ( log σ · σ · n ) bits of space. this is done by replacing the binary wavelet tree by a new data structure, the enhanced prefixsum rank dictionary ( epr - dictionary ). we implemented this method in the seqan c + + library and experimentally validated our theoretical results. in addition we compared our implementation with other freely available implementations of bidirectional indices and show that we are between ≈ 2. 6 − 4. 8 times faster. this will have a large impact for many bioinformatics applications that rely on practical implementations of ( 2 ) fm indices e. g. for read mapping. to our knowledge this is the first implementation of a constant time method for a search step in 2fm indices. keywords : fm index, bidirectional, bwt, bit vector, rank queries, read mapping. 1 introduction it is seldom that new data structures or algorithms have such a large practical impact as full text indices had for biological sequence analysis. the so - called next - generation sequencing ( ngs ) allows to produce billions of small [SEP]
Text from DS:  EPR-dictionaries: A practical and fast data
structure for constant time searches in
unidirectional and bidirectional FM-indices
Christopher Pockrandt⋆, Marcel Ehrhardt⋆⋆ , and Knut Reinert⋆ ⋆ ⋆

arXiv:1608.02413v2 [] 17 Nov 2016

Department of Computer Science and Mathematics, Freie Universität Berlin, Germany

Abstract. The unidirectional FM index was introduced by Ferragina and
Manzini in 2000 and allows to search a pattern in the index in one direction.
The bidirectional FM index (2FM) was introduced by Lam et al. in 2009. It
allows to search for a pattern by extending an infix of the pattern arbitrarily
to the left or right. The method of Lam et al. can conduct one step in time
O(σ) while needing space O(σ · n) using constant time rank queries on bit
vectors. Schnattinger and colleagues improved this time to O(log σ) while using
O(log σ · n) bits of space for both, the FM and 2FM index. This is achieved
by the use of binary wavelet trees.
In this paper we introduce a new, practica
Original label:  cs.SY
Predicted label:  2
Correct label:  6
Text:  [CLS] sparsity preserving optimal control of discretized pde systems arxiv : 1801. 05194v3 [ math. oc ] 20 feb 2018 aleksandar habera, ∗, michel verhaegenb a department of engineering science and physics, city university of new york, college of staten island, new york 10314, usa b delft center for systems and control, delft university of technology, 2628 cd delft, the netherlands abstract we focus on the problem of optimal control of large - scale systems whose models are obtained by discretization of partial differential equations using the finite element ( fe ) or finite difference ( fd ) methods. the motivation for studying this pressing problem originates from the fact that the classical numerical tools used to solve low - dimensional optimal control problems are computationally infeasible for large - scale systems. furthermore, although the matrices of large - scale fe or fd models are usually sparse banded or highly structured, the optimal control solution computed using the classical methods is dense and unstructured. consequently, it is not suitable for efficient centralized and distributed real - time implementations. we show that the a priori ( sparsity ) patterns of the exact solutions of the generalized lyapunov equations for fe and fd models are banded matrices. the a priori pattern predicts the dominant non - zero entries of the exact solution. we furthermore show that for wellconditioned problems, the a priori patterns are not only banded but also sparse matrices. on the basis of these results, we develop two computationally efficient methods for computing sparse approximate solutions of generalized lyapunov equations. using these two methods and the inexact newton method, we show that the solution of the generalized riccati equation can be approximated by a banded matrix. this enables us to develop a novel computationally efficient optimal control approach that is able to preserve the sparsity of the control law. we perform extensive numerical experiments that demonstrate the effectiveness of our approach. keywords : finite element methods ; optimal control ; large - scale systems ; riccati equation ; lyapunov equation. ∗ corresponding author email address : aleksandar. haber @ gmail. com ; aleksandar. haber @ csi. cuny. edu ( aleksandar haber ) preprint submitted to computer methods in applied mechanics and engineeringfebruary 21, 2018 1. introduction large - scale systems with the dynamics described by partial differential equations [SEP]
Text from DS:  Sparsity Preserving Optimal Control of Discretized
PDE Systems

arXiv:1801.05194v3 [math.OC] 20 Feb 2018

Aleksandar Habera,∗, Michel Verhaegenb
a Department

of Engineering Science and Physics, City University of New York, College of
Staten Island, New York 10314, USA
b Delft Center for Systems and Control, Delft University of Technology, 2628 CD Delft, The
Netherlands

Abstract
We focus on the problem of optimal control of large-scale systems whose models
are obtained by discretization of partial differential equations using the Finite
Element (FE) or Finite Difference (FD) methods. The motivation for studying this pressing problem originates from the fact that the classical numerical
tools used to solve low-dimensional optimal control problems are computationally infeasible for large-scale systems. Furthermore, although the matrices of
large-scale FE or FD models are usually sparse banded or highly structured,
the optimal control solution computed using the classical methods is dens
Original label:  math.ST
Predicted label:  8
Correct label:  10
Text:  [CLS] arxiv : 1609. 07696v1 [ ] 25 sep 2016 the independence process in conditional quantile location - scale models and an application to testing for monotonicity melanie birke natalie neumeyer stanislav volgushev∗ universitat bayreuth universitat hamburg university of toronto september 27, 2016 abstract in this paper the nonparametric quantile regression model is considered in a locationscale context. the asymptotic properties of the empirical independence process based on covariates and estimated residuals are investigated. in particular an asymptotic expansion and weak convergence to a gaussian process are proved. the results can, on the one hand, be applied to test for validity of the location - scale model. on the other hand, they allow to derive various specification tests in conditional quantile location - scale models. in detail a test for monotonicity of the conditional quantile curve is investigated. for the test for validity of the location - scale model as well as for the monotonicity test smooth residual bootstrap versions of kolmogorov - smirnov and cramer - von mises type test statistics are suggested. we give rigorous proofs for bootstrap versions of the weak convergence results. the performance of the tests is demonstrated in a simulation study. ams classification : 62g10, 62g08, 62g30 keywords and phrases : bootstrap, empirical independence process, kolmogorov - smirnov test, model test, monotone rearrangements, nonparametric quantile regression, residual processes, sequential empirical process ∗ the authors would like to thank two anonymous referees and the associate editor for careful reading and for very constructive suggestions to improve the paper. our special thanks go to one of the referees for several very careful readings of the manuscript and insightful comments. part of this work was conducted while stanislav volgushev was postdoctoral fellow at the ruhr university bochum, germany. during that time stanislav volgushev was supported by the sonderforschungsbereich “ statistical modelling of nonlinear dynamic processes ” ( sfb 823 ), teilprojekt ( c1 ), of the deutsche forschungsgemeinschaft. 1 1 introduction quantile regression was introduced by koenker and bassett ( 1978 ) as an extension of least squares methods focusing on the estimation of the conditional mean function. due to its many attractive features as robustness with respect to [SEP]
Text from DS:  arXiv:1609.07696v1 [] 25 Sep 2016

The independence process in conditional
quantile location-scale models and an
application to testing for monotonicity
Melanie Birke

Natalie Neumeyer

Stanislav Volgushev∗

Universität Bayreuth

Universität Hamburg

University of Toronto

September 27, 2016

Abstract
In this paper the nonparametric quantile regression model is considered in a locationscale context. The asymptotic properties of the empirical independence process based
on covariates and estimated residuals are investigated. In particular an asymptotic
expansion and weak convergence to a Gaussian process are proved. The results can,
on the one hand, be applied to test for validity of the location-scale model. On the
other hand, they allow to derive various specification tests in conditional quantile
location-scale models. In detail a test for monotonicity of the conditional quantile
curve is investigated. For the test for validity of the location-scale model as well as
for the monotoni
Original label:  math.GR
Predicted label:  1
Correct label:  2
Text:  [CLS] arxiv : 1702. 03439v1 [ ] 11 feb 2017 on number of isomorphism classes of derived subgroups l. jafari taghvasani and s. marzang abstract. in this paper we show that a finite nonabelian characteristically simple group g satisfying n = | π ( g ) | + 2 if and only if g [UNK] = a5, where n is the number of isomorphism classes of derived subgroups of g and π ( g ) is the set of prime divisors of the group g. also, we give a negative answer to a question raised in [ 11 ]. keywords. derived subgroup ; simple group. mathematics subject classification ( 2000 ). 20f24, 20e14. 1. introduction and results following [ 1 ], we say that a group g has the property grn if it has a finite number n of derived subgroups. in 2005, de giovanni and robinson [ 1 ] and, independently, herzog, longobardi, maj in [ 5 ] studied new finiteness conditions related to the derived subgroups of a group. they proved that every locally graded grn group is finite - by - abelian ( or g ′ is finite ). more recently the author in [ 11 ], has been improved this result, by proving that every locally graded grn - group is nilpotentby - abelian - by - ( finite of order ≤ k! ) - by - abelian. subsequently, the authors in [ 6, 7 ], investigated the class of groups which have at most n isomorphism classes of derived subgroups ( denoted by dn ) with n ∈ { 2, 3 }. clearly a group is d1 - group if and only if it is abelian. also the authors, in [ 7 ], classified completely the locally finite d3 - groups. it seems interesting to study groups grn - groups with a given value for n. in this paper, among other things, we first show that for every nonabelian characteristically simple dn - group g, n ≥ | π ( g ) | + 2. moreover, we show that this inequality is proper unless for the alternating group a5. in fact, we have the following new characterization of a5 as follows : theorem 1. 1. for every nonabelian characteristically simple dn - group g we have n = | π ( g ) | + 2 if and only if g [UNK] = a5. finally, [SEP]
Text from DS:  arXiv:1702.03439v1 [] 11 Feb 2017

ON NUMBER OF ISOMORPHISM CLASSES OF DERIVED
SUBGROUPS
L. JAFARI TAGHVASANI AND S. MARZANG
Abstract. In this paper we show that a finite nonabelian characteristically
simple group G satisfying n = |π(G)| + 2 if and only if G ∼
= A5 , where n is the
number of isomorphism classes of derived subgroups of G and π(G) is the set
of prime divisors of the group G. Also, we give a negative answer to a question
raised in [11].
Keywords. derived subgroup; simple group.
Mathematics Subject Classification (2000). 20F24, 20E14.

1. Introduction and results
Following [1], we say that a group G has the property GRn if it has a finite
number n of derived subgroups. In 2005, de Giovanni and Robinson [1] and, independently, Herzog, Longobardi, Maj in [5] studied new finiteness conditions related
to the derived subgroups of a group. They proved that every locally graded GRn group is finite-by-abelian (or G′ is finite). More recently the author in [11], has been
improved t
Original label:  cs.AI
Predicted label:  3
Correct label:  10
Text:  [CLS] arxiv : 1704. 08101v1 [ cs. db ] 25 apr 2017 event stream - based process discovery using abstract representations s. j. van zelst∗, b. f. van dongen, and w. m. p. van der aalst department of mathematics and computer science eindhoven university of technology p. o. box 513, 5600 mb eindhoven, the netherlands april 27, 2017 abstract the aim of process discovery, originating from the area of process mining, is to discover a process model based on business process execution data. a majority of process discovery techniques relies on an event log as an input. an event log is a static source of historical data capturing the execution of a business process. in this paper we focus on process discovery relying on online streams of business process execution events. learning process models from event streams poses both challenges and opportunities, i. e. we need to handle unlimited amounts of data using finite memory and, preferably, constant time. we propose a generic architecture that allows for adopting several classes of existing process discovery techniques in context of event streams. moreover, we provide several instantiations of the architecture, accompanied by implementations in the process mining tool - kit prom1. using these instantiations, we evaluate several dimensions of stream - based process discovery. the evaluation shows that the proposed architecture allows us to lift process discovery to the streaming domain. 1 introduction process mining [ 2 ] aims at understanding and improving business processes. the field consists of three main branches, i. e. process discovery, conformance checking and process enhancement. process discovery aims at discovering a process model based on event data. conformance checking is concerned with assessing whether a process model and event data conform to each other in terms ∗ corresponding author : s. j. v. zelst @ tue. nl 1 http : / / promtools. org 1 of possible behaviour. process enhancement is concerned with improvement of process models based on knowledge gained from event data, e. g. a process model is extended with performance diagnostics based on event data. several process discovery algorithms exist [ 4, 5, 24, 30, 45, 48 ]. these algorithms all use an event log as an input. an event log is a static data source describing sequences of executed business process activities recorded over a historical time - span. as the number of events recorded for operational processes is growing tremendously every year, so does the average event log size. conventional process discovery techniques are not able to [SEP]
Text from DS:  arXiv:1704.08101v1 [cs.DB] 25 Apr 2017

Event Stream-Based Process Discovery using
Abstract Representations
S.J. van Zelst∗, B.F. van Dongen, and W.M.P. van der Aalst
Department of Mathematics and Computer Science
Eindhoven University of Technology
P.O. Box 513, 5600 MB Eindhoven, The Netherlands
April 27, 2017

Abstract
The aim of process discovery, originating from the area of process mining, is to discover a process model based on business process execution
data. A majority of process discovery techniques relies on an event log as
an input. An event log is a static source of historical data capturing the execution of a business process. In this paper we focus on process discovery
relying on online streams of business process execution events. Learning
process models from event streams poses both challenges and opportunities, i.e. we need to handle unlimited amounts of data using finite memory
and, preferably, constant time. We propose a generic architecture that allows for adopting 
Original label:  cs.AI
Predicted label:  5
Correct label:  9
Text:  [CLS] investigating the impact of data volume and domain similarity on transfer learning applications michael bernico∗, yuntao li †, dingchao zhang ‡ arxiv : 1712. 04008v2 [ ] 3 jan 2018 state farm mutual insurance abstract transfer learning helps to build a system to recognize and apply knowledge and experience learned in previous tasks ( source task ) to new tasks or new domains ( target task ), which share some commonality. the two important factors that impact the performance of transfer learning models are : ( a ) the size of the target dataset and ( b ) the similarity in distribution between source and target domains. thus far there has been little investigation into just how important these factors are. in this paper, we investigated the impact of target dataset size and source / target domain similarity on model performance through a series of experiments. we found that more data is always beneficial, and that model performance improved linearly with the log of data size, until we were out of data. as source / target domains differ, more data is required and fine tuning will render better performance than feature extraction. when source / target domains are similar and data size is small, fine tuning and feature extraction renders equivalent performance. we hope that our study inspires further work in transfer learning, which continues to be a very important technique for developing practical machine learning applications in business domains. 1 introduction for many applications of computer vision, data is in short supply. while convolutional neural networks ( convnets ) trained on large datasets such as imagenet [ 1 ] with the benefit of massive computational power have revolutionized computer vision, many business applications of computer vision has limited relevant data. many researchers and machine learning engineers have had great success in addressing this problem by utilizing transfer learning [ 2 ]. with transfer learning the knowledge from a network trained on a large dataset such as imagenet ( source domain ) are transferred to another problem domain ( target domain ). there are a variety of techniques that can be applied to accomplish this, however most commonly the final network layers of the original network are replaced with layers more suitable for the target domain and the network is then trained on data related to that target domain. this network benefits from the learnings of the original network, allowing the network to perform its task using significantly less training data. ∗ michael. bernico. qepz @ statefarm. com yuntao. li. e0b5 @ statefarm. com ‡ dingchao. zhang. ejlq [SEP]
Text from DS:  Investigating the Impact of Data Volume and Domain
Similarity on Transfer Learning Applications
Michael Bernico∗, Yuntao Li†, Dingchao Zhang‡

arXiv:1712.04008v2 [] 3 Jan 2018

State Farm Mutual Insurance

Abstract
Transfer learning helps to build a system to recognize and apply knowledge and experience learned in previous tasks (source task) to new tasks or new domains (target task),
which share some commonality. The two important factors that impact the performance
of transfer learning models are: (a) the size of the target dataset and (b) the similarity
in distribution between source and target domains. Thus far there has been little investigation into just how important these factors are. In this paper, we investigated the
impact of target dataset size and source/target domain similarity on model performance
through a series of experiments. We found that more data is always beneficial, and that
model performance improved linearly with the log of data size, until we were out of data
Original label:  math.AC
Predicted label:  7
Correct label:  10
Text:  [CLS] analogs of jacobian conditions for subrings arxiv : 1601. 01508v1 [ ] 7 jan 2016 piotr jedrzejewicz, janusz zielinski abstract we present a generalization of the jacobian conjecture for m polynomials in n variables : f1,..., fm ∈ k [ x1,..., xn ], where k is a field of characteristic zero and m ∈ { 1,..., n }. we express the generalized jacobian condition in terms of irreducible and square - free elements of the subalgebra k [ f1,..., fm ]. we also discuss obtained properties in a more general setting – for subrings of unique factorization domains. introduction the jacobian conjecture asserts that if k is a ﬁeld of characteristic zero and polynomials f1,..., fn ∈ k [ x1,..., xn ] satisfy the jacobian condition ( 1 ) jac ( f1,..., fn ) ∈ k \ { 0 } ( where jac denotes the jacobian determinant ), then k [ f1,..., fn ] = k [ x1,..., xn ]. in terms of endomorphisms of the polynomial algebra k [ x1,..., xn ] : if a k - endomorphism [UNK] satisﬁes the jacobian condition ( 2 ) jac ( [UNK] ( x1 ),..., [UNK] ( xn ) ) ∈ k \ { 0 }, then [UNK] is an automorphism. for more information on the jacobian conjecture we refer the reader to van den essen ’ s book [ 7 ]. in section 1 we present and discuss the following generalization of the jacobian conjecture, denoted by jc ( m, n, k ), where k is a ﬁeld of characteristic zero, n is a positive integer, m ∈ { 1,..., n } and jac denotes the jacobian determinant with respect to given variables : keywords : jacobian conjecture, irreducible element, square - free element. 2010 mathematics subject classification : primary 13f20, secondary 14r15, 13n15. 1 ” for arbitrary polynomials f1,..., fm ∈ k [ x1,..., xn ], if ( 3 ) m gcd jacfx1i, [SEP]
Text from DS:  Analogs of Jacobian conditions for subrings
arXiv:1601.01508v1 [] 7 Jan 2016

Piotr Jedrzejewicz,
Janusz Zieliński
֒
Abstract
We present a generalization of the Jacobian Conjecture for m polynomials in n variables: f1 , . . . , fm ∈ k[x1 , . . . , xn ], where k is a field
of characteristic zero and m ∈ {1, . . . , n}. We express the generalized
Jacobian condition in terms of irreducible and square-free elements of
the subalgebra k[f1 , . . . , fm ]. We also discuss obtained properties in
a more general setting – for subrings of unique factorization domains.

Introduction
The Jacobian Conjecture asserts that if k is a ﬁeld of characteristic zero
and polynomials f1 , . . . , fn ∈ k[x1 , . . . , xn ] satisfy the Jacobian condition
(1)

jac(f1 , . . . , fn ) ∈ k \ {0}

(where jac denotes the Jacobian determinant), then k[f1 , . . . , fn ] = k[x1 , . . . ,
xn ]. In terms of endomorphisms of the polynomial algebra k[x1 , . . . , xn ]: if
a k-endomorphism ϕ satisﬁes the Jacobian condition
(2
Original label:  math.AC
Predicted label:  1
Correct label:  2
Text:  [CLS] the derived category analogue of the hartshorne - lichtenbaum vanishing theorem arxiv : 1208. 4447v1 [ ] 22 aug 2012 marziyeh hatamkhani and kamran divaani - aazar abstract. let a be an ideal of a local ring ( r, m ) and x a d - dimensional homologically bounded complex of r - modules whose all homology modules are finitely generated. we show that had ( x ) = 0 if b r b + p > 0 for all prime ideals p of r such that dim r / p − inf ( x ⊗r r ) p = d. and only if dim r / a 1. introduction the hartshorne - lichtenbaum vanishing theorem is one of the most important results in the theory of local cohomology modules. there are several proofs known now of this result ; see e. g. [ bh ], [ cs ] and [ sc ]. also, there are several generalizations of this result. the second named author, naghipour and tousi [ dnt ] have extended it to local cohomology with support in stable under specialization subsets. takahashi, yoshino and yoshizawa [ tyy ] have extended it to local cohomology with respect to pairs of ideals. also, more recently, the hartshorne - lichtenbaum vanishing theorem is extended to generalized local cohomology modules ; see [ dh ]. our aim in this paper is to establish a generalization of the hartshorne - lichtenbaum vanishing theorem which contains all of these generalizations. we do this by establishing the derived category analogue of the hartshorne - lichtenbaum vanishing theorem. for giving the precise statement of this result, we need to fix some notation. throughout, r is a commutative noetherian ring with nonzero identity. the derived category of rmodules is denoted by d ( r ). we use the symbol [UNK] for denoting isomorphisms in d ( r ). for a complex x ∈ d ( r ), its supremum and infimum are defined, respectively, by sup x : = sup { i ∈ z | hi ( x ) 6 = 0 } and inf x : = inf { i ∈ z | hi ( x ) 6 = 0 }, with the usual convention that sup ∅ = −∞ and inf ∅ = ∞. also, amplitude of x is [SEP]
Text from DS:  THE DERIVED CATEGORY ANALOGUE OF THE
HARTSHORNE-LICHTENBAUM VANISHING THEOREM

arXiv:1208.4447v1 [] 22 Aug 2012

MARZIYEH HATAMKHANI AND KAMRAN DIVAANI-AAZAR

Abstract. Let a be an ideal of a local ring (R, m) and X a d-dimensional homologically bounded
complex of R-modules whose all homology modules are finitely generated. We show that Had (X) = 0 if
b R
b + p > 0 for all prime ideals p of R̂ such that dim R̂/p − inf(X ⊗R R̂)p = d.
and only if dim R/a

1. Introduction
The Hartshorne-Lichtenbaum Vanishing Theorem is one of the most important results in the theory
of local cohomology modules. There are several proofs known now of this result; see e.g. [BH], [CS] and
[Sc]. Also, there are several generalizations of this result. The second named author, Naghipour and
Tousi [DNT] have extended it to local cohomology with support in stable under specialization subsets.
Takahashi, Yoshino and Yoshizawa [TYY] have extended it to local cohomology with respect to pairs of
ideals. Also, more rec
Original label:  cs.AI
Predicted label:  1
Correct label:  9
Text:  [CLS] a traversable fixed size small object allocator in c + + christian schußlera, b, roland gruberb { roland. gruber and christian. schuessler } @ iis. fraunhofer. de arxiv : 1611. 01667v2 [ ] 8 nov 2016 a b technische hochschule nurnberg department production monitoring, fraunhofer ezrt abstract at the allocation and deallocation of small objects with fixed size, the standard allocator of the runtime system has commonly a worse time performance compared to allocators adapted for a special application field. we propose a memory allocator, originally developed for mesh primitives but also usable for any other small equally sized objects. for a large amount of objects it leads to better results than allocating data with the c + + new instruction and behaves nowhere worse. the proposed synchronization approach for this allocator behaves lock - free in practical scenarios without using machine instructions, such as compare - and - swap. a traversal structure is integrated requiring less memory than using containers such as stl - vectors or lists, but with comparable time performance. keywords : small object allocation, traversable memory allocator, non - blocking memory allocator 1. introduction at the allocation and deallocation of huge amounts of small objects, a specialized memory allocator leads to better performance than using the standard allocator of the runtime system. the purpose of this algorithm is to allocate and deallocate mesh primitives. this means vertices, edges, and faces. a mesh often consists of millions of them. however, this allocator can be applied to any application having the same requirements. we give a brief introduction to the data structures of the implemented memory allocator in the first section. afterwards we describe how to preserve the consistency of the traversing data structure in the allocator after a deallocation. for multithreaded applications a synchronization approach is proposed. the result section shows the time performance and memory consumption of the implemented allocator. 1 2. concepts and data structures a common approach for custom memory allocation is to pre - allocate a large memory block and split it into small pieces, which are then assigned to the user. this is often called region - based - memory management [ 1, 2, 3, 4 ]. we call a memory block a bin, the small pieces corresponding to the individual requested [SEP]
Text from DS:  A Traversable Fixed Size Small Object Allocator in C++
Christian Schüßlera,b , Roland Gruberb
{roland.gruber and christian.schuessler}@iis.fraunhofer.de

arXiv:1611.01667v2 [] 8 Nov 2016

a

b

Technische Hochschule Nürnberg
Department production monitoring, Fraunhofer EZRT

Abstract
At the allocation and deallocation of small objects with fixed size, the standard allocator of the runtime system has commonly a worse time performance
compared to allocators adapted for a special application field.
We propose a memory allocator, originally developed for mesh primitives
but also usable for any other small equally sized objects.
For a large amount of objects it leads to better results than allocating data
with the C++new instruction and behaves nowhere worse. The proposed
synchronization approach for this allocator behaves lock-free in practical
scenarios without using machine instructions, such as compare-and-swap.
A traversal structure is integrated requiring less memory than using cont
Original label:  cs.CV
Predicted label:  7
Correct label:  3
Text:  [CLS] ieee transactions on multimedia, vol.?, no.?,? 2018 1 cross - media similarity evaluation for web image retrieval in the wild arxiv : 1709. 01305v2 [ ] 6 jan 2018 jianfeng dong, xirong li, and duanqing xu abstract — in order to retrieve unlabeled images by textual queries, cross - media similarity computation is a key ingredient. although novel methods are continuously introduced, little has been done to evaluate these methods together with large - scale query log analysis. consequently, how far have these methods brought us in answering real - user queries is unclear. given baseline methods that use relatively simple text / image matching, how much progress have advanced models made is also unclear. this paper takes a pragmatic approach to answering the two questions. queries are automatically categorized according to the proposed query visualness measure, and later connected to the evaluation of multiple cross - media similarity models on three test sets. such a connection reveals that the success of the stateof - the - art is mainly attributed to their good performance on visual - oriented queries, which account for only a small part of real - user queries. to quantify the current progress, we propose a simple text2image method, representing a novel query by a set of images selected from large - scale query log. consequently, computing cross - media similarity between the query and a given image boils down to comparing the visual similarity between the given image and the selected images. image retrieval experiments on the challenging clickture dataset show that the proposed text2image is a strong baseline, comparing favorably to recent deep learning alternatives. index terms — web image retrieval, real - user query, crossmedia similarity computation. i. i ntroduction ince the early 1990s how to retrieve unlabeled images by textual queries has been a grand challenge in multimedia retrieval, and remains hot to this day [ 1 ] – [ 4 ]. in order to understand and exploit the interplay between visual content, textual query and user behaviors, web image retrieval demands multi - modal approaches [ 5 ] – [ 7 ] and thus makes it right at the heart of the multimedia field. as image and query are two distinct modalities, a cross - media similarity metric that effectively reflects image - query relevance is essential. the key to cross - media similarity computation is to represent both images and queries in a common space [ 9 ] – [ 14 ]. while the idea is simple, constructing a proper [SEP]
Text from DS:  IEEE TRANSACTIONS ON MULTIMEDIA , VOL. ?, NO. ?, ? 2018

1

Cross-Media Similarity Evaluation for
Web Image Retrieval in the Wild

arXiv:1709.01305v2 [] 6 Jan 2018

Jianfeng Dong, Xirong Li, and Duanqing Xu

Abstract—In order to retrieve unlabeled images by textual
queries, cross-media similarity computation is a key ingredient.
Although novel methods are continuously introduced, little has
been done to evaluate these methods together with large-scale
query log analysis. Consequently, how far have these methods
brought us in answering real-user queries is unclear. Given
baseline methods that use relatively simple text/image matching,
how much progress have advanced models made is also unclear.
This paper takes a pragmatic approach to answering the two
questions. Queries are automatically categorized according to
the proposed query visualness measure, and later connected to
the evaluation of multiple cross-media similarity models on three
test sets. Such a connection reveals that the su
Original label:  cs.CV
Predicted label:  3
Correct label:  9
Text:  [CLS] arxiv : 1709. 02940v1 [ ] 9 sep 2017 how to train triplet networks with 100k identities? chong wang orion star beijing, china xue zhang orion star beijing, china xipeng lan orion star beijing, china chongwang. nlpr @ gmail. com yuannixue @ 126. com xipeng. lan @ gmail. com lfw accuracy / # sample in each identity ( n ) abstract softmax 100 training triplet networks with large - scale data is challenging in face recognition. due to the number of possible triplets explodes with the number of samples, previous studies adopt the online hard negative mining ( ohnm ) to handle it. however, as the number of identities becomes extremely large, the training will suffer from bad local minima because effective hard triplets are difficult to be found. to solve the problem, in this paper, we propose training triplet networks with subspace learning, which splits the space of all identities into subspaces consisting of only similar identities. combined with the batch ohnm, hard triplets can be found much easier. experiments on the large - scale msceleb - 1m challenge with 100k identities demonstrate that the proposed method can largely improve the performance. in addition, to deal with heavy noise and large - scale retrieval, we also make some efforts on robust noise removing and efficient image retrieval, which are used jointly with the subspace learning to obtain the state - of - the - art performance on the ms - celeb - 1m competition ( without external data in challenge1 ). 96. 73 triplet 97. 96 97. 16 98. 26 98. 06 95 90 87. 16 85 80 n = 2 n = 5 n = 10 figure 1. the lfw accuracy of the models trained with softmax and triplet loss with the number of samples in each class set to be 2, 5 and 10. the model is trained on ms - celeb - 1m [ 2 ] with 100k identities, and the evaluation is given by lfw [ 6 ]. size, while the small batchsize will take too long to train. another reason is that if only a few samples are available in each class, training with softmax loss is difficult, and fig. 1 shows its influence on softmax and triplet loss with 100k identities. the triplet performs much better when the number of samples in each class is small ( n = 2 ). though the advantage is [SEP]
Text from DS:  arXiv:1709.02940v1 [] 9 Sep 2017

How to Train Triplet Networks with 100K Identities?
Chong Wang
Orion Star
Beijing, China

Xue Zhang
Orion Star
Beijing, China

Xipeng Lan
Orion Star
Beijing, China

chongwang.nlpr@gmail.com

yuannixue@126.com

xipeng.lan@gmail.com

LFW accuracy / #sample in each identity(n)

Abstract

Softmax

100

Training triplet networks with large-scale data is challenging in face recognition. Due to the number of possible triplets explodes with the number of samples, previous
studies adopt the online hard negative mining(OHNM) to
handle it. However, as the number of identities becomes extremely large, the training will suffer from bad local minima
because effective hard triplets are difficult to be found. To
solve the problem, in this paper, we propose training triplet
networks with subspace learning, which splits the space of
all identities into subspaces consisting of only similar identities. Combined with the batch OHNM, hard triplets can
be found much easier. 
Original label:  cs.NE
Predicted label:  8
Correct label:  10
Text:  [CLS] deepsafe : a data - driven approach for checking adversarial robustness in neural networks divya gopinath1, guy katz2, corina s. pasareanu1, and clark barrett2 1 arxiv : 1710. 00486v1 [ ] 2 oct 2017 carnegie mellon university silicon valley divgml @ gmail. com, corina. pasareanu @ west. cmu. edu, corina. s. pasareanu @ nasa. gov 2 stanford university guyk @ cs. stanford. edu, barrett @ cs. stanford. edu abstract. deep neural networks have become widely used, obtaining remarkable results in domains such as computer vision, speech recognition, natural language processing, audio recognition, social network filtering, machine translation, and bio - informatics, where they have produced results comparable to human experts. however, these networks can be easily “ fooled ” by adversarial perturbations : minimal changes to correctly - classified inputs, that cause the network to misclassify them. this phenomenon represents a concern for both safety and security, but it is currently unclear how to measure a network ’ s robustness against such perturbations. existing techniques are limited to checking robustness around a few individual input points, providing only very limited guarantees. we propose a novel approach for automatically identifying safe regions of the input space, within which the network is robust against adversarial perturbations. the approach is data - guided, relying on clustering to identify well - defined geometric regions as candidate safe regions. we then utilize verification techniques to confirm that these regions are safe or to provide counter - examples showing that they are not safe. we also introduce the notion of targeted robustness which, for a given target label and region, ensures that a nn does not map any input in the region to the target label. we evaluated our technique on the mnist dataset and on a neural network implementation of a controller for the next - generation airborne collision avoidance system for unmanned aircraft ( acas xu ). for these networks, our approach identified multiple regions which were completely safe as well as some which were only safe for specific labels. it also discovered several adversarial perturbations of interest. 1 introduction in recent years, advances in deep neural networks ( nn ) have enabled the representation and modeling of complex non - linear relationships. in this paper, we study a common use of nn as classifiers that take in complex, [SEP]
Text from DS:  DeepSafe: A Data-driven Approach for Checking
Adversarial Robustness in Neural Networks
Divya Gopinath1 , Guy Katz2 , Corina S. Păsăreanu1 , and Clark Barrett2
1

arXiv:1710.00486v1 [] 2 Oct 2017

Carnegie Mellon University Silicon Valley
divgml@gmail.com,
corina.pasareanu@west.cmu.edu, corina.s.pasareanu@nasa.gov
2
Stanford University
guyk@cs.stanford.edu, barrett@cs.stanford.edu

Abstract. Deep neural networks have become widely used, obtaining remarkable results in domains such as computer vision, speech recognition, natural language processing, audio recognition, social network filtering, machine translation, and bio-informatics, where they have produced results comparable to human
experts. However, these networks can be easily “fooled” by adversarial perturbations: minimal changes to correctly-classified inputs, that cause the network
to misclassify them. This phenomenon represents a concern for both safety and
security, but it is currently unclear how to measure a network’s rob
Original label:  cs.CE
Predicted label:  7
Correct label:  2
Text:  [CLS] arxiv : 1708. 08340v1 [ cs. cr ] 28 aug 2017 a type system for privacy properties ( technical report ) veronique cortier niklas grimm cnrs, loria nancy, france veronique. cortier @ loria. fr tu wien vienna, austria niklas. grimm @ tuwien. ac. at joseph lallemand matteo [UNK] inria, loria nancy, france joseph. lallemand @ loria. fr tu wien vienna, austria matteo. [UNK] @ tuwien. ac. at abstract mature push button tools have emerged for checking trace properties ( e. g. secrecy or authentication ) of security protocols. the case of indistinguishability - based privacy properties ( e. g. ballot privacy or anonymity ) is more complex and constitutes an active research topic with several recent propositions of techniques and tools. we explore a novel approach based on type systems and provide a ( sound ) type system for proving equivalence of protocols, for a bounded or an unbounded number of sessions. the resulting prototype implementation has been tested on various protocols of the literature. it provides a signiﬁcant speed - up ( by orders of magnitude ) compared to tools for a bounded number of sessions and complements in terms of expressiveness other state - of - the - art tools, such as proverif and tamarin : e. g., we show that our analysis technique is the ﬁrst one to handle a faithful encoding of the helios e - voting protocol in the context of an untrusted ballot box. 1 introduction formal methods proved to be indispensable tools for the analysis of advanced cryptographic protocols such as those for key distribution [ 43 ], mobile payments [ 30 ], e - voting [ 12, 29, 35 ], and ehealth [ 38 ]. in the last years, mature push - button analysis tools have emerged and have been successfully applied to many protocols from the literature in the context of trace properties such as authentication or conﬁdentiality. these tools employ a variety of analysis techniques, such as model checking ( e. g., avispa [ 10 ] and scyther [ 33 ] ), horn clause resolution ( e. g., proverif [ 19 ] ), term rewriting ( e. g., scyther [ 33 ] and tamarin [ 40 ] ), and type systems [ 11, 17, 22, 36 ]. [SEP]
Text from DS:  arXiv:1708.08340v1 [cs.CR] 28 Aug 2017

A Type System for Privacy Properties (Technical Report)
Véronique Cortier

Niklas Grimm

CNRS, LORIA
Nancy, France
veronique.cortier@loria.fr

TU Wien
Vienna, Austria
niklas.grimm@tuwien.ac.at

Joseph Lallemand

Matteo Maﬀei

Inria, LORIA
Nancy, France
joseph.lallemand@loria.fr

TU Wien
Vienna, Austria
matteo.maﬀei@tuwien.ac.at

ABSTRACT
Mature push button tools have emerged for checking trace properties (e.g. secrecy or authentication) of security protocols. The case
of indistinguishability-based privacy properties (e.g. ballot privacy
or anonymity) is more complex and constitutes an active research
topic with several recent propositions of techniques and tools.
We explore a novel approach based on type systems and provide a (sound) type system for proving equivalence of protocols,
for a bounded or an unbounded number of sessions. The resulting prototype implementation has been tested on various protocols of the literature. It provides a signiﬁc
Original label:  cs.SY
Predicted label:  8
Correct label:  5
Text:  [CLS] integral control of port - hamiltonian systems : non - passive outputs without coordinate transformation arxiv : 1703. 07934v1 [ ] 23 mar 2017 joel ferguson, alejandro donaire and richard h. middleton abstract — in this paper we present a method for the addition of integral action to non - passive outputs of a class of porthamiltonian systems. the proposed integral controller is a dynamic extension, constructed from the open loop system, such that the closed loop preserves the port - hamiltonian form. it is shown that the controller is able to reject the effects of both matched and unmatched disturbances, preserving the regulation of the non - passive outputs. previous solutions to this problem have relied on a change of coordinates whereas the presented solution is developed using the original state vector and, therefore, retains its physical interpretation. in addition, the resulting closed loop dynamics have a natural interpretation as a control by interconnection scheme. i. introduction port - hamiltonian ( ph ) models describe system dynamics in terms of the energy, interconnection and dissipation structures [ 1 ]. the physical information readily available from models written in ph form has inspired successful nonlinear control techniques such as energy shaping ( es ) and interconnection and damping assignment ( ida ) [ 2 ], [ 3 ]. controllers designed with these methods are such that the closed - loop dynamics can be written as a ph system with a desired structure and energy function [ 1 ]. the closed - loop energy function is chosen to have a minimum at the desired equilibrium point of the control system. control by interconnection ( cbi ) is a passivity - based control ( pbc ) methods that considers the dynamics of the controller to be in the ph form [ 4 ]. the controller is then interconnected to the plant via a power - preserving interconnection which implies that, the closed - loop dynamics are passive if both the plant and controller are passive. casimir functions ( dynamic invariants ) are used to collapse the dynamics of the controller and generate a static - feedback law [ 4 ]. the developments of cbi methods has primarily focused on the stabilisation problem by developing static state - feedback controllers [ 1 ], [ 4 ], [ 5 ]. the action of external disturbances on controlled ph systems can produce a shift of the equilibrium or may induce instabilities. typically, passivity with respect the original inputoutput pair no longer holds which means that the hamiltonian cannot be used as a lyapunov [SEP]
Text from DS:  Integral control of port-Hamiltonian systems: non-passive outputs
without coordinate transformation

arXiv:1703.07934v1 [] 23 Mar 2017

Joel Ferguson, Alejandro Donaire and Richard H. Middleton

Abstract—In this paper we present a method for the addition
of integral action to non-passive outputs of a class of portHamiltonian systems. The proposed integral controller is a
dynamic extension, constructed from the open loop system, such
that the closed loop preserves the port-Hamiltonian form. It is
shown that the controller is able to reject the effects of both
matched and unmatched disturbances, preserving the regulation
of the non-passive outputs. Previous solutions to this problem
have relied on a change of coordinates whereas the presented
solution is developed using the original state vector and, therefore,
retains its physical interpretation. In addition, the resulting closed
loop dynamics have a natural interpretation as a Control by
Interconnection scheme.

I. INTRODUCTION
Port-Ha
Original label:  math.ST
Predicted label:  10
Correct label:  5
Text:  [CLS] bayesian estimation of a decreasing density geurt jongbloed, frank van der meulen and lixue pang arxiv : 1801. 02539v1 [ ] 8 jan 2018 delft university of technology abstract : suppose x1,..., xn is a random sample from a bounded and decreasing density f0 on [ 0, ∞ ). we are interested in estimating such f0, with special interest in f0 ( 0 ). this problem is encountered in various statistical applications and has gained quite some attention in the statistical literature. it is well known that the maximum likelihood estimator is inconsistent at zero. this has led several authors to propose alternative estimators which are consistent. as any decreasing density can be represented as a scale mixture of uniform densities, a bayesian estimator is obtained by endowing the mixture distribution with the dirichlet process prior. assuming this prior, we derive contraction rates of the posterior density at zero by carefully revising arguments presented in salomond ( 2014 ). various methods for estimating the density are compared using a simulation study. we apply the bayesian procedure to the current durations data described in keiding et al. ( 2012 ). key words and phrases : bayesian nonparametric approach, posterior consistency, concentrate rate. 1 introduction consider an independent and identically distributed ( i. i. d. ) sample x1,..., xn from a bounded decreasing density f0 on [ 0, ∞ ). the problem of estimating f0 based on the sample, only using the information that it is decreasing, has attracted quite some attention in the literature. one of the reasons for this is that the estimation problem arises naturally in several applications. see for instance the introductory section of kulikov & lopuhaa ( 2006 ), vardi ( 1989 ), watson ( 1971 ) and keiding et al. ( 2012 ). in all these examples, the sampling density f0 can be expressed in terms of an underlying distribution function of interest h0 : 1 − h0 ( x ) f0 ( x ) = r ∞, x ≥ 0. 0 y dh0 ( y ) ( 1 ) in words : the sampling density is proportional to a survival function of interest, which is by definition decreasing. having an estimate of the bounded decreasing density f0, an estimate of h0 is obtained using the ‘ inverse relation ’ h0 ( x ) = 1 − f0 ( x ), x ≥ [SEP]
Text from DS:  Bayesian estimation of a decreasing density
Geurt Jongbloed, Frank van der Meulen and Lixue Pang

arXiv:1801.02539v1 [] 8 Jan 2018

Delft University of Technology

Abstract: Suppose X1 , . . . , Xn is a random sample from a bounded and decreasing
density f0 on [0, ∞). We are interested in estimating such f0 , with special interest
in f0 (0). This problem is encountered in various statistical applications and has
gained quite some attention in the statistical literature. It is well known that the
maximum likelihood estimator is inconsistent at zero. This has led several authors
to propose alternative estimators which are consistent. As any decreasing density
can be represented as a scale mixture of uniform densities, a Bayesian estimator
is obtained by endowing the mixture distribution with the Dirichlet process prior.
Assuming this prior, we derive contraction rates of the posterior density at zero
by carefully revising arguments presented in Salomond (2014). Various methods
for estima
Original label:  cs.PL
Predicted label:  7
Correct label:  10
Text:  [CLS] 1 common - message broadcast channels with feedback in the nonasymptotic regime : full feedback arxiv : 1706. 07731v1 [ ] 23 jun 2017 kasper fløe trillingsgaard, student member, ieee, wei yang, member, ieee, giuseppe durisi, senior member, ieee, and petar popovski, fellow, ieee abstract we investigate the maximum coding rate achievable on a two - user broadcast channel for the case where a common message is transmitted with feedback using either fixed - blocklength codes or variable - length codes. for the fixed - blocklength - code setup, we establish nonasymptotic converse and achievability bounds. an asymptotic analysis of these bounds reveals that feedback improves the second - order term compared to the no - feedback case. in particular, for a certain class of anti - symmetric broadcast channels, we show that the dispersion is halved. for the variable - length - code setup, we demonstrate that the channel dispersion is zero. i. i ntroduction we consider a two - user common - message discrete - time memoryless broadcast channel ( cmdmbc ) with full feedback. when fixed - length codes are used, it is well - known that feedback does the work of k. f. trillingsgaard and p. popovski was supported by the european research council ( erc consolidator grant nr. 648382 willow ) within the horizon 2020 program. the work of g. durisi was supported by the swedish research council under the grant 2016 - 03293. the material of this paper was presented in part at the 2017 ieee international symposium on information theory [ 1 ]. k. f. trillingsgaard and p. popovski are with the department of eletronic systems, aalborg university, 9220, aalborg øst, denmark ( e - mail : { kft, petarp } @ es. aau. dk ). w. yang is with the department of electrical engineering, princeton university, 08544, princeton, usa ( e - mail : weiy @ princeton. edu ). g. durisi is with the department of electrical engineering, chalmers university of technology, 41296, gothenburg, sweden ( e - mail : durisi @ chalmers. se ). june 26, 2017 draft 2 not improve capacity ( [SEP]
Text from DS:  1

Common-Message Broadcast Channels with
Feedback in the Nonasymptotic Regime: Full
Feedback
arXiv:1706.07731v1 [] 23 Jun 2017

Kasper Fløe Trillingsgaard, Student Member, IEEE, Wei Yang, Member, IEEE,
Giuseppe Durisi, Senior Member, IEEE, and Petar Popovski, Fellow, IEEE

Abstract
We investigate the maximum coding rate achievable on a two-user broadcast channel for the case where
a common message is transmitted with feedback using either fixed-blocklength codes or variable-length
codes. For the fixed-blocklength-code setup, we establish nonasymptotic converse and achievability bounds.
An asymptotic analysis of these bounds reveals that feedback improves the second-order term compared to
the no-feedback case. In particular, for a certain class of anti-symmetric broadcast channels, we show that
the dispersion is halved. For the variable-length-code setup, we demonstrate that the channel dispersion is
zero.

I. I NTRODUCTION
We consider a two-user common-message discrete-time memoryless
Original label:  cs.IT
Predicted label:  4
Correct label:  8
Text:  [CLS] arxiv : 1801. 07656v1 [ ] 23 jan 2018 byzantine gathering in polynomial time∗ sebastien bouchard1, yoann dieudonne2, anissa lamani2 1 sorbonne universites, upmc univ paris 06, cnrs, inria, lip6 umr 7606, paris, france e - mail : sebastien. bouchard @ lip6. fr 2 laboratoire mis & universite de picardie jules verne, amiens, france. e - mails : { yoann. dieudonne, anissa. lamani } @ u - picardie. fr abstract gathering a group of mobile agents is a fundamental task in the field of distributed and mobile systems. this can be made drastically more difficult to achieve when some agents are subject to faults, especially the byzantine ones that are known as being the worst faults to handle. in this paper we study, from a deterministic point of view, the task of byzantine gathering in a network modeled as a graph. in other words, despite the presence of byzantine agents, all the other ( good ) agents, starting from possibly different nodes and applying the same deterministic algorithm, have to meet at the same node in finite time and stop moving. an adversary chooses the initial nodes of the agents ( the number of agents may be larger than the number of nodes ) and assigns a different positive integer ( called label ) to each of them. initially, each agent knows its label. the agents move in synchronous rounds and can communicate with each other only when located at the same node. within the team, f of the agents are byzantine. a byzantine agent acts in an unpredictable and arbitrary way. for example, it can choose an arbitrary port when it moves, can convey arbitrary information to other agents and can change its label in every round, in particular by forging the label of another agent or by creating a completely new one. besides its label, which corresponds to a local knowledge, an agent is assigned some global knowledge denoted by gk that is common to all agents. in literature, the byzantine gathering problem has been analyzed in arbitrary n - node graphs by considering the scenario when gk = ( n, f ) and the scenario when gk = f. in the first ( resp. second ) scenario, it has been shown that the minimum number of good agents guaranteeing deterministic gathering of all of them is f + 1 ( resp. f + 2 ). however, for both [SEP]
Text from DS:  arXiv:1801.07656v1 [] 23 Jan 2018

Byzantine Gathering in Polynomial Time∗
Sébastien Bouchard1 , Yoann Dieudonné2 , Anissa Lamani2
1
Sorbonne Universités, UPMC Univ Paris 06, CNRS, INRIA, LIP6 UMR 7606, Paris, France
E-mail: sebastien.bouchard@lip6.fr
2
Laboratoire MIS & Université de Picardie Jules Verne, Amiens, France.
E-mails: {yoann.dieudonne,anissa.lamani}@u-picardie.fr
Abstract
Gathering a group of mobile agents is a fundamental task in the field of distributed and mobile
systems. This can be made drastically more difficult to achieve when some agents are subject to faults,
especially the Byzantine ones that are known as being the worst faults to handle. In this paper we study,
from a deterministic point of view, the task of Byzantine gathering in a network modeled as a graph. In
other words, despite the presence of Byzantine agents, all the other (good) agents, starting from possibly
different nodes and applying the same deterministic algorithm, have to meet at the same nod
Original label:  math.AC
Predicted label:  7
Correct label:  10
Text:  [CLS] arxiv : 1506. 03614v2 [ ] 16 dec 2015 on a generalization of a result of peskine and szpiro tony j. puthenpurakal abstract. let ( r, m ) be a regular local ring containing a field k. let i be a cohen - macaulay ideal of height g. if char k = p > 0 then by a result of peskine and szpiro the local cohomology modules hii ( r ) vanish for i > g. this result is not true if char k = 0. however we prove that the bass numbers of the local cohomology module hig ( r ) completely determine whether hii ( r ) vanish for i > g. the result of this paper has been proved more generally for gorenstein local rings by hellus and schenzel [ 3, theorem 3. 2 ]. however our result for regular rings is elementary to prove. in particular we do not use spectral sequences in our proof. 1. introduction let ( r, m ) be a regular local ring containing a field k. motivated by a result of peskine and szpiro we make the following : definition 1. 1. an ideal i of r is said to be a peskine - szpiro ideal of r if ( 1 ) i is a cohen - macaulay ideal. ( 2 ) hii ( r ) = 0 for all i 6 = height i. note that as height i = grade i we have hii ( r ) = 0 for i < height i. thus the only real condition for a cohen - macaulay ideal i to be a peskine - szpiro ideal is that hii ( r ) = 0 for i > height i. in their fundamental paper [ 7, proposition iii. 4. 1 ] peskine and szpiro proved that if char k = p > 0 then for all cohen - macaulay ideals i the local cohomology modules hii ( r ) vanish for i > height i. this result is not true if char k = 0, for instance see [ 2, example 21. 31 ]. we prove the following surprising result : theorem 1. 2. let ( r, m ) be a regular local ring of dimension d containing a field k. let i be a cohen - macaulay ideal of height g. the following conditions are equivalent : ( i ) i is a peskine - szpiro ideal of [SEP]
Text from DS:  arXiv:1506.03614v2 [] 16 Dec 2015

ON A GENERALIZATION OF A RESULT OF PESKINE AND
SZPIRO
TONY J. PUTHENPURAKAL
Abstract. Let (R, m) be a regular local ring containing a field K. Let I be
a Cohen-Macaulay ideal of height g. If char K = p > 0 then by a result of
Peskine and Szpiro the local cohomology modules HIi (R) vanish for i > g.
This result is not true if char K = 0. However we prove that the Bass numbers
of the local cohomology module HIg (R) completely determine whether HIi (R)
vanish for i > g.

The result of this paper has been proved more generally for Gorenstein local rings
by Hellus and Schenzel [3, Theorem 3.2]. However our result for regular rings is
elementary to prove. In particular we do not use spectral sequences in our proof.
1. introduction
Let (R, m) be a regular local ring containing a field K. Motivated by a result of
Peskine and Szpiro we make the following:
Definition 1.1. An ideal I of R is said to be a Peskine-Szpiro ideal of R if
(1) I is a Cohen-Macaulay ide
Original label:  math.ST
Predicted label:  7
Correct label:  9
Text:  [CLS] geometrically stopped markovian random growth processes and pareto tails brendan k. beare and alexis akira toda arxiv : 1712. 01431v1 [ econ. em ] 5 dec 2017 department of economics, university of california, san diego december 6, 2017 abstract many empirical studies document power law behavior in size distributions of economic interest such as cities, firms, income, and wealth. one mechanism for generating such behavior combines independent and identically distributed gaussian additive shocks to log - size with a geometric age distribution. we generalize this mechanism by allowing the shocks to be non - gaussian ( but light - tailed ) and dependent upon a markov state variable. our main results provide sharp bounds on tail probabilities and simple formulas for pareto exponents. we present two applications : ( i ) we show that the tails of the wealth distribution in a heterogeneous - agent dynamic general equilibrium model with idiosyncratic endowment risk decay exponentially, unlike models with investment risk where the tails may be paretian, and ( ii ) we show that a random growth model for the population dynamics of japanese prefectures is consistent with the observed pareto exponent but only after allowing for markovian dynamics. keywords : exponential tails, gibrat ’ s law, pareto tails, power law, random growth, tauberian theorem. jel codes : c46, c65, d30, d52, d58, r12. 1 introduction in this paper we are concerned with the tail behavior of geometric sums of the form t x wt = xt, ( 1. 1 ) t = 1 we thank alberto bisin, xavier gabaix, emilien gouin - bonenfant, makoto nirei, werner ploberger, jonathan weinstein, and seminar participants at queen ’ s university, ucsb, ucsd, the university of toronto, washington university in st. louis, and the 2017 summer workshop in economic theory at the cowles foundation for helpful comments and suggestions. 1 where { xt } ∞ t = 1 is a sequence of random innovations and t is a geometrically distributed random variable. the innovations { xt } ∞ t = 1 may depend contemporaneously on a time - homogeneous markov state variable ( i. e., xt is a “ hidden markov process ” ; see definition 3. 1 below ). we may view wt in ( 1. 1 ) as a geometrically stopped [SEP]
Text from DS:  Geometrically stopped Markovian random growth
processes and Pareto tails
Brendan K. Beare and Alexis Akira Toda

arXiv:1712.01431v1 [econ.EM] 5 Dec 2017

Department of Economics, University of California, San Diego
December 6, 2017

Abstract
Many empirical studies document power law behavior in size distributions of economic interest such as cities, firms, income, and wealth. One
mechanism for generating such behavior combines independent and identically distributed Gaussian additive shocks to log-size with a geometric
age distribution. We generalize this mechanism by allowing the shocks
to be non-Gaussian (but light-tailed) and dependent upon a Markov state
variable. Our main results provide sharp bounds on tail probabilities and
simple formulas for Pareto exponents. We present two applications: (i) we
show that the tails of the wealth distribution in a heterogeneous-agent dynamic general equilibrium model with idiosyncratic endowment risk decay
exponentially, unlike models with inves
Original label:  cs.IT
Predicted label:  2
Correct label:  3
Text:  [CLS] arxiv : 1603. 09205v1 [ cs. dm ] 30 mar 2016 a comprehensive theory of cascading via - paths and the reciprocal pointer chain method brandon smock, joseph wilson∗ march 31, 2016 abstract in this paper, we consolidate and expand upon the current theory and potential applications of the set of k best cascading via - paths ( cvps ) and the reciprocal pointer chain ( rpc ) method for identifying them. cvps are a collection of up to | v | paths between a source and a target node in a graph g = ( v, e ), computed using two shortest path trees, that have distinctive properties relative to other path sets. they have been shown to be particularly useful in geospatial applications, where they are an intuitive and efficient means for identifying a set of spatially diverse alternatives to the single shortest path between the source and target. however, spatial diversity is not intrinsic to paths in a graph, and little theory has been developed outside of application to describe the nature of these paths and the rpc method in general. here we divorce the rpc method from its typical geospatial applications and develop a comprehensive theory of cvps from an abstract graph - theoretic perspective. restricting ourselves to properties of the cvps and of the entire set of k - best cvps that can be computed in o ( | e | + | v | log | v | ), we are able to then propose, among other things, new and efficient approaches to problems such as generating a diverse set of paths and to computing the k shortest loopless paths between two nodes in a graph. we conclude by demonstrating the new theory in practice, first for a typical application of finding alternative routes in road networks and then for a novel application of identifying layer - boundaries in ground - penetrating radar ( gpr ) data. it is our hope that by generalizing the rpc method, providing a sound theoretical foundation, and demonstrating novel uses, we are able to broaden its perceived applicability and stimulate new research in this area, both applied and theoretical. 1 introduction a via - path is the shortest path in a graph g = ( v, e ) from a source node, s, to a target node, t, that passes through an intermediate node, v. from the ∗ computer and information science and engineering department, e301 cse building, po box 116120, gainesville, fl 32611. 1 perspective of graph theory, the k - best via [SEP]
Text from DS:  arXiv:1603.09205v1 [cs.DM] 30 Mar 2016

A comprehensive theory of cascading via-paths
and the reciprocal pointer chain method
Brandon Smock, Joseph Wilson∗
March 31, 2016

Abstract
In this paper, we consolidate and expand upon the current theory and
potential applications of the set of k best cascading via-paths (CVPs) and
the reciprocal pointer chain (RPC) method for identifying them. CVPs
are a collection of up to |V | paths between a source and a target node
in a graph G = (V, E), computed using two shortest path trees, that
have distinctive properties relative to other path sets. They have been
shown to be particularly useful in geospatial applications, where they are
an intuitive and efficient means for identifying a set of spatially diverse
alternatives to the single shortest path between the source and target.
However, spatial diversity is not intrinsic to paths in a graph, and little
theory has been developed outside of application to describe the nature
of these paths and the 
Original label:  cs.IT
Predicted label:  9
Correct label:  5
Text:  [CLS] demand prediction and placement optimization for electric vehicle charging stations ragavendran gopalakrishnan xerox research centre india, bangalore, karnataka 560103, ragavendran. gopalakrishnan @ xerox. com arxiv : 1604. 05472v2 [ ] 13 jul 2016 arpita biswas xerox research centre india, bangalore, karnataka 560103, arpita. biswas @ xerox. com alefiya lightwala xerox research centre india, bangalore, karnataka 560103, alefiya. lightwala @ xerox. com skanda vasudevan xerox research centre india, bangalore, karnataka 560103, skanda. vasudevan @ xerox. com abhishek tripathi xerox research centre india, bangalore, karnataka 560103, abishek. tripathi3 @ xerox. com partha dutta xerox research centre india, bangalore, karnataka 560103, partha. dutta @ xerox. com due to the environmental impact of fossil fuels and high variability in their prices, there is rising interest in adopting electric vehicles ( evs ) by both individuals and governments. despite the advances in vehicle efficiency and battery capacity, a key hurdle is the inherent interdependence between ev adoption and charging station deployment – ev adoption ( and hence, charging demand ) increases with the availability of charging stations ( operated by service providers ) and vice versa. thus, effective placement of charging stations plays a key role in ev adoption. in the placement problem, given a set of candidate sites, an optimal subset needs to be selected with respect to the concerns of both ( a ) the charging station service provider, such as the demand at the candidate sites and the budget for deployment, and ( b ) the ev user, such as charging station reachability and short waiting times at the station. this work addresses these concerns, making the following three novel contributions : ( i ) a supervised multi - view learning framework using canonical correlation analysis ( cca ) for demand prediction at candidate sites, using multiple datasets such as points of interest information, traffic density, and the historical usage at existing charging stations ; ( ii ) a “ mixed - packing - and - covering ” optimization framework that models competing concerns of the service provider and ev users, which is also extended to optimize government grant allocation to multiple service providers ; ( iii ) an iterative heuristic to solve [SEP]
Text from DS:  Demand Prediction and Placement Optimization for
Electric Vehicle Charging Stations
Ragavendran Gopalakrishnan
Xerox Research Centre India, Bangalore, Karnataka 560103,
Ragavendran.Gopalakrishnan@xerox.com

arXiv:1604.05472v2 [] 13 Jul 2016

Arpita Biswas
Xerox Research Centre India, Bangalore, Karnataka 560103,
Arpita.Biswas@xerox.com

Alefiya Lightwala
Xerox Research Centre India, Bangalore, Karnataka 560103,
Alefiya.Lightwala@xerox.com

Skanda Vasudevan
Xerox Research Centre India, Bangalore, Karnataka 560103,
Skanda.Vasudevan@xerox.com

Abhishek Tripathi
Xerox Research Centre India, Bangalore, Karnataka 560103,
Abishek.Tripathi3@xerox.com

Partha Dutta
Xerox Research Centre India, Bangalore, Karnataka 560103,
Partha.Dutta@xerox.com

Due to the environmental impact of fossil fuels and high variability in their prices, there is rising interest
in adopting electric vehicles (EVs) by both individuals and governments. Despite the advances in vehicle
efficiency and battery capacity, a ke
Original label:  cs.CE
Predicted label:  3
Correct label:  8
Text:  [CLS] stochastic superoptimization eric schkufza rahul sharma alex aiken stanford university stanford, ca stanford university stanford, ca stanford university stanford, ca eschkufz @ cs. stanford. edu sharmar @ cs. stanford. edu arxiv : 1211. 0557v1 [ cs. pf ] 2 nov 2012 abstract generating consistently good code, leads to the well - known phase ordering problem. in many cases, the best possible code can only be obtained through the simultaneous consideration of mutually dependent issues such as instruction selection, register allocation, and target - dependent optimization. previous approaches to this problem have focused on the exploration of all possibilities within some limited class of programs. in contrast to a traditional compiler, which uses performance constraints to drive code generation of a single program, these systems consider multiple programs and then ask how well they satisfy those constraints. solutions range from the explicit enumeration of a class of programs that can be formed using a large executable hardware instruction set [ 3 ] to implicit enumeration through symbolic theorem proving techniques of programs over some restricted register transaction language [ 14, 11, 9 ]. an attractive feature of these systems is completeness : if a program exists meeting the desired constraints, that program will be found. unfortunately, completeness also places limitations on the space of programs that can be effectively reasoned about. because of the huge number of programs involved explicit enumeration - based techniques are limited to programs up to some fixed length, and currently this bound is well below the threshold at which many interesting optimizations take place. implicit enumeration techniques can overcome this limitation, but at the cost of expert - written rules for shrinking the search space. the resulting optimizations are as good, but no better, than the quality of the rules written by an expert. to overcome these limitations we take a different approach based on incomplete search. we show how the competing requirements of correctness and speed can be defined as terms in a cost function over the complex search space of all loopfree executable hardware instruction sequences, and how the program optimization problem can be formulated as a cost minimization problem. although the resulting search space is highly irregular and not amenable to exact optimization techniques, we demonstrate that the common approach of employing a markov chain monte carlo ( mcmc ) sampler to explore the function and produce low - cost samples is sufficient for producing high quality code sequences. although our technique sacrifices completeness by trading systematic enumeration for stoch [SEP]
Text from DS:  Stochastic Superoptimization
Eric Schkufza

Rahul Sharma

Alex Aiken

Stanford University
Stanford, CA

Stanford University
Stanford, CA

Stanford University
Stanford, CA

eschkufz@cs.stanford.edu sharmar@cs.stanford.edu

arXiv:1211.0557v1 [cs.PF] 2 Nov 2012

ABSTRACT

generating consistently good code, leads to the well-known
phase ordering problem. In many cases, the best possible
code can only be obtained through the simultaneous consideration of mutually dependent issues such as instruction selection, register allocation, and target-dependent optimization.
Previous approaches to this problem have focused on the
exploration of all possibilities within some limited class of
programs. In contrast to a traditional compiler, which uses
performance constraints to drive code generation of a single
program, these systems consider multiple programs and then
ask how well they satisfy those constraints. Solutions range
from the explicit enumeration of a class of programs that
can be formed us
Original label:  cs.AI
Predicted label:  2
Correct label:  7
Text:  [CLS] cobra : a fast and simple method for active clustering with pairwise constraints arxiv : 1801. 09955v1 [ ] 30 jan 2018 toon van craenendonck, sebastijan dumancic and hendrik blockeel department of computer science, ku leuven, belgium { firstname. lastname } @ kuleuven. be abstract clustering is inherently ill - posed : there often exist multiple valid clusterings of a single dataset, and without any additional information a clustering system has no way of knowing which clustering it should produce. this motivates the use of constraints in clustering, as they allow users to communicate their interests to the clustering system. active constraint - based clustering algorithms select the most useful constraints to query, aiming to produce a good clustering using as few constraints as possible. we propose cobra, an active method that first over - clusters the data by running k - means with a k that is intended to be too large, and subsequently merges the resulting small clusters into larger ones based on pairwise constraints. in its merging step, cobra is able to keep the number of pairwise queries low by maximally exploiting constraint transitivity and entailment. we experimentally show that cobra outperforms the state of the art in terms of clustering quality and runtime, without requiring the number of clusters in advance. 1 introduction clustering is inherently subjective [ caruana et al., 2006 ; von luxburg et al., 2014 ] : a single dataset can often be clustered in multiple ways, and different users may prefer different clusterings. this subjectivity is one of the motivations for constraint - based ( or semi - supervised ) clustering [ wagstaff et al., 2001 ; bilenko et al., 2004 ]. methods in this setting exploit background knowledge to obtain clusterings that are more aligned with the user ’ s preferences. often, this knowledge is given in the form of pairwise constraints that indicate whether two instances should be in the same cluster ( a mustlink constraint ) or not ( a cannot - link constraint ) [ wagstaff et al., 2001 ]. in traditional constraint - based clustering systems the set of constraints is assumed to be given a priori, and in practice, the pairs that are queried are often selected randomly. in contrast, in active clustering [ basu et al., 2004a ; mallapragada et al., 2008 ; xiong [SEP]
Text from DS:  COBRA: A Fast and Simple Method for
Active Clustering with Pairwise Constraints

arXiv:1801.09955v1 [] 30 Jan 2018

Toon Van Craenendonck, Sebastijan Dumančić and Hendrik Blockeel
Department of Computer Science, KU Leuven, Belgium
{firstname.lastname}@kuleuven.be

Abstract
Clustering is inherently ill-posed: there often exist multiple valid clusterings of a single dataset,
and without any additional information a clustering system has no way of knowing which clustering it should produce. This motivates the use
of constraints in clustering, as they allow users to
communicate their interests to the clustering system. Active constraint-based clustering algorithms
select the most useful constraints to query, aiming to produce a good clustering using as few constraints as possible. We propose COBRA, an active
method that first over-clusters the data by running
K-means with a K that is intended to be too large,
and subsequently merges the resulting small clusters into larger ones based on 
Original label:  cs.IT
Predicted label:  3
Correct label:  2
Text:  [CLS] reconciling graphs and sets of sets michael mitzenmacher∗ tom morgan † arxiv : 1707. 05867v1 [ ] 18 jul 2017 abstract we explore a generalization of set reconciliation, where the goal is to reconcile sets of sets. alice and bob each have a parent set consisting of s child sets, each containing at most h elements from a universe of size u. they want to reconcile their sets of sets in a scenario where the total number of differences between all of their child sets ( under the minimum difference matching between their child sets ) is d. we give several algorithms for this problem, and discuss applications to reconciliation problems on graphs, databases, and collections of documents. we specifically focus on graph reconciliation, providing protocols based on sets of sets reconciliation for random graphs from g ( n, p ) and for forests of rooted trees. 1 introduction in the standard problem of set reconciliation, two parties alice and bob each hold sets of items sa and sb respectively from a common universe ( with items generally represented as words of w bits ), and the goal is for one or both of the parties to determine the union of the two sets. typically in applications the set difference size d is small, and we seek an algorithm that computes the set difference efficiently and with small communication. when a bound d on the size of the set difference is known, standard polynomial interpolation methods allow reconciliation using only d words, but this approach in fairly inefficient computationally [ 23, 26 ]. a more practical approach based on invertible bloom lookup tables ( or iblts, also called invertible bloom filters ) uses o ( d ) space and linear time, and succeeds with high probability [ 12, 14, 16 ]. we explore the problem of reconciling sets of sets. specifically, alice and bob each have a parent set consisting of s child sets, each containing at most h elements a universe of size u. we call the sum of the sizes of the child sets n. alice and bob wish to reconcile their sets of sets under the scenario that the total number of differences among all of their child sets ( under the minimum difference matching between their child sets ) is d. we consider primarily the one - way notion of reconciliation, in which at the end of the protocol, bob can completely recover alice ’ s data. ( our work can be extended to mutual reconciliation in various ways. ) the problem of reconciling sets of sets naturally occurs in several reconciliation problems. we [SEP]
Text from DS:  Reconciling Graphs and Sets of Sets
Michael Mitzenmacher∗

Tom Morgan†

arXiv:1707.05867v1 [] 18 Jul 2017

Abstract
We explore a generalization of set reconciliation, where the goal is to reconcile sets of sets.
Alice and Bob each have a parent set consisting of s child sets, each containing at most h
elements from a universe of size u. They want to reconcile their sets of sets in a scenario where
the total number of differences between all of their child sets (under the minimum difference
matching between their child sets) is d. We give several algorithms for this problem, and discuss
applications to reconciliation problems on graphs, databases, and collections of documents. We
specifically focus on graph reconciliation, providing protocols based on sets of sets reconciliation
for random graphs from G(n, p) and for forests of rooted trees.

1

Introduction

In the standard problem of set reconciliation, two parties Alice and Bob each hold sets of items
SA and SB respectively from a co
Original label:  math.ST
Predicted label:  1
Correct label:  2
Text:  [CLS] phase transitions in approximate ranking arxiv : 1711. 11189v1 [ ] 30 nov 2017 chao gao university of chicago chaogao @ galton. uchicago. edu december 1, 2017 abstract we study the problem of approximate ranking from observations of pairwise interactions. the goal is to estimate the underlying ranks of n objects from data through interactions of comparison or collaboration. under a general framework of approximate ranking models, we characterize the exact optimal statistical error rates of estimating the underlying ranks. we discover important phase transition boundaries of the optimal error rates. depending on the value of the signal - to - noise ratio ( snr ) parameter, the optimal rate, as a function of snr, is either trivial, polynomial, exponential or zero. the four corresponding regimes thus have completely different error behaviors. to the best of our knowledge, this phenomenon, especially the phase transition between the polynomial and the exponential rates, has not been discovered before. keywords : minimax rate, permutation, sorting, pairwise comparison, latent space. 1 introduction given data { xij } 1≤i6 = j≤n, we study recovery of the underlying ranks of the n objects in the paper. the observation xij can be interpreted as the outcome of an interaction between i and j. for example, in sports, xij can be the match result of a game between team i and team j. in a coauthorship network, xij can be the number of scientific papers jointly written by author i and author j. we consider a very general approximate ranking model in the paper. it imposes the mean structure exij = µr ( i ) r ( j ). here r ( i ) ∈ { 1, 2,..., n } is the rank of object i. the interaction outcome µr ( i ) r ( j ) is only determined by the latent positions of i and j, and xij is thus a noisy measurement of µr ( i ) r ( j ). the goal of approximate ranking is to recover the underlying r ( i ) for each i ∈ { 1, 2,..., n }. in the literature, the problem of exact ranking is a well studied topic, especially in the settings of pairwise comparison with bernoulli outcomes. the goal of exact ranking assumes that the underlying r is a permutation, and therefore estimating r is equivalent to sorting the 1 n objects, which gives an alternative name “ noisy sorting ” [SEP]
Text from DS:  Phase Transitions in Approximate Ranking

arXiv:1711.11189v1 [] 30 Nov 2017

Chao Gao
University of Chicago
chaogao@galton.uchicago.edu
December 1, 2017
Abstract
We study the problem of approximate ranking from observations of pairwise interactions. The goal is to estimate the underlying ranks of n objects from data through
interactions of comparison or collaboration. Under a general framework of approximate
ranking models, we characterize the exact optimal statistical error rates of estimating
the underlying ranks. We discover important phase transition boundaries of the optimal
error rates. Depending on the value of the signal-to-noise ratio (SNR) parameter, the
optimal rate, as a function of SNR, is either trivial, polynomial, exponential or zero. The
four corresponding regimes thus have completely different error behaviors. To the best of
our knowledge, this phenomenon, especially the phase transition between the polynomial
and the exponential rates, has not been discovered before.
Original label:  cs.IT
Predicted label:  7
Correct label:  10
Text:  [CLS] determining tournament payout structures for daily fantasy sports christopher musco ∗ maxim sviridenko † justin thaler ‡ arxiv : 1601. 04203v2 [ ] 4 nov 2016 november 7, 2016 abstract with an exploding global market and the recent introduction of online cash prize tournaments, fantasy sports contests are quickly becoming a central part of the social gaming and sports industries. for sports fans and online media companies, fantasy sports contests are an opportunity for large financial gains. however, they present a host of technical challenges that arise from the complexities involved in running a web - scale, prize driven fantasy sports platform. we initiate the study of these challenges by examining one concrete problem in particular : how to algorithmically generate contest payout structures that are 1 ) economically motivating and appealing to contestants and 2 ) reasonably structured and succinctly representable. we formalize this problem and present a general two - staged approach for producing satisfying payout structures given constraints on contest size, entry fee, prize bucketing, etc. we then propose and evaluate several potential algorithms for solving the payout problem efficiently, including methods based on dynamic programming, integer programming, and heuristic techniques. experimental results show that a carefully designed heuristic scales very well, even to contests with over 100, 000 prize winners. our approach extends beyond fantasy sports – it is suitable for generating engaging payout structures for any contest with a large number of entrants and a large number of prize winners, including other massive online games, poker tournaments, and real - life sports tournaments. ∗ massachusetts institute of technology. worked completed while at yahoo labs. email : cpmusco @ mit. edu yahoo labs. email : sviri @ yahoo - inc. com ‡ georgetown university. worked completed while at yahoo labs. email : jthaler @ fas. harvard. edu † 1 introduction in many competitions, a large number of entrants compete against each other and are then ordered based on performance. prize money is distributed to the entrants based on their rank in the order, with higher ranks receiving more money than lower ranks. the question that we are interested in is : how should prize money be distributed among the entrants? that is, how much money should go to the winner of the contest? how much to 2nd place? how much to 1, 128th place? 1. 1 motivation we became interested in this problem in the context of daily fantasy sports 1, a growing sector of online fantasy sports competitions where users pay [SEP]
Text from DS:  Determining Tournament Payout Structures
for Daily Fantasy Sports
Christopher Musco

∗

Maxim Sviridenko

†

Justin Thaler

‡

arXiv:1601.04203v2 [] 4 Nov 2016

November 7, 2016

Abstract
With an exploding global market and the recent introduction of online cash prize tournaments, fantasy sports contests are quickly becoming a central part of the social gaming and
sports industries. For sports fans and online media companies, fantasy sports contests are an
opportunity for large financial gains. However, they present a host of technical challenges that
arise from the complexities involved in running a web-scale, prize driven fantasy sports platform.
We initiate the study of these challenges by examining one concrete problem in particular:
how to algorithmically generate contest payout structures that are 1) economically motivating
and appealing to contestants and 2) reasonably structured and succinctly representable. We
formalize this problem and present a general two-staged approach fo
Original label:  cs.CE
Predicted label:  3
Correct label:  6
Text:  [CLS] arxiv : 1311. 7256v1 [ ] 28 nov 2013 the ins and outs of iteration in mezzo armael gueneau francois pottier jonathan protzenko ens lyon & inria armael. gueneau @ inria. fr inria francois. pottier @ inria. fr inria jonathan. protzenko @ ens - lyon. org abstract 3. higher - order iteration this is a talk proposal for hope 2013. using iteration over a collection as a case study, we wish to illustrate the strengths and weaknesses of the prototype programming language mezzo. the type - checker can split permissions ( as above ), join them, and set them aside when they are not needed ( a “ frame rule ” ). this makes it easy to write a recursive function that descends into a tree. for instance, the type of the “ tree size ” function is : val size : [ a ] tree a - > int 1. introduction ( square brackets denote universal quantification. ) by convention, this means that the call “ size t ” requires the permission “ t @ tree a ” and returns it. it is equally easy to write a higherorder function that descends into a tree and invokes a clientsupplied function at every node : mezzo [ 2 ] is a high - level programming language in the style of ml. it is equipped with a strong static discipline of duplicable and affine permissions, which controls aliasing and ownership, and rules out certain mistakes, such as representation exposure and data races. in this talk, we would like to illustrate how mezzo expresses transfers of ownership : sometimes easily, sometimes less so. we use iteration, a surprisingly rich problem, as a case study. val iter : [ a, s : perm ] a | s ) - > bool, ( f : ( t : tree a | s ) - > bool the function f has access to one tree element at a time : it receives a permission of the form “ x @ a ” and must return it. thus, this element is temporarily “ borrowed ” from the tree. the function f cannot access the tree, since it does not receive a permission for it. the universal quantification over a permission s, which f receives and returns, and which iter also receives and returns, allows the client to supply a function f that has a side effect on an area of memory represented by s. the boolean value returned [SEP]
Text from DS:  arXiv:1311.7256v1 [] 28 Nov 2013

The ins and outs of iteration in Mezzo
Armaël Guéneau

François Pottier

Jonathan Protzenko

ENS Lyon & INRIA
armael.gueneau@inria.fr

INRIA
francois.pottier@inria.fr

INRIA
jonathan.protzenko@ens-lyon.org

Abstract

3. Higher-order iteration

This is a talk proposal for HOPE 2013. Using iteration over a
collection as a case study, we wish to illustrate the strengths and
weaknesses of the prototype programming language Mezzo.

The type-checker can split permissions (as above), join them, and
set them aside when they are not needed (a “frame rule”). This
makes it easy to write a recursive function that descends into a tree.
For instance, the type of the “tree size” function is:
val size: [a] tree a -> int

1. Introduction

(Square brackets denote universal quantification.) By convention, this means that the call “size t” requires the permission
“t @ tree a” and returns it. It is equally easy to write a higherorder function that descends into a tree and 
Original label:  cs.PL
Predicted label:  2
Correct label:  8
Text:  [CLS] an operational characterization of mutual information in algorithmic information theory arxiv : 1710. 05984v3 [ ] 15 feb 2018 andrei romashchenko ∗ marius zimand † february 16, 2018 abstract we show that the mutual information, in the sense of kolmogorov complexity, of any pair of strings x and y is equal, up to logarithmic precision, to the length of the longest shared secret key that two parties, one having x and the complexity profile of the pair and the other one having y and the complexity profile of the pair, can establish via a probabilistic protocol with interaction on a public channel. for ℓ > 2, the longest shared secret that can be established from a tuple of strings ( x1,..., xℓ ) by ℓ parties, each one having one component of the tuple and the complexity profile of the tuple, is equal, up to logarithmic precision, to the complexity of the tuple minus the minimum communication necessary for distributing the tuple to all parties. we establish the communication complexity of secret key agreement protocols that produce a secret key of maximal length, for protocols with public randomness. we also show that if the communication complexity drops below the established threshold then only very short secret keys can be obtained. 1 introduction mutual information is a concept of central importance in both information theory ( it ) and algorithmic information theory ( ait ), also known as kolmogorov complexity. we show an interpretation of mutual information in ait, which links it to a basic concept from cryptography. even though a similar interpretation was known in the it framework, an operational characterization of mutual information in ait has been elusive till now. to present our result, let us consider two strings x and y. it is common to draw a venn - like diagram such as the one in figure 1 to visualize the information relations between them. as explained in the figure legend there are six important regions. the regions ( 1 ) to ( 5 ) have a clear operational meaning. for instance, c ( x ) is the length of a shortest program that prints x, c ( x | y ) is the length of a shortest program that prints x when y is given to it, and so on. on the other hand, the mutual information i ( x : y ) from region ( 6 ) is defined by a formula : i ( x : y ) = c ( x ) + c ( y ) − c ( x, y [SEP]
Text from DS:  An operational characterization of mutual information in
algorithmic information theory

arXiv:1710.05984v3 [] 15 Feb 2018

Andrei Romashchenko

∗

Marius Zimand

†

February 16, 2018

Abstract
We show that the mutual information, in the sense of Kolmogorov complexity, of any pair of strings
x and y is equal, up to logarithmic precision, to the length of the longest shared secret key that
two parties, one having x and the complexity profile of the pair and the other one having y and the
complexity profile of the pair, can establish via a probabilistic protocol with interaction on a public
channel. For ℓ > 2, the longest shared secret that can be established from a tuple of strings (x1 , ..., xℓ )
by ℓ parties, each one having one component of the tuple and the complexity profile of the tuple, is
equal, up to logarithmic precision, to the complexity of the tuple minus the minimum communication
necessary for distributing the tuple to all parties. We establish the communication complexity
Original label:  cs.IT
Predicted label:  9
Correct label:  5
Text:  [CLS] a randomized rounding algorithm for sparse pca arxiv : 1508. 03337v5 [ ] 22 nov 2016 kimon fountoulakis∗ abhisek kundu † eugenia - maria kontopoulou ‡ petros drineas § abstract we present and analyze a simple, two - step algorithm to approximate the optimal solution of the sparse pca problem. our approach first solves an ℓ1 - penalized version of the np - hard sparse pca optimization problem and then uses a randomized rounding strategy to sparsify the resulting dense solution. our main theoretical result guarantees an additive error approximation and provides a tradeoff between sparsity and accuracy. our experimental evaluation indicates that our approach is competitive in practice, even compared to state - of - the - art toolboxes such as spasm. keywords. sparce pca, rounding randomized algorithm. 1 introduction large matrices are a common way of representing modern, massive datasets, since an m × n real - valued matrix x provides a natural structure for encoding information about m objects, each of which is described by n features. principal components analysis ( pca ) and the singular value decomposition ( svd ) are fundamental data analysis tools, expressing a data matrix in terms of a sequence of orthogonal vectors of decreasing importance. while these vectors enjoy strong optimality properties and are often interpreted as fundamental latent factors that underlie the observed data, they are linear combinations of up to all the data points and features. as a result, they are notoriously difficult to interpret in terms of the underlying processes generating the data [ md09 ]. the seminal work of [ dgj07 ] introduced the concept of sparse pca, where sparsity constraints are enforced on the singular vectors in order to improve interpretability. as noted in [ dgj07, md09, pdk13 ], an example where sparsity implies interpretability is document analysis, where sparse principal components can be mapped to specific topics by inspecting the ( few ) keywords in their support. formally, sparse pca can be defined as1 ( see eqn. ( 1 ) in [ pdk13 ] ) : zopt = max x∈rn, kxk2 ≤1 xt ax, s. t. kxk0 ≤ k. ( 1 ) in the above formulation, the parameter k controls the sparsity of the resulting vector and is part of the input ; a = x [SEP]
Text from DS:  A Randomized Rounding Algorithm for Sparse PCA

arXiv:1508.03337v5 [] 22 Nov 2016

Kimon Fountoulakis∗

Abhisek Kundu†

Eugenia-Maria Kontopoulou‡

Petros Drineas§

Abstract
We present and analyze a simple, two-step algorithm to approximate the optimal solution of the
sparse PCA problem. Our approach first solves an ℓ1 -penalized version of the NP-hard sparse PCA optimization problem and then uses a randomized rounding strategy to sparsify the resulting dense solution.
Our main theoretical result guarantees an additive error approximation and provides a tradeoff between
sparsity and accuracy. Our experimental evaluation indicates that our approach is competitive in practice,
even compared to state-of-the-art toolboxes such as Spasm.

Keywords.

Sparce pca, rounding randomized algorithm.

1 Introduction
Large matrices are a common way of representing modern, massive datasets, since an m × n real-valued
matrix X provides a natural structure for encoding information about m objects, each 
Original label:  cs.CV
Predicted label:  3
Correct label:  5
Text:  [CLS] neural computing and applications manuscript no. ( will be inserted by the editor ) on usage of autoencoders and siamese networks for online handwritten signature verification arxiv : 1712. 02781v2 [ ] 29 dec 2017 kian ahrabian · bagher babaali submitted : december 2017 abstract in this paper, we propose a novel writerindependent global feature extraction framework for the task of automatic signature verification which aims to make robust systems for automatically distinguishing negative and positive samples. our method consists of an autoencoder for modeling the sample space into a fixed length latent space and a siamese network for classifying the fixed - length samples obtained from the autoencoder based on the reference samples of a subject as being genuine or forged. during our experiments, usage of attention mechanism and applying downsampling significantly improved the accuracy of the proposed framework. we evaluated our proposed framework using sigwicomp2013 japanese and gpdssyntheticonlineofflinesignature datasets. on the sigwicomp2013 japanese dataset, we achieved 8. 65 % eer1 that means 1. 2 % relative improvement compared to the best - reported result. furthermore, on the gpdssyntheticonlineofflinesignature dataset, we achieved average eers of 0. 13 %, 0. 12 %, 0. 21 % and 0. 25 % respectively for 150, 300, 1000 and 2000 test subjects which indicates improvement of relative eer on the best - reported result by 95. 67 %, 95. 26 %, 92. 9 % and 91. 52 % respectively. apart from the kian ahrabian school of mathematics, statistics, and computer science, university of tehran, tehran, iran tel. : + 98 - 9125482934 e - mail : kahrabian @ ut. ac. ir bagher babaali school of mathematics, statistics, and computer science, university of tehran, tehran, iran tel. : + 98 - 9125248895 e - mail : babaali @ ut. ac. ir accuracy gain, because of the nature of our proposed framework which is based on neural networks and consequently is as simple as some consecutive matrix multiplications, it has less computational cost than conventional methods such as dtw2 and could be used concurrently on devices such as gpu3, tpu4, etc. keywords online handwritten signature verification · siamese networks · autoencoders [SEP]
Text from DS:  Neural Computing and Applications manuscript No.
(will be inserted by the editor)

On Usage of Autoencoders and Siamese Networks for Online
Handwritten Signature Verification

arXiv:1712.02781v2 [] 29 Dec 2017

Kian Ahrabian · Bagher Babaali

Submitted: December 2017

Abstract In this paper, we propose a novel writerindependent global feature extraction framework for
the task of automatic signature verification which aims
to make robust systems for automatically distinguishing negative and positive samples. Our method consists of an autoencoder for modeling the sample space
into a fixed length latent space and a Siamese Network for classifying the fixed-length samples obtained
from the autoencoder based on the reference samples of a subject as being Genuine or Forged. During our experiments, usage of Attention Mechanism
and applying Downsampling significantly improved
the accuracy of the proposed framework. We evaluated our proposed framework using SigWiComp2013
Japanese and GPDSsynthe
Original label:  math.AC
Predicted label:  3
Correct label:  9
Text:  [CLS] algebraic geometric codes on hirzebruch surfaces arxiv : 1801. 08407v1 [ ] 25 jan 2018 jade nardi ∗ january 26, 2018 abstract we define a linear code cη ( δt, δx ) by evaluating polynomials of bidegree ( δt, δx ) in the cox ring on fq - rational points of the hirzebruch surface on the finite field fq. we give explicit parameters of the code, notably using grobner bases. the minimum distance provides an upper bound of the number of fq - rational points of a non - filling curve on a hirzebruch surface. we also display some punctured codes having optimal parameters. ams classification : 94b27, 14g50, 13p25, 14g15, 14m25 keywords : hirzebruch surface, algebraic geometric code, grobner basis, rational scroll introduction until the 00 ’ s, most goppa codes were associated to curves. in 2001 s. h. hansen [ 8 ] estimated parameters of goppa codes associated to normal projective varieties of dimension at least 2. as hansen required very few assumptions on the varieties, the parameters he gave depended only on the seshadri constant of the line bundle, which is hard to compute in practice. new classes of error correcting codes have thus been constructed, focusing on specific well - known families of varieties to better grasp the parameters. among goppa codes associated to a surface which have been studied until now, some toric and projectives codes are based on hirzebruch surfaces. toric codes, first introduced by j. p. hansen [ 7 ] and further investigated by d. joyner [ 9 ] and d. ruano [ 12 ], are goppa codes on toric varieties evaluating global sections of a line bundle at the fq - rational points of the torus. projective codes evaluate homogeneous polynomials on the rational points of a variety embedded in a projective space. a first example of projective codes is reed - muller projective codes on p2 [ 10 ]. a. couvreur and i. duursma [ 2 ] studied codes on the biprojective space p1 × p1 embedded in p3. the authors took advantage of the product structure of the variety, yielding a description of the code as a tensor product of two well understood reed - muller codes on ∗ institut de mathematiques de toulouse ; umr 5219, universite de toulouse [SEP]
Text from DS:  Algebraic Geometric codes on Hirzebruch
surfaces

arXiv:1801.08407v1 [] 25 Jan 2018

Jade Nardi

∗

January 26, 2018

Abstract
We define a linear code Cη (δT , δX ) by evaluating polynomials of bidegree (δT , δX ) in the Cox ring on Fq -rational points of the Hirzebruch
surface on the finite field Fq . We give explicit parameters of the code,
notably using Gröbner bases. The minimum distance provides an upper bound of the number of Fq -rational points of a non-filling curve on a
Hirzebruch surface. We also display some punctured codes having optimal
parameters.

AMS classification : 94B27, 14G50, 13P25, 14G15, 14M25
Keywords: Hirzebruch surface, Algebraic Geometric code, Gröbner basis, Rational scroll

Introduction
Until the 00’s, most Goppa codes were associated to curves. In 2001 S.H. Hansen
[8] estimated parameters of Goppa codes associated to normal projective varieties of dimension at least 2. As Hansen required very few assumptions on the
varieties, the parameters he gave depende
Original label:  cs.NE
Predicted label:  4
Correct label:  0
Text:  [CLS] arxiv : 1803. 05796v1 [ stat. ml ] 15 mar 2018 deep architectures for learning context - dependent ranking functions karlson pfannschmidt pritha gupta eyke hullermeier department of computer science warburger str. 100 paderborn university, germany kiudee @ mail. upb. de department of computer science warburger str. 100 paderborn university, germany prithag @ mail. upb. de department of computer science warburger str. 100 paderborn university, germany eyke @ upb. de abstract object ranking is an important problem in the realm of preference learning. on the basis of training data in the form of a set of rankings of objects, which are typically represented as feature vectors, the goal is to learn a ranking function that predicts a linear order of any new set of objects. current approaches commonly focus on ranking by scoring, i. e., on learning an underlying latent utility function that seeks to capture the inherent utility of each object. these approaches, however, are not able to take possible effects of context - dependence into account, where context - dependence means that the utility or usefulness of an object may also depend on what other objects are available as alternatives. in this paper, we formalize the problem of context - dependent ranking and present two general approaches based on two natural representations of context - dependent ranking functions. both approaches are instantiated by means of appropriate neural network architectures. we demonstrate empirically that our methods outperform traditional approaches on benchmark tasks, for which context - dependence is playing a relevant role. ccs concepts • computing methodologies −→ ranking ; learning to rank ; neural networks ; batch learning ; keywords learning to rank, object ranking, context - dependence, preference learning, neural networks 1 introduction preference learning has received increasing attention in machine learning in recent years [ 15 ]. roughly speaking, the goal in preference learning is to induce preference models from observed data that reveals information about the preferences of an individual or a group of individuals in a direct or indirect way ; these models are then used to predict the preferences in a new situation. in general, a preference learning system is provided with a set of items ( e. g., products ) for which preferences are known, and the task is to learn a function that predicts preferences for a new set of items ( e. g., new products not seen so far ), or for the same [SEP]
Text from DS:  arXiv:1803.05796v1 [stat.ML] 15 Mar 2018

Deep architectures for learning
context-dependent ranking functions
Karlson Pfannschmidt

Pritha Gupta

Eyke Hüllermeier

Department of Computer Science
Warburger Str. 100
Paderborn University, Germany
kiudee@mail.upb.de

Department of Computer Science
Warburger Str. 100
Paderborn University, Germany
prithag@mail.upb.de

Department of Computer Science
Warburger Str. 100
Paderborn University, Germany
eyke@upb.de

ABSTRACT
Object ranking is an important problem in the realm of preference learning. On the basis of training data in the form of a set
of rankings of objects, which are typically represented as feature
vectors, the goal is to learn a ranking function that predicts a linear
order of any new set of objects. Current approaches commonly
focus on ranking by scoring, i.e., on learning an underlying latent
utility function that seeks to capture the inherent utility of each
object. These approaches, however, are not able to take possible effe
Original label:  cs.SY
Predicted label:  2
Correct label:  7
Text:  [CLS] global performance metrics for synchronization of heterogeneously rated power systems : the role of machine models and inertia arxiv : 1710. 07195v2 [ math. oc ] 24 oct 2017 fernando paganini, fellow, ieee, and enrique mallada, member, ieee abstract — a recent trend in control of power systems has sought to quantify the synchronization dynamics in terms of a global performance metric, compute it under very simplified assumptions, and use it to gain insight on the role of system parameters, in particular, inertia. in this paper, we wish to extend this approach to more realistic scenarios, by incorporating the heterogeneity of machine ratings, more complete machine models, and also to more closely map it to classical power engineering notions such as nadir, rate of change of frequency ( rocof ), and inter - area oscillations. we consider the system response to a step change in power excitation, and define the system frequency as a weighted average of generator frequencies ( with weights proportional to each machine ’ s rating ) ; we characterize nadir and rocof by the l∞ norm of the system frequency and its derivative, respectively, and inter - areas oscillations by the l2 norm of the error of the vector of bus frequencies w. r. t. the system frequency. for machine models where the dynamic parameters ( inertia, damping, etc. ) are proportional to rating, we analytically compute these norms and use them to show that the role of inertia is more nuanced than in the conventional wisdom. with the classical swing dynamics, inertia constant plays a secondary role in performance. it is only when the turbine dynamics are introduced that the benefits of inertia become more prominent. i. i ntroduction the synchronization performance of the power grid has been a major concern of system operators since the early days [ 1 ], [ 2 ]. most generators and loads are designed on the assumption that the grid frequency is tightly regulated around a nominal value ( e. g. 60hz in the u. s., 50hz in europe ). when the frequency deviates significantly ( a few hundred mhz ) due to some network fault, several mechanisms, such as machine protections or under frequency load shedding ( ulfs ) [ 3 ], automatically disconnect critical network elements, potentially causing cascading failures and ultimately blackouts [ 4 ] [SEP]
Text from DS:  Global performance metrics for synchronization of heterogeneously
rated power systems: The role of machine models and inertia

arXiv:1710.07195v2 [math.OC] 24 Oct 2017

Fernando Paganini, Fellow, IEEE, and Enrique Mallada, Member, IEEE

Abstract— A recent trend in control of power systems has
sought to quantify the synchronization dynamics in terms of
a global performance metric, compute it under very simplified
assumptions, and use it to gain insight on the role of system
parameters, in particular, inertia. In this paper, we wish to extend this approach to more realistic scenarios, by incorporating
the heterogeneity of machine ratings, more complete machine
models, and also to more closely map it to classical power
engineering notions such as Nadir, Rate of Change of Frequency
(RoCoF), and inter-area oscillations.
We consider the system response to a step change in power
excitation, and define the system frequency as a weighted
average of generator frequencies (with weights proportion
Original label:  cs.SY
Predicted label:  1
Correct label:  2
Text:  [CLS] kernel methods for the approximation of nonlinear systems arxiv : 1108. 2903v3 [ math. oc ] 31 mar 2016 jake bouvrie † ¶ and boumediene hamzi ‡ ¶ abstract. we introduce a data - driven model approximation method for nonlinear control systems, drawing on recent progress in machine learning and statistical dimensionality reduction. the method is based on embedding the nonlinear system in a high ( or infinite ) dimensional reproducing kernel hilbert space ( rkhs ) where linear balanced truncation may be carried out implicitly. this leads to a nonlinear reduction map which can be combined with a representation of the system belonging to a rkhs to give a closed, reduced order dynamical system which captures the essential input - output characteristics of the original model. working in rkhs provides a convenient, general functional - analytical framework for theoretical understanding. empirical simulations illustrating the approach are also provided. 1. introduction. data - based modelling of nonlinear dynamical systems has been addressed by many authors. for example, several methods have been developed in time series analysis ( [ 19 ] for example ) and system identification ( [ 52 ], [ 51 ] for example ). coifman et al. discuss data - based modelling of a stochastic langevin system [ 9 ]. archambeau et al. [ 2 ] proposed methods to approximate sdes from data. smale and zhou use kernel methods to approximate a hyperbolic dynamical system [ 45 ]. in this paper we propose a scheme for the approximation of nonlinear systems using balanced model - order reduction. a key, and to our knowledge, novel point of departure from the literature on nonlinear model reduction is that our approach marries approximation and dimensionality reduction methods known to the machine learning and statistics communities with existing ideas in linear and nonlinear control. in particular, we apply a method similar to kernel pca ( principal component analysis ) as well as function approximation in reproducing kernel hilbert spaces ( rkhses ) to the problem of balanced model reduction. working in rkhses provides a convenient, general functional - analytical framework for theoretical understanding as well as a ready source of existing results and error estimates. the approach presented here is also strongly empirical, in that observability and controllability, and in some cases the dynamics of the nonlinear system are estimated from simulated or measured trajectories. the approach we propose begins by viewing the controllability and observability energies for nonlinear systems as gramians in a [SEP]
Text from DS:  KERNEL METHODS FOR THE
APPROXIMATION OF NONLINEAR SYSTEMS

arXiv:1108.2903v3 [math.OC] 31 Mar 2016

JAKE BOUVRIE† ¶ AND BOUMEDIENE HAMZI‡ ¶
Abstract. We introduce a data-driven model approximation method for nonlinear control
systems, drawing on recent progress in machine learning and statistical dimensionality reduction. The
method is based on embedding the nonlinear system in a high (or infinite) dimensional reproducing
kernel Hilbert space (RKHS) where linear balanced truncation may be carried out implicitly. This
leads to a nonlinear reduction map which can be combined with a representation of the system
belonging to a RKHS to give a closed, reduced order dynamical system which captures the essential
input-output characteristics of the original model. Working in RKHS provides a convenient, general
functional-analytical framework for theoretical understanding. Empirical simulations illustrating the
approach are also provided.

1. Introduction. Data-based modelling of nonlinear dynam
Original label:  cs.SY
Predicted label:  8
Correct label:  9
Text:  [CLS] polling - systems - based autonomous vehicle coordination in traffic intersections with no traffic signals arxiv : 1607. 07896v1 [ ] 26 jul 2016 david miculescu abstract — the rapid development of autonomous vehicles spurred a careful investigation of the potential benefits of allautonomous transportation networks. most studies conclude that autonomous systems can enable drastic improvements in performance. a widely studied concept is all - autonomous, collision - free intersections, where vehicles arriving in a traffic intersection with no traffic light adjust their speeds to cross safely through the intersection as quickly as possible. in this paper, we propose a coordination control algorithm for this problem, assuming stochastic models for the arrival times of the vehicles. the proposed algorithm provides provable guarantees on safety and performance. more precisely, it is shown that no collisions occur surely, and moreover a rigorous upper bound is provided for the expected wait time. the algorithm is also demonstrated in simulations. the proposed algorithms are inspired by polling systems. in fact, the problem studied in this paper leads to a new polling system where customers are subject to differential constraints, which may be interesting in its own right. i. i ntroduction autonomous vehicles hold the potential to revolutionize transportation and logistics. self - driving cars may reduce congestion and emissions, while substantially enhancing safety [ 1 ], [ 2 ]. drones may be used for delivering goods in urban centers or for providing emergency supplies in disaster - struck areas [ 3 ], [ 4 ]. almost all studies on autonomous vehicles, including those mentioned above, envision large fleets of autonomous vehicles that work in coordination to enable efficient transportation and logistics services. in fact, in many cases, well - coordinated fleets are key for economic and societal impact. for instance, self - driving cars create the most value when they are deployed as a fleet of autonomous taxis for mobility on demand [ 2 ], [ 5 ] ; delivery drones are most useful when they can relay packages from one to another [ 4 ]. in almost all such examples, efficient coordination algorithms can enable substantial savings in energy, increase in throughput and capacity, and reduction in delays and emissions. in fact, the overall performance of the system is often highly sensitive to the operator ’ s choice of the underlying coordination algorithms [ 5 ]. thus, designing effective coordination algorithms is vital towards understanding the real potential for impact that autonomous vehicles provide. the application domain of such coordination algorithms is not limited to autonomous cars and delivery drones. there are already a number of existing applications where effective coordination of a fleet of autonomous vehicles is [SEP]
Text from DS:  Polling-systems-based Autonomous Vehicle Coordination
in Traffic Intersections with No Traffic Signals

arXiv:1607.07896v1 [] 26 Jul 2016

David Miculescu

Abstract—The rapid development of autonomous vehicles
spurred a careful investigation of the potential benefits of allautonomous transportation networks. Most studies conclude that
autonomous systems can enable drastic improvements in performance. A widely studied concept is all-autonomous, collision-free
intersections, where vehicles arriving in a traffic intersection with
no traffic light adjust their speeds to cross safely through the
intersection as quickly as possible. In this paper, we propose
a coordination control algorithm for this problem, assuming
stochastic models for the arrival times of the vehicles. The
proposed algorithm provides provable guarantees on safety and
performance. More precisely, it is shown that no collisions occur
surely, and moreover a rigorous upper bound is provided for
the expected wait time. The al
Original label:  cs.CV
Predicted label:  7
Correct label:  10
Text:  [CLS] fast and robust misalignment correction of fourier ptychographic microscopy arxiv : 1803. 00395v1 [ ] 20 feb 2018 ao zhou1, 2, wei wang3, ni chen1, 4, *, edmund y. lam5, byoungho lee4, and guohai situ1 1 shanghai institute of optics and fine mechanics, chinese academy of sciences, shanghai 201800, china 2 university of chinese academy of sciences, beijing 100049, china. 3 mechanobiology institute, national university of singapore, 5a engineering drive 1, 117411, singapore. 4 department of electrical and computer engineering, seoul national university, seoul 08826, korea. 5 department of electrical and electronic engineering, the university of hong kong, hong kong. * corresponding author : nichen @ siom. ac. cn march 2, 2018 abstract fourier ptychographic microscopy ( fpm ) is a newly developed computational imaging technique that can provide gigapixel images with both high resolution ( hr ) and wide field of view ( fov ). however, the position misalignment of the led array induces a degradation of the reconstructed image, especially in the regions away from the optical axis. in this paper, we propose a robust and fast method to correct the led misalignment of the fpm, termed as misalignment correction for the fpm ( mcfpm ). although different regions in the fov have different sensitivity to the led misalignment, the experimental results show that the mcfpm is robust with respect to the elimination of each region. compared with the state - of - the - art methods, the mcfpm is much faster. 1 introduction as we all know, almost all of the conventional microscope has a trade - off between its resolution and fov. to solve this problem, a new computational imaging technique called fpm has been proposed [ 19, 17 ]. in a typical fpm system, a programmable led array is used instead of the conventional microscope ’ s light source for providing angularly variant illumination. after capturing a sequence of low resolution ( lr ) images under different illumination angles, an iterative phase retrieval process [ 5, 8, 2 ] is used to stitch together those lr images in the fourier space, and then an hr and high space - bandwidth product ( sbp ) 1 complex field of the sample can be recovered. compared with the conventional microscopy, the fpm can achieve hr, wide fov and [SEP]
Text from DS:  Fast and robust misalignment correction of
Fourier ptychographic microscopy

arXiv:1803.00395v1 [] 20 Feb 2018

Ao Zhou1,2 , Wei Wang3 , Ni Chen1,4,* , Edmund Y. Lam5 , Byoungho
Lee4 , and Guohai Situ1
1

Shanghai Institute of Optics and Fine Mechanics, Chinese
Academy of Sciences, Shanghai 201800, China
2
University of Chinese Academy of Sciences, Beijing 100049, China.
3
Mechanobiology Institute, National University of Singapore, 5A
Engineering Drive 1, 117411, Singapore.
4
Department of Electrical and Computer Engineering, Seoul
National University, Seoul 08826, Korea.
5
Department of Electrical and Electronic Engineering, The
University of Hong Kong, Hong Kong.
*
Corresponding author: nichen@siom.ac.cn
March 2, 2018
Abstract
Fourier ptychographic microscopy (FPM) is a newly developed computational imaging technique that can provide gigapixel images with both
high resolution (HR) and wide field of view (FOV). However, the position
misalignment of the LED array induces a degradation 
Original label:  cs.PL
Predicted label:  9
Correct label:  2
Text:  [CLS] journal, vol., no., month year 1 models and information rates for wiener phase noise channels arxiv : 1503. 03130v2 [ ] 11 aug 2017 hassan ghozlan, member, ieee, and gerhard kramer, fellow, ieee abstract — a waveform channel is considered where the transmitted signal is corrupted by wiener phase noise and additive white gaussian noise. a discrete - time channel model that takes into account the effect of filtering on the phase noise is developed. the model is based on a multi - sample receiver, i. e., an integrateand - dump filter whose output is sampled at a rate higher than the signaling rate. it is shown that, at high signal - to - noise ratio ( snr ), the multi - sample receiver achieves a rate that grows logarithmically with the snr if the number of samples per symbol ( oversampling factor ) grows with the cubic root of the snr. moreover, the pre - log factor is at least 1 / 2 and can be achieved by amplitude modulation. for an approximate discretetime model of the multi - sample receiver, the capacity pre - log at high snr is shown to be at least 3 / 4 if the number of samples per symbol grows with the square root of the snr. the analysis shows that phase modulation achieves a pre - log of at least 1 / 4 while amplitude modulation still achieves a pre - log of 1 / 2. this is strictly greater than the capacity pre - log of the ( approximate ) discrete - time wiener phase noise channel with only one sample per symbol, which is 1 / 2. numerical simulations are used to compute lower bounds on the information rates achieved by the multi - sample receiver. the simulations show that oversampling is beneficial for both strong and weak phase noise at high snr. in fact, the information rates are sometimes substantially larger than when using commonly - used approximate discretetime models. index terms — phase noise, wiener process, waveform channel, capacity, oversampling. i. i ntroduction phase noise arises due to the instability of oscillators [ 1 ] in communication systems such as satellite communication [ 2 ], microwave links [ 3 ] or optical fiber communication [ 4 ]. the statistical characterization of the phase noise depends on the application. in systems with phase - locked loops ( pll ), the residual phase noise follows a tikhonov distribution [ 5 ]. in digital video broadcasting dvb - s2, [SEP]
Text from DS:  JOURNAL, VOL. , NO. , MONTH YEAR

1

Models and Information Rates for
Wiener Phase Noise Channels

arXiv:1503.03130v2 [] 11 Aug 2017

Hassan Ghozlan, Member, IEEE, and Gerhard Kramer, Fellow, IEEE

Abstract—A waveform channel is considered where the transmitted signal is corrupted by Wiener phase noise and additive
white Gaussian noise. A discrete-time channel model that takes
into account the effect of filtering on the phase noise is developed.
The model is based on a multi-sample receiver, i.e., an integrateand-dump filter whose output is sampled at a rate higher than
the signaling rate. It is shown that, at high Signal-to-Noise Ratio
(SNR), the multi-sample receiver achieves a rate that grows
logarithmically with the SNR if the number of samples per
symbol (oversampling factor) grows with the cubic root of the
SNR. Moreover, the pre-log factor is at least 1/2 and can be
achieved by amplitude modulation. For an approximate discretetime model of the multi-sample receiver, the capacity
